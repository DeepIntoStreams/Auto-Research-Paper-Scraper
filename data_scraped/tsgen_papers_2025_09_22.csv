Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
FocalCodec-Stream: Streaming Low-Bitrate Speech Coding via Causal Distillation,19/09/2025,"Luca Della Libera, Cem Subakan, Mirco Ravanelli","Neural audio codecs are a fundamental component of modern generative audio
pipelines. Although recent codecs achieve strong low-bitrate reconstruction and
provide powerful representations for downstream tasks, most are non-streamable,
limiting their use in real-time applications. We present FocalCodec-Stream, a
hybrid codec based on focal modulation that compresses speech into a single
binary codebook at 0.55 - 0.80 kbps with a theoretical latency of 80 ms. Our
approach combines multi-stage causal distillation of WavLM with targeted
architectural improvements, including a lightweight refiner module that
enhances quality under latency constraints. Experiments show that
FocalCodec-Stream outperforms existing streamable codecs at comparable
bitrates, while preserving both semantic and acoustic information. The result
is a favorable trade-off between reconstruction quality, downstream task
performance, latency, and efficiency. Code and checkpoints will be released at
https://github.com/lucadellalib/focalcodec.",http://arxiv.org/pdf/2509.16195v1,,False
Quantum Generative Adversarial Autoencoders: Learning latent representations for quantum data generation,19/09/2025,"Naipunnya Raj, Rajiv Sangle, Avinash Singh, Krishna Kumar Sabapathy","In this work, we introduce the Quantum Generative Adversarial Autoencoder
(QGAA), a quantum model for generation of quantum data. The QGAA consists of
two components: (a) Quantum Autoencoder (QAE) to compress quantum states, and
(b) Quantum Generative Adversarial Network (QGAN) to learn the latent space of
the trained QAE. This approach imparts the QAE with generative capabilities.
The utility of QGAA is demonstrated in two representative scenarios: (a)
generation of pure entangled states, and (b) generation of parameterized
molecular ground states for H$_2$ and LiH. The average errors in the energies
estimated by the trained QGAA are 0.02 Ha for H$_2$ and 0.06 Ha for LiH in
simulations upto 6 qubits. These results illustrate the potential of QGAA for
quantum state generation, quantum chemistry, and near-term quantum machine
learning applications.",http://arxiv.org/pdf/2509.16186v1,,False
Randomized Smoothing Meets Vision-Language Models,19/09/2025,"Emmanouil Seferis, Changshun Wu, Stefanos Kollias, Saddek Bensalem, Chih-Hong Cheng","Randomized smoothing (RS) is one of the prominent techniques to ensure the
correctness of machine learning models, where point-wise robustness
certificates can be derived analytically. While RS is well understood for
classification, its application to generative models is unclear, since their
outputs are sequences rather than labels. We resolve this by connecting
generative outputs to an oracle classification task and showing that RS can
still be enabled: the final response can be classified as a discrete action
(e.g., service-robot commands in VLAs), as harmful vs. harmless (content
moderation or toxicity detection in VLMs), or even applying oracles to cluster
answers into semantically equivalent ones. Provided that the error rate for the
oracle classifier comparison is bounded, we develop the theory that associates
the number of samples with the corresponding robustness radius. We further
derive improved scaling laws analytically relating the certified radius and
accuracy to the number of samples, showing that the earlier result of 2 to 3
orders of magnitude fewer samples sufficing with minimal loss remains valid
even under weaker assumptions. Together, these advances make robustness
certification both well-defined and computationally feasible for
state-of-the-art VLMs, as validated against recent jailbreak-style adversarial
attacks.",http://arxiv.org/pdf/2509.16088v1,,False
Compose by Focus: Scene Graph-based Atomic Skills,19/09/2025,"Han Qi, Changhe Chen, Heng Yang","A key requirement for generalist robots is compositional generalization - the
ability to combine atomic skills to solve complex, long-horizon tasks. While
prior work has primarily focused on synthesizing a planner that sequences
pre-learned skills, robust execution of the individual skills themselves
remains challenging, as visuomotor policies often fail under distribution
shifts induced by scene composition. To address this, we introduce a scene
graph-based representation that focuses on task-relevant objects and relations,
thereby mitigating sensitivity to irrelevant variation. Building on this idea,
we develop a scene-graph skill learning framework that integrates graph neural
networks with diffusion-based imitation learning, and further combine ""focused""
scene-graph skills with a vision-language model (VLM) based task planner.
Experiments in both simulation and real-world manipulation tasks demonstrate
substantially higher success rates than state-of-the-art baselines,
highlighting improved robustness and compositional generalization in
long-horizon tasks.",http://arxiv.org/pdf/2509.16053v1,,False
ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching,19/09/2025,"Graham Clyne, Guillaume Couairon, Guillaume Gastineau, Claire Monteleoni, Anastase Charantonis","Climate projections have uncertainties related to components of the climate
system and their interactions. A typical approach to quantifying these
uncertainties is to use climate models to create ensembles of repeated
simulations under different initial conditions. Due to the complexity of these
simulations, generating such ensembles of projections is computationally
expensive. In this work, we present ArchesClimate, a deep learning-based
climate model emulator that aims to reduce this cost. ArchesClimate is trained
on decadal hindcasts of the IPSL-CM6A-LR climate model at a spatial resolution
of approximately 2.5x1.25 degrees. We train a flow matching model following
ArchesWeatherGen, which we adapt to predict near-term climate. Once trained,
the model generates states at a one-month lead time and can be used to
auto-regressively emulate climate model simulations of any length. We show that
for up to 10 years, these generations are stable and physically consistent. We
also show that for several important climate variables, ArchesClimate generates
simulations that are interchangeable with the IPSL model. This work suggests
that climate model emulators could significantly reduce the cost of climate
model simulations.",http://arxiv.org/pdf/2509.15942v1,,False
UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation,19/09/2025,"Mingdong Wu, Long Yang, Jin Liu, Weiyao Huang, Lehong Wu, Zelin Chen, Daolin Ma, Hao Dong","Accurate estimation of the in-hand pose of an object based on its CAD model
is crucial in both industrial applications and everyday tasks, ranging from
positioning workpieces and assembling components to seamlessly inserting
devices like USB connectors. While existing methods often rely on regression,
feature matching, or registration techniques, achieving high precision and
generalizability to unseen CAD models remains a significant challenge. In this
paper, we propose a novel three-stage framework for in-hand pose estimation.
The first stage involves sampling and pre-ranking pose candidates, followed by
iterative refinement of these candidates in the second stage. In the final
stage, post-ranking is applied to identify the most likely pose candidates.
These stages are governed by a unified energy-based diffusion model, which is
trained solely on simulated data. This energy model simultaneously generates
gradients to refine pose estimates and produces an energy scalar that
quantifies the quality of the pose estimates. Additionally, borrowing the idea
from the computer vision domain, we incorporate a render-compare architecture
within the energy-based score network to significantly enhance sim-to-real
performance, as demonstrated by our ablation studies. We conduct comprehensive
experiments to show that our method outperforms conventional baselines based on
regression, matching, and registration techniques, while also exhibiting strong
intra-category generalization to previously unseen CAD models. Moreover, our
approach integrates tactile object pose estimation, pose tracking, and
uncertainty estimation into a unified framework, enabling robust performance
across a variety of real-world conditions.",http://arxiv.org/pdf/2509.15934v1,,False
Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search,19/09/2025,"Zhiyu Mou, Yiqin Lv, Miao Xu, Cheems Wang, Yixiu Mao, Qichen Ye, Chao Li, Rongquan Bai, Chuan Yu, Jian Xu, Bo Zheng","Auto-bidding is an essential tool for advertisers to enhance their
advertising performance. Recent progress has shown that AI-Generated Bidding
(AIGB), which formulates the auto-bidding as a trajectory generation task and
trains a conditional diffusion-based planner on offline data, achieves superior
and stable performance compared to typical offline reinforcement learning
(RL)-based auto-bidding methods. However, existing AIGB methods still encounter
a performance bottleneck due to their neglect of fine-grained generation
quality evaluation and inability to explore beyond static datasets. To address
this, we propose AIGB-Pearl (\emph{Planning with EvAluator via RL}), a novel
method that integrates generative planning and policy optimization. The key to
AIGB-Pearl is to construct a non-bootstrapped \emph{trajectory evaluator} to
assign rewards and guide policy search, enabling the planner to optimize its
generation quality iteratively through interaction. Furthermore, to enhance
trajectory evaluator accuracy in offline settings, we incorporate three key
techniques: (i) a Large Language Model (LLM)-based architecture for better
representational capacity, (ii) hybrid point-wise and pair-wise losses for
better score learning, and (iii) adaptive integration of expert feedback for
better generalization ability. Extensive experiments on both simulated and
real-world advertising systems demonstrate the state-of-the-art performance of
our approach.",http://arxiv.org/pdf/2509.15927v1,,False
Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds,19/09/2025,"Remo Sasso, Michelangelo Conserva, Dominik Jeurissen, Paulo Rauber","While reinforcement learning from scratch has shown impressive results in
solving sequential decision-making tasks with efficient simulators, real-world
applications with expensive interactions require more sample-efficient agents.
Foundation models (FMs) are natural candidates to improve sample efficiency as
they possess broad knowledge and reasoning capabilities, but it is yet unclear
how to effectively integrate them into the reinforcement learning framework. In
this paper, we anticipate and, most importantly, evaluate two promising
strategies. First, we consider the use of foundation world models (FWMs) that
exploit the prior knowledge of FMs to enable training and evaluating agents
with simulated interactions. Second, we consider the use of foundation agents
(FAs) that exploit the reasoning capabilities of FMs for decision-making. We
evaluate both approaches empirically in a family of grid-world environments
that are suitable for the current generation of large language models (LLMs).
Our results suggest that improvements in LLMs already translate into better
FWMs and FAs; that FAs based on current LLMs can already provide excellent
policies for sufficiently simple environments; and that the coupling of FWMs
and reinforcement learning agents is highly promising for more complex settings
with partial observability and stochastic elements.",http://arxiv.org/pdf/2509.15915v1,,False
SolarCrossFormer: Improving day-ahead Solar Irradiance Forecasting by Integrating Satellite Imagery and Ground Sensors,19/09/2025,"Baptiste Schubnel, Jelena SimeunoviÄ‡, Corentin Tissier, Pierre-Jean Alet, Rafael E. Carrillo","Accurate day-ahead forecasts of solar irradiance are required for the
large-scale integration of solar photovoltaic (PV) systems into the power grid.
However, current forecasting solutions lack the temporal and spatial resolution
required by system operators. In this paper, we introduce SolarCrossFormer, a
novel deep learning model for day-ahead irradiance forecasting, that combines
satellite images and time series from a ground-based network of meteorological
stations. SolarCrossFormer uses novel graph neural networks to exploit the
inter- and intra-modal correlations of the input data and improve the accuracy
and resolution of the forecasts. It generates probabilistic forecasts for any
location in Switzerland with a 15-minute resolution for horizons up to 24 hours
ahead. One of the key advantages of SolarCrossFormer its robustness in real
life operations. It can incorporate new time-series data without retraining the
model and, additionally, it can produce forecasts for locations without input
data by using only their coordinates. Experimental results over a dataset of
one year and 127 locations across Switzerland show that SolarCrossFormer yield
a normalized mean absolute error of 6.1 % over the forecasting horizon. The
results are competitive with those achieved by a commercial numerical weather
prediction service.",http://arxiv.org/pdf/2509.15827v1,,False
ThermalGuardian: Temperature-Aware Testing of Automotive Deep Learning Frameworks,19/09/2025,"Yinglong Zou, Juan Zhai, Chunrong Fang, Zhenyu Chen","Deep learning models play a vital role in autonomous driving systems,
supporting critical functions such as environmental perception. To accelerate
model inference, these deep learning models' deployment relies on automotive
deep learning frameworks, for example, PaddleInference in Apollo and TensorRT
in AutoWare. However, unlike deploying deep learning models on the cloud,
vehicular environments experience extreme ambient temperatures varying from
-40{\deg}C to 50{\deg}C, significantly impacting GPU temperature. Additionally,
heats generated when computing further lead to the GPU temperature increase.
These temperature fluctuations lead to dynamic GPU frequency adjustments
through mechanisms such as DVFS. However, automotive deep learning frameworks
are designed without considering the impact of temperature-induced frequency
variations. When deployed on temperature-varying GPUs, these frameworks suffer
critical quality issues: compute-intensive operators face delays or errors,
high/mixed-precision operators suffer from precision errors, and time-series
operators suffer from synchronization issues. The above quality issues cannot
be detected by existing deep learning framework testing methods because they
ignore temperature's effect on the deep learning framework quality. To bridge
this gap, we propose ThermalGuardian, the first automotive deep learning
framework testing method under temperature-varying environments. Specifically,
ThermalGuardian generates test input models using model mutation rules
targeting temperature-sensitive operators, simulates GPU temperature
fluctuations based on Newton's law of cooling, and controls GPU frequency based
on real-time GPU temperature.",http://arxiv.org/pdf/2509.15815v1,,False
Monte Carlo Tree Diffusion with Multiple Experts for Protein Design,19/09/2025,"Xuefeng Liu, Mingxuan Cao, Songhao Jiang, Xiao Luo, Xiaotian Duan, Mengdi Wang, Tobin R. Sosnick, Jinbo Xu, Rick Stevens","The goal of protein design is to generate amino acid sequences that fold into
functional structures with desired properties. Prior methods combining
autoregressive language models with Monte Carlo Tree Search (MCTS) struggle
with long-range dependencies and suffer from an impractically large search
space. We propose MCTD-ME, Monte Carlo Tree Diffusion with Multiple Experts,
which integrates masked diffusion models with tree search to enable multi-token
planning and efficient exploration. Unlike autoregressive planners, MCTD-ME
uses biophysical-fidelity-enhanced diffusion denoising as the rollout engine,
jointly revising multiple positions and scaling to large sequence spaces. It
further leverages experts of varying capacities to enrich exploration, guided
by a pLDDT-based masking schedule that targets low-confidence regions while
preserving reliable residues. We propose a novel multi-expert selection rule
(PH-UCT-ME) extends predictive-entropy UCT to expert ensembles. On the inverse
folding task (CAMEO and PDB benchmarks), MCTD-ME outperforms single-expert and
unguided baselines in both sequence recovery (AAR) and structural similarity
(scTM), with gains increasing for longer proteins and benefiting from
multi-expert guidance. More generally, the framework is model-agnostic and
applicable beyond inverse folding, including de novo protein engineering and
multi-objective molecular generation.",http://arxiv.org/pdf/2509.15796v1,,False
Impact of Single Rotations and Entanglement Topologies in Quantum Neural Networks,19/09/2025,"Marco Mordacci, Michele Amoretti","In this work, an analysis of the performance of different Variational Quantum
Circuits is presented, investigating how it changes with respect to
entanglement topology, adopted gates, and Quantum Machine Learning tasks to be
performed. The objective of the analysis is to identify the optimal way to
construct circuits for Quantum Neural Networks. In the presented experiments,
two types of circuits are used: one with alternating layers of rotations and
entanglement, and the other, similar to the first one, but with an additional
final layer of rotations. As rotation layers, all combinations of one and two
rotation sequences are considered. Four different entanglement topologies are
compared: linear, circular, pairwise, and full. Different tasks are considered,
namely the generation of probability distributions and images, and image
classification. Achieved results are correlated with the expressibility and
entanglement capability of the different circuits to understand how these
features affect performance.",http://arxiv.org/pdf/2509.15722v1,,False
Inference Offloading for Cost-Sensitive Binary Classification at the Edge,19/09/2025,"Vishnu Narayanan Moothedath, Umang Agarwal, Umeshraja N, James Richard Gross, Jaya Prakash Champati, Sharayu Moharir","We focus on a binary classification problem in an edge intelligence system
where false negatives are more costly than false positives. The system has a
compact, locally deployed model, which is supplemented by a larger, remote
model, which is accessible via the network by incurring an offloading cost. For
each sample, our system first uses the locally deployed model for inference.
Based on the output of the local model, the sample may be offloaded to the
remote model. This work aims to understand the fundamental trade-off between
classification accuracy and these offloading costs within such a hierarchical
inference (HI) system. To optimize this system, we propose an online learning
framework that continuously adapts a pair of thresholds on the local model's
confidence scores. These thresholds determine the prediction of the local model
and whether a sample is classified locally or offloaded to the remote model. We
present a closed-form solution for the setting where the local model is
calibrated. For the more general case of uncalibrated models, we introduce
H2T2, an online two-threshold hierarchical inference policy, and prove it
achieves sublinear regret. H2T2 is model-agnostic, requires no training, and
learns in the inference phase using limited feedback. Simulations on real-world
datasets show that H2T2 consistently outperforms naive and single-threshold HI
policies, sometimes even surpassing offline optima. The policy also
demonstrates robustness to distribution shifts and adapts effectively to
mismatched classifiers.",http://arxiv.org/pdf/2509.15674v1,,False
Efficient Extractive Text Summarization for Online News Articles Using Machine Learning,19/09/2025,"Sajib Biswas, Milon Biswas, Arunima Mandal, Fatema Tabassum Liza, Joy Sarker","In the age of information overload, content management for online news
articles relies on efficient summarization to enhance accessibility and user
engagement. This article addresses the challenge of extractive text
summarization by employing advanced machine learning techniques to generate
concise and coherent summaries while preserving the original meaning. Using the
Cornell Newsroom dataset, comprising 1.3 million article-summary pairs, we
developed a pipeline leveraging BERT embeddings to transform textual data into
numerical representations. By framing the task as a binary classification
problem, we explored various models, including logistic regression,
feed-forward neural networks, and long short-term memory (LSTM) networks. Our
findings demonstrate that LSTM networks, with their ability to capture
sequential dependencies, outperform baseline methods like Lede-3 and simpler
models in F1 score and ROUGE-1 metrics. This study underscores the potential of
automated summarization in improving content management systems for online news
platforms, enabling more efficient content organization and enhanced user
experiences.",http://arxiv.org/pdf/2509.15614v1,,False
Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios,19/09/2025,"Yuting Zeng, Zhiwen Zheng, You Zhou, JiaLing Xiao, Yongbin Yu, Manping Fan, Bo Gong, Liyong Ren","This paper proposes a momentum-constrained hybrid heuristic trajectory
optimization framework (MHHTOF) tailored for assistive navigation in visually
impaired scenarios, integrating trajectory sampling generation, optimization
and evaluation with residual-enhanced deep reinforcement learning (DRL). In the
first stage, heuristic trajectory sampling cluster (HTSC) is generated in the
Frenet coordinate system using third-order interpolation with fifth-order
polynomials and momentum-constrained trajectory optimization (MTO) constraints
to ensure smoothness and feasibility. After first stage cost evaluation, the
second stage leverages a residual-enhanced actor-critic network with LSTM-based
temporal feature modeling to adaptively refine trajectory selection in the
Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with
weight transfer aligns semantic priorities across stages, supporting
human-centered optimization. Experimental results demonstrate that the proposed
LSTM-ResB-PPO achieves significantly faster convergence, attaining stable
policy performance in approximately half the training iterations required by
the PPO baseline, while simultaneously enhancing both reward outcomes and
training stability. Compared to baseline method, the selected model reduces
average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle
risks by over 77%. These findings validate the framework's effectiveness in
enhancing robustness, safety, and real-time feasibility in complex assistive
planning tasks.",http://arxiv.org/pdf/2509.15582v1,,False
Geometric Integration for Neural Control Variates,19/09/2025,"Daniel Meister, Takahiro Harada","Control variates are a variance-reduction technique for Monte Carlo
integration. The principle involves approximating the integrand by a function
that can be analytically integrated, and integrating using the Monte Carlo
method only the residual difference between the integrand and the
approximation, to obtain an unbiased estimate. Neural networks are universal
approximators that could potentially be used as a control variate. However, the
challenge lies in the analytic integration, which is not possible in general.
In this manuscript, we study one of the simplest neural network models, the
multilayered perceptron (MLP) with continuous piecewise linear activation
functions, and its possible analytic integration. We propose an integration
method based on integration domain subdivision, employing techniques from
computational geometry to solve this problem in 2D. We demonstrate that an MLP
can be used as a control variate in combination with our integration method,
showing applications in the light transport simulation.",http://arxiv.org/pdf/2509.15538v1,,False
Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers,19/09/2025,"Zahra Aref, Narayan B. Mandayam","Transformers have emerged as a compelling architecture for sequential
decision-making by modeling trajectories via self-attention. In reinforcement
learning (RL), they enable return-conditioned control without relying on value
function approximation. Decision Transformers (DTs) exploit this by casting RL
as supervised sequence modeling, but they are restricted to offline data and
lack exploration. Online Decision Transformers (ODTs) address this limitation
through entropy-regularized training on on-policy rollouts, offering a stable
alternative to traditional RL methods like Soft Actor-Critic, which depend on
bootstrapped targets and reward shaping. Despite these advantages, ODTs use
standard attention, which lacks explicit memory of action-specific outcomes.
This leads to inefficiencies in learning long-term action effectiveness.
Inspired by cognitive models such as Experience-Weighted Attraction (EWA), we
propose Experience-Weighted Attraction with Vector Quantization for Online
Decision Transformers (EWA-VQ-ODT), a lightweight module that maintains
per-action mental accounts summarizing recent successes and failures.
Continuous actions are routed via direct grid lookup to a compact
vector-quantized codebook, where each code stores a scalar attraction updated
online through decay and reward-based reinforcement. These attractions modulate
attention by biasing the columns associated with action tokens, requiring no
change to the backbone or training objective. On standard continuous-control
benchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT,
particularly in early training. The module is computationally efficient,
interpretable via per-code traces, and supported by theoretical guarantees that
bound the attraction dynamics and its impact on attention drift.",http://arxiv.org/pdf/2509.15498v1,,False
