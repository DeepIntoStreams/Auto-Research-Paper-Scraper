Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Bayesian Experimental Design via Contrastive Diffusions,15/10/2024,"Jacopo Iollo, Christophe Heinkel√©, Pierre Alliez, Florence Forbes","Bayesian Optimal Experimental Design (BOED) is a powerful tool to reduce the
cost of running a sequence of experiments. When based on the Expected
Information Gain (EIG), design optimization corresponds to the maximization of
some intractable expected {\it contrast} between prior and posterior
distributions. Scaling this maximization to high dimensional and complex
settings has been an issue due to BOED inherent computational complexity. In
this work, we introduce an {\it expected posterior} distribution with
cost-effective sampling properties and provide a tractable access to the EIG
contrast maximization via a new EIG gradient expression. Diffusion-based
samplers are used to compute the dynamics of the expected posterior and ideas
from bi-level optimization are leveraged to derive an efficient joint
sampling-optimization loop, without resorting to lower bound approximations of
the EIG. The resulting efficiency gain allows to extend BOED to the well-tested
generative capabilities of diffusion models. By incorporating generative models
into the BOED framework, we expand its scope and its use in scenarios that were
previously impractical. Numerical experiments and comparison with
state-of-the-art methods show the potential of the approach.",http://arxiv.org/pdf/2410.11826v1,,False
Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies,15/10/2024,"Zixuan Chen, Xialin He, Yen-Jen Wang, Qiayuan Liao, Yanjie Ze, Zhongyu Li, S. Shankar Sastry, Jiajun Wu, Koushil Sreenath, Saurabh Gupta, Xue Bin Peng","Reinforcement learning combined with sim-to-real transfer offers a general
framework for developing locomotion controllers for legged robots. To
facilitate successful deployment in the real world, smoothing techniques, such
as low-pass filters and smoothness rewards, are often employed to develop
policies with smooth behaviors. However, because these techniques are
non-differentiable and usually require tedious tuning of a large set of
hyperparameters, they tend to require extensive manual tuning for each robotic
platform. To address this challenge and establish a general technique for
enforcing smooth behaviors, we propose a simple and effective method that
imposes a Lipschitz constraint on a learned policy, which we refer to as
Lipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint can
be implemented in the form of a gradient penalty, which provides a
differentiable objective that can be easily incorporated with automatic
differentiation frameworks. We demonstrate that LCP effectively replaces the
need for smoothing rewards or low-pass filters and can be easily integrated
into training frameworks for many distinct humanoid robots. We extensively
evaluate LCP in both simulation and real-world humanoid robots, producing
smooth and robust locomotion controllers. All simulation and deployment code,
along with complete checkpoints, is available on our project page:
https://lipschitz-constrained-policy.github.io.",http://arxiv.org/pdf/2410.11825v1,,False
FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting,15/10/2024,"Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Qingsong Wen, Christian S. Jensen, Bin Yang","Time Series Forecasting (TSF) is key functionality in numerous fields,
including in finance, weather services, and energy management. While TSF
methods are emerging these days, many of them require domain-specific data
collection and model training and struggle with poor generalization performance
on new domains. Foundation models aim to overcome this limitation. Pre-trained
on large-scale language or time series data, they exhibit promising inferencing
capabilities in new or unseen data. This has spurred a surge in new TSF
foundation models. We propose a new benchmark, FoundTS, to enable thorough and
fair evaluation and comparison of such models. FoundTS covers a variety of TSF
foundation models, including those based on large language models and those
pretrained on time series. Next, FoundTS supports different forecasting
strategies, including zero-shot, few-shot, and full-shot, thereby facilitating
more thorough evaluations. Finally, FoundTS offers a pipeline that standardizes
evaluation processes such as dataset splitting, loading, normalization, and
few-shot sampling, thereby facilitating fair evaluations. Building on this, we
report on an extensive evaluation of TSF foundation models on a broad range of
datasets from diverse domains and with different statistical characteristics.
Specifically, we identify pros and cons and inherent limitations of existing
foundation models, and we identify directions for future model design. We make
our code and datasets available at
https://anonymous.4open.science/r/FoundTS-C2B0.",http://arxiv.org/pdf/2410.11802v1,,False
Time-Series Foundation Model for Value-at-Risk,15/10/2024,"Anubha Goel, Puneet Pasricha, Juho Kanniainen","This study is the first to explore the application of a time-series
foundation model for VaR estimation. Foundation models, pre-trained on vast and
varied datasets, can be used in a zero-shot setting with relatively minimal
data or further improved through finetuning. We compare the performance of
Google's model, called TimesFM, against conventional parametric and
non-parametric models, including GARCH, Generalized Autoregressive Score (GAS),
and empirical quantile estimates, using daily returns from the S\&P 100 index
and its constituents over 19 years. Our backtesting results indicate that, in
terms of the actual-over-expected ratio, the fine-tuned TimesFM model
consistently outperforms traditional methods. Regarding the quantile score loss
function, it achieves performance comparable to the best econometric approach,
the GAS model. Overall, the foundation model is either the best or among the
top performers in forecasting VaR across the 0.01, 0.025, 0.05, and 0.1 VaR
levels. We also found that fine-tuning significantly improves the results, and
the model should not be used in zero-shot settings. Overall, foundation models
can provide completely alternative approaches to traditional econometric
methods, yet there are challenges to be tackled.",http://arxiv.org/pdf/2410.11773v1,,False
Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis,15/10/2024,"Isaac R. Galatzer-Levy, Jed McGiffin, David Munday, Xin Liu, Danny Karmon, Ilia Labzovsky, Rivka Moroshko, Amir Zait, Daniel McDuff","Generative AI's rapid advancement sparks interest in its cognitive abilities,
especially given its capacity for tasks like language understanding and code
generation. This study explores how several recent GenAI models perform on the
Clock Drawing Test (CDT), a neuropsychological assessment of visuospatial
planning and organization. While models create clock-like drawings, they
struggle with accurate time representation, showing deficits similar to
mild-severe cognitive impairment (Wechsler, 2009). Errors include numerical
sequencing issues, incorrect clock times, and irrelevant additions, despite
accurate rendering of clock features. Only GPT 4 Turbo and Gemini Pro 1.5
produced the correct time, scoring like healthy individuals (4/4). A follow-up
clock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawing
deficits stem from difficulty with numerical concepts. These findings may
reflect weaknesses in visual-spatial understanding, working memory, or
calculation, highlighting strengths in learned knowledge but weaknesses in
reasoning. Comparing human and machine performance is crucial for understanding
AI's cognitive capabilities and guiding development toward human-like cognitive
functions.",http://arxiv.org/pdf/2410.11756v1,,False
Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers,15/10/2024,"Davide Celestini, Amirhossein Afsharrad, Daniele Gammelli, Tommaso Guffanti, Gioele Zardini, Sanjay Lall, Elisa Capello, Simone D'Amico, Marco Pavone","Effective trajectory generation is essential for reliable on-board spacecraft
autonomy. Among other approaches, learning-based warm-starting represents an
appealing paradigm for solving the trajectory generation problem, effectively
combining the benefits of optimization- and data-driven methods. Current
approaches for learning-based trajectory generation often focus on fixed,
single-scenario environments, where key scene characteristics, such as obstacle
positions or final-time requirements, remain constant across problem instances.
However, practical trajectory generation requires the scenario to be frequently
reconfigured, making the single-scenario approach a potentially impractical
solution. To address this challenge, we present a novel trajectory generation
framework that generalizes across diverse problem configurations, by leveraging
high-capacity transformer neural networks capable of learning from multimodal
data sources. Specifically, our approach integrates transformer-based neural
network models into the trajectory optimization process, encoding both
scene-level information (e.g., obstacle locations, initial and goal states) and
trajectory-level constraints (e.g., time bounds, fuel consumption targets) via
multimodal representations. The transformer network then generates near-optimal
initial guesses for non-convex optimization problems, significantly enhancing
convergence speed and performance. The framework is validated through extensive
simulations and real-world experiments on a free-flyer platform, achieving up
to 30% cost improvement and 80% reduction in infeasible cases with respect to
traditional approaches, and demonstrating robust generalization across diverse
scenario variations.",http://arxiv.org/pdf/2410.11723v1,,False
Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations,15/10/2024,"M. Germ√°n-Morales, A. J. Rivera-Rivas, M. J. del Jesus D√≠az, C. J. Carmona","High computational power and the availability of large datasets have
supported the development of Foundational Models. They are a new emerging
technique widely used in Generative Artificial Intelligence, characterized by
their scalability and their use in Transfer Learning. The enormous and
heterogeneous amounts of data used in their initial training phase, known as
pre-training, give them a higher generalization capacity than any other
specific model, constituting a solid base that can be adapted or adjusted to a
wide range of tasks, increasing their applicability. This study proposes LLIAM,
the Llama Lora-Integrated Autorregresive Model. Low-Rank Adaptations are used
to enhance the knowledge of the model with diverse time series datasets, known
as the fine-tuning phase. To illustrate the capabilities of our proposal, two
sets of experiments have been carried out that obtained favorable and promising
results with lower training times than other Deep Learning approaches. With
this work, we also encourage the use of available resources (such as these
pre-trained models) to avoid unnecessary and costly training, narrowing the gap
between the goals of traditional Artificial Intelligence and those specified by
the definition of Green Artificial Intelligence.",http://arxiv.org/pdf/2410.11539v1,,False
Multi-round jailbreak attack on large language models,15/10/2024,"Yihua Zhou, Xiaochuan Shi","Ensuring the safety and alignment of large language models (LLMs) with human
values is crucial for generating responses that are beneficial to humanity.
While LLMs have the capability to identify and avoid harmful queries, they
remain vulnerable to ""jailbreak"" attacks, where carefully crafted prompts can
induce the generation of toxic content. Traditional single-round jailbreak
attacks, such as GCG and AutoDAN, do not alter the sensitive words in the
dangerous prompts. Although they can temporarily bypass the model's safeguards
through prompt engineering, their success rate drops significantly as the LLM
is further fine-tuned, and they cannot effectively circumvent static rule-based
filters that remove the hazardous vocabulary.
  In this study, to better understand jailbreak attacks, we introduce a
multi-round jailbreak approach. This method can rewrite the dangerous prompts,
decomposing them into a series of less harmful sub-questions to bypass the
LLM's safety checks. We first use the LLM to perform a decomposition task,
breaking down a set of natural language questions into a sequence of
progressive sub-questions, which are then used to fine-tune the Llama3-8B
model, enabling it to decompose hazardous prompts. The fine-tuned model is then
used to break down the problematic prompt, and the resulting sub-questions are
sequentially asked to the victim model. If the victim model rejects a
sub-question, a new decomposition is generated, and the process is repeated
until the final objective is achieved. Our experimental results show a 94\%
success rate on the llama2-7B and demonstrate the effectiveness of this
approach in circumventing static rule-based filters.",http://arxiv.org/pdf/2410.11533v1,,False
On Rank-Dependent Generalisation Error Bounds for Transformers,15/10/2024,Lan V. Truong,"In this paper, we introduce various covering number bounds for linear
function classes, each subject to different constraints on input and matrix
norms. These bounds are contingent on the rank of each class of matrices. We
then apply these bounds to derive generalization errors for single layer
transformers. Our results improve upon several existing generalization bounds
in the literature and are independent of input sequence length, highlighting
the advantages of employing low-rank matrices in transformer design. More
specifically, our achieved generalisation error bound decays as $O(1/\sqrt{n})$
where $n$ is the sample length, which improves existing results in research
literature of the order $O((\log n)/(\sqrt{n}))$. It also decays as $O(\log
r_w)$ where $r_w$ is the rank of the combination of query and and key matrices.",http://arxiv.org/pdf/2410.11500v1,,False
BSM: Small but Powerful Biological Sequence Model for Genes and Proteins,15/10/2024,"Weixi Xiang, Xueting Han, Xiujuan Chai, Jing Bai","Modeling biological sequences such as DNA, RNA, and proteins is crucial for
understanding complex processes like gene regulation and protein synthesis.
However, most current models either focus on a single type or treat multiple
types of data separately, limiting their ability to capture cross-modal
relationships. We propose that by learning the relationships between these
modalities, the model can enhance its understanding of each type. To address
this, we introduce BSM, a small but powerful mixed-modal biological sequence
foundation model, trained on three types of data: RefSeq, Gene Related
Sequences, and interleaved biological sequences from the web. These datasets
capture the genetic flow, gene-protein relationships, and the natural
co-occurrence of diverse biological data, respectively. By training on
mixed-modal data, BSM significantly enhances learning efficiency and
cross-modal representation, outperforming models trained solely on unimodal
data. With only 110M parameters, BSM achieves performance comparable to much
larger models across both single-modal and mixed-modal tasks, and uniquely
demonstrates in-context learning capability for mixed-modal tasks, which is
absent in existing models. Further scaling to 270M parameters demonstrates even
greater performance gains, highlighting the potential of BSM as a significant
advancement in multimodal biological sequence modeling.",http://arxiv.org/pdf/2410.11499v1,,False
Can sparse autoencoders make sense of latent representations?,15/10/2024,Viktoria Schuster,"Sparse autoencoders (SAEs) have lately been used to uncover interpretable
latent features in large language models. Here, we explore their potential for
decomposing latent representations in complex and high-dimensional biological
data, where the underlying variables are often unknown. On simulated data we
show that generative hidden variables can be captured in learned
representations in the form of superpositions. The degree to which they are
learned depends on the completeness of the representations. Superpositions,
however, are not identifiable if these generative variables are unknown. SAEs
can to some extent recover these variables, yielding interpretable features.
Applied to single-cell multi-omics data, we show that an SAE can uncover key
biological processes such as carbon dioxide transport and ion homeostasis,
which are crucial for red blood cell differentiation and immune function. Our
findings highlight how SAEs can be used in advancing interpretability in
biological and other scientific domains.",http://arxiv.org/pdf/2410.11468v1,,False
Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement,15/10/2024,"Zhi Wang, Li Zhang, Wenhao Wu, Yuanheng Zhu, Dongbin Zhao, Chunlin Chen","A longstanding goal of artificial general intelligence is highly capable
generalists that can learn from diverse experiences and generalize to unseen
tasks. The language and vision communities have seen remarkable progress toward
this trend by scaling up transformer-based models trained on massive datasets,
while reinforcement learning (RL) agents still suffer from poor generalization
capacity under such paradigms. To tackle this challenge, we propose Meta
Decision Transformer (Meta-DT), which leverages the sequential modeling ability
of the transformer architecture and robust task representation learning via
world model disentanglement to achieve efficient generalization in offline
meta-RL. We pretrain a context-aware world model to learn a compact task
representation, and inject it as a contextual condition to the causal
transformer to guide task-oriented sequence generation. Then, we subtly utilize
history trajectories generated by the meta-policy as a self-guided prompt to
exploit the architectural inductive bias. We select the trajectory segment that
yields the largest prediction error on the pretrained world model to construct
the prompt, aiming to encode task-specific information complementary to the
world model maximally. Notably, the proposed framework eliminates the
requirement of any expert demonstration or domain knowledge at test time.
Experimental results on MuJoCo and Meta-World benchmarks across various dataset
types show that Meta-DT exhibits superior few and zero-shot generalization
capacity compared to strong baselines while being more practical with fewer
prerequisites. Our code is available at https://github.com/NJU-RL/Meta-DT.",http://arxiv.org/pdf/2410.11448v1,,False
Role of Delay in Brain Dynamics,15/10/2024,"Yuval Meir, Ofek Tevet, Yarden Tzach, Shiri Hodassman, Ido Kanter","Significant variations of delays among connecting neurons cause an inevitable
disadvantage of asynchronous brain dynamics compared to synchronous deep
learning. However, this study demonstrates that this disadvantage can be
converted into a computational advantage using a network with a single output
and M multiple delays between successive layers, thereby generating a
polynomial time-series outputs with M. The proposed role of delay in brain
dynamics (RoDiB) model, is capable of learning increasing number of classified
labels using a fixed architecture, and overcomes the inflexibility of the brain
to update the learning architecture using additional neurons and connections.
Moreover, the achievable accuracies of the RoDiB system are comparable with
those of its counterpart tunable single delay architectures with M outputs.
Further, the accuracies are significantly enhanced when the number of output
labels exceeds its fully connected input size. The results are mainly obtained
using simulations of VGG-6 on CIFAR datasets and also include multiple label
inputs. However, currently only a small fraction of the abundant number of
RoDiB outputs is utilized, thereby suggesting its potential for advanced
computational power yet to be discovered.",http://arxiv.org/pdf/2410.11384v1,10.1016/j.physa.2024.130166,False
DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation,15/10/2024,"Jaehyun Park, Yunho Kim, Sejin Kim, Byung-Jun Lee, Sundong Kim","We propose a novel offline reinforcement learning (offline RL) approach,
introducing the Diffusion-model-guided Implicit Q-learning with Adaptive
Revaluation (DIAR) framework. We address two key challenges in offline RL:
out-of-distribution samples and long-horizon problems. We leverage diffusion
models to learn state-action sequence distributions and incorporate value
functions for more balanced and adaptive decision-making. DIAR introduces an
Adaptive Revaluation mechanism that dynamically adjusts decision lengths by
comparing current and future state values, enabling flexible long-term
decision-making. Furthermore, we address Q-value overestimation by combining
Q-network learning with a value function guided by a diffusion model. The
diffusion model generates diverse latent trajectories, enhancing policy
robustness and generalization. As demonstrated in tasks like Maze2D, AntMaze,
and Kitchen, DIAR consistently outperforms state-of-the-art algorithms in
long-horizon, sparse-reward environments.",http://arxiv.org/pdf/2410.11338v1,,False
Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task,15/10/2024,"Yunho Kim, Jaehyun Park, Heejun Kim, Sejin Kim, Byung-Jun Lee, Sundong Kim","Effective long-term strategies enable AI systems to navigate complex
environments by making sequential decisions over extended horizons. Similarly,
reinforcement learning (RL) agents optimize decisions across sequences to
maximize rewards, even without immediate feedback. To verify that Latent
Diffusion-Constrained Q-learning (LDCQ), a prominent diffusion-based offline RL
method, demonstrates strong reasoning abilities in multi-step decision-making,
we aimed to evaluate its performance on the Abstraction and Reasoning Corpus
(ARC). However, applying offline RL methodologies to enhance strategic
reasoning in AI for solving tasks in ARC is challenging due to the lack of
sufficient experience data in the ARC training set. To address this limitation,
we introduce an augmented offline RL dataset for ARC, called Synthesized
Offline Learning Data for Abstraction and Reasoning (SOLAR), along with the
SOLAR-Generator, which generates diverse trajectory data based on predefined
rules. SOLAR enables the application of offline RL methods by offering
sufficient experience data. We synthesized SOLAR for a simple task and used it
to train an agent with the LDCQ method. Our experiments demonstrate the
effectiveness of the offline RL approach on a simple ARC task, showing the
agent's ability to make multi-step sequential decisions and correctly identify
answer states. These results highlight the potential of the offline RL approach
to enhance AI's strategic reasoning capabilities.",http://arxiv.org/pdf/2410.11324v1,,False
UmambaTSF: A U-shaped Multi-Scale Long-Term Time Series Forecasting Method Using Mamba,15/10/2024,"Li Wu, Wenbin Pei, Jiulong Jiao, Qiang Zhang","Multivariate Time series forecasting is crucial in domains such as
transportation, meteorology, and finance, especially for predicting extreme
weather events. State-of-the-art methods predominantly rely on Transformer
architectures, which utilize attention mechanisms to capture temporal
dependencies. However, these methods are hindered by quadratic time complexity,
limiting the model's scalability with respect to input sequence length. This
significantly restricts their practicality in the real world. Mamba, based on
state space models (SSM), provides a solution with linear time complexity,
increasing the potential for efficient forecasting of sequential data. In this
study, we propose UmambaTSF, a novel long-term time series forecasting
framework that integrates multi-scale feature extraction capabilities of
U-shaped encoder-decoder multilayer perceptrons (MLP) with Mamba's long
sequence representation. To improve performance and efficiency, the Mamba
blocks introduced in the framework adopt a refined residual structure and
adaptable design, enabling the capture of unique temporal signals and flexible
channel processing. In the experiments, UmambaTSF achieves state-of-the-art
performance and excellent generality on widely used benchmark datasets while
maintaining linear time complexity and low memory consumption.",http://arxiv.org/pdf/2410.11278v1,,False
ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis,15/10/2024,"Abhijit Manatkar, Devarsh Patel, Hima Patel, Naresh Manwani","Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging
open problem, often tackled through Reinforcement Learning (RL) by learning to
predict a sequence of analysis operations (FILTER, GROUP, etc). Defining
rewards for each operation is a challenging task and existing methods rely on
various \emph{interestingness measures} to craft reward functions to capture
the importance of each operation. In this work, we argue that not all of the
essential features of what makes an operation important can be accurately
captured mathematically using rewards. We propose an AutoEDA model trained
through imitation learning from expert EDA sessions, bypassing the need for
manually defined interestingness measures. Our method, based on generative
adversarial imitation learning (GAIL), generalizes well across datasets, even
with limited expert data. We also introduce a novel approach for generating
synthetic EDA demonstrations for training. Our method outperforms the existing
state-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing
strong performance and generalization, while naturally capturing diverse
interestingness measures in generated EDA sessions.",http://arxiv.org/pdf/2410.11276v1,,False
Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning,15/10/2024,"Jiayu Chen, Wentse Chen, Jeff Schneider","Offline reinforcement learning (RL) is a powerful approach for data-driven
decision-making and control. Compared to model-free methods, offline
model-based reinforcement learning (MBRL) explicitly learns world models from a
static dataset and uses them as surrogate simulators, improving the data
efficiency and enabling the learned policy to potentially generalize beyond the
dataset support. However, there could be various MDPs that behave identically
on the offline dataset and so dealing with the uncertainty about the true MDP
can be challenging. In this paper, we propose modeling offline MBRL as a Bayes
Adaptive Markov Decision Process (BAMDP), which is a principled framework for
addressing model uncertainty. We further introduce a novel Bayes Adaptive
Monte-Carlo planning algorithm capable of solving BAMDPs in continuous state
and action spaces with stochastic transitions. This planning process is based
on Monte Carlo Tree Search and can be integrated into offline MBRL as a policy
improvement operator in policy iteration. Our ``RL + Search"" framework follows
in the footsteps of superhuman AIs like AlphaZero, improving on current offline
MBRL methods by incorporating more computation input. The proposed algorithm
significantly outperforms state-of-the-art model-based and model-free offline
RL methods on twelve D4RL MuJoCo benchmark tasks and three target tracking
tasks in a challenging, stochastic tokamak control simulator.",http://arxiv.org/pdf/2410.11234v1,,False
Latent-Predictive Empowerment: Measuring Empowerment without a Simulator,15/10/2024,"Andrew Levy, Alessandro Allievi, George Konidaris","Empowerment has the potential to help agents learn large skillsets, but is
not yet a scalable solution for training general-purpose agents. Recent
empowerment methods learn diverse skillsets by maximizing the mutual
information between skills and states; however, these approaches require a
model of the transition dynamics, which can be challenging to learn in
realistic settings with high-dimensional and stochastic observations. We
present Latent-Predictive Empowerment (LPE), an algorithm that can compute
empowerment in a more practical manner. LPE learns large skillsets by
maximizing an objective that is a principled replacement for the mutual
information between skills and states and that only requires a simpler
latent-predictive model rather than a full simulator of the environment. We
show empirically in a variety of settings--including ones with high-dimensional
observations and highly stochastic transition dynamics--that our empowerment
objective (i) learns similar-sized skillsets as the leading empowerment
algorithm that assumes access to a model of the transition dynamics and (ii)
outperforms other model-based approaches to empowerment.",http://arxiv.org/pdf/2410.11155v1,,False
