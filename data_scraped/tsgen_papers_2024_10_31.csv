Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks,30/10/2024,"Matteo Citterio, Marco D'Errico, Gabriele Visentin","We introduce a novel Dynamic Graph Neural Network (DGNN) architecture for
solving conditional $m$-steps ahead forecasting problems in temporal financial
networks. The proposed DGNN is validated on simulated data from a temporal
financial network model capturing stylized features of Interest Rate Swaps
(IRSs) transaction networks, where financial entities trade swap contracts
dynamically and the network topology evolves conditionally on a reference rate.
The proposed model is able to produce accurate conditional forecasts of net
variation margins up to a $21$-day horizon by leveraging conditional
information under pre-determined stress test scenarios. Our work shows that the
network dynamics can be successfully incorporated into stress-testing
practices, thus providing regulators and policymakers with a crucial tool for
systemic risk monitoring.",http://arxiv.org/pdf/2410.23275v1,,False
TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models,30/10/2024,"Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan","Existing benchmarks often highlight the remarkable performance achieved by
state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal
context for video understanding. However, how well do the models truly perform
visual temporal reasoning? Our study of existing benchmarks shows that this
capability of MFMs is likely overestimated as many questions can be solved by
using a single, few, or out-of-order frames. To systematically examine current
visual temporal reasoning tasks, we propose three principles with corresponding
metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame
Information Disparity. Following these principles, we introduce TOMATO,
Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to
rigorously assess MFMs' temporal reasoning capabilities in video understanding.
TOMATO comprises 1,484 carefully curated, human-annotated questions spanning
six tasks (i.e., action count, direction, rotation, shape & trend, velocity &
frequency, and visual cues), applied to 1,417 videos, including 805
self-recorded and -generated videos, that encompass human-centric, real-world,
and simulated scenarios. Our comprehensive evaluation reveals a human-model
performance gap of 57.3% with the best-performing model. Moreover, our in-depth
analysis uncovers more fundamental limitations beyond this gap in current MFMs.
While they can accurately recognize events in isolated frames, they fail to
interpret these frames as a continuous sequence. We believe TOMATO will serve
as a crucial testbed for evaluating the next-generation MFMs and as a call to
the community to develop AI systems capable of comprehending human world
dynamics through the video modality.",http://arxiv.org/pdf/2410.23266v1,,False
"A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment",30/10/2024,"Matteo G. Mecattaf, Ben Slater, Marko Tešić, Jonathan Prunty, Konstantinos Voudouris, Lucy G. Cheke","As general-purpose tools, Large Language Models (LLMs) must often reason
about everyday physical environments. In a question-and-answer capacity,
understanding the interactions of physical objects may be necessary to give
appropriate responses. Moreover, LLMs are increasingly used as reasoning
engines in agentic systems, designing and controlling their action sequences.
The vast majority of research has tackled this issue using static benchmarks,
comprised of text or image-based questions about the physical world. However,
these benchmarks do not capture the complexity and nuance of real-life physical
processes. Here we advocate for a second, relatively unexplored, approach:
'embodying' the LLMs by granting them control of an agent within a 3D
environment. We present the first embodied and cognitively meaningful
evaluation of physical common-sense reasoning in LLMs. Our framework allows
direct comparison of LLMs with other embodied agents, such as those based on
Deep Reinforcement Learning, and human and non-human animals. We employ the
Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study
physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a
suite of experiments that replicate laboratory studies with non-human animals,
to study physical reasoning capabilities including distance estimation,
tracking out-of-sight objects, and tool use. We demonstrate that
state-of-the-art multi-modal models with no finetuning can complete this style
of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI
Olympics competition and to human children. Our results show that LLMs are
currently outperformed by human children on these tasks. We argue that this
approach allows the study of physical reasoning using ecologically valid
experiments drawn directly from cognitive science, improving the predictability
and reliability of LLMs.",http://arxiv.org/pdf/2410.23242v1,,False
Full-waveform earthquake source inversion using simulation-based inference,30/10/2024,"A. A. Saoulis, D. Piras, A. Spurio Mancini, B. Joachimi, A. M. G. Ferreira","This paper presents a novel framework for full-waveform seismic source
inversion using simulation-based inference (SBI). Traditional probabilistic
approaches often rely on simplifying assumptions about data errors, which we
show can lead to inaccurate uncertainty quantification. SBI addresses this
limitation by building an empirical probabilistic model of the data errors
using machine learning models, known as neural density estimators, which can
then be integrated into the Bayesian inference framework. We apply the SBI
framework to point-source moment tensor inversions as well as joint moment
tensor and time-location inversions. We construct a range of synthetic examples
to explore the quality of the SBI solutions, as well as to compare the SBI
results with standard Gaussian likelihood-based Bayesian inversions. We then
demonstrate that under real seismic noise, common Gaussian likelihood
assumptions for treating full-waveform data yield overconfident posterior
distributions that underestimate the moment tensor component uncertainties by
up to a factor of 3. We contrast this with SBI, which produces well-calibrated
posteriors that generally agree with the true seismic source parameters, and
offers an order-of-magnitude reduction in the number of simulations required to
perform inference compared to standard Monte Carlo techniques. Finally, we
apply our methodology to a pair of moderate magnitude earthquakes in the North
Atlantic. We utilise seismic waveforms recorded by the recent UPFLOW ocean
bottom seismometer array as well as by regional land stations in the Azores,
comparing full moment tensor and source-time location posteriors between SBI
and a Gaussian likelihood approach. We find that our adaptation of SBI can be
directly applied to real earthquake sources to efficiently produce high quality
posterior distributions that significantly improve upon Gaussian likelihood
approaches.",http://arxiv.org/pdf/2410.23238v1,,False
EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning,30/10/2024,"Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang","This paper introduces a framework, called EMOTION, for generating expressive
motion sequences in humanoid robots, enhancing their ability to engage in
humanlike non-verbal communication. Non-verbal cues such as facial expressions,
gestures, and body movements play a crucial role in effective interpersonal
interactions. Despite the advancements in robotic behaviors, existing methods
often fall short in mimicking the diversity and subtlety of human non-verbal
communication. To address this gap, our approach leverages the in-context
learning capability of large language models (LLMs) to dynamically generate
socially appropriate gesture motion sequences for human-robot interaction. We
use this framework to generate 10 different expressive gestures and conduct
online user studies comparing the naturalness and understandability of the
motions generated by EMOTION and its human-feedback version, EMOTION++, against
those by human operators. The results demonstrate that our approach either
matches or surpasses human performance in generating understandable and natural
robot motions under certain scenarios. We also provide design implications for
future research to consider a set of variables when generating expressive
robotic gestures.",http://arxiv.org/pdf/2410.23234v1,,False
Improved convergence rate of kNN graph Laplacians,30/10/2024,"Yixuan Tan, Xiuyuan Cheng","In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widely
used due to their adaptivity to local data densities. Allowing weighted edges
in the graph, the kernelized graph affinity provides a more general type of
$k$NN graph where the $k$NN distance is used to set the kernel bandwidth
adaptively. In this work, we consider a general class of $k$NN graph where the
graph affinity is $W_{ij} = \epsilon^{-d/2} \; k_0 ( \| x_i - x_j \|^2 /
\epsilon \phi( \widehat{\rho}(x_i), \widehat{\rho}(x_j) )^2 ) $, with
$\widehat{\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$,
$\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on
$[0,\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$
are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded in
a high dimensional Euclidean space, we prove the point-wise convergence of the
$k$NN graph Laplacian to the limiting manifold operator (depending on $p$) at
the rate of $O(N^{-2/(d+6)}\,)$, up to a log factor, when $k_0$ and $\phi$ have
$C^3$ regularity and satisfy other technical conditions. This fast rate is
obtained when $\epsilon \sim N^{-2/(d+6)}\,$ and $k \sim N^{6/(d+6)}\,$, both
at the optimal order to balance the theoretical bias and variance errors. When
$k_0$ and $\phi$ have lower regularities, including when $k_0$ is a compactly
supported function as in the standard $k$NN graph, the convergence rate
degenerates to $O(N^{-1/(d+4)}\,)$. Our improved convergence rate is based on a
refined analysis of the $k$NN estimator, which can be of independent interest.
We validate our theory by numerical experiments on simulated data.",http://arxiv.org/pdf/2410.23212v1,,False
Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks,30/10/2024,"Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster","While large models trained with self-supervised learning on offline datasets
have shown remarkable capabilities in text and image domains, achieving the
same generalisation for agents that act in sequential decision problems remains
an open challenge. In this work, we take a step towards this goal by
procedurally generating tens of millions of 2D physics-based tasks and using
these to train a general reinforcement learning (RL) agent for physical
control. To this end, we introduce Kinetix: an open-ended space of
physics-based RL environments that can represent tasks ranging from robotic
locomotion and grasping to video games and classic RL environments, all within
a unified framework. Kinetix makes use of our novel hardware-accelerated
physics engine Jax2D that allows us to cheaply simulate billions of environment
steps during training. Our trained agent exhibits strong physical reasoning
capabilities, being able to zero-shot solve unseen human-designed environments.
Furthermore, fine-tuning this general agent on tasks of interest shows
significantly stronger performance than training an RL agent *tabula rasa*.
This includes solving some environments that standard RL training completely
fails at. We believe this demonstrates the feasibility of large scale,
mixed-quality pre-training for online RL and we hope that Kinetix will serve as
a useful framework to investigate this further.",http://arxiv.org/pdf/2410.23208v1,,False
FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities,30/10/2024,"Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk","Developing a foundation model for time series forecasting across diverse
domains has attracted significant attention in recent years. Existing works
typically assume regularly sampled, well-structured data, limiting their
applicability to more generalized scenarios where time series often contain
missing values, unequal sequence lengths, and irregular time intervals between
measurements. To cover diverse domains and handle variable regularities, we
propose FlexTSF, a universal time series forecasting model that possesses
better generalization and natively support both regular and irregular time
series. FlexTSF produces forecasts in an autoregressive manner and incorporates
three novel designs: VT-Norm, a normalization strategy to ablate data domain
barriers, IVP Patcher, a patching module to learn representations from flexibly
structured time series, and LED attention, an attention mechanism to seamlessly
integrate these two and propagate forecasts with awareness of domain and time
information. Experiments on 12 datasets show that FlexTSF outperforms
state-of-the-art forecasting models respectively designed for regular and
irregular time series. Furthermore, after self-supervised pre-training, FlexTSF
shows exceptional performance in both zero-shot and few-show settings for time
series forecasting.",http://arxiv.org/pdf/2410.23160v1,,False
VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning,30/10/2024,"Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, João F. Henriques, Kevin Ellis","Broadly intelligent agents should form task-specific abstractions that
selectively expose the essential elements of a task, while abstracting away the
complexity of the raw sensorimotor space. In this work, we present
Neuro-Symbolic Predicates, a first-order abstraction language that combines the
strengths of symbolic and neural knowledge representations. We outline an
online algorithm for inventing such predicates and learning abstract world
models. We compare our approach to hierarchical reinforcement learning,
vision-language model planning, and symbolic predicate invention approaches, on
both in- and out-of-distribution tasks across five simulated robotic domains.
Results show that our approach offers better sample complexity, stronger
out-of-distribution generalization, and improved interpretability.",http://arxiv.org/pdf/2410.23156v1,,False
Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation,30/10/2024,"Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati","Contemporary radio access networks employ link adaption (LA) algorithms to
optimize the modulation and coding schemes to adapt to the prevailing
propagation conditions and are near-optimal in terms of the achieved spectral
efficiency. LA is a challenging task in the presence of mobility, fast fading,
and imperfect channel quality information and limited knowledge of the receiver
characteristics at the transmitter, which render model-based LA algorithms
complex and suboptimal. Model-based LA is especially difficult as connected
user equipment devices become increasingly heterogeneous in terms of receiver
capabilities, antenna configurations and hardware characteristics. Recognizing
these difficulties, previous works have proposed reinforcement learning (RL)
for LA, which faces deployment difficulties due to their potential negative
impacts on live performance. To address this challenge, this paper considers
offline RL to learn LA policies from data acquired in live networks with
minimal or no intrusive effects on the network operation. We propose three LA
designs based on batch-constrained deep Q-learning, conservative Q-learning,
and decision transformers, showing that offline RL algorithms can achieve
performance of state-of-the-art online RL methods when data is collected with a
proper behavioral policy.",http://arxiv.org/pdf/2410.23031v1,,False
A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics,30/10/2024,"Jonas Bode, Bastian Pätzold, Raphael Memmesheimer, Sven Behnke","Recent advances in LLM have been instrumental in autonomous robot control and
human-robot interaction by leveraging their vast general knowledge and
capabilities to understand and reason across a wide range of tasks and
scenarios. Previous works have investigated various prompt engineering
techniques for improving the performance of \glspl{LLM} to accomplish tasks,
while others have proposed methods that utilize LLMs to plan and execute tasks
based on the available functionalities of a given robot platform. In this work,
we consider both lines of research by comparing prompt engineering techniques
and combinations thereof within the application of high-level task planning and
execution in service robotics. We define a diverse set of tasks and a simple
set of functionalities in simulation, and measure task completion accuracy and
execution time for several state-of-the-art models.",http://arxiv.org/pdf/2410.22997v1,,False
Higher-order Cross-structural Embedding Model for Time Series Analysis,30/10/2024,"Guancen Lin, Cong Shen, Aijing Lin","Time series analysis has gained significant attention due to its critical
applications in diverse fields such as healthcare, finance, and sensor
networks. The complexity and non-stationarity of time series make it
challenging to capture the interaction patterns across different timestamps.
Current approaches struggle to model higher-order interactions within time
series, and focus on learning temporal or spatial dependencies separately,
which limits performance in downstream tasks. To address these gaps, we propose
Higher-order Cross-structural Embedding Model for Time Series (High-TS), a
novel framework that jointly models both temporal and spatial perspectives by
combining multiscale Transformer with Topological Deep Learning (TDL).
Meanwhile, High-TS utilizes contrastive learning to integrate these two
structures for generating robust and discriminative representations. Extensive
experiments show that High-TS outperforms state-of-the-art methods in various
time series tasks and demonstrate the importance of higher-order
cross-structural information in improving model performance.",http://arxiv.org/pdf/2410.22984v1,,False
DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting,30/10/2024,"Zhiding Liu, Jiqian Yang, Qingyang Mao, Yuze Zhao, Mingyue Cheng, Zhi Li, Qi Liu, Enhong Chen","Multivariate time series forecasting plays a crucial role in various
real-world applications. Significant efforts have been made to integrate
advanced network architectures and training strategies that enhance the capture
of temporal dependencies, thereby improving forecasting accuracy. On the other
hand, mainstream approaches typically utilize a single unified model with
simplistic channel-mixing embedding or cross-channel attention operations to
account for the critical intricate inter-channel dependencies. Moreover, some
methods even trade capacity for robust prediction based on the
channel-independent assumption. Nonetheless, as time series data may display
distinct evolving patterns due to the unique characteristics of each channel
(including multiple strong seasonalities and trend changes), the unified
modeling methods could yield suboptimal results. To this end, we propose
DisenTS, a tailored framework for modeling disentangled channel evolving
patterns in general multivariate time series forecasting. The central idea of
DisenTS is to model the potential diverse patterns within the multivariate time
series data in a decoupled manner. Technically, the framework employs multiple
distinct forecasting models, each tasked with uncovering a unique evolving
pattern. To guide the learning process without supervision of pattern
partition, we introduce a novel Forecaster Aware Gate (FAG) module that
generates the routing signals adaptively according to both the forecasters'
states and input series' characteristics. The forecasters' states are derived
from the Linear Weight Approximation (LWA) strategy, which quantizes the
complex deep neural networks into compact matrices. Additionally, the
Similarity Constraint (SC) is further proposed to guide each model to
specialize in an underlying pattern by minimizing the mutual information
between the representations.",http://arxiv.org/pdf/2410.22981v1,,False
Simulation-Free Training of Neural ODEs on Paired Data,30/10/2024,"Semin Kim, Jaehoon Yoo, Jinwoo Kim, Yeonwoo Cha, Saehoon Kim, Seunghoon Hong","In this work, we investigate a method for simulation-free training of Neural
Ordinary Differential Equations (NODEs) for learning deterministic mappings
between paired data. Despite the analogy of NODEs as continuous-depth residual
networks, their application in typical supervised learning tasks has not been
popular, mainly due to the large number of function evaluations required by ODE
solvers and numerical instability in gradient estimation. To alleviate this
problem, we employ the flow matching framework for simulation-free training of
NODEs, which directly regresses the parameterized dynamics function to a
predefined target velocity field. Contrary to generative tasks, however, we
show that applying flow matching directly between paired data can often lead to
an ill-defined flow that breaks the coupling of the data pairs (e.g., due to
crossing trajectories). We propose a simple extension that applies flow
matching in the embedding space of data pairs, where the embeddings are learned
jointly with the dynamic function to ensure the validity of the flow which is
also easier to learn. We demonstrate the effectiveness of our method on both
regression and classification tasks, where our method outperforms existing
NODEs with a significantly lower number of function evaluations. The code is
available at https://github.com/seminkim/simulation-free-node.",http://arxiv.org/pdf/2410.22918v1,,False
Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions,30/10/2024,"J. Quetzalcoatl Toledo-Marin, Sebastian Gonzalez, Hao Jia, Ian Lu, Deniz Sogutlu, Abhishek Abhishek, Colin Gay, Eric Paquet, Roger Melko, Geoffrey C. Fox, Maximilian Swiatlowski, Wojciech Fedorko","Particle collisions at accelerators such as the Large Hadron Collider,
recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite
measurements of the Standard Model and searches for new phenomena. Simulations
of collision events at these detectors have played a pivotal role in shaping
the design of future experiments and analyzing ongoing ones. However, the quest
for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing
computational cost, with projections estimating the need for millions of
CPU-years annually during the High Luminosity LHC (HL-LHC) run
\cite{collaboration2022atlas}. Simulating a single LHC event with
\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of
the calorimeter subdetectors in particular imposing substantial computational
demands \cite{rousseau2023experimental}. To address this challenge, we propose
a conditioned quantum-assisted deep generative model. Our model integrates a
conditioned variational autoencoder (VAE) on the exterior with a conditioned
Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced
expressiveness compared to conventional VAEs. The RBM nodes and connections are
meticulously engineered to enable the use of qubits and couplers on D-Wave's
Pegasus-structured \textit{Advantage} quantum annealer (QA) for sampling. We
introduce a novel method for conditioning the quantum-assisted RBM using
\textit{flux biases}. We further propose a novel adaptive mapping to estimate
the effective inverse temperature in quantum annealers. The effectiveness of
our framework is illustrated using Dataset 2 of the CaloChallenge
\cite{calochallenge}.",http://arxiv.org/pdf/2410.22870v1,,False
Universality of the $π^2/6$ Pathway in Avoiding Model Collapse,30/10/2024,"Apratim Dey, David Donoho","Researchers in empirical machine learning recently spotlighted their fears of
so-called Model Collapse. They imagined a discard workflow, where an initial
generative model is trained with real data, after which the real data are
discarded, and subsequently, the model generates synthetic data on which a new
model is trained. They came to the conclusion that models degenerate as
model-fitting generations proceed. However, other researchers considered an
augment workflow, where the original real data continue to be used in each
generation of training, augmented by synthetic data from models fit in all
earlier generations. Empirical results on canonical datasets and learning
procedures confirmed the occurrence of model collapse under the discard
workflow and avoidance of model collapse under the augment workflow. Under the
augment workflow, theoretical evidence also confirmed avoidance in particular
instances; specifically, Gerstgrasser et al. (2024) found that for classical
Linear Regression, test risk at any later generation is bounded by a moderate
multiple, viz. pi-squared-over-6 of the test risk of training with the original
real data alone. Some commentators questioned the generality of theoretical
conclusions based on the generative model assumed in Gerstgrasser et al.
(2024): could similar conclusions be reached for other task/model pairings? In
this work, we demonstrate the universality of the pi-squared-over-6 augment
risk bound across a large family of canonical statistical models, offering key
insights into exactly why collapse happens under the discard workflow and is
avoided under the augment workflow. In the process, we provide a framework that
is able to accommodate a large variety of workflows (beyond discard and
augment), thereby enabling an experimenter to judge the comparative merits of
multiple different workflows by simulating a simple Gaussian process.",http://arxiv.org/pdf/2410.22812v1,,False
Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation,30/10/2024,"Yang Zhang, Juntao You, Yimeng Bai, Jizhi Zhang, Keqin Bao, Wenjie Wang, Tat-Seng Chua","Recent advancements in recommender systems have focused on leveraging Large
Language Models (LLMs) to improve user preference modeling, yielding promising
outcomes. However, current LLM-based approaches struggle to fully leverage user
behavior sequences, resulting in suboptimal preference modeling for
personalized recommendations. In this study, we propose a novel Counterfactual
Fine-Tuning (CFT) method to address this issue by explicitly emphasizing the
role of behavior sequences when generating recommendations. Specifically, we
employ counterfactual reasoning to identify the causal effects of behavior
sequences on model output and introduce a task that directly fits the
ground-truth labels based on these effects, achieving the goal of explicit
emphasis. Additionally, we develop a token-level weighting mechanism to adjust
the emphasis strength for different item tokens, reflecting the diminishing
influence of behavior sequences from earlier to later tokens during predicting
an item. Extensive experiments on real-world datasets demonstrate that CFT
effectively improves behavior sequence modeling. Our codes are available at
https://github.com/itsmeyjt/CFT.",http://arxiv.org/pdf/2410.22809v1,,False
Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation,30/10/2024,"Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao","Sequential recommender systems (SRSs) aim to predict the subsequent items
which may interest users via comprehensively modeling users' complex preference
embedded in the sequence of user-item interactions. However, most of existing
SRSs often model users' single low-level preference based on item ID
information while ignoring the high-level preference revealed by item attribute
information, such as item category. Furthermore, they often utilize limited
sequence context information to predict the next item while overlooking richer
inter-item semantic relations. To this end, in this paper, we proposed a novel
hierarchical preference modeling framework to substantially model the complex
low- and high-level preference dynamics for accurate sequential recommendation.
Specifically, in the framework, a novel dual-transformer module and a novel
dual contrastive learning scheme have been designed to discriminatively learn
users' low- and high-level preference and to effectively enhance both low- and
high-level preference learning respectively. In addition, a novel
semantics-enhanced context embedding module has been devised to generate more
informative context embedding for further improving the recommendation
performance. Extensive experiments on six real-world datasets have demonstrated
both the superiority of our proposed method over the state-of-the-art ones and
the rationality of our design.",http://arxiv.org/pdf/2410.22790v1,,False
Self-Driving Car Racing: Application of Deep Reinforcement Learning,30/10/2024,"Florentiana Yuwono, Gan Pang Yen, Jason Christopher","This paper explores the application of deep reinforcement learning (RL)
techniques in the domain of autonomous self-driving car racing. Motivated by
the rise of AI-driven mobility and autonomous racing events, the project aims
to develop an AI agent that efficiently drives a simulated car in the OpenAI
Gymnasium CarRacing environment. We investigate various RL algorithms,
including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and novel
adaptations that incorporate transfer learning and recurrent neural networks
(RNNs) for enhanced performance. The project demonstrates that while DQN
provides a strong baseline for policy learning, integrating ResNet and LSTM
models significantly improves the agent's ability to capture complex spatial
and temporal dynamics. PPO, particularly in continuous action spaces, shows
promising results for fine control, although challenges such as policy collapse
remain. We compare the performance of these approaches and outline future
research directions focused on improving computational efficiency and
addressing model stability. Our findings contribute to the ongoing development
of AI systems in autonomous driving and related control tasks.",http://arxiv.org/pdf/2410.22766v1,,False
SoftCTRL: Soft conservative KL-control of Transformer Reinforcement Learning for Autonomous Driving,30/10/2024,"Minh Tri Huynh, Duc Dung Nguyen","In recent years, motion planning for urban self-driving cars (SDV) has become
a popular problem due to its complex interaction of road components. To tackle
this, many methods have relied on large-scale, human-sampled data processed
through Imitation learning (IL). Although effective, IL alone cannot adequately
handle safety and reliability concerns. Combining IL with Reinforcement
learning (RL) by adding KL divergence between RL and IL policy to the RL loss
can alleviate IL's weakness but suffer from over-conservation caused by
covariate shift of IL. To address this limitation, we introduce a method that
combines IL with RL using an implicit entropy-KL control that offers a simple
way to reduce the over-conservation characteristic. In particular, we validate
different challenging simulated urban scenarios from the unseen dataset,
indicating that although IL can perform well in imitation tasks, our proposed
method significantly improves robustness (over 17\% reduction in failures) and
generates human-like driving behavior.",http://arxiv.org/pdf/2410.22752v1,,False
Extensional Properties of Recurrent Neural Networks,30/10/2024,"Evgeny Dantsin, Alexander Wolpert","A property of a recurrent neural network (RNN) is called \emph{extensional}
if, loosely speaking, it is a property of the function computed by the RNN
rather than a property of the RNN algorithm. Many properties of interest in
RNNs are extensional, for example, robustness against small changes of input or
good clustering of inputs. Given an RNN, it is natural to ask whether it has
such a property. We give a negative answer to the general question about
testing extensional properties of RNNs. Namely, we prove a version of Rice's
theorem for RNNs: any nontrivial extensional property of RNNs is undecidable.",http://arxiv.org/pdf/2410.22730v1,,False
"Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots",30/10/2024,"Vincent Guan, Joseph Janssen, Hossein Rahmani, Andrew Warren, Stephen Zhang, Elina Robeva, Geoffrey Schiebinger","Stochastic differential equations (SDEs) are a fundamental tool for modelling
dynamic processes, including gene regulatory networks (GRNs), contaminant
transport, financial markets, and image generation. However, learning the
underlying SDE from observational data is a challenging task, especially when
individual trajectories are not observable. Motivated by burgeoning research in
single-cell datasets, we present the first comprehensive approach for jointly
estimating the drift and diffusion of an SDE from its temporal marginals.
Assuming linear drift and additive diffusion, we prove that these parameters
are identifiable from marginals if and only if the initial distribution is not
invariant to a class of generalized rotations, a condition that is satisfied by
most distributions. We further prove that the causal graph of any SDE with
additive diffusion can be recovered from the SDE parameters. To complement this
theory, we adapt entropy-regularized optimal transport to handle anisotropic
diffusion, and introduce APPEX (Alternating Projection Parameter Estimation
from $X_0$), an iterative algorithm designed to estimate the drift, diffusion,
and causal graph of an additive noise SDE, solely from temporal marginals. We
show that each of these steps are asymptotically optimal with respect to the
Kullback-Leibler divergence, and demonstrate APPEX's effectiveness on simulated
data from linear additive noise SDEs.",http://arxiv.org/pdf/2410.22729v1,,False
Community search signatures as foundation features for human-centered geospatial modeling,30/10/2024,"Mimi Sun, Chaitanya Kamath, Mohit Agarwal, Arbaaz Muslim, Hector Yee, David Schottlander, Shailesh Bavadekar, Niv Efron, Shravya Shetty, Gautam Prasad","Aggregated relative search frequencies offer a unique composite signal
reflecting people's habits, concerns, interests, intents, and general
information needs, which are not found in other readily available datasets.
Temporal search trends have been successfully used in time series modeling
across a variety of domains such as infectious diseases, unemployment rates,
and retail sales. However, most existing applications require curating
specialized datasets of individual keywords, queries, or query clusters, and
the search data need to be temporally aligned with the outcome variable of
interest. We propose a novel approach for generating an aggregated and
anonymized representation of search interest as foundation features at the
community level for geospatial modeling. We benchmark these features using
spatial datasets across multiple domains. In zip codes with a population
greater than 3000 that cover over 95% of the contiguous US population, our
models for predicting missing values in a 20% set of holdout counties achieve
an average $R^2$ score of 0.74 across 21 health variables, and 0.80 across 6
demographic and environmental variables. Our results demonstrate that these
search features can be used for spatial predictions without strict temporal
alignment, and that the resulting models outperform spatial interpolation and
state of the art methods using satellite imagery features.",http://arxiv.org/pdf/2410.22721v1,,False
Multi-Task Interactive Robot Fleet Learning with Visual World Models,30/10/2024,"Huihan Liu, Yu Zhang, Vaarij Betala, Evan Zhang, James Liu, Crystal Ding, Yuke Zhu","Recent advancements in large-scale multi-task robot learning offer the
potential for deploying robot fleets in household and industrial settings,
enabling them to perform diverse tasks across various environments. However,
AI-enabled robots often face challenges with generalization and robustness when
exposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a
multi-task interactive robot fleet learning framework to address these
challenges. Sirius-Fleet monitors robot performance during deployment and
involves humans to correct the robot's actions when necessary. We employ a
visual world model to predict the outcomes of future actions and build anomaly
predictors to predict whether they will likely result in anomalies. As the
robot autonomy improves, the anomaly predictors automatically adapt their
prediction criteria, leading to fewer requests for human intervention and
gradually reducing human workload over time. Evaluations on large-scale
benchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task
policy performance and monitoring accuracy. We demonstrate Sirius-Fleet's
performance in both RoboCasa in simulation and Mutex in the real world, two
diverse, large-scale multi-task benchmarks. More information is available on
the project website: https://ut-austin-rpl.github.io/sirius-fleet",http://arxiv.org/pdf/2410.22689v1,,False
Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings,30/10/2024,"Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui","Accurately quantifying uncertainty in large language models (LLMs) is crucial
for their reliable deployment, especially in high-stakes applications. Current
state-of-the-art methods for measuring semantic uncertainty in LLMs rely on
strict bidirectional entailment criteria between multiple generated responses
and also depend on sequence likelihoods. While effective, these approaches
often overestimate uncertainty due to their sensitivity to minor wording
differences, additional correct information, and non-important words in the
sequence. We propose a novel approach that leverages semantic embeddings to
achieve smoother and more robust estimation of semantic uncertainty in LLMs. By
capturing semantic similarities without depending on sequence likelihoods, our
method inherently reduces any biases introduced by irrelevant words in the
answers. Furthermore, we introduce an amortised version of our approach by
explicitly modelling semantics as latent variables in a joint probabilistic
model. This allows for uncertainty estimation in the embedding space with a
single forward pass, significantly reducing computational overhead compared to
existing multi-pass methods. Experiments across multiple question-answering
datasets and frontier LLMs demonstrate that our embedding-based methods provide
more accurate and nuanced uncertainty quantification than traditional
approaches.",http://arxiv.org/pdf/2410.22685v1,,False
Dynamic PET Image Prediction Using a Network Combining Reversible and Irreversible Modules,30/10/2024,"Jie Sun, Qian Xia, Chuanfu Sun, Yumei Chen, Huafeng Liu, Wentao Zhu, Qiegen Liu","Dynamic positron emission tomography (PET) images can reveal the distribution
of tracers in the organism and the dynamic processes involved in biochemical
reactions, and it is widely used in clinical practice. Despite the high
effectiveness of dynamic PET imaging in studying the kinetics and metabolic
processes of radiotracers. Pro-longed scan times can cause discomfort for both
patients and medical personnel. This study proposes a dynamic frame prediction
method for dynamic PET imaging, reduc-ing dynamic PET scanning time by applying
a multi-module deep learning framework composed of reversible and irreversible
modules. The network can predict kinetic parameter images based on the early
frames of dynamic PET images, and then generate complete dynamic PET images. In
validation experiments with simulated data, our network demonstrated good
predictive performance for kinetic parameters and was able to reconstruct
high-quality dynamic PET images. Additionally, in clinical data experiments,
the network exhibited good generalization performance and attached that the
proposed method has promising clinical application prospects.",http://arxiv.org/pdf/2410.22674v1,,False
