Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre,30/01/2025,"Tasfia Noor Chowdhury, Sanjida Afrin Mou, Kazi Naimur Rahman","Patient length of stay (LoS) is a critical metric for evaluating the efficacy
of hospital management. The primary objectives encompass to improve efficiency
and reduce costs while enhancing patient outcomes and hospital capacity within
the patient journey. By seamlessly merging data-driven techniques with
simulation methodologies, the study proposes an all-encompassing framework for
the optimization of patient flow. Using a comprehensive dataset of 2.3 million
de-identified patient records, we analyzed demographics, diagnoses, treatments,
services, costs, and charges with machine learning models (Decision Tree,
Logistic Regression, Random Forest, Adaboost, LightGBM) and Python tools
(Spark, AWS clusters, dimensionality reduction). Our model predicts patient
length of stay (LoS) upon admission using supervised learning algorithms. This
hybrid approach enables the identification of key factors influencing LoS,
offering a robust framework for hospitals to streamline patient flow and
resource utilization. The research focuses on patient flow, corroborating the
efficacy of the approach, illustrating decreased patient length of stay within
a real healthcare environment. The findings underscore the potential of hybrid
data-driven models in transforming hospital management practices. This
innovative methodology provides generally flexible decision-making, training,
and patient flow enhancement; such a system could have huge implications for
healthcare administration and overall satisfaction with healthcare.",http://arxiv.org/pdf/2501.18535v1,,False
adabmDCA 2.0 -- a flexible but easy-to-use package for Direct Coupling Analysis,30/01/2025,"Lorenzo Rosset, Roberto Netti, Anna Paola Muntoni, Martin Weigt, Francesco Zamponi","In this methods article, we provide a flexible but easy-to-use implementation
of Direct Coupling Analysis (DCA) based on Boltzmann machine learning, together
with a tutorial on how to use it. The package \texttt{adabmDCA 2.0} is
available in different programming languages (C++, Julia, Python) usable on
different architectures (single-core and multi-core CPU, GPU) using a common
front-end interface. In addition to several learning protocols for dense and
sparse generative DCA models, it allows to directly address common downstream
tasks like residue-residue contact prediction, mutational-effect prediction,
scoring of sequence libraries and generation of artificial sequences for
sequence design. It is readily applicable to protein and RNA sequence data.",http://arxiv.org/pdf/2501.18456v1,,False
DeepExtractor: Time-domain reconstruction of signals and glitches in gravitational wave data with deep learning,30/01/2025,"Tom Dooney, Harsh Narola, Stefano Bromuri, R. Lyana Curier, Chris Van Den Broeck, Sarah Caudill, Daniel Stanley Tan","Gravitational wave (GW) interferometers, detect faint signals from distant
astrophysical events, such as binary black hole mergers. However, their high
sensitivity also makes them susceptible to background noise, which can obscure
these signals. This noise often includes transient artifacts called ""glitches""
that can mimic astrophysical signals or mask their characteristics. Fast and
accurate reconstruction of both signals and glitches is crucial for reliable
scientific inference. In this study, we present DeepExtractor, a deep learning
framework designed to reconstruct signals and glitches with power exceeding
interferometer noise, regardless of their source. We design DeepExtractor to
model the inherent noise distribution of GW interferometers, following
conventional assumptions that the noise is Gaussian and stationary over short
time scales. It operates by predicting and subtracting the noise component of
the data, retaining only the clean reconstruction. Our approach achieves
superior generalization capabilities for arbitrary signals and glitches
compared to methods that directly map inputs to the clean training waveforms.
We validate DeepExtractor's effectiveness through three experiments: (1)
reconstructing simulated glitches injected into simulated detector noise, (2)
comparing performance with the state-of-the-art BayesWave algorithm, and (3)
analyzing real data from the Gravity Spy dataset to demonstrate effective
glitch subtraction from LIGO strain data. DeepExtractor achieves a median
mismatch of only 0.9% for simulated glitches, outperforming several deep
learning baselines. Additionally, DeepExtractor surpasses BayesWave in glitch
recovery, offering a dramatic computational speedup by reconstructing one
glitch sample in approx. 0.1 seconds on a CPU, compared to BayesWave's
processing time of approx. one hour per glitch.",http://arxiv.org/pdf/2501.18423v1,,False
GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing,30/01/2025,"Shuyin Xia, Xiaoyu Lian, Binbin Sang, Guoyin Wang, Xinbo Gao","Fuzzy rough set theory is effective for processing datasets with complex
attributes, supported by a solid mathematical foundation and closely linked to
kernel methods in machine learning. Attribute reduction algorithms and
classifiers based on fuzzy rough set theory exhibit promising performance in
the analysis of high-dimensional multivariate complex data. However, most
existing models operate at the finest granularity, rendering them inefficient
and sensitive to noise, especially for high-dimensional big data. Thus,
enhancing the robustness of fuzzy rough set models is crucial for effective
feature selection. Muiti-garanularty granular-ball computing, a recent
development, uses granular-balls of different sizes to adaptively represent and
cover the sample space, performing learning based on these granular-balls. This
paper proposes integrating multi-granularity granular-ball computing into fuzzy
rough set theory, using granular-balls to replace sample points. The
coarse-grained characteristics of granular-balls make the model more robust.
Additionally, we propose a new method for generating granular-balls, scalable
to the entire supervised method based on granular-ball computing. A forward
search algorithm is used to select feature sequences by defining the
correlation between features and categories through dependence functions.
Experiments demonstrate the proposed model's effectiveness and superiority over
baseline methods.",http://arxiv.org/pdf/2501.18413v1,,False
Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents,30/01/2025,"Nolan Koblischke, Hyunseok Jang, Kristen Menou, Mohamad Ali-Dib","Modern science emerged from reasoning over repeatedly-observed planetary
motions. We present Gravity-Bench-v1, an environment-based benchmark that
challenges AI agents on tasks that parallel this historical development.
Gravity-Bench-v1 evaluates agents on the discovery of physics concealed within
a dynamic environment, using rigorous gravitational dynamics simulations.
Gravity-Bench includes out-of-distribution cases, i.e. with physics that
deviates from the real world, to evaluate true scientific generalization
capabilities. Agents must plan to collect data within an experimental budget
and must perform a dynamic form of data analysis and reasoning to solve tasks
efficiently. Our benchmark admits an open-ended space of solutions. PhD-level
solutions for each task are provided, to calibrate AI performance against human
expertise. Technically at an upper-undergraduate level, our benchmark proves
challenging to baseline AI agents. Gravity-Bench-v1 and planned extensions
should help map out AI progress towards scientific discovery capabilities.",http://arxiv.org/pdf/2501.18411v1,,False
Segmentation of cracks in 3d images of fiber reinforced concrete using deep learning,30/01/2025,"Anna Nowacka, Katja Schladitz, Szymon Grzesiak, Matthias Pahn","Cracks in concrete structures are very common and are an integral part of
this heterogeneous material. Characteristics of cracks induced by standardized
tests yield valuable information about the tested concrete formulation and its
mechanical properties. Observing cracks on the surface of the concrete
structure leaves a wealth of structural information unused. Computed tomography
enables looking into the sample without interfering or destroying the
microstructure. The reconstructed tomographic images are 3d images, consisting
of voxels whose gray values represent local X-ray absorption. In order to
identify voxels belonging to the crack, so to segment the crack structure in
the images, appropriate algorithms need to be developed. Convolutional neural
networks are known to solve this type of task very well given enough and
consistent training data. We adapted a 3d version of the well-known U-Net and
trained it on semi-synthetic 3d images of real concrete samples equipped with
simulated crack structures. Here, we explain the general approach. Moreover, we
show how to teach the network to detect also real crack systems in 3d images of
varying types of real concrete, in particular of fiber reinforced concrete.",http://arxiv.org/pdf/2501.18405v1,,False
A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series,30/01/2025,"Yifan Wang, Hongfeng Ai, Ruiqi Li, Maowei Jiang, Cheng Jiang, Chenzhong Li","In medical time series disease diagnosis, two key challenges are
identified.First, the high annotation cost of medical data leads to overfitting
in models trained on label-limited, single-center datasets. To address this, we
propose incorporating external data from related tasks and leveraging AE-GAN to
extract prior knowledge,providing valuable references for downstream tasks.
Second, many existing studies employ contrastive learning to derive more
generalized medical sequence representations for diagnostic tasks, usually
relying on manually designed diverse positive and negative sample
pairs.However, these approaches are complex, lack generalizability, and fail to
adaptively capture disease-specific features across different conditions.To
overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),
a framework that integrates a multi-head attention mechanism and adaptively
learns representations from different views through inter-view and intra-view
contrastive learning strategies.Additionally, the pre-trained AE-GAN is used to
reconstruct discrepancies in the target data as disease probabilities, which
are then integrated into the contrastive learning process.Experiments on three
target datasets demonstrate that our method consistently outperforms seven
other baselines, highlighting its significant impact on healthcare applications
such as the diagnosis of myocardial infarction, Alzheimer's disease, and
Parkinson's disease.",http://arxiv.org/pdf/2501.18367v1,,False
State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence,30/01/2025,Thea Aviss,"We introduce the State Stream Transformer (SST), a novel LLM architecture
that reveals emergent reasoning behaviours and capabilities latent in
pretrained weights through addressing a fundamental limitation in traditional
transformer models: the lack of latent computational continuity across
autoregressive generations in the state space. SST introduces a sliding window
latent state (FFN) cache with weighted decay that maintains and evolves
persistent latent processes throughout autoregressive generations. Through
controlled experiments comparing base and SST architectures using the same
frozen weights, we demonstrate that this architectural modification alone
enables enhanced reasoning capabilities which appear best explained by some
form of potential higher-order processing, as evidenced by emergent
metacognitive behaviours. These behaviours persist under controlled conditions
designed to eliminate confounding factors such as stochastic variation or
learned response patterns. Analysis of latent state distributions and
processing dynamics provides evidence that it is solely the 'state stream' that
is responsible for these phenomena. In quantitative evaluations, the SST
achieves substantial performance improvements over the base model on two
reasoning benchmarks, reaching 89.01\% accuracy on GSM-8K (0-shot) and 91.04\%
on ARC Challenge (0-shot CoT). These findings indicate that persistent
computation in the latent state space enables fundamentally different
information processing and internal reasoning strategies, with implications for
our understanding of artificial intelligence systems.",http://arxiv.org/pdf/2501.18356v1,,False
A Unified Perspective on the Dynamics of Deep Transformers,30/01/2025,"Valérie Castin, Pierre Ablin, José Antonio Carrillo, Gabriel Peyré","Transformers, which are state-of-the-art in most machine learning tasks,
represent the data as sequences of vectors called tokens. This representation
is then exploited by the attention function, which learns dependencies between
tokens and is key to the success of Transformers. However, the iterative
application of attention across layers induces complex dynamics that remain to
be fully understood. To analyze these dynamics, we identify each input sequence
with a probability measure and model its evolution as a Vlasov equation called
Transformer PDE, whose velocity field is non-linear in the probability measure.
Our first set of contributions focuses on compactly supported initial data. We
show the Transformer PDE is well-posed and is the mean-field limit of an
interacting particle system, thus generalizing and extending previous analysis
to several variants of self-attention: multi-head attention, L2 attention,
Sinkhorn attention, Sigmoid attention, and masked attention--leveraging a
conditional Wasserstein framework. In a second set of contributions, we are the
first to study non-compactly supported initial conditions, by focusing on
Gaussian initial data. Again for different types of attention, we show that the
Transformer PDE preserves the space of Gaussian measures, which allows us to
analyze the Gaussian case theoretically and numerically to identify typical
behaviors. This Gaussian analysis captures the evolution of data anisotropy
through a deep Transformer. In particular, we highlight a clustering phenomenon
that parallels previous results in the non-normalized discrete case.",http://arxiv.org/pdf/2501.18322v1,,False
CueTip: An Interactive and Explainable Physics-aware Pool Assistant,30/01/2025,"Sean Memery, Kevin Denamganai, Jiaxin Zhang, Zehai Tu, Yiwen Guo, Kartic Subr","We present an interactive and explainable automated coaching assistant called
CueTip for a variant of pool/billiards. CueTip's novelty lies in its
combination of three features: a natural-language interface, an ability to
perform contextual, physics-aware reasoning, and that its explanations are
rooted in a set of predetermined guidelines developed by domain experts. We
instrument a physics simulator so that it generates event traces in natural
language alongside traditional state traces. Event traces lend themselves to
interpretation by language models, which serve as the interface to our
assistant. We design and train a neural adaptor that decouples tactical choices
made by CueTip from its interactivity and explainability allowing it to be
reconfigured to mimic any pool playing agent. Our experiments show that CueTip
enables contextual query-based assistance and explanations while maintaining
the strength of the agent in terms of win rate (improving it in some
situations). The explanations generated by CueTip are physically-aware and
grounded in the expert rules and are therefore more reliable.",http://arxiv.org/pdf/2501.18291v1,,False
Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition,30/01/2025,"Arthur Hoarau, Benjamin Quost, Sébastien Destercke, Willem Waegeman","To generate accurate and reliable predictions, modern AI systems need to
combine data from multiple modalities, such as text, images, audio,
spreadsheets, and time series. Multi-modal data introduces new opportunities
and challenges for disentangling uncertainty: it is commonly assumed in the
machine learning community that epistemic uncertainty can be reduced by
collecting more data, while aleatoric uncertainty is irreducible. However, this
assumption is challenged in modern AI systems when information is obtained from
different modalities. This paper introduces an innovative data acquisition
framework where uncertainty disentanglement leads to actionable decisions,
allowing sampling in two directions: sample size and data modality. The main
hypothesis is that aleatoric uncertainty decreases as the number of modalities
increases, while epistemic uncertainty decreases by collecting more
observations. We provide proof-of-concept implementations on two multi-modal
datasets to showcase our data acquisition framework, which combines ideas from
active learning, active feature acquisition and uncertainty quantification.",http://arxiv.org/pdf/2501.18268v1,,False
DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification,30/01/2025,"Siyuan Jiang, Yihan Hu, Wenjie Li, Pengcheng Zeng","Functional data analysis (FDA) is essential for analyzing continuous,
high-dimensional data, yet existing methods often decouple functional
registration and classification, limiting their efficiency and performance. We
present DeepFRC, an end-to-end deep learning framework that unifies these tasks
within a single model. Our approach incorporates an alignment module that
learns time warping functions via elastic function registration and a learnable
basis representation module for dimensionality reduction on aligned data. This
integration enhances both alignment accuracy and predictive performance.
Theoretical analysis establishes that DeepFRC achieves low misalignment and
generalization error, while simulations elucidate the progression of
registration, reconstruction, and classification during training. Experiments
on real-world datasets demonstrate that DeepFRC consistently outperforms
state-of-the-art methods, particularly in addressing complex registration
challenges. Code is available at: https://github.com/Drivergo-93589/DeepFRC.",http://arxiv.org/pdf/2501.18116v1,,False
Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge,30/01/2025,"Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, Tianlu Wang","LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to
capture the step-bystep reasoning process that underlies the final evaluation
of a response. However, due to the lack of human annotated CoTs for evaluation,
the required components and structure of effective reasoning traces remain
understudied. Consequently, previous approaches often (1) constrain reasoning
traces to hand-designed components, such as a list of criteria, reference
answers, or verification questions and (2) structure them such that planning is
intertwined with the reasoning for evaluation. In this work, we propose
EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge
that first generates an unconstrained evaluation plan, followed by its
execution, and then the final judgment. In a self-training loop, EvalPlanner
iteratively optimizes over synthetically constructed evaluation plans and
executions, leading to better final verdicts. Our method achieves a new
state-of-the-art performance for generative reward models on RewardBench (with
a score of 93.9), despite being trained on fewer amount of, and synthetically
generated, preference pairs. Additional experiments on other benchmarks like
RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both
planning and reasoning for building robust LLM-as-a-Judge reasoning models.",http://arxiv.org/pdf/2501.18099v1,,False
