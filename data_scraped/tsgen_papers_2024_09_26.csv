Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
"Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset",25/09/2024,"Andrew Goldberg, Kavish Kondap, Tianshuang Qiu, Zehan Ma, Letian Fu, Justin Kerr, Huang Huang, Kaiyuan Chen, Kuan Fang, Ken Goldberg","Generative AI systems have shown impressive capabilities in creating text,
code, and images. Inspired by the rich history of research in industrial
''Design for Assembly'', we introduce a novel problem: Generative
Design-for-Robot-Assembly (GDfRA). The task is to generate an assembly based on
a natural language prompt (e.g., ''giraffe'') and an image of available
physical components, such as 3D-printed blocks. The output is an assembly, a
spatial arrangement of these components, and instructions for a robot to build
this assembly. The output must 1) resemble the requested object and 2) be
reliably assembled by a 6 DoF robot arm with a suction gripper. We then present
Blox-Net, a GDfRA system that combines generative vision language models with
well-established methods in computer vision, simulation, perturbation analysis,
motion planning, and physical robot experimentation to solve a class of GDfRA
problems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of
63.5% in the ''recognizability'' of its designed assemblies (eg, resembling
giraffe as judged by a VLM). These designs, after automated perturbation
redesign, were reliably assembled by a robot, achieving near-perfect success
across 10 consecutive assembly iterations with human intervention only during
reset prior to assembly. Surprisingly, this entire design process from textual
word (''giraffe'') to reliable physical assembly is performed with zero human
intervention.",http://arxiv.org/pdf/2409.17126v1,,False
Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification,25/09/2024,"Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni","In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.",http://arxiv.org/pdf/2409.17091v1,,False
SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking,25/09/2024,"Luigi Russo, Francesco Mauro, Alessandro Sebastianelli, Paolo Gamba, Silvia Liberata Ullo","Climate change and increasing droughts pose significant challenges to water
resource management around the world. These problems lead to severe water
shortages that threaten ecosystems, agriculture, and human communities. To
advance the fight against these challenges, we present a new dataset,
SEN12-WATER, along with a benchmark using a novel end-to-end Deep Learning (DL)
framework for proactive drought-related analysis. The dataset, identified as a
spatiotemporal datacube, integrates SAR polarization, elevation, slope, and
multispectral optical bands. Our DL framework enables the analysis and
estimation of water losses over time in reservoirs of interest, revealing
significant insights into water dynamics for drought analysis by examining
temporal changes in physical quantities such as water volume. Our methodology
takes advantage of the multitemporal and multimodal characteristics of the
proposed dataset, enabling robust generalization and advancing understanding of
drought, contributing to climate change resilience and sustainable water
resource management. The proposed framework involves, among the several
components, speckle noise removal from SAR data, a water body segmentation
through a U-Net architecture, the time series analysis, and the predictive
capability of a Time-Distributed-Convolutional Neural Network (TD-CNN). Results
are validated through ground truth data acquired on-ground via dedicated
sensors and (tailored) metrics, such as Precision, Recall, Intersection over
Union, Mean Squared Error, Structural Similarity Index Measure and Peak
Signal-to-Noise Ratio.",http://arxiv.org/pdf/2409.17087v1,,False
ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis,25/09/2024,"Fangshuo Zhou, Huaxia Li, Rui Hu, Sensen Wu, Hailin Feng, Zhenhong Du, Liuchang Xu","Volunteer Geographic Information (VGI), with its rich variety, large volume,
rapid updates, and diverse sources, has become a critical source of geospatial
data. However, VGI data from platforms like OSM exhibit significant quality
heterogeneity across different data types, particularly with urban building
data. To address this, we propose a multi-source geographic data transformation
solution, utilizing accessible and complete VGI data to assist in generating
urban building footprint data. We also employ a multimodal data generation
framework to improve accuracy. First, we introduce a pipeline for constructing
an 'image-text-metadata-building footprint' dataset, primarily based on road
network data and supplemented by other multimodal data. We then present
ControlCity, a geographic data transformation method based on a multimodal
diffusion model. This method first uses a pre-trained text-to-image model to
align text, metadata, and building footprint data. An improved ControlNet
further integrates road network and land-use imagery, producing refined
building footprint data. Experiments across 22 global cities demonstrate that
ControlCity successfully simulates real urban building patterns, achieving
state-of-the-art performance. Specifically, our method achieves an average FID
score of 50.94, reducing error by 71.01% compared to leading methods, and a
MIoU score of 0.36, an improvement of 38.46%. Additionally, our model excels in
tasks like urban morphology transfer, zero-shot city generation, and spatial
data completeness assessment. In the zero-shot city task, our method accurately
predicts and generates similar urban structures, demonstrating strong
generalization. This study confirms the effectiveness of our approach in
generating urban building footprint data and capturing complex city
characteristics.",http://arxiv.org/pdf/2409.17049v1,,False
Counterfactual Token Generation in Large Language Models,25/09/2024,"Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, Manuel Gomez-Rodriguez","""Sure, I am happy to generate a story for you: Captain Lyra stood at the helm
of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]
Lyra's eyes welled up with tears as she realized the bitter truth - she had
sacrificed everything for fleeting riches, and lost the love of her crew, her
family, and herself."" Although this story, generated by a large language model,
is captivating, one may wonder -- how would the story have unfolded if the
model had chosen ""Captain Maeve"" as the protagonist instead? We cannot know.
State-of-the-art large language models are stateless -- they maintain no
internal memory or state. Given a prompt, they generate a sequence of tokens as
an output using an autoregressive process. As a consequence, they cannot reason
about counterfactual alternatives to tokens they have generated in the past. In
this work, our goal is to enhance them with this functionality. To this end, we
develop a causal model of token generation that builds upon the Gumbel-Max
structural causal model. Our model allows any large language model to perform
counterfactual token generation at almost no cost in comparison with vanilla
token generation, it is embarrassingly simple to implement, and it does not
require any fine-tuning nor prompt engineering. We implement our model on Llama
3 8B-instruct and conduct both qualitative and quantitative analyses of
counterfactually generated text. We conclude with a demonstrative application
of counterfactual token generation for bias detection, unveiling interesting
insights about the model of the world constructed by large language models.",http://arxiv.org/pdf/2409.17027v1,,False
INT-FlashAttention: Enabling Flash Attention for INT8 Quantization,25/09/2024,"Shimao Chen, Zirui Liu, Zhiying Wu, Ce Zheng, Peizhuang Cong, Zihan Jiang, Lei Su, Tong Yang","As the foundation of large language models (LLMs), self-attention module
faces the challenge of quadratic time and memory complexity with respect to
sequence length. FlashAttention accelerates attention computation and reduces
its memory usage by leveraging the GPU memory hierarchy. A promising research
direction is to integrate FlashAttention with quantization methods. This paper
introduces INT-FlashAttention, the first INT8 quantization architecture
compatible with the forward workflow of FlashAttention, which significantly
improves the inference speed of FlashAttention on Ampere GPUs. We implement our
INT-FlashAttention prototype with fully INT8 activations and general
matrix-multiplication (GEMM) kernels, making it the first attention operator
with fully INT8 input. As a general token-level post-training quantization
framework, INT-FlashAttention is also compatible with other data formats like
INT4, etc. Experimental results show INT-FlashAttention achieves 72% faster
inference speed and 82% smaller quantization error compared to standard
FlashAttention with FP16 and FP8 data format.",http://arxiv.org/pdf/2409.16997v1,,False
Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion,25/09/2024,"Vineet Punyamoorty, Pascal Jutras-Dubé, Ruqi Zhang, Vaneet Aggarwal, Damon Conover, Aniket Bera","By framing reinforcement learning as a sequence modeling problem, recent work
has enabled the use of generative models, such as diffusion models, for
planning. While these models are effective in predicting long-horizon state
trajectories in deterministic environments, they face challenges in dynamic
settings with moving obstacles. Effective collision avoidance demands
continuous monitoring and adaptive decision-making. While replanning at every
timestep could ensure safety, it introduces substantial computational overhead
due to the repetitive prediction of overlapping state sequences -- a process
that is particularly costly with diffusion models, known for their intensive
iterative sampling procedure. We propose an adaptive generative planning
approach that dynamically adjusts replanning frequency based on the uncertainty
of action predictions. Our method minimizes the need for frequent,
computationally expensive, and redundant replanning while maintaining robust
collision avoidance performance. In experiments, we obtain a 13.5% increase in
the mean trajectory length and a 12.7% increase in mean reward over
long-horizon planning, indicating a reduction in collision rates and an
improved ability to navigate the environment safely.",http://arxiv.org/pdf/2409.16950v1,,False
OffRIPP: Offline RL-based Informative Path Planning,25/09/2024,"Srikar Babu Gadipudi, Srujan Deolasee, Siva Kailas, Wenhao Luo, Katia Sycara, Woojun Kim","Informative path planning (IPP) is a crucial task in robotics, where agents
must design paths to gather valuable information about a target environment
while adhering to resource constraints. Reinforcement learning (RL) has been
shown to be effective for IPP, however, it requires environment interactions,
which are risky and expensive in practice. To address this problem, we propose
an offline RL-based IPP framework that optimizes information gain without
requiring real-time interaction during training, offering safety and
cost-efficiency by avoiding interaction, as well as superior performance and
fast computation during execution -- key advantages of RL. Our framework
leverages batch-constrained reinforcement learning to mitigate extrapolation
errors, enabling the agent to learn from pre-collected datasets generated by
arbitrary algorithms. We validate the framework through extensive simulations
and real-world experiments. The numerical results show that our framework
outperforms the baselines, demonstrating the effectiveness of the proposed
approach.",http://arxiv.org/pdf/2409.16830v1,,False
Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability,25/09/2024,"Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters","Optimal decision-making under partial observability requires reasoning about
the uncertainty of the environment's hidden state. However, most reinforcement
learning architectures handle partial observability with sequence models that
have no internal mechanism to incorporate uncertainty in their hidden state
representation, such as recurrent neural networks, deterministic state-space
models and transformers. Inspired by advances in probabilistic world models for
reinforcement learning, we propose a standalone Kalman filter layer that
performs closed-form Gaussian inference in linear state-space models and train
it end-to-end within a model-free architecture to maximize returns. Similar to
efficient linear recurrent layers, the Kalman filter layer processes sequential
data using a parallel scan, which scales logarithmically with the sequence
length. By design, Kalman filter layers are a drop-in replacement for other
recurrent layers in standard model-free architectures, but importantly they
include an explicit mechanism for probabilistic filtering of the latent state
representation. Experiments in a wide variety of tasks with partial
observability show that Kalman filter layers excel in problems where
uncertainty reasoning is key for decision-making, outperforming other stateful
models.",http://arxiv.org/pdf/2409.16824v1,,False
A parametric framework for kernel-based dynamic mode decomposition using deep learning,25/09/2024,"Konstantinos Kevopoulos, Dongwei Ye","Surrogate modelling is widely applied in computational science and
engineering to mitigate computational efficiency issues for the real-time
simulations of complex and large-scale computational models or for many-query
scenarios, such as uncertainty quantification and design optimisation. In this
work, we propose a parametric framework for kernel-based dynamic mode
decomposition method based on the linear and nonlinear disambiguation
optimization (LANDO) algorithm. The proposed parametric framework consists of
two stages, offline and online. The offline stage prepares the essential
component for prediction, namely a series of LANDO models that emulate the
dynamics of the system with particular parameters from a training dataset. The
online stage leverages those LANDO models to generate new data at a desired
time instant, and approximate the mapping between parameters and the state with
the data using deep learning techniques. Moreover, dimensionality reduction
technique is applied to high-dimensional dynamical systems to reduce the
computational cost of training. Three numerical examples including
Lotka-Volterra model, heat equation and reaction-diffusion equation are
presented to demonstrate the efficiency and effectiveness of the proposed
framework.",http://arxiv.org/pdf/2409.16817v1,,False
Interpreting Deep Neural Network-Based Receiver Under Varying Signal-To-Noise Ratios,25/09/2024,"Marko Tuononen, Dani Korpi, Ville Hautamäki","We propose a novel method for interpreting neural networks, focusing on
convolutional neural network-based receiver model. The method identifies which
unit or units of the model contain most (or least) information about the
channel parameter(s) of the interest, providing insights at both global and
local levels -- with global explanations aggregating local ones. Experiments on
link-level simulations demonstrate the method's effectiveness in identifying
units that contribute most (and least) to signal-to-noise ratio processing.
Although we focus on a radio receiver model, the method generalizes to other
neural network architectures and applications, offering robust estimation even
in high-dimensional settings.",http://arxiv.org/pdf/2409.16768v1,,False
"MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features",25/09/2024,"Katharina Anderer, Andreas Reich, Matthias Wölfel","This paper presents a benchmark dataset for aligning lecture videos with
corresponding slides and introduces a novel multimodal algorithm leveraging
features from speech, text, and images. It achieves an average accuracy of 0.82
in comparison to SIFT (0.56) while being approximately 11 times faster. Using
dynamic programming the algorithm tries to determine the optimal slide
sequence. The results show that penalizing slide transitions increases
accuracy. Features obtained via optical character recognition (OCR) contribute
the most to a high matching accuracy, followed by image features. The findings
highlight that audio transcripts alone provide valuable information for
alignment and are beneficial if OCR data is lacking. Variations in matching
accuracy across different lectures highlight the challenges associated with
video quality and lecture style. The novel multimodal algorithm demonstrates
robustness to some of these challenges, underscoring the potential of the
approach.",http://arxiv.org/pdf/2409.16765v1,10.21437/Interspeech.2024-978,False
Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models,25/09/2024,"Alexander Popov, Alperen Degirmenci, David Wehr, Shashank Hegde, Ryan Oldja, Alexey Kamenev, Bertrand Douillard, David Nistér, Urs Muller, Ruchi Bhargava, Stan Birchfield, Nikolai Smolyanskiy","We propose the use of latent space generative world models to address the
covariate shift problem in autonomous driving. A world model is a neural
network capable of predicting an agent's next state given past states and
actions. By leveraging a world model during training, the driving policy
effectively mitigates covariate shift without requiring an excessive amount of
training data. During end-to-end training, our policy learns how to recover
from errors by aligning with states observed in human demonstrations, so that
at runtime it can recover from perturbations outside the training distribution.
Additionally, we introduce a novel transformer-based perception encoder that
employs multi-view cross-attention and a learned scene query. We present
qualitative and quantitative results, demonstrating significant improvements
upon prior state of the art in closed-loop testing in the CARLA simulator, as
well as showing the ability to handle perturbations in both CARLA and NVIDIA's
DRIVE Sim.",http://arxiv.org/pdf/2409.16663v1,,False
The Credibility Transformer,25/09/2024,"Ronald Richman, Salvatore Scognamiglio, Mario V. Wüthrich","Inspired by the large success of Transformers in Large Language Models, these
architectures are increasingly applied to tabular data. This is achieved by
embedding tabular data into low-dimensional Euclidean spaces resulting in
similar structures as time-series data. We introduce a novel credibility
mechanism to this Transformer architecture. This credibility mechanism is based
on a special token that should be seen as an encoder that consists of a
credibility weighted average of prior information and observation based
information. We demonstrate that this novel credibility mechanism is very
beneficial to stabilize training, and our Credibility Transformer leads to
predictive models that are superior to state-of-the-art deep learning models.",http://arxiv.org/pdf/2409.16653v1,,False
Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data,25/09/2024,"Kota Dohi, Aoi Ito, Harsh Purohit, Tomoya Nishida, Takashi Endo, Yohei Kawaguchi","Due to scarcity of time-series data annotated with descriptive texts,
training a model to generate descriptive texts for time-series data is
challenging. In this study, we propose a method to systematically generate
domain-independent descriptive texts from time-series data. We identify two
distinct approaches for creating pairs of time-series data and descriptive
texts: the forward approach and the backward approach. By implementing the
novel backward approach, we create the Temporal Automated Captions for
Observations (TACO) dataset. Experimental results demonstrate that a
contrastive learning based model trained using the TACO dataset is capable of
generating descriptive texts for time-series data in novel domains.",http://arxiv.org/pdf/2409.16647v1,,False
Functional Stochastic Gradient MCMC for Bayesian Neural Networks,25/09/2024,"Mengjing Wu, Junyu Xuan, Jie Lu","Classical variational inference for Bayesian neural networks (BNNs) in
parameter space usually suffers from unresolved prior issues such as knowledge
encoding intractability and pathological behaviors in deep networks, which
could lead to an improper posterior inference. Hence, functional variational
inference has been proposed recently to resolve these issues via stochastic
process priors. Beyond variational inference, stochastic gradient Markov Chain
Monte Carlo (SGMCMC) is another scalable and effective inference method for
BNNs to asymptotically generate samples from true posterior by simulating a
continuous dynamic. However, the existing SGMCMC methods only work in
parametric space, which has the same issues of parameter-space variational
inference, and extending the parameter-space dynamics to function-space
dynamics is not a trivial undertaking. In this paper, we introduce a new
functional SGMCMC scheme via newly designed diffusion dynamics, which can
incorporate more informative functional priors. Moreover, we prove that the
stationary distribution of these functional dynamics is the target posterior
distribution over functions. We demonstrate better performance in both accuracy
and uncertainty quantification of our functional SGMCMC on several tasks
compared with naive SGMCMC and functional variational inference methods.",http://arxiv.org/pdf/2409.16632v1,,False
ECG-Image-Database: A Dataset of ECG Images with Real-World Imaging and Scanning Artifacts; A Foundation for Computerized ECG Image Digitization and Analysis,25/09/2024,"Matthew A. Reyna, Deepanshi, James Weigle, Zuzana Koscova, Kiersten Campbell, Kshama Kodthalu Shivashankara, Soheil Saghafi, Sepideh Nikookar, Mohsen Motie-Shirazi, Yashar Kiarashi, Salman Seyedi, Gari D. Clifford, Reza Sameni","We introduce the ECG-Image-Database, a large and diverse collection of
electrocardiogram (ECG) images generated from ECG time-series data, with
real-world scanning, imaging, and physical artifacts. We used ECG-Image-Kit, an
open-source Python toolkit, to generate realistic images of 12-lead ECG
printouts from raw ECG time-series. The images include realistic distortions
such as noise, wrinkles, stains, and perspective shifts, generated both
digitally and physically. The toolkit was applied to 977 12-lead ECG records
from the PTB-XL database and 1,000 from Emory Healthcare to create
high-fidelity synthetic ECG images. These unique images were subjected to both
programmatic distortions using ECG-Image-Kit and physical effects like soaking,
staining, and mold growth, followed by scanning and photography under various
lighting conditions to create real-world artifacts.
  The resulting dataset includes 35,595 software-labeled ECG images with a wide
range of imaging artifacts and distortions. The dataset provides ground truth
time-series data alongside the images, offering a reference for developing
machine and deep learning models for ECG digitization and classification. The
images vary in quality, from clear scans of clean papers to noisy photographs
of degraded papers, enabling the development of more generalizable digitization
algorithms.
  ECG-Image-Database addresses a critical need for digitizing paper-based and
non-digital ECGs for computerized analysis, providing a foundation for
developing robust machine and deep learning models capable of converting ECG
images into time-series. The dataset aims to serve as a reference for ECG
digitization and computerized annotation efforts. ECG-Image-Database was used
in the PhysioNet Challenge 2024 on ECG image digitization and classification.",http://arxiv.org/pdf/2409.16612v1,,False
Random Forest Regression Feature Importance for Climate Impact Pathway Detection,25/09/2024,"Meredith G. L. Brown, Matt Peterson, Irina Tezaur, Kara Peterson, Diana Bull","Disturbances to the climate system, both natural and anthropogenic, have far
reaching impacts that are not always easy to identify or quantify using
traditional climate science analyses or causal modeling techniques. In this
paper, we develop a novel technique for discovering and ranking the chain of
spatio-temporal downstream impacts of a climate source, referred to herein as a
source-impact pathway, using Random Forest Regression (RFR) and SHapley
Additive exPlanation (SHAP) feature importances. Rather than utilizing RFR for
classification or regression tasks (the most common use case for RFR), we
propose a fundamentally new RFR-based workflow in which we: (i) train random
forest (RF) regressors on a set of spatio-temporal features of interest, (ii)
calculate their pair-wise feature importances using the SHAP weights associated
with those features, and (iii) translate these feature importances into a
weighted pathway network (i.e., a weighted directed graph), which can be used
to trace out and rank interdependencies between climate features and/or
modalities. We adopt a tiered verification approach to verify our new pathway
identification methodology. In this approach, we apply our method to ensembles
of data generated by running two increasingly complex benchmarks: (i) a set of
synthetic coupled equations, and (ii) a fully coupled simulation of the 1991
eruption of Mount Pinatubo in the Philippines performed using a modified
version 2 of the U.S. Department of Energy's Energy Exascale Earth System Model
(E3SMv2). We find that our RFR feature importance-based approach can accurately
detect known pathways of impact for both test cases.",http://arxiv.org/pdf/2409.16609v1,,False
FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning,25/09/2024,"Jiaheng Hu, Rose Hendrix, Ali Farhadi, Aniruddha Kembhavi, Roberto Martin-Martin, Peter Stone, Kuo-Hao Zeng, Kiana Ehsan","In recent years, the Robotics field has initiated several efforts toward
building generalist robot policies through large-scale multi-task Behavior
Cloning. However, direct deployments of these policies have led to
unsatisfactory performance, where the policy struggles with unseen states and
tasks. How can we break through the performance plateau of these models and
elevate their capabilities to new heights? In this paper, we propose FLaRe, a
large-scale Reinforcement Learning fine-tuning framework that integrates robust
pre-trained representations, large-scale training, and gradient stabilization
techniques. Our method aligns pre-trained policies towards task completion,
achieving state-of-the-art (SoTA) performance both on previously demonstrated
and on entirely novel tasks and embodiments. Specifically, on a set of
long-horizon mobile manipulation tasks, FLaRe achieves an average success rate
of 79.5% in unseen environments, with absolute improvements of +23.6% in
simulation and +30.7% on real robots over prior SoTA methods. By utilizing only
sparse rewards, our approach can enable generalizing to new capabilities beyond
the pretraining data with minimal human effort. Moreover, we demonstrate rapid
adaptation to new embodiments and behaviors with less than a day of
fine-tuning. Videos can be found on the project website at
https://robot-flare.github.io/",http://arxiv.org/pdf/2409.16578v1,,False
Efficient and generalizable nested Fourier-DeepONet for three-dimensional geological carbon sequestration,25/09/2024,"Jonathan E. Lee, Min Zhu, Ziqiao Xi, Kun Wang, Yanhua O. Yuan, Lu Lu","Geological carbon sequestration (GCS) involves injecting CO$_2$ into
subsurface geological formations for permanent storage. Numerical simulations
could guide decisions in GCS projects by predicting CO$_2$ migration pathways
and the pressure distribution in storage formation. However, these simulations
are often computationally expensive due to highly coupled physics and large
spatial-temporal simulation domains. Surrogate modeling with data-driven
machine learning has become a promising alternative to accelerate physics-based
simulations. Among these, the Fourier neural operator (FNO) has been applied to
three-dimensional synthetic subsurface models. Here, to further improve
performance, we have developed a nested Fourier-DeepONet by combining the
expressiveness of the FNO with the modularity of a deep operator network
(DeepONet). This new framework is twice as efficient as a nested FNO for
training and has at least 80% lower GPU memory requirement due to its
flexibility to treat temporal coordinates separately. These performance
improvements are achieved without compromising prediction accuracy. In
addition, the generalization and extrapolation ability of nested
Fourier-DeepONet beyond the training range has been thoroughly evaluated.
Nested Fourier-DeepONet outperformed the nested FNO for extrapolation in time
with more than 50% reduced error. It also exhibited good extrapolation accuracy
beyond the training range in terms of reservoir properties, number of wells,
and injection rate.",http://arxiv.org/pdf/2409.16572v1,,False
Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference,25/09/2024,"Zongyue Qin, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun","Large language models (LLMs) have shown outstanding performance across
numerous real-world tasks. However, the autoregressive nature of these models
makes the inference process slow and costly. Speculative decoding has emerged
as a promising solution, leveraging a smaller auxiliary model to draft future
tokens, which are then validated simultaneously by the larger model, achieving
a speed-up of 1-2x. Although speculative decoding matches the same distribution
as multinomial sampling, multinomial sampling itself is prone to suboptimal
outputs, whereas beam sampling is widely recognized for producing
higher-quality results by maintaining multiple candidate sequences at each
step. This paper explores the novel integration of speculative decoding with
beam sampling. However, there are four key challenges: (1) how to generate
multiple sequences from the larger model's distribution given drafts sequences
from the small model; (2) how to dynamically optimize the number of beams to
balance efficiency and accuracy; (3) how to efficiently verify the multiple
drafts in parallel; and (4) how to address the extra memory costs inherent in
beam sampling. To address these challenges, we propose dynamic-width
speculative beam decoding (DSBD). Specifically, we first introduce a novel
draft and verification scheme that generates multiple sequences following the
large model's distribution based on beam sampling trajectories from the small
model. Then, we introduce an adaptive mechanism to dynamically tune the number
of beams based on the context, optimizing efficiency and effectiveness.
Besides, we extend tree-based parallel verification to handle multiple trees
simultaneously, accelerating the verification process. Finally, we illustrate a
simple modification to our algorithm to mitigate the memory overhead of beam
sampling...",http://arxiv.org/pdf/2409.16560v1,,False
EMIT- Event-Based Masked Auto Encoding for Irregular Time Series,25/09/2024,"Hrishikesh Patel, Ruihong Qiu, Adam Irwin, Shazia Sadiq, Sen Wang","Irregular time series, where data points are recorded at uneven intervals,
are prevalent in healthcare settings, such as emergency wards where vital signs
and laboratory results are captured at varying times. This variability, which
reflects critical fluctuations in patient health, is essential for informed
clinical decision-making. Existing self-supervised learning research on
irregular time series often relies on generic pretext tasks like forecasting,
which may not fully utilise the signal provided by irregular time series. There
is a significant need for specialised pretext tasks designed for the
characteristics of irregular time series to enhance model performance and
robustness, especially in scenarios with limited data availability. This paper
proposes a novel pretraining framework, EMIT, an event-based masking for
irregular time series. EMIT focuses on masking-based reconstruction in the
latent space, selecting masking points based on the rate of change in the data.
This method preserves the natural variability and timing of measurements while
enhancing the model's ability to process irregular intervals without losing
essential information. Extensive experiments on the MIMIC-III and PhysioNet
Challenge datasets demonstrate the superior performance of our event-based
masking strategy. The code has been released at
https://github.com/hrishi-ds/EMIT .",http://arxiv.org/pdf/2409.16554v1,,False
Generative AI-driven forecasting of oil production,24/09/2024,"Yash Gandhi, Kexin Zheng, Birendra Jha, Ken-ichi Nomura, Aiichiro Nakano, Priya Vashishta, Rajiv K. Kalia","Forecasting oil production from oilfields with multiple wells is an important
problem in petroleum and geothermal energy extraction, as well as energy
storage technologies. The accuracy of oil forecasts is a critical determinant
of economic projections, hydrocarbon reserves estimation, construction of fluid
processing facilities, and energy price fluctuations. Leveraging generative AI
techniques, we model time series forecasting of oil and water productions
across four multi-well sites spanning four decades. Our goal is to effectively
model uncertainties and make precise forecasts to inform decision-making
processes at the field scale. We utilize an autoregressive model known as
TimeGrad and a variant of a transformer architecture named Informer, tailored
specifically for forecasting long sequence time series data. Predictions from
both TimeGrad and Informer closely align with the ground truth data. The
overall performance of the Informer stands out, demonstrating greater
efficiency compared to TimeGrad in forecasting oil production rates across all
sites.",http://arxiv.org/pdf/2409.16482v1,,False
HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions,24/09/2024,"Xuhui Zhou, Hyunwoo Kim, Faeze Brahman, Liwei Jiang, Hao Zhu, Ximing Lu, Frank Xu, Bill Yuchen Lin, Yejin Choi, Niloofar Mireshghallah, Ronan Le Bras, Maarten Sap","AI agents are increasingly autonomous in their interactions with human users
and tools, leading to increased interactional safety risks. We present
HAICOSYSTEM, a framework examining AI agent safety within diverse and complex
social interactions. HAICOSYSTEM features a modular sandbox environment that
simulates multi-turn interactions between human users and AI agents, where the
AI agents are equipped with a variety of tools (e.g., patient management
platforms) to navigate diverse scenarios (e.g., a user attempting to access
other patients' profiles). To examine the safety of AI agents in these
interactions, we develop a comprehensive multi-dimensional evaluation framework
that uses metrics covering operational, content-related, societal, and legal
risks. Through running 1840 simulations based on 92 scenarios across seven
domains (e.g., healthcare, finance, education), we demonstrate that HAICOSYSTEM
can emulate realistic user-AI interactions and complex tool use by AI agents.
Our experiments show that state-of-the-art LLMs, both proprietary and
open-sourced, exhibit safety risks in over 50\% cases, with models generally
showing higher risks when interacting with simulated malicious users. Our
findings highlight the ongoing challenge of building agents that can safely
navigate complex interactions, particularly when faced with malicious users. To
foster the AI agent safety ecosystem, we release a code platform that allows
practitioners to create custom scenarios, simulate interactions, and evaluate
the safety and performance of their agents.",http://arxiv.org/pdf/2409.16427v1,,False
Rao-Blackwellized POMDP Planning,24/09/2024,"Jiho Lee, Nisar R. Ahmed, Kyle H. Wray, Zachary N. Sunberg","Partially Observable Markov Decision Processes (POMDPs) provide a structured
framework for decision-making under uncertainty, but their application requires
efficient belief updates. Sequential Importance Resampling Particle Filters
(SIRPF), also known as Bootstrap Particle Filters, are commonly used as belief
updaters in large approximate POMDP solvers, but they face challenges such as
particle deprivation and high computational costs as the system's state
dimension grows. To address these issues, this study introduces
Rao-Blackwellized POMDP (RB-POMDP) approximate solvers and outlines generic
methods to apply Rao-Blackwellization in both belief updates and online
planning. We compare the performance of SIRPF and Rao-Blackwellized Particle
Filters (RBPF) in a simulated localization problem where an agent navigates
toward a target in a GPS-denied environment using POMCPOW and RB-POMCPOW
planners. Our results not only confirm that RBPFs maintain accurate belief
approximations over time with fewer particles, but, more surprisingly, RBPFs
combined with quadrature-based integration improve planning quality
significantly compared to SIRPF-based planning under the same computational
limits.",http://arxiv.org/pdf/2409.16392v1,,False
Scalable quantum dynamics compilation via quantum machine learning,24/09/2024,"Yuxuan Zhang, Roeland Wiersema, Juan Carrasquilla, Lukasz Cincio, Yong Baek Kim","Quantum dynamics compilation is an important task for improving quantum
simulation efficiency: It aims to synthesize multi-qubit target dynamics into a
circuit consisting of as few elementary gates as possible. Compared to
deterministic methods such as Trotterization, variational quantum compilation
(VQC) methods employ variational optimization to reduce gate costs while
maintaining high accuracy. In this work, we explore the potential of a VQC
scheme by making use of out-of-distribution generalization results in quantum
machine learning (QML): By learning the action of a given many-body dynamics on
a small data set of product states, we can obtain a unitary circuit that
generalizes to highly entangled states such as the Haar random states. The
efficiency in training allows us to use tensor network methods to compress such
time-evolved product states by exploiting their low entanglement features. Our
approach exceeds state-of-the-art compilation results in both system size and
accuracy in one dimension ($1$D). For the first time, we extend VQC to systems
on two-dimensional (2D) strips with a quasi-1D treatment, demonstrating a
significant resource advantage over standard Trotterization methods,
highlighting the method's promise for advancing quantum simulation tasks on
near-term quantum processors.",http://arxiv.org/pdf/2409.16346v1,,False
Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking,24/09/2024,"Xi Wang, Tianxing Chen, Qiaojun Yu, Tianling Xu, Zanxin Chen, Yiting Fu, Cewu Lu, Yao Mu, Ping Luo","Articulated object manipulation requires precise object interaction, where
the object's axis must be carefully considered. Previous research employed
interactive perception for manipulating articulated objects, but typically,
open-loop approaches often suffer from overlooking the interaction dynamics. To
address this limitation, we present a closed-loop pipeline integrating
interactive perception with online axis estimation from segmented 3D point
clouds. Our method leverages any interactive perception technique as a
foundation for interactive perception, inducing slight object movement to
generate point cloud frames of the evolving dynamic scene. These point clouds
are then segmented using Segment Anything Model 2 (SAM2), after which the
moving part of the object is masked for accurate motion online axis estimation,
guiding subsequent robotic actions. Our approach significantly enhances the
precision and efficiency of manipulation tasks involving articulated objects.
Experiments in simulated environments demonstrate that our method outperforms
baseline approaches, especially in tasks that demand precise axis-based
control. Project Page:
https://hytidel.github.io/video-tracking-for-axis-estimation/.",http://arxiv.org/pdf/2409.16287v1,,False
Transformer based time series prediction of the maximum power point for solar photovoltaic cells,24/09/2024,"Palaash Agrawal, Hari Om Bansal, Aditya R. Gautam, Om Prakash Mahela, Baseem Khan","This paper proposes an improved deep learning based maximum power point
tracking (MPPT) in solar photovoltaic cells considering various time series
based environmental inputs. Generally, artificial neural network based MPPT
algorithms use basic neural network architectures and inputs which do not
represent the ambient conditions in a comprehensive manner. In this article,
the ambient conditions of a location are represented through a comprehensive
set of environmental features. Furthermore, the inclusion of time based
features in the input data is considered to model cyclic patterns temporally
within the atmospheric conditions leading to robust modeling of the MPPT
algorithm. A transformer based deep learning architecture is trained as a time
series prediction model using multidimensional time series input features. The
model is trained on a dataset containing typical meteorological year data
points of ambient weather conditions from 50 locations. The attention mechanism
in the transformer modules allows the model to learn temporal patterns in the
data efficiently. The proposed model achieves a 0.47% mean average percentage
error of prediction on non zero operating voltage points in a test dataset
consisting of data collected over a period of 200 consecutive hours resulting
in the average power efficiency of 99.54% and peak power efficiency of 99.98%.
The proposed model is validated through real time simulations. The proposed
model performs power point tracking in a robust, dynamic, and nonlatent manner,
over a wide range of atmospheric conditions.",http://arxiv.org/pdf/2409.16342v1,10.1002/ese3.1226,False
LLM Echo Chamber: personalized and automated disinformation,24/09/2024,Tony Ma,"Recent advancements have showcased the capabilities of Large Language Models
like GPT4 and Llama2 in tasks such as summarization, translation, and content
review. However, their widespread use raises concerns, particularly around the
potential for LLMs to spread persuasive, humanlike misinformation at scale,
which could significantly influence public opinion. This study examines these
risks, focusing on LLMs ability to propagate misinformation as factual. To
investigate this, we built the LLM Echo Chamber, a controlled digital
environment simulating social media chatrooms, where misinformation often
spreads. Echo chambers, where individuals only interact with like minded
people, further entrench beliefs. By studying malicious bots spreading
misinformation in this environment, we can better understand this phenomenon.
We reviewed current LLMs, explored misinformation risks, and applied sota
finetuning techniques. Using Microsoft phi2 model, finetuned with our custom
dataset, we generated harmful content to create the Echo Chamber. This setup,
evaluated by GPT4 for persuasiveness and harmfulness, sheds light on the
ethical concerns surrounding LLMs and emphasizes the need for stronger
safeguards against misinformation.",http://arxiv.org/pdf/2409.16241v1,,False
MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents,24/09/2024,"Ming Zhu, Yi Zhou","Developing AI agents powered by large language models (LLMs) faces
significant challenges in achieving true Turing completeness and adaptive,
code-driven evolution. Current approaches often generate code independently of
its runtime context, relying heavily on the LLM's memory, which results in
inefficiencies and limits adaptability. Manual protocol development in sandbox
environments further constrains the agent's autonomous adaptability. Crucially,
achieving consistency in code and context across multi-turn interactions and
ensuring isolation of local variables within each interaction remains an
unsolved problem.
  We introduce MOSS (llM-oriented Operating System Simulation), a novel
framework that addresses these challenges by integrating code generation with a
dynamic context management system. MOSS ensures consistency and adaptability by
using a mechanism that maintains the Python context across interactions,
including isolation of local variables and preservation of runtime integrity.
At its core, the framework employs an Inversion of Control (IoC) container in
conjunction with decorators to enforce the least knowledge principle, allowing
agents to focus on abstract interfaces rather than concrete implementations.
This facilitates seamless integration of new tools and libraries, enables
runtime instance replacement, and reduces prompt complexity, providing a ""what
you see is what you get"" environment for the agent.
  Through a series of case studies, we show how this framework can enhance the
efficiency and capabilities of agent development and highlight its advantages
in moving towards Turing-complete agents capable of evolving through code.",http://arxiv.org/pdf/2409.16120v1,,False
Semi-strong Efficient Market of Bitcoin and Twitter: an Analysis of Semantic Vector Spaces of Extracted Keywords and Light Gradient Boosting Machine Models,24/09/2024,"Fang Wang, Marko Gacesa","This study extends the examination of the Efficient-Market Hypothesis in
Bitcoin market during a five year fluctuation period, from September 1 2017 to
September 1 2022, by analyzing 28,739,514 qualified tweets containing the
targeted topic ""Bitcoin"". Unlike previous studies, we extracted fundamental
keywords as an informative proxy for carrying out the study of the EMH in the
Bitcoin market rather than focusing on sentiment analysis, information volume,
or price data. We tested market efficiency in hourly, 4-hourly, and daily time
periods to understand the speed and accuracy of market reactions towards the
information within different thresholds. A sequence of machine learning methods
and textual analyses were used, including measurements of distances of semantic
vector spaces of information, keywords extraction and encoding model, and Light
Gradient Boosting Machine (LGBM) classifiers. Our results suggest that 78.06%
(83.08%), 84.63% (87.77%), and 94.03% (94.60%) of hourly, 4-hourly, and daily
bullish (bearish) market movements can be attributed to public information
within organic tweets.",http://arxiv.org/pdf/2409.15988v1,,False
TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting,24/09/2024,"Hongnan Ma, Kevin McAreavey, Weiru Liu","Time series forecasting, while vital in various applications, often employs
complex models that are difficult for humans to understand. Effective
explainable AI techniques are crucial to bridging the gap between model
predictions and user understanding. This paper presents a framework -
TSFeatLIME, extending TSLIME, tailored specifically for explaining univariate
time series forecasting. TSFeatLIME integrates an auxiliary feature into the
surrogate model and considers the pairwise Euclidean distances between the
queried time series and the generated samples to improve the fidelity of the
surrogate models. However, the usefulness of such explanations for human beings
remains an open question. We address this by conducting a user study with 160
participants through two interactive interfaces, aiming to measure how
individuals from different backgrounds can simulate or predict model output
changes in the treatment group and control group. Our results show that the
surrogate model under the TSFeatLIME framework is able to better simulate the
behaviour of the black-box considering distance, without sacrificing accuracy.
In addition, the user study suggests that the explanations were significantly
more effective for participants without a computer science background.",http://arxiv.org/pdf/2409.15950v1,,False
Multi-UAV Pursuit-Evasion with Online Planning in Unknown Environments by Deep Reinforcement Learning,24/09/2024,"Jiayu Chen, Chao Yu, Guosheng Li, Wenhao Tang, Xinyi Yang, Botian Xu, Huazhong Yang, Yu Wang","Multi-UAV pursuit-evasion, where pursuers aim to capture evaders, poses a key
challenge for UAV swarm intelligence. Multi-agent reinforcement learning (MARL)
has demonstrated potential in modeling cooperative behaviors, but most RL-based
approaches remain constrained to simplified simulations with limited dynamics
or fixed scenarios. Previous attempts to deploy RL policy to real-world
pursuit-evasion are largely restricted to two-dimensional scenarios, such as
ground vehicles or UAVs at fixed altitudes. In this paper, we address multi-UAV
pursuit-evasion by considering UAV dynamics and physical constraints. We
introduce an evader prediction-enhanced network to tackle partial observability
in cooperative strategy learning. Additionally, we propose an adaptive
environment generator within MARL training, enabling higher exploration
efficiency and better policy generalization across diverse scenarios.
Simulations show our method significantly outperforms all baselines in
challenging scenarios, generalizing to unseen scenarios with a 100% capture
rate. Finally, we derive a feasible policy via a two-stage reward refinement
and deploy the policy on real quadrotors in a zero-shot manner. To our
knowledge, this is the first work to derive and deploy an RL-based policy using
collective thrust and body rates control commands for multi-UAV pursuit-evasion
in unknown environments. The open-source code and videos are available at
https://sites.google.com/view/pursuit-evasion-rl.",http://arxiv.org/pdf/2409.15866v2,,False
BeSimulator: A Large Language Model Powered Text-based Behavior Simulator,24/09/2024,"Jianan Wang, Bin Li, Xueying Wang, Fu Li, Yunlong Wu, Juan Chen, Xiaodong Yi","Traditional robot simulators focus on physical process modeling and realistic
rendering, often suffering from high computational costs, inefficiencies, and
limited adaptability. To handle this issue, we propose Behavior Simulation in
robotics to emphasize checking the behavior logic of robots and achieving
sufficient alignment between the outcome of robot actions and real scenarios.
In this paper, we introduce BeSimulator, a modular and novel LLM-powered
framework, as an attempt towards behavior simulation in the context of
text-based environments. By constructing text-based virtual environments and
performing semantic-level simulation, BeSimulator can generalize across
scenarios and achieve long-horizon complex simulation. Inspired by human
cognition processes, it employs a ""consider-decide-capture-transfer""
methodology, termed Chain of Behavior Simulation, which excels at analyzing
action feasibility and state transitions. Additionally, BeSimulator
incorporates code-driven reasoning to enable arithmetic operations and enhance
reliability, as well as integrates reflective feedback to refine simulation.
Based on our manually constructed behavior-tree-based simulation benchmark
BTSIMBENCH, our experiments show a significant performance improvement in
behavior simulation compared to baselines, ranging from 14.7% to 26.6%.",http://arxiv.org/pdf/2409.15865v1,,False
Zero-shot forecasting of chaotic systems,24/09/2024,"Yuanzhao Zhang, William Gilpin","Time-series forecasting is a challenging task that traditionally requires
specialized models custom-trained for the specific task at hand. Recently,
inspired by the success of large language models, foundation models pre-trained
on vast amounts of time-series data from diverse domains have emerged as a
promising candidate for general-purpose time-series forecasting. The defining
characteristic of these foundation models is their ability to perform zero-shot
learning, that is, forecasting a new system from limited context data without
explicit re-training or fine-tuning. Here, we evaluate whether the zero-shot
learning paradigm extends to the challenging task of forecasting chaotic
systems. Across 135 distinct chaotic dynamical systems and $10^8$ timepoints,
we find that foundation models produce competitive forecasts compared to
custom-trained models (including NBEATS, TiDE, etc.), particularly when
training data is limited. Interestingly, even after point forecasts fail,
foundation models preserve the geometric and statistical properties of the
chaotic attractors, demonstrating a surprisingly strong ability to capture the
long-term behavior of chaotic dynamical systems. Our results highlight the
promises and pitfalls of foundation models in making zero-shot forecasts of
chaotic systems.",http://arxiv.org/pdf/2409.15771v1,,False
Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach,24/09/2024,"Muhammad Dany Alfikri, Rafael Kaliski","Artificial intelligence (AI) has become integral to our everyday lives.
Computer vision has advanced to the point where it can play the safety critical
role of detecting pedestrians at road intersections in intelligent
transportation systems and alert vehicular traffic as to potential collisions.
Centralized computing analyzes camera feeds and generates alerts for nearby
vehicles. However, real-time applications face challenges such as latency,
limited data transfer speeds, and the risk of life loss. Edge servers offer a
potential solution for real-time applications, providing localized computing
and storage resources and lower response times. Unfortunately, edge servers
have limited processing power. Lightweight deep learning (DL) techniques enable
edge servers to utilize compressed deep neural network (DNN) models.
  The research explores implementing a lightweight DL model on Artificial
Intelligence of Things (AIoT) edge devices. An optimized You Only Look Once
(YOLO) based DL model is deployed for real-time pedestrian detection, with
detection events transmitted to the edge server using the Message Queuing
Telemetry Transport (MQTT) protocol. The simulation results demonstrate that
the optimized YOLO model can achieve real-time pedestrian detection, with a
fast inference speed of 147 milliseconds, a frame rate of 2.3 frames per
second, and an accuracy of 78%, representing significant improvements over
baseline models.",http://arxiv.org/pdf/2409.15740v1,,False
Sequential Learning in the Dense Associative Memory,24/09/2024,"Hayden McAlister, Anthony Robins, Lech Szymanski","Sequential learning involves learning tasks in a sequence, and proves
challenging for most neural networks. Biological neural networks regularly
conquer the sequential learning challenge and are even capable of transferring
knowledge both forward and backwards between tasks. Artificial neural networks
often totally fail to transfer performance between tasks, and regularly suffer
from degraded performance or catastrophic forgetting on previous tasks. Models
of associative memory have been used to investigate the discrepancy between
biological and artificial neural networks due to their biological ties and
inspirations, of which the Hopfield network is perhaps the most studied model.
The Dense Associative Memory, or modern Hopfield network, generalizes the
Hopfield network, allowing for greater capacities and prototype learning
behaviors, while still retaining the associative memory structure. We
investigate the performance of the Dense Associative Memory in sequential
learning problems, and benchmark various sequential learning techniques in the
network. We give a substantial review of the sequential learning space with
particular respect to the Hopfield network and associative memories, as well as
describe the techniques we implement in detail. We also draw parallels between
the classical and Dense Associative Memory in the context of sequential
learning, and discuss the departures from biological inspiration that may
influence the utility of the Dense Associative Memory as a tool for studying
biological neural networks. We present our findings, and show that existing
sequential learning methods can be applied to the Dense Associative Memory to
improve sequential learning performance.",http://arxiv.org/pdf/2409.15729v1,,False
dnaGrinder: a lightweight and high-capacity genomic foundation model,24/09/2024,"Qihang Zhao, Chi Zhang, Weixiong Zhang","The task of understanding and interpreting the complex information encoded
within genomic sequences remains a grand challenge in biological research and
clinical applications. In this context, recent advancements in large language
model research have led to the development of both encoder-only and
decoder-only foundation models designed to decode intricate information in DNA
sequences. However, several issues persist, particularly regarding the
efficient management of long-range dependencies inherent in genomic sequences,
the effective representation of nucleotide variations, and the considerable
computational costs associated with large model architectures and extensive
pretraining datasets. Current genomic foundation models often face a critical
tradeoff: smaller models with mediocre performance versus large models with
improved performance. To address these challenges, we introduce dnaGrinder, a
unique and efficient genomic foundation model. dnaGrinder excels at managing
long-range dependencies within genomic sequences while minimizing computational
costs without compromising performance. It achieves results that are not just
comparable but often superior to leading DNA models such as Nucleotide
Transformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy
fine-tuning on workstation-grade GPUs, accommodating input lengths exceeding
17,000 tokens. On a single high-performance GPU, it supports sequences longer
than 140,000 tokens, making it a highly efficient and accessible tool for both
basic biological research and clinical applications.",http://arxiv.org/pdf/2409.15697v1,,False
Linear Contextual Bandits with Interference,24/09/2024,"Yang Xu, Wenbin Lu, Rui Song","Interference, a key concept in causal inference, extends the reward modeling
process by accounting for the impact of one unit's actions on the rewards of
others. In contextual bandit (CB) settings, where multiple units are present in
the same round, potential interference can significantly affect the estimation
of expected rewards for different arms, thereby influencing the decision-making
process. Although some prior work has explored multi-agent and adversarial
bandits in interference-aware settings, the effect of interference in CB, as
well as the underlying theory, remains significantly underexplored. In this
paper, we introduce a systematic framework to address interference in Linear CB
(LinCB), bridging the gap between causal inference and online decision-making.
We propose a series of algorithms that explicitly quantify the interference
effect in the reward modeling process and provide comprehensive theoretical
guarantees, including sublinear regret bounds, finite sample upper bounds, and
asymptotic properties. The effectiveness of our approach is demonstrated
through simulations and a synthetic data generated based on MovieLens data.",http://arxiv.org/pdf/2409.15682v1,,False
ReLEP: A Novel Framework for Real-world Long-horizon Embodied Planning,24/09/2024,"Siyuan Liu, Jiawei Du, Sicheng Xiang, Zibo Wang, Dingsheng Luo","Real-world long-horizon embodied planning underpins embodied AI. To
accomplish long-horizon tasks, agents need to decompose abstract instructions
into detailed steps. Prior works mostly rely on GPT-4V for task decomposition
into predefined actions, which limits task diversity due to GPT-4V's finite
understanding of larger skillsets. Therefore, we present ReLEP, a
groundbreaking framework for Real world Long-horizon Embodied Planning, which
can accomplish a wide range of daily tasks. At its core lies a fine-tuned large
vision language model that formulates plans as sequences of skill functions
according to input instruction and scene image. These functions are selected
from a carefully designed skill library. ReLEP is also equipped with a Memory
module for plan and status recall, and a Robot Configuration module for
versatility across robot types. In addition, we propose a semi-automatic data
generation pipeline to tackle dataset scarcity. Real-world off-line experiments
across eight daily embodied tasks demonstrate that ReLEP is able to accomplish
long-horizon embodied tasks and outperforms other state-of-the-art baseline
methods.",http://arxiv.org/pdf/2409.15658v1,,False
Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI,24/09/2024,"Liang Zhang, Jionghao Lin, John Sabatini, Conrad Borchers, Daniel Weitekamp, Meng Cao, John Hollander, Xiangen Hu, Arthur C. Graesser","Learning performance data describe correct and incorrect answers or
problem-solving attempts in adaptive learning, such as in intelligent tutoring
systems (ITSs). Learning performance data tend to be highly sparse
(80\%\(\sim\)90\% missing observations) in most real-world applications due to
adaptive item selection. This data sparsity presents challenges to using
learner models to effectively predict future performance explore new hypotheses
about learning. This article proposes a systematic framework for augmenting
learner data to address data sparsity in learning performance data. First,
learning performance is represented as a three-dimensional tensor of learners'
questions, answers, and attempts, capturing longitudinal knowledge states
during learning. Second, a tensor factorization method is used to impute
missing values in sparse tensors of collected learner data, thereby grounding
the imputation on knowledge tracing tasks that predict missing performance
values based on real observations. Third, a module for generating patterns of
learning is used. This study contrasts two forms of generative Artificial
Intelligence (AI), including Generative Adversarial Networks (GANs) and
Generate Pre-Trained Transformers (GPT) to generate data associated with
different clusters of learner data. We tested this approach on an adult
literacy dataset from AutoTutor lessons developed for Adult Reading
Comprehension (ARC). We found that: (1) tensor factorization improved the
performance in tracing and predicting knowledge mastery compared with other
knowledge tracing techniques without data augmentation, showing higher relative
fidelity for this imputation method, and (2) the GAN-based simulation showed
greater overall stability and less statistical bias based on a divergence
evaluation with varying simulation sample sizes compared to GPT.",http://arxiv.org/pdf/2409.15631v1,,False
Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents,23/09/2024,"Bandhav Veluri, Benjamin N Peloquin, Bokai Yu, Hongyu Gong, Shyamnath Gollakota","Despite broad interest in modeling spoken dialogue agents, most approaches
are inherently ""half-duplex"" -- restricted to turn-based interaction with
responses requiring explicit prompting by the user or implicit tracking of
interruption or silence events. Human dialogue, by contrast, is ""full-duplex""
allowing for rich synchronicity in the form of quick and dynamic turn-taking,
overlapping speech, and backchanneling. Technically, the challenge of achieving
full-duplex dialogue with LLMs lies in modeling synchrony as pre-trained LLMs
do not have a sense of ""time"". To bridge this gap, we propose Synchronous LLMs
for full-duplex spoken dialogue modeling. We design a novel mechanism to
integrate time information into Llama3-8b so that they run synchronously with
the real-world clock. We also introduce a training recipe that uses 212k hours
of synthetic spoken dialogue data generated from text dialogue data to create a
model that generates meaningful and natural spoken dialogue, with just 2k hours
of real-world spoken dialogue data. Synchronous LLMs outperform
state-of-the-art in dialogue meaningfulness while maintaining naturalness.
Finally, we demonstrate the model's ability to participate in full-duplex
dialogue by simulating interaction between two agents trained on different
datasets, while considering Internet-scale latencies of up to 240 ms. Webpage:
https://syncllm.cs.washington.edu/.",http://arxiv.org/pdf/2409.15594v1,,False
TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU,23/09/2024,"Rosemary Y. He, Jeffrey N. Chiang","Trajectory forecasting in healthcare data has been an important area of
research in precision care and clinical integration for computational methods.
In recent years, generative AI models have demonstrated promising results in
capturing short and long range dependencies in time series data. While these
models have also been applied in healthcare, most of them only predict one
value at a time, which is unrealistic in a clinical setting where multiple
measures are taken at once. In this work, we extend the framework temporal
fusion transformer (TFT), a multi-horizon time series prediction tool, and
propose TFT-multi, an end-to-end framework that can predict multiple vital
trajectories simultaneously. We apply TFT-multi to forecast 5 vital signs
recorded in the intensive care unit: blood pressure, pulse, SpO2, temperature
and respiratory rate. We hypothesize that by jointly predicting these measures,
which are often correlated with one another, we can make more accurate
predictions, especially in variables with large missingness. We validate our
model on the public MIMIC dataset and an independent institutional dataset, and
demonstrate that this approach outperforms state-of-the-art univariate
prediction tools including the original TFT and Prophet, as well as vector
regression modeling for multivariate prediction. Furthermore, we perform a
study case analysis by applying our pipeline to forecast blood pressure changes
in response to actual and hypothetical pressor administration.",http://arxiv.org/pdf/2409.15586v2,,False
Nothing Conformal about Adaptive Conformal Inference,23/09/2024,Johan Hallberg Szabadváry,"Conformal prediction is a widely-used framework for distribution-free
uncertainty quantification, which generates valid prediction sets at a
user-defined significance level. However, this framework relies on the
assumption that the data-generating distribution is exchangeable, a condition
that is frequently violated in time-series and other structured data. In such
cases, the validity guarantees of conformal prediction break down.
  Adaptive conformal inference (ACI) has been proposed as a solution for
non-exchangeable data by dynamically adjusting the significance level to retain
at least finite sample guarantees on the marginal coverage error rate. This
paper demonstrates that, despite its name, ACI does not strictly require the
use of conformal predictors. Instead, it can operate effectively with the more
general concept of a confidence predictor, which is often computationally
simpler. The key requirement is that larger significance levels correspond to
smaller prediction sets, a property known as nested prediction sets.
  Through experiments on synthetic and real-world data, we investigate whether
ACI with conformal predictors offers advantages over confidence predictors. Our
results indicate that confidence predictors can perform just as well, and
sometimes better than conformal predictors in some cases, although further
empirical studies are needed to determine when one approach may be preferable.",http://arxiv.org/pdf/2409.15548v1,,False
Learning Diverse Robot Striking Motions with Diffusion Models and Kinematically Constrained Gradient Guidance,23/09/2024,"Kin Man Lee, Sean Ye, Qingyu Xiao, Zixuan Wu, Zulfiqar Zaidi, David B. D'Ambrosio, Pannag R. Sanketi, Matthew Gombolay","Advances in robot learning have enabled robots to generate skills for a
variety of tasks. Yet, robot learning is typically sample inefficient,
struggles to learn from data sources exhibiting varied behaviors, and does not
naturally incorporate constraints. These properties are critical for fast,
agile tasks such as playing table tennis. Modern techniques for learning from
demonstration improve sample efficiency and scale to diverse data, but are
rarely evaluated on agile tasks. In the case of reinforcement learning,
achieving good performance requires training on high-fidelity simulators. To
overcome these limitations, we develop a novel diffusion modeling approach that
is offline, constraint-guided, and expressive of diverse agile behaviors. The
key to our approach is a kinematic constraint gradient guidance (KCGG)
technique that computes gradients through both the forward kinematics of the
robot arm and the diffusion model to direct the sampling process. KCGG
minimizes the cost of violating constraints while simultaneously keeping the
sampled trajectory in-distribution of the training data. We demonstrate the
effectiveness of our approach for time-critical robotic tasks by evaluating
KCGG in two challenging domains: simulated air hockey and real table tennis. In
simulated air hockey, we achieved a 25.4% increase in block rate, while in
table tennis, we saw a 17.3% increase in success rate compared to imitation
learning baselines.",http://arxiv.org/pdf/2409.15528v1,,False
Enhancing Pedestrian Trajectory Prediction with Crowd Trip Information,23/09/2024,"Rei Tamaru, Pei Li, Bin Ran","Pedestrian trajectory prediction is essential for various applications in
active traffic management, urban planning, traffic control, crowd management,
and autonomous driving, aiming to enhance traffic safety and efficiency.
Accurately predicting pedestrian trajectories requires a deep understanding of
individual behaviors, social interactions, and road environments. Existing
studies have developed various models to capture the influence of social
interactions and road conditions on pedestrian trajectories. However, these
approaches are limited by the lack of a comprehensive view of social
interactions and road environments. To address these limitations and enhance
the accuracy of pedestrian trajectory prediction, we propose a novel approach
incorporating trip information as a new modality into pedestrian trajectory
models. We propose RNTransformer, a generic model that utilizes crowd trip
information to capture global information on social interactions. We
incorporated RNTransformer with various socially aware local pedestrian
trajectory prediction models to demonstrate its performance. Specifically, by
leveraging a pre-trained RNTransformer when training different pedestrian
trajectory prediction models, we observed improvements in performance metrics:
a 1.3/2.2% enhancement in ADE/FDE on Social-LSTM, a 6.5/28.4% improvement on
Social-STGCNN, and an 8.6/4.3% improvement on S-Implicit. Evaluation results
demonstrate that RNTransformer significantly enhances the accuracy of various
pedestrian trajectory prediction models across multiple datasets. Further
investigation reveals that the RNTransformer effectively guides local models to
more accurate directions due to the consideration of global information. By
exploring crowd behavior within the road network, our approach shows great
promise in improving pedestrian safety through accurate trajectory predictions.",http://arxiv.org/pdf/2409.15224v1,,False
MotifDisco: Motif Causal Discovery For Time Series Motifs,23/09/2024,"Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Sam Hatfield, Joost van der Linden","Many time series, particularly health data streams, can be best understood as
a sequence of phenomenon or events, which we call motifs. A time series motif
is a short trace segment which may implicitly capture an underlying phenomenon
within the time series. Specifically, we focus on glucose traces collected from
continuous glucose monitors (CGMs), which inherently contain motifs
representing underlying human behaviors such as eating and exercise. The
ability to identify and quantify causal relationships amongst motifs can
provide a mechanism to better understand and represent these patterns, useful
for improving deep learning and generative models and for advanced technology
development (e.g., personalized coaching and artificial insulin delivery
systems). However, no previous work has developed causal discovery methods for
time series motifs. Therefore, in this paper we develop MotifDisco (motif
disco-very of causality), a novel causal discovery framework to learn causal
relations amongst motifs from time series traces. We formalize a notion of
Motif Causality (MC), inspired from Granger Causality and Transfer Entropy, and
develop a Graph Neural Network-based framework that learns causality between
motifs by solving an unsupervised link prediction problem. We also integrate MC
with three model use cases of forecasting, anomaly detection and clustering, to
showcase the use of MC as a building block for other downstream tasks. Finally,
we evaluate our framework and find that Motif Causality provides a significant
performance improvement in all use cases.",http://arxiv.org/pdf/2409.15219v1,,False
ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction,23/09/2024,"Iwo Naglik, Mateusz Lango","Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of
aspect-based sentiment analysis that consists in extracting (aspect phrase,
opinion phrase, sentiment polarity) triples from a given sentence. Recent
state-of-the-art methods approach this task by first extracting all possible
text spans from a given text, then filtering the potential aspect and opinion
phrases with a classifier, and finally considering all their pairs with another
classifier that additionally assigns sentiment polarity to them. Although
several variations of the above scheme have been proposed, the common feature
is that the final result is constructed by a sequence of independent classifier
decisions. This hinders the exploitation of dependencies between extracted
phrases and prevents the use of knowledge about the interrelationships between
classifier predictions to improve performance. In this paper, we propose a new
ASTE approach consisting of three transformer-inspired layers, which enables
the modelling of dependencies both between phrases and between the final
classifier decisions. Experimental results show that the method achieves higher
performance in terms of F1 measure than other methods studied on popular
benchmarks. In addition, we show that a simple pre-training technique further
improves the performance of the model.",http://arxiv.org/pdf/2409.15202v1,,False
Harmonic Path Integral Diffusion,23/09/2024,"Hamidreza Behjoo, Michael Chertkov","In this manuscript, we present a novel approach for sampling from a
continuous multivariate probability distribution, which may either be
explicitly known (up to a normalization factor) or represented via empirical
samples. Our method constructs a time-dependent bridge from a delta function
centered at the origin of the state space at $t=0$, optimally transforming it
into the target distribution at $t=1$. We formulate this as a Stochastic
Optimal Control problem of the Path Integral Control type, with a cost function
comprising (in its basic form) a quadratic control term, a quadratic state
term, and a terminal constraint. This framework, which we refer to as Harmonic
Path Integral Diffusion (H-PID), leverages an analytical solution through a
mapping to an auxiliary quantum harmonic oscillator in imaginary time.
  The H-PID framework results in a set of efficient sampling algorithms,
without the incorporation of Neural Networks. The algorithms are validated on
two standard use cases: a mixture of Gaussians over a grid and images from
CIFAR-10. We contrast these algorithms with other sampling methods,
particularly simulated annealing and path integral sampling, highlighting their
advantages in terms of analytical control, accuracy, and computational
efficiency on benchmark problems.
  Additionally, we extend the methodology to more general cases where the
underlying stochastic differential equation includes an external deterministic,
possibly non-conservative force, and where the cost function incorporates a
gauge potential term. These extensions open up new possibilities for applying
our framework to a broader range of statistics specific to applications.",http://arxiv.org/pdf/2409.15166v1,,False
CSPS: A Communication-Efficient Sequence-Parallelism based Serving System for Transformer based Models with Long Prompts,23/09/2024,"Zeyu Zhang, Haiying Shen","Long-sequence generative large-language model (LLM) applications have become
increasingly popular. In this paper, through trace-based experiments, we found
that the existing method for long sequences results in a high
Time-To-First-Token (TTFT) due to sequential chunk processing, long
Time-Between-Tokens (TBT) from batching long-sequence prefills and decodes, and
low throughput due to constrained key-value cache (KVC) for long sequences. To
address these issues, we propose two Sequence-Parallelism (SP) architectures
for both tensor parallelism (TP) and non-TP. However, SP introduces two
challenges: 1) network communication and computation become performance
bottlenecks; 2) the latter two issues above are mitigated but not resolved, and
SP's resultant KV value distribution across GPUs still requires communication
for decode, increasing TBT. Hence, we propose a Communication-efficient Sparse
Attention (CSA) and communication-computation-communication three-phase
pipelining. We also propose SP-based decode that processes decode separately
from prefill, distributes KV values of a request across different GPUs, and
novelly moves Query (Q) values instead of KV values to reduce communication
overhead. These methods constitute a communication-efficient
Sequence-Parallelism based LLM Serving System (SPS2). Our trace-driven
evaluation demonstrates that SPS2 improves the average TTFT, TBT, and response
time by up to 7.5x, 1.92x, and 9.8x and improves the prefill and decode
throughput by 8.2x and 5.2x while maintaining the accuracy compared to
Sarathi-Serve. We distributed our source code.",http://arxiv.org/pdf/2409.15104v1,,False
Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19,23/09/2024,"Mohammad Amin Roshani, Xiangyu Zhou, Yao Qiang, Srinivasan Suresh, Steve Hicks, Usha Sethuraman, Dongxiao Zhu","Large language models (LLMs) have shown remarkable capabilities in various
natural language tasks and are increasingly being applied in healthcare
domains. This work demonstrates a new LLM-powered disease risk assessment
approach via streaming human-AI conversation, eliminating the need for
programming required by traditional machine learning approaches. In a COVID-19
severity risk assessment case study, we fine-tune pre-trained generative LLMs
(e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language
examples, comparing their performance with traditional classifiers (i.e.,
Logistic Regression, XGBoost, Random Forest) that are trained de novo using
tabular data across various experimental settings. We develop a mobile
application that uses these fine-tuned LLMs as its generative AI (GenAI) core
to facilitate real-time interaction between clinicians and patients, providing
no-code risk assessment through conversational interfaces. This integration not
only allows for the use of streaming Questions and Answers (QA) as inputs but
also offers personalized feature importance analysis derived from the LLM's
attention layers, enhancing the interpretability of risk assessments. By
achieving high Area Under the Curve (AUC) scores with a limited number of
fine-tuning samples, our results demonstrate the potential of generative LLMs
to outperform discriminative classification methods in low-data regimes,
highlighting their real-world adaptability and effectiveness. This work aims to
fill the existing gap in leveraging generative LLMs for interactive no-code
risk assessment and to encourage further research in this emerging field.",http://arxiv.org/pdf/2409.15027v1,,False
A Diagonal Structured State Space Model on Loihi 2 for Efficient Streaming Sequence Processing,23/09/2024,"Svea Marie Meyer, Philipp Weidel, Philipp Plank, Leobardo Campos-Macias, Sumit Bam Shrestha, Philipp Stratmann, Mathis Richter","Deep State-Space Models (SSM) demonstrate state-of-the art performance on
long-range sequence modeling tasks. While the recurrent structure of SSMs can
be efficiently implemented as a convolution or as a parallel scan during
training, recurrent token-by-token processing cannot currently be implemented
efficiently on GPUs. Here, we demonstrate efficient token-by-token inference of
the SSM S4D on Intel's Loihi 2 state-of-the-art neuromorphic processor. We
compare this first ever neuromorphic-hardware implementation of an SSM on
sMNIST, psMNIST, and sCIFAR to a recurrent and a convolutional implementation
of S4D on Jetson Orin Nano (Jetson). While we find Jetson to perform better in
an offline sample-by-sample based batched processing mode, Loihi 2 outperforms
during token-by-token based processing, where it consumes 1000 times less
energy with a 75 times lower latency and a 75 times higher throughput compared
to the recurrent implementation of S4D on Jetson. This opens up new avenues
towards efficient real-time streaming applications of SSMs.",http://arxiv.org/pdf/2409.15022v1,,False
Evaluating Synthetic Activations composed of SAE Latents in GPT-2,23/09/2024,"Giorgi Giglemiani, Nora Petrova, Chatrik Singh Mangat, Jett Janiak, Stefan Heimersheim","Sparse Auto-Encoders (SAEs) are commonly employed in mechanistic
interpretability to decompose the residual stream into monosemantic SAE
latents. Recent work demonstrates that perturbing a model's activations at an
early layer results in a step-function-like change in the model's final layer
activations. Furthermore, the model's sensitivity to this perturbation differs
between model-generated (real) activations and random activations. In our
study, we assess model sensitivity in order to compare real activations to
synthetic activations composed of SAE latents. Our findings indicate that
synthetic activations closely resemble real activations when we control for the
sparsity and cosine similarity of the constituent SAE latents. This suggests
that real activations cannot be explained by a simple ""bag of SAE latents""
lacking internal structure, and instead suggests that SAE latents possess
significant geometric and statistical properties. Notably, we observe that our
synthetic activations exhibit less pronounced activation plateaus compared to
those typically surrounding real activations.",http://arxiv.org/pdf/2409.15019v1,,False
Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network,23/09/2024,"Sijia Du, Chengfeng Zhou, Suncheng Xiang, Jianwei Xu, Dahong Qian","Objective: Depth estimation is crucial for endoscopic navigation and
manipulation, but obtaining ground-truth depth maps in real clinical scenarios,
such as the colon, is challenging. This study aims to develop a robust
framework that generalizes well to real colonoscopy images, overcoming
challenges like non-Lambertian surface reflection and diverse data
distributions. Methods: We propose a framework combining a convolutional neural
network (CNN) for capturing local features and a Transformer for capturing
global information. An uncertainty-based fusion block was designed to enhance
generalization by identifying complementary contributions from the CNN and
Transformer branches. The network can be trained with simulated datasets and
generalize directly to unseen clinical data without any fine-tuning. Results:
Our method is validated on multiple datasets and demonstrates an excellent
generalization ability across various datasets and anatomical structures.
Furthermore, qualitative analysis in real clinical scenarios confirmed the
robustness of the proposed method. Conclusion: The integration of local and
global features through the CNN-Transformer architecture, along with the
uncertainty-based fusion block, improves depth estimation performance and
generalization in both simulated and real-world endoscopic environments.
Significance: This study offers a novel approach to estimate depth maps for
endoscopy images despite the complex conditions in clinic, serving as a
foundation for endoscopic automatic navigation and other clinical tasks, such
as polyp detection and segmentation.",http://arxiv.org/pdf/2409.15006v1,,False
KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems,23/09/2024,"Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan","Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.",http://arxiv.org/pdf/2409.14908v1,,False
The ParlaSpeech Collection of Automatically Generated Speech and Text Datasets from Parliamentary Proceedings,23/09/2024,"Nikola Ljubešić, Peter Rupnik, Danijel Koržinek","Recent significant improvements in speech and language technologies come both
from self-supervised approaches over raw language data as well as various types
of explicit supervision. To ensure high-quality processing of spoken data, the
most useful type of explicit supervision is still the alignment between the
speech signal and its corresponding text transcript, which is a data type that
is not available for many languages. In this paper, we present our approach to
building large and open speech-and-text-aligned datasets of less-resourced
languages based on transcripts of parliamentary proceedings and their
recordings. Our starting point are the ParlaMint comparable corpora of
transcripts of parliamentary proceedings of 26 national European parliaments.
In the pilot run on expanding the ParlaMint corpora with aligned publicly
available recordings, we focus on three Slavic languages, namely Croatian,
Polish, and Serbian. The main challenge of our approach is the lack of any
global alignment between the ParlaMint texts and the available recordings, as
well as the sometimes varying data order in each of the modalities, which
requires a novel approach in aligning long sequences of text and audio in a
large search space. The results of this pilot run are three high-quality
datasets that span more than 5,000 hours of speech and accompanying text
transcripts. Although these datasets already make a huge difference in the
availability of spoken and textual data for the three languages, we want to
emphasize the potential of the presented approach in building similar datasets
for many more languages.",http://arxiv.org/pdf/2409.15397v1,,False
Multiscale scattered data analysis in samplet coordinates,23/09/2024,"Sara Avesani, Rüdiger Kempf, Michael Multerer, Holger Wendland","We study multiscale scattered data interpolation schemes for globally
supported radial basis functions, with a focus on the Mat\'ern class. The
multiscale approximation is constructed through a sequence of residual
corrections, where radial basis functions with different lengthscale parameters
are employed to capture varying levels of detail. To apply this approach to
large data sets, we suggest to represent the resulting generalized Vandermonde
matrices in samplet coordinates. Samplets are localized, discrete signed
measures exhibiting vanishing moments and allow for the sparse approximation of
generalized Vandermonde matrices issuing from a vast class of radial basis
functions. Given a quasi-uniform set of $N$ data sites, and local approximation
spaces with geometrically decreasing dimension, the full multiscale system can
be assembled with cost $\mathcal{O}(N \log N)$. We prove that the condition
numbers of the linear systems at each level remain bounded independent of the
particular level, allowing us to use an iterative solver with a bounded number
of iterations for the numerical solution. Hence, the overall cost of the
proposed approach is $\mathcal{O}(N \log N)$. The theoretical findings are
accompanied by extensive numerical studies in two and three spatial dimensions.",http://arxiv.org/pdf/2409.14791v1,,False
Automated Spatio-Temporal Weather Modeling for Load Forecasting,23/09/2024,"Julie Keisler, Margaux Bregere","Electricity is difficult to store, except at prohibitive cost, and therefore
the balance between generation and load must be maintained at all times.
Electricity is traditionally managed by anticipating demand and intermittent
production (wind, solar) and matching flexible production (hydro, nuclear, coal
and gas). Accurate forecasting of electricity load and renewable production is
therefore essential to ensure grid performance and stability. Both are highly
dependent on meteorological variables (temperature, wind, sunshine). These
dependencies are complex and difficult to model. On the one hand, spatial
variations do not have a uniform impact because population, industry, and wind
and solar farms are not evenly distributed across the territory. On the other
hand, temporal variations can have delayed effects on load (due to the thermal
inertia of buildings). With access to observations from different weather
stations and simulated data from meteorological models, we believe that both
phenomena can be modeled together. In today's state-of-the-art load forecasting
models, the spatio-temporal modeling of the weather is fixed. In this work, we
aim to take advantage of the automated representation and spatio-temporal
feature extraction capabilities of deep neural networks to improve
spatio-temporal weather modeling for load forecasting. We compare our deep
learning-based methodology with the state-of-the-art on French national load.
This methodology could also be fully adapted to forecasting renewable energy
production.",http://arxiv.org/pdf/2409.16326v1,,False
LatentQGAN: A Hybrid QGAN with Classical Convolutional Autoencoder,22/09/2024,"Vieloszynski Alexis, Soumaya Cherkaoui, Jean-Frédéric Laprade, Oliver Nahman-Lévesque, Abdallah Aaraba, Shengrui Wang","Quantum machine learning consists in taking advantage of quantum computations
to generate classical data. A potential application of quantum machine learning
is to harness the power of quantum computers for generating classical data, a
process essential to a multitude of applications such as enriching training
datasets, anomaly detection, and risk management in finance. Given the success
of Generative Adversarial Networks in classical image generation, the
development of its quantum versions has been actively conducted. However,
existing implementations on quantum computers often face significant
challenges, such as scalability and training convergence issues. To address
these issues, we propose LatentQGAN, a novel quantum model that uses a hybrid
quantum-classical GAN coupled with an autoencoder. Although it was initially
designed for image generation, the LatentQGAN approach holds potential for
broader application across various practical data generation tasks.
Experimental outcomes on both classical simulators and noisy intermediate scale
quantum computers have demonstrated significant performance enhancements over
existing quantum methods, alongside a significant reduction in quantum
resources overhead.",http://arxiv.org/pdf/2409.14622v1,,False
Implicit Dynamical Flow Fusion (IDFF) for Generative Modeling,22/09/2024,"Mohammad R. Rezaei, Rahul G. Krishnan, Milos R. Popovic, Milad Lankarany","Conditional Flow Matching (CFM) models can generate high-quality samples from
a non-informative prior, but they can be slow, often needing hundreds of
network evaluations (NFE). To address this, we propose Implicit Dynamical Flow
Fusion (IDFF); IDFF learns a new vector field with an additional momentum term
that enables taking longer steps during sample generation while maintaining the
fidelity of the generated distribution. Consequently, IDFFs reduce the NFEs by
a factor of ten (relative to CFMs) without sacrificing sample quality, enabling
rapid sampling and efficient handling of image and time-series data generation
tasks. We evaluate IDFF on standard benchmarks such as CIFAR-10 and CelebA for
image generation. We achieved likelihood and quality performance comparable to
CFMs and diffusion-based models with fewer NFEs. IDFF also shows superior
performance on time-series datasets modeling, including molecular simulation
and sea surface temperature (SST) datasets, highlighting its versatility and
effectiveness across different domains.",http://arxiv.org/pdf/2409.14599v1,,False
SPAQ-DL-SLAM: Towards Optimizing Deep Learning-based SLAM for Resource-Constrained Embedded Platforms,22/09/2024,"Niraj Pudasaini, Muhammad Abdullah Hanif, Muhammad Shafique","Optimizing Deep Learning-based Simultaneous Localization and Mapping
(DL-SLAM) algorithms is essential for efficient implementation on
resource-constrained embedded platforms, enabling real-time on-board
computation in autonomous mobile robots. This paper presents SPAQ-DL-SLAM, a
framework that strategically applies Structured Pruning and Quantization (SPAQ)
to the architecture of one of the state-ofthe-art DL-SLAM algorithms,
DROID-SLAM, for resource and energy-efficiency. Specifically, we perform
structured pruning with fine-tuning based on layer-wise sensitivity analysis
followed by 8-bit post-training static quantization (PTQ) on the deep learning
modules within DROID-SLAM. Our SPAQ-DROIDSLAM model, optimized version of
DROID-SLAM model using our SPAQ-DL-SLAM framework with 20% structured pruning
and 8-bit PTQ, achieves an 18.9% reduction in FLOPs and a 79.8% reduction in
overall model size compared to the DROID-SLAM model. Our evaluations on the
TUM-RGBD benchmark shows that SPAQ-DROID-SLAM model surpasses the DROID-SLAM
model by an average of 10.5% on absolute trajectory error (ATE) metric.
Additionally, our results on the ETH3D SLAM training benchmark demonstrate
enhanced generalization capabilities of the SPAQ-DROID-SLAM model, seen by a
higher Area Under the Curve (AUC) score and success in 2 additional data
sequences compared to the DROIDSLAM model. Despite these improvements, the
model exhibits performance variance on the distinct Vicon Room sequences from
the EuRoC dataset, which are captured at high angular velocities. This varying
performance at some distinct scenarios suggests that designing DL-SLAM
algorithms taking operating environments and tasks in consideration can achieve
optimal performance and resource efficiency for deployment in
resource-constrained embedded platforms.",http://arxiv.org/pdf/2409.14515v1,,False
A Unified Approach for Learning the Dynamics of Power System Generators and Inverter-based Resources,22/09/2024,"Shaohui Liu, Weiqian Cai, Hao Zhu, Brian Johnson","The growing prevalence of inverter-based resources (IBRs) for renewable
energy integration and electrification greatly challenges power system dynamic
analysis. To account for both synchronous generators (SGs) and IBRs, this work
presents an approach for learning the model of an individual dynamic component.
The recurrent neural network (RNN) model is used to match the recursive
structure in predicting the key dynamical states of a component from its
terminal bus voltage and set-point input. To deal with the fast transients
especially due to IBRs, we develop a Stable Integral (SI-)RNN to mimic
high-order integral methods that can enhance the stability and accuracy for the
dynamic learning task. We demonstrate that the proposed SI-RNN model not only
can successfully predict the component's dynamic behaviors, but also offers the
possibility of efficiently computing the dynamic sensitivity relative to a
set-point change. These capabilities have been numerically validated based on
full-order Electromagnetic Transient (EMT) simulations on a small test system
with both SGs and IBRs, particularly for predicting the dynamics of
grid-forming inverters.",http://arxiv.org/pdf/2409.14454v1,,False
COSBO: Conservative Offline Simulation-Based Policy Optimization,22/09/2024,"Eshagh Kargar, Ville Kyrki","Offline reinforcement learning allows training reinforcement learning models
on data from live deployments. However, it is limited to choosing the best
combination of behaviors present in the training data. In contrast, simulation
environments attempting to replicate the live environment can be used instead
of the live data, yet this approach is limited by the simulation-to-reality
gap, resulting in a bias. In an attempt to get the best of both worlds, we
propose a method that combines an imperfect simulation environment with data
from the target environment, to train an offline reinforcement learning policy.
Our experiments demonstrate that the proposed method outperforms
state-of-the-art approaches CQL, MOPO, and COMBO, especially in scenarios with
diverse and challenging dynamics, and demonstrates robust behavior across a
variety of experimental conditions. The results highlight that using
simulator-generated data can effectively enhance offline policy learning
despite the sim-to-real gap, when direct interaction with the real-world is not
possible.",http://arxiv.org/pdf/2409.14412v1,,False
MaskedMimic: Unified Physics-Based Character Control Through Masked Motion Inpainting,22/09/2024,"Chen Tessler, Yunrong Guo, Ofir Nabati, Gal Chechik, Xue Bin Peng","Crafting a single, versatile physics-based controller that can breathe life
into interactive characters across a wide spectrum of scenarios represents an
exciting frontier in character animation. An ideal controller should support
diverse control modalities, such as sparse target keyframes, text instructions,
and scene information. While previous works have proposed physically simulated,
scene-aware control models, these systems have predominantly focused on
developing controllers that each specializes in a narrow set of tasks and
control modalities. This work presents MaskedMimic, a novel approach that
formulates physics-based character control as a general motion inpainting
problem. Our key insight is to train a single unified model to synthesize
motions from partial (masked) motion descriptions, such as masked keyframes,
objects, text descriptions, or any combination thereof. This is achieved by
leveraging motion tracking data and designing a scalable training method that
can effectively utilize diverse motion descriptions to produce coherent
animations. Through this process, our approach learns a physics-based
controller that provides an intuitive control interface without requiring
tedious reward engineering for all behaviors of interest. The resulting
controller supports a wide range of control modalities and enables seamless
transitions between disparate tasks. By unifying character control through
motion inpainting, MaskedMimic creates versatile virtual characters. These
characters can dynamically adapt to complex scenes and compose diverse motions
on demand, enabling more interactive and immersive experiences.",http://arxiv.org/pdf/2409.14393v1,,False
Sparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers,22/09/2024,"Dominic Schneider, Lutz Rapp","Optical fiber amplifiers are key elements in present optical networks.
Failures of these components result in high financial loss of income of the
network operator as the communication traffic over an affected link is
interrupted. Applying Remaining useful lifetime (RUL) prediction in the context
of Predictive Maintenance (PdM) to optical fiber amplifiers to predict upcoming
system failures at an early stage, so that network outages can be minimized
through planning of targeted maintenance actions, ensures reliability and
safety. Optical fiber amplifier are complex systems, that work under various
operating conditions, which makes correct forecasting a difficult task.
Increased monitoring capabilities of systems results in datasets that
facilitate the application of data-driven RUL prediction methods. Deep learning
models in particular have shown good performance, but generalization based on
comparatively small datasets for RUL prediction is difficult. In this paper, we
propose Sparse Low-ranked self-Attention Transformer (SLAT) as a novel RUL
prediction method. SLAT is based on an encoder-decoder architecture, wherein
two parallel working encoders extract features for sensors and time steps. By
utilizing the self-attention mechanism, long-term dependencies can be learned
from long sequences. The implementation of sparsity in the attention matrix and
a low-rank parametrization reduce overfitting and increase generalization.
Experimental application to optical fiber amplifiers exemplified on EDFA, as
well as a reference dataset from turbofan engines, shows that SLAT outperforms
the state-of-the-art methods.",http://arxiv.org/pdf/2409.14378v1,,False
A Distribution-Aware Flow-Matching for Generating Unstructured Data for Few-Shot Reinforcement Learning,21/09/2024,"Mohammad Pivezhandi, Abusayeed Saifullah","Generating realistic and diverse unstructured data is a significant challenge
in reinforcement learning (RL), particularly in few-shot learning scenarios
where data is scarce. Traditional RL methods often rely on extensive datasets
or simulations, which are costly and time-consuming. In this paper, we
introduce a distribution-aware flow matching, designed to generate synthetic
unstructured data tailored specifically for an application of few-shot RL
called Dynamic Voltage and Frequency Scaling (DVFS) on embedded processors.
This method leverages the sample efficiency of flow matching and incorporates
statistical learning techniques such as bootstrapping to improve its
generalization and robustness of the latent space. Additionally, we apply
feature weighting through Random Forests to prioritize critical data aspects,
thereby improving the precision of the generated synthetic data. This approach
not only mitigates the challenges of overfitting and data correlation in
unstructured data in traditional Model-Based RL but also aligns with the Law of
Large Numbers, ensuring convergence to true empirical values and optimal policy
as the number of samples increases. Through extensive experimentation on an
application of DVFS for low energy processing, we demonstrate that our method
provides an stable convergence based on max Q-value while enhancing frame rate
by 30\% in the very beginning first timestamps, making this RL model efficient
in resource-constrained environments.",http://arxiv.org/pdf/2409.14178v1,,False
PepINVENT: Generative peptide design beyond the natural amino acids,21/09/2024,"Gökçe Geylan, Jon Paul Janet, Alessandro Tibo, Jiazhen He, Atanas Patronov, Mikhail Kabeshov, Florian David, Werngard Czechtizky, Ola Engkvist, Leonardo De Maria","Peptides play a crucial role in the drug design and discovery whether as a
therapeutic modality or a delivery agent. Non-natural amino acids (NNAAs) have
been used to enhance the peptide properties from binding affinity, plasma
stability to permeability. Incorporating novel NNAAs facilitates the design of
more effective peptides with improved properties. The generative models used in
the field, have focused on navigating the peptide sequence space. The sequence
space is formed by combinations of a predefined set of amino acids. However,
there is still a need for a tool to explore the peptide landscape beyond this
enumerated space to unlock and effectively incorporate de novo design of new
amino acids. To thoroughly explore the theoretical chemical space of the
peptides, we present PepINVENT, a novel generative AI-based tool as an
extension to the small molecule molecular design platform, REINVENT. PepINVENT
navigates the vast space of natural and non-natural amino acids to propose
valid, novel, and diverse peptide designs. The generative model can serve as a
central tool for peptide-related tasks, as it was not trained on peptides with
specific properties or topologies. The prior was trained to understand the
granularity of peptides and to design amino acids for filling the masked
positions within a peptide. PepINVENT coupled with reinforcement learning
enables the goal-oriented design of peptides using its chemistry-informed
generative capabilities. This study demonstrates PepINVENT's ability to explore
the peptide space with unique and novel designs, and its capacity for property
optimization in the context of therapeutically relevant peptides. Our tool can
be employed for multi-parameter learning objectives, peptidomimetics, lead
optimization, and variety of other tasks within the peptide domain.",http://arxiv.org/pdf/2409.14040v1,,False
ChronoGAN: Supervised and Embedded Generative Adversarial Networks for Time Series Generation,21/09/2024,"MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi","Generating time series data using Generative Adversarial Networks (GANs)
presents several prevalent challenges, such as slow convergence, information
loss in embedding spaces, instability, and performance variability depending on
the series length. To tackle these obstacles, we introduce a robust framework
aimed at addressing and mitigating these issues effectively. This advanced
framework integrates the benefits of an Autoencoder-generated embedding space
with the adversarial training dynamics of GANs. This framework benefits from a
time series-based loss function and oversight from a supervisory network, both
of which capture the stepwise conditional distributions of the data
effectively. The generator functions within the latent space, while the
discriminator offers essential feedback based on the feature space. Moreover,
we introduce an early generation algorithm and an improved neural network
architecture to enhance stability and ensure effective generalization across
both short and long time series. Through joint training, our framework
consistently outperforms existing benchmarks, generating high-quality time
series data across a range of real and synthetic datasets with diverse
characteristics.",http://arxiv.org/pdf/2409.14013v1,,False
Relevance-driven Decision Making for Safer and More Efficient Human Robot Collaboration,21/09/2024,"Xiaotong Zhang, Dingcheng Huang, Kamal Youcef-Toumi","Human intelligence possesses the ability to effectively focus on important
environmental components, which enhances perception, learning, reasoning, and
decision-making. Inspired by this cognitive mechanism, we introduced a novel
concept termed relevance for Human-Robot Collaboration (HRC). Relevance is
defined as the importance of the objects based on the applicability and
pertinence of the objects for the human objective or other factors. In this
paper, we further developed a novel two-loop framework integrating real-time
and asynchronous processing to quantify relevance and apply relevance for safer
and more efficient HRC. The asynchronous loop leverages the world knowledge
from an LLM and quantifies relevance, and the real-time loop executes scene
understanding, human intent prediction, and decision-making based on relevance.
In decision making, we proposed and developed a human robot task allocation
method based on relevance and a novel motion generation and collision avoidance
methodology considering the prediction of human trajectory. Simulations and
experiments show that our methodology for relevance quantification can
accurately and robustly predict the human objective and relevance, with an
average accuracy of up to 0.90 for objective prediction and up to 0.96 for
relevance prediction. Moreover, our motion generation methodology reduces
collision cases by 63.76% and collision frames by 44.74% when compared with a
state-of-the-art (SOTA) collision avoidance method. Our framework and
methodologies, with relevance, guide the robot on how to best assist humans and
generate safer and more efficient actions for HRC.",http://arxiv.org/pdf/2409.13998v1,,False
Contrastive Learning for Knowledge-Based Question Generation in Large Language Models,21/09/2024,"Zhenhong Zhang, Jiajing Chen, Weiyan Shi, Lingjie Yi, Chihang Wang, Qian Yu","With the rapid development of artificial intelligence technology, especially
the increasingly widespread application of question-and-answer systems,
high-quality question generation has become a key component in supporting the
development of these systems. This article focuses on knowledge-based question
generation technology, which aims to enable computers to simulate the human
questioning process based on understanding specific texts or knowledge bases.
In light of the issues of hallucination and knowledge gaps present in
large-scale language models when applied to knowledge-intensive tasks, this
paper proposes an enhanced question generation method that incorporates
contrastive learning. This method utilizes multiple models to jointly mine
domain knowledge and uses contrastive learning to guide the model in reducing
noise and hallucinations in generation. Experimental results show that by
designing prompts containing contrasting examples, the model's performance in
question generation improves considerably, particularly when contrasting
instructions and examples are used simultaneously, leading to the highest
quality of generated questions and improved accuracy. These results demonstrate
that the method proposed in this study, which combines contrasting context and
chain-of-thought prompts, can effectively improve both the quality and the
practicality of question generation.",http://arxiv.org/pdf/2409.13994v1,,False
High-Resolution Flood Probability Mapping Using Generative Machine Learning with Large-Scale Synthetic Precipitation and Inundation Data,20/09/2024,"Lipai Huang, Federico Antolini, Ali Mostafavi, Russell Blessing, Matthew Garcia, Samuel D. Brody","High-resolution flood probability maps are essential for addressing the
limitations of existing flood risk assessment approaches but are often limited
by the availability of historical event data. Also, producing simulated data
needed for creating probabilistic flood maps using physics-based models
involves significant computation and time effort inhibiting the feasibility. To
address this gap, this study introduces Flood-Precip GAN (Flood-Precipitation
Generative Adversarial Network), a novel methodology that leverages generative
machine learning to simulate large-scale synthetic inundation data to produce
probabilistic flood maps. With a focus on Harris County, Texas, Flood-Precip
GAN begins with training a cell-wise depth estimator using a limited number of
physics-based model-generated precipitation-flood events. This model, which
emphasizes precipitation-based features, outperforms universal models.
Subsequently, a Generative Adversarial Network (GAN) with constraints is
employed to conditionally generate synthetic precipitation records. Strategic
thresholds are established to filter these records, ensuring close alignment
with true precipitation patterns. For each cell, synthetic events are smoothed
using a K-nearest neighbors algorithm and processed through the depth estimator
to derive synthetic depth distributions. By iterating this procedure and after
generating 10,000 synthetic precipitation-flood events, we construct flood
probability maps in various formats, considering different inundation depths.
Validation through similarity and correlation metrics confirms the fidelity of
the synthetic depth distributions relative to true data. Flood-Precip GAN
provides a scalable solution for generating synthetic flood depth data needed
to create high-resolution flood probability maps, significantly enhancing flood
preparedness and mitigation efforts.",http://arxiv.org/pdf/2409.13936v1,,False
High-dimensional learning of narrow neural networks,20/09/2024,Hugo Cui,"Recent years have been marked with the fast-pace diversification and
increasing ubiquity of machine learning applications. Yet, a firm theoretical
understanding of the surprising efficiency of neural networks to learn from
high-dimensional data still proves largely elusive. In this endeavour, analyses
inspired by statistical physics have proven instrumental, enabling the tight
asymptotic characterization of the learning of neural networks in high
dimensions, for a broad class of solvable models. This manuscript reviews the
tools and ideas underlying recent progress in this line of work. We introduce a
generic model -- the sequence multi-index model -- which encompasses numerous
previously studied models as special instances. This unified framework covers a
broad class of machine learning architectures with a finite number of hidden
units, including multi-layer perceptrons, autoencoders, attention mechanisms;
and tasks, including (un)supervised learning, denoising, contrastive learning,
in the limit of large data dimension, and comparably large number of samples.
We explicate in full detail the analysis of the learning of sequence
multi-index models, using statistical physics techniques such as the replica
method and approximate message-passing algorithms. This manuscript thus
provides a unified presentation of analyses reported in several previous works,
and a detailed overview of central techniques in the field of statistical
physics of machine learning. This review should be a useful primer for machine
learning theoreticians curious of statistical physics approaches; it should
also be of value to statistical physicists interested in the transfer of such
ideas to the study of neural networks.",http://arxiv.org/pdf/2409.13904v1,,False
MAGICS: Adversarial RL with Minimax Actors Guided by Implicit Critic Stackelberg for Convergent Neural Synthesis of Robot Safety,20/09/2024,"Justin Wang, Haimin Hu, Duy Phuong Nguyen, Jaime Fernández Fisac","While robust optimal control theory provides a rigorous framework to compute
robot control policies that are provably safe, it struggles to scale to
high-dimensional problems, leading to increased use of deep learning for
tractable synthesis of robot safety. Unfortunately, existing neural safety
synthesis methods often lack convergence guarantees and solution
interpretability. In this paper, we present Minimax Actors Guided by Implicit
Critic Stackelberg (MAGICS), a novel adversarial reinforcement learning (RL)
algorithm that guarantees local convergence to a minimax equilibrium solution.
We then build on this approach to provide local convergence guarantees for a
general deep RL-based robot safety synthesis algorithm. Through both simulation
studies on OpenAI Gym environments and hardware experiments with a
36-dimensional quadruped robot, we show that MAGICS can yield robust control
policies outperforming the state-of-the-art neural safety synthesis methods.",http://arxiv.org/pdf/2409.13867v1,,False
Learning to Simulate Aerosol Dynamics with Graph Neural Networks,20/09/2024,"Fabiana Ferracina, Payton Beeler, Mahantesh Halappanavar, Bala Krishnamoorthy, Marco Minutoli, Laura Fierce","Aerosol effects on climate, weather, and air quality depend on
characteristics of individual particles, which are tremendously diverse and
change in time. Particle-resolved models are the only models able to capture
this diversity in particle physiochemical properties, and these models are
computationally expensive. As a strategy for accelerating particle-resolved
microphysics models, we introduce Graph-based Learning of Aerosol Dynamics
(GLAD) and use this model to train a surrogate of the particle-resolved model
PartMC-MOSAIC. GLAD implements a Graph Network-based Simulator (GNS), a machine
learning framework that has been used to simulate particle-based fluid dynamics
models. In GLAD, each particle is represented as a node in a graph, and the
evolution of the particle population over time is simulated through learned
message passing. We demonstrate our GNS approach on a simple aerosol system
that includes condensation of sulfuric acid onto particles composed of sulfate,
black carbon, organic carbon, and water. A graph with particles as nodes is
constructed, and a graph neural network (GNN) is then trained using the model
output from PartMC-MOSAIC. The trained GNN can then be used for simulating and
predicting aerosol dynamics over time. Results demonstrate the framework's
ability to accurately learn chemical dynamics and generalize across different
scenarios, achieving efficient training and prediction times. We evaluate the
performance across three scenarios, highlighting the framework's robustness and
adaptability in modeling aerosol microphysics and chemistry.",http://arxiv.org/pdf/2409.13861v1,,False
Learning Ordering in Crystalline Materials with Symmetry-Aware Graph Neural Networks,20/09/2024,"Jiayu Peng, James Damewood, Jessica Karaguesian, Jaclyn R. Lunger, Rafael Gómez-Bombarelli","Graph convolutional neural networks (GCNNs) have become a machine learning
workhorse for screening the chemical space of crystalline materials in fields
such as catalysis and energy storage, by predicting properties from structures.
Multicomponent materials, however, present a unique challenge since they can
exhibit chemical (dis)order, where a given lattice structure can encompass a
variety of elemental arrangements ranging from highly ordered structures to
fully disordered solid solutions. Critically, properties like stability,
strength, and catalytic performance depend not only on structures but also on
orderings. To enable rigorous materials design, it is thus critical to ensure
GCNNs are capable of distinguishing among atomic orderings. However, the
ordering-aware capability of GCNNs has been poorly understood. Here, we
benchmark various neural network architectures for capturing the
ordering-dependent energetics of multicomponent materials in a custom-made
dataset generated with high-throughput atomistic simulations. Conventional
symmetry-invariant GCNNs were found unable to discern the structural difference
between the diverse symmetrically inequivalent atomic orderings of the same
material, while symmetry-equivariant model architectures could inherently
preserve and differentiate the distinct crystallographic symmetries of various
orderings.",http://arxiv.org/pdf/2409.13851v1,,False
A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics,20/09/2024,"Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai","Understanding the structure and motion of the heart is crucial for diagnosing
and managing cardiovascular diseases, the leading cause of global death. There
is wide variation in cardiac shape and motion patterns, that are influenced by
demographic, anthropometric and disease factors. Unravelling the normal
patterns of shape and motion, as well as understanding how each individual
deviates from the norm, would facilitate accurate diagnosis and personalised
treatment strategies. To this end, we developed a novel conditional generative
model, MeshHeart, to learn the distribution of cardiac shape and motion
patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences,
taking into account clinical factors such as age, sex, weight and height. To
model the high-dimensional and complex spatio-temporal mesh data, MeshHeart
employs a geometric encoder to represent cardiac meshes in a latent space,
followed by a temporal Transformer to model the motion dynamics of latent
representations. Based on MeshHeart, we investigate the latent space of 3D+t
cardiac mesh sequences and propose a novel distance metric termed latent delta,
which quantifies the deviation of a real heart from its personalised normative
pattern in the latent space. In experiments using a large dataset of 38,309
subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence
reconstruction and generation. Features defined in the latent space are highly
discriminative for cardiac disease classification, whereas the latent delta
exhibits strong correlation with clinical phenotypes in phenome-wide
association studies. The codes and models of this study will be released to
benefit further research on digital heart modelling.",http://arxiv.org/pdf/2409.13825v1,,False
Benchmarking Reliability of Deep Learning Models for Pathological Gait Classification,20/09/2024,"Abhishek Jaiswal, Nisheeth Srivastava","Early detection of neurodegenerative disorders is an important open problem,
since early diagnosis and treatment may yield a better prognosis. Researchers
have recently sought to leverage advances in machine learning algorithms to
detect symptoms of altered gait, possibly corresponding to the emergence of
neurodegenerative etiologies. However, while several claims of positive and
accurate detection have been made in the recent literature, using a variety of
sensors and algorithms, solutions are far from being realized in practice. This
paper analyzes existing approaches to identify gaps inhibiting translation.
Using a set of experiments across three Kinect-simulated and one real
Parkinson's patient datasets, we highlight possible sources of errors and
generalization failures in these approaches. Based on these observations, we
propose our strong baseline called Asynchronous Multi-Stream Graph
Convolutional Network (AMS-GCN) that can reliably differentiate multiple
categories of pathological gaits across datasets.",http://arxiv.org/pdf/2409.13643v1,,False
Towards Long-Context Time Series Foundation Models,20/09/2024,"Nina Żukowska, Mononito Goswami, Michał Wiliński, Willa Potosnak, Artur Dubrawski","Time series foundation models have shown impressive performance on a variety
of tasks, across a wide range of domains, even in zero-shot settings. However,
most of these models are designed to handle short univariate time series as an
input. This limits their practical use, especially in domains such as
healthcare with copious amounts of long and multivariate data with strong
temporal and intra-variate dependencies. Our study bridges this gap by
cataloging and systematically comparing various context expansion techniques
from both language and time series domains, and introducing a novel compressive
memory mechanism to allow encoder-only TSFMs to effectively model intra-variate
dependencies. We demonstrate the benefits of our approach by imbuing MOMENT, a
recent family of multi-task time series foundation models, with the
multivariate context.",http://arxiv.org/pdf/2409.13530v1,,False
Stimulus-to-Stimulus Learning in RNNs with Cortical Inductive Biases,20/09/2024,"Pantelis Vafidis, Antonio Rangel","Animals learn to predict external contingencies from experience through a
process of conditioning. A natural mechanism for conditioning is stimulus
substitution, whereby the neuronal response to a stimulus with no prior
behavioral significance becomes increasingly identical to that generated by a
behaviorally significant stimulus it reliably predicts. We propose a recurrent
neural network model of stimulus substitution which leverages two forms of
inductive bias pervasive in the cortex: representational inductive bias in the
form of mixed stimulus representations, and architectural inductive bias in the
form of two-compartment pyramidal neurons that have been shown to serve as a
fundamental unit of cortical associative learning. The properties of these
neurons allow for a biologically plausible learning rule that implements
stimulus substitution, utilizing only information available locally at the
synapses. We show that the model generates a wide array of conditioning
phenomena, and can learn large numbers of associations with an amount of
training commensurate with animal experiments, without relying on parameter
fine-tuning for each individual experimental task. In contrast, we show that
commonly used Hebbian rules fail to learn generic stimulus-stimulus
associations with mixed selectivity, and require task-specific parameter
fine-tuning. Our framework highlights the importance of multi-compartment
neuronal processing in the cortex, and showcases how it might confer cortical
animals the evolutionary edge.",http://arxiv.org/pdf/2409.13471v1,,False
Revisiting Synthetic Human Trajectories: Imitative Generation and Benchmarks Beyond Datasaurus,20/09/2024,"Bangchao Deng, Xin Jing, Tianyue Yang, Bingqing Qu, Philippe Cudre-Mauroux, Dingqi Yang","Human trajectory data, which plays a crucial role in various applications
such as crowd management and epidemic prevention, is challenging to obtain due
to practical constraints and privacy concerns. In this context, synthetic human
trajectory data is generated to simulate as close as possible to real-world
human trajectories, often under summary statistics and distributional
similarities. However, the complexity of human mobility patterns is
oversimplified by these similarities (a.k.a. ``Datasaurus''), resulting in
intrinsic biases in both generative model design and benchmarks of the
generated trajectories. Against this background, we propose MIRAGE, a
huMan-Imitative tRAjectory GenErative model designed as a neural Temporal Point
Process integrating an Exploration and Preferential Return model. It imitates
the human decision-making process in trajectory generation, rather than fitting
any specific statistical distributions as traditional methods do, thus avoiding
the Datasaurus issue. Moreover, we also propose a comprehensive task-based
evaluation protocol beyond Datasaurus to systematically benchmark trajectory
generative models on four typical downstream tasks, integrating multiple
techniques and evaluation metrics for each task, to comprehensively assess the
ultimate utility of the generated trajectories. We conduct a thorough
evaluation of MIRAGE on three real-world user trajectory datasets against a
sizeable collection of baselines. Results show that compared to the best
baselines, MIRAGE-generated trajectory data not only achieves the best
statistical and distributional similarities with 59.0-71.5% improvement, but
also yields the best performance in the task-based evaluation with 10.9-33.4%
improvement.",http://arxiv.org/pdf/2409.13790v1,,False
Generative Aerodynamic Design with Diffusion Probabilistic Models,20/09/2024,"Thomas Wagenaar, Simone Mancini, Andrés Mateo-Gabín","The optimization of geometries for aerodynamic design often relies on a large
number of expensive simulations to evaluate and iteratively improve the
geometries. It is possible to reduce the number of simulations by providing a
starting geometry that has properties close to the desired requirements, often
in terms of lift and drag, aerodynamic moments and surface areas. We show that
generative models have the potential to provide such starting geometries by
generalizing geometries over a large dataset of simulations. In particular, we
leverage diffusion probabilistic models trained on XFOIL simulations to
synthesize two-dimensional airfoil geometries conditioned on given aerodynamic
features and constraints. The airfoils are parameterized with Bernstein
polynomials, ensuring smoothness of the generated designs. We show that the
models are able to generate diverse candidate designs for identical
requirements and constraints, effectively exploring the design space to provide
multiple starting points to optimization procedures. However, the quality of
the candidate designs depends on the distribution of the simulated designs in
the dataset. Importantly, the geometries in this dataset must satisfy other
requirements and constraints that are not used in conditioning of the diffusion
model, to ensure that the generated geometries are physical.",http://arxiv.org/pdf/2409.13328v1,,False
SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation,20/09/2024,"Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu","Inspired by the success of large language models (LLMs), there is growing
research interest in developing LLMs in the medical domain to assist
clinicians. However, for hospitals, using closed-source commercial LLMs
involves privacy issues, and developing open-source public LLMs requires
large-scale computational resources, which are usually limited, especially in
resource-efficient regions and low-income countries. We propose an open-source
Small Language and Vision Assistant (SLaVA-CXR) that can be used for Chest
X-Ray report automation. To efficiently train a small assistant, we first
propose the Re$^3$Training method, which simulates the cognitive development of
radiologists and optimizes the model in the Recognition, Reasoning, and
Reporting training manner. Then, we introduce a data synthesis method, RADEX,
which can generate a high-quality and diverse training corpus with privacy
regulation compliance. The extensive experiments show that our SLaVA-CXR built
on a 2.7B backbone not only outperforms but also achieves 6 times faster
inference efficiency than previous state-of-the-art larger models.",http://arxiv.org/pdf/2409.13321v1,,False
Learning to Generalize Unseen Domains via Multi-Source Meta Learning for Text Classification,20/09/2024,"Yuxuan Hu, Chenwei Zhang, Min Yang, Xiaodan Liang, Chengming Li, Xiping Hu","With the rapid development of deep learning methods, there have been many
breakthroughs in the field of text classification. Models developed for this
task have been shown to achieve high accuracy. However, most of these models
are trained using labeled data from seen domains. It is difficult for these
models to maintain high accuracy in a new challenging unseen domain, which is
directly related to the generalization of the model. In this paper, we study
the multi-source Domain Generalization of text classification and propose a
framework to use multiple seen domains to train a model that can achieve high
accuracy in an unseen domain. Specifically, we propose a multi-source
meta-learning Domain Generalization framework to simulate the process of model
generalization to an unseen domain, so as to extract sufficient domain-related
features. We introduced a memory mechanism to store domain-specific features,
which coordinate with the meta-learning framework. Besides, we adopt the novel
""jury"" mechanism that enables the model to learn sufficient domain-invariant
features. Experiments demonstrate that our meta-learning framework can
effectively enhance the ability of the model to generalize to an unseen domain
and can outperform the state-of-the-art methods on multi-source text
classification datasets.",http://arxiv.org/pdf/2409.13787v1,,False
Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia,20/09/2024,"Elisa Castagnari, Lillian Muyama, Adrien Coulet","In practice, clinicians achieve a diagnosis by following a sequence of steps,
such as laboratory exams, observations, or imaging. The pathways to reach
diagnosis decisions are documented by guidelines authored by expert
organizations, which guide clinicians to reach a correct diagnosis through
these sequences of steps. While these guidelines are beneficial for following
medical reasoning and consolidating medical knowledge, they have some
drawbacks. They often fail to address patients with uncommon conditions due to
their focus on the majority population, and are slow and costly to update,
making them unsuitable for rapidly emerging diseases or new practices. Inspired
by clinical guidelines, our study aimed to develop pathways similar to those
that can be obtained in clinical guidelines. We tested three Large Language
Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language
Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to
differentially diagnose anemia and its subtypes. By using advanced prompting
techniques to enhance the decision-making process, we generated diagnostic
pathways using these models. Experimental results indicate that LLMs hold huge
potential in clinical pathway discovery from patient data, with GPT-4
exhibiting the best performance in all conducted experiments.",http://arxiv.org/pdf/2409.15377v1,,False
Overcoming Data Limitations in Internet Traffic Forecasting: LSTM Models with Transfer Learning and Wavelet Augmentation,20/09/2024,"Sajal Saha, Anwar Haque, Greg Sidebottom","Effective internet traffic prediction in smaller ISP networks is challenged
by limited data availability. This paper explores this issue using transfer
learning and data augmentation techniques with two LSTM-based models,
LSTMSeq2Seq and LSTMSeq2SeqAtn, initially trained on a comprehensive dataset
provided by Juniper Networks and subsequently applied to smaller datasets. The
datasets represent real internet traffic telemetry, offering insights into
diverse traffic patterns across different network domains. Our study revealed
that while both models performed well in single-step predictions, multi-step
forecasts were challenging, particularly in terms of long-term accuracy. In
smaller datasets, LSTMSeq2Seq generally outperformed LSTMSeq2SeqAtn, indicating
that higher model complexity does not necessarily translate to better
performance. The models' effectiveness varied across different network domains,
reflecting the influence of distinct traffic characteristics. To address data
scarcity, Discrete Wavelet Transform was used for data augmentation, leading to
significant improvements in model performance, especially in shorter-term
forecasts. Our analysis showed that data augmentation is crucial in scenarios
with limited data. Additionally, the study included an analysis of the models'
variability and consistency, with attention mechanisms in LSTMSeq2SeqAtn
providing better short-term forecasting consistency but greater variability in
longer forecasts. The results highlight the benefits and limitations of
different modeling approaches in traffic prediction. Overall, this research
underscores the importance of transfer learning and data augmentation in
enhancing the accuracy of traffic prediction models, particularly in smaller
ISP networks with limited data availability.",http://arxiv.org/pdf/2409.13181v1,,False
FedAT: Federated Adversarial Training for Distributed Insider Threat Detection,19/09/2024,"R G Gayathri, Atul Sajjanhar, Md Palash Uddin, Yong Xiang","Insider threats usually occur from within the workplace, where the attacker
is an entity closely associated with the organization. The sequence of actions
the entities take on the resources to which they have access rights allows us
to identify the insiders. Insider Threat Detection (ITD) using Machine Learning
(ML)-based approaches gained attention in the last few years. However, most
techniques employed centralized ML methods to perform such an ITD.
Organizations operating from multiple locations cannot contribute to the
centralized models as the data is generated from various locations. In
particular, the user behavior data, which is the primary source of ITD, cannot
be shared among the locations due to privacy concerns. Additionally, the data
distributed across various locations result in extreme class imbalance due to
the rarity of attacks. Federated Learning (FL), a distributed data modeling
paradigm, gained much interest recently. However, FL-enabled ITD is not yet
explored, and it still needs research to study the significant issues of its
implementation in practical settings. As such, our work investigates an
FL-enabled multiclass ITD paradigm that considers non-Independent and
Identically Distributed (non-IID) data distribution to detect insider threats
from different locations (clients) of an organization. Specifically, we propose
a Federated Adversarial Training (FedAT) approach using a generative model to
alleviate the extreme data skewness arising from the non-IID data distribution
among the clients. Besides, we propose to utilize a Self-normalized Neural
Network-based Multi-Layer Perceptron (SNN-MLP) model to improve ITD. We perform
comprehensive experiments and compare the results with the benchmarks to
manifest the enhanced performance of the proposed FedATdriven ITD scheme.",http://arxiv.org/pdf/2409.13083v1,,False
Unrolled denoising networks provably learn optimal Bayesian inference,19/09/2024,"Aayush Karan, Kulin Shah, Sitan Chen, Yonina C. Eldar","Much of Bayesian inference centers around the design of estimators for
inverse problems which are optimal assuming the data comes from a known prior.
But what do these optimality guarantees mean if the prior is unknown? In recent
years, algorithm unrolling has emerged as deep learning's answer to this
age-old question: design a neural network whose layers can in principle
simulate iterations of inference algorithms and train on data generated by the
unknown prior. Despite its empirical success, however, it has remained unclear
whether this method can provably recover the performance of its optimal,
prior-aware counterparts.
  In this work, we prove the first rigorous learning guarantees for neural
networks based on unrolling approximate message passing (AMP). For compressed
sensing, we prove that when trained on data drawn from a product prior, the
layers of the network approximately converge to the same denoisers used in
Bayes AMP. We also provide extensive numerical experiments for compressed
sensing and rank-one matrix estimation demonstrating the advantages of our
unrolled architecture - in addition to being able to obliviously adapt to
general priors, it exhibits improvements over Bayes AMP in more general
settings of low dimensions, non-Gaussian designs, and non-product priors.",http://arxiv.org/pdf/2409.12947v1,,False
Online Proximal ADMM for Graph Learning from Streaming Smooth Signals,19/09/2024,"Hector Chahuara, Gonzalo Mateos","Graph signal processing deals with algorithms and signal representations that
leverage graph structures for multivariate data analysis. Often said graph
topology is not readily available and may be time-varying, hence (dynamic)
graph structure learning from nodal (e.g., sensor) observations becomes a
critical first step. In this paper, we develop a novel algorithm for online
graph learning using observation streams, assumed to be smooth on the latent
graph. Unlike batch algorithms for topology identification from smooth signals,
our modus operandi is to process graph signals sequentially and thus keep
memory and computational costs in check. To solve the resulting
smoothness-regularized, time-varying inverse problem, we develop online and
lightweight iterations built upon the proximal variant of the alternating
direction method of multipliers (ADMM), well known for its fast convergence in
batch settings. The proximal term in the topology updates seamlessly implements
a temporal-variation regularization, and we argue the online procedure exhibits
sublinear static regret under some simplifying assumptions. Reproducible
experiments with synthetic and real graphs demonstrate the effectiveness of our
method in adapting to streaming signals and tracking slowly-varying network
connectivity. The proposed approach also exhibits better tracking performance
(in terms of suboptimality), when compared to state-of-the-art online graph
learning baselines.",http://arxiv.org/pdf/2409.12916v1,,False
Physics aware machine learning for micromagnetic energy minimization: recent algorithmic developments,19/09/2024,"Sebastian Schaffer, Thomas Schrefl, Harald Oezelt, Norbert J Mauser, Lukas Exl","In this work, we explore advanced machine learning techniques for minimizing
Gibbs free energy in full 3D micromagnetic simulations. Building on Brown's
bounds for magnetostatic self-energy, we revisit their application in the
context of variational formulations of the transmission problems for the scalar
and vector potential. To overcome the computational challenges posed by
whole-space integrals, we reformulate these bounds on a finite domain, making
the method more efficient and scalable for numerical simulation. Our approach
utilizes an alternating optimization scheme for joint minimization of Brown's
energy bounds and the Gibbs free energy. The Cayley transform is employed to
rigorously enforce the unit norm constraint, while R-functions are used to
impose essential boundary conditions in the computation of magnetostatic
fields. Our results highlight the potential of mesh-free Physics-Informed
Neural Networks (PINNs) and Extreme Learning Machines (ELMs) when integrated
with hard constraints, providing highly accurate approximations. These methods
exhibit competitive performance compared to traditional numerical approaches,
showing significant promise in computing magnetostatic fields and the
application for energy minimization, such as the computation of hysteresis
curves. This work opens the path for future directions of research on more
complex geometries, such as grain structure models, and the application to
large scale problem settings which are intractable with traditional numerical
methods.",http://arxiv.org/pdf/2409.12877v1,,False
Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences,19/09/2024,"Ricky Sahu, Eric Marriott, Ethan Siegel, David Wagner, Flore Uzan, Troy Yang, Asim Javed","With U.S. healthcare spending approaching $5T (NHE Fact Sheet 2024), and 25%
of it estimated to be wasteful (Waste in the US the health care system:
estimated costs and potential for savings, n.d.), the need to better predict
risk and optimal patient care is evermore important. This paper introduces the
Large Medical Model (LMM), a generative pre-trained transformer (GPT) designed
to guide and predict the broad facets of patient care and healthcare
administration. The model is trained on medical event sequences from over 140M
longitudinal patient claims records with a specialized vocabulary built from
medical terminology systems and demonstrates a superior capability to forecast
healthcare costs and identify potential risk factors. Through experimentation
and validation, we showcase the LMM's proficiency in not only in cost and risk
predictions, but also in discerning intricate patterns within complex medical
conditions and an ability to identify novel relationships in patient care. The
LMM is able to improve both cost prediction by 14.1% over the best commercial
models and chronic conditions prediction by 1.9% over the best transformer
models in research predicting a broad set of conditions. The LMM is a
substantial advancement in healthcare analytics, offering the potential to
significantly enhance risk assessment, cost management, and personalized
medicine.",http://arxiv.org/pdf/2409.13000v1,,False
Vision Language Models Can Parse Floor Plan Maps,19/09/2024,"David DeFazio, Hrudayangam Mehta, Jeremy Blackburn, Shiqi Zhang","Vision language models (VLMs) can simultaneously reason about images and
texts to tackle many tasks, from visual question answering to image captioning.
This paper focuses on map parsing, a novel task that is unexplored within the
VLM context and particularly useful to mobile robots. Map parsing requires
understanding not only the labels but also the geometric configurations of a
map, i.e., what areas are like and how they are connected. To evaluate the
performance of VLMs on map parsing, we prompt VLMs with floorplan maps to
generate task plans for complex indoor navigation. Our results demonstrate the
remarkable capability of VLMs in map parsing, with a success rate of 0.96 in
tasks requiring a sequence of nine navigation actions, e.g., approaching and
going through doors. Other than intuitive observations, e.g., VLMs do better in
smaller maps and simpler navigation tasks, there was a very interesting
observation that its performance drops in large open areas. We provide
practical suggestions to address such challenges as validated by our
experimental results. Webpage: https://shorturl.at/OUkEY",http://arxiv.org/pdf/2409.12842v1,,False
Multi-Source and Multi-Sequence Myocardial Pathology Segmentation Using a Cascading Refinement CNN,19/09/2024,"Franz Thaler, Darko Stern, Gernot Plank, Martin Urschler","Myocardial infarction (MI) is one of the most prevalent cardiovascular
diseases and consequently, a major cause for mortality and morbidity worldwide.
Accurate assessment of myocardial tissue viability for post-MI patients is
critical for diagnosis and treatment planning, e.g. allowing surgical
revascularization, or to determine the risk of adverse cardiovascular events in
the future. Fine-grained analysis of the myocardium and its surrounding
anatomical structures can be performed by combining the information obtained
from complementary medical imaging techniques. In this work, we use late
gadolinium enhanced (LGE) magnetic resonance (MR), T2-weighted (T2) MR and
balanced steady-state free precession (bSSFP) cine MR in order to semantically
segment the left and right ventricle, healthy and scarred myocardial tissue, as
well as edema. To this end, we propose the Multi-Sequence Cascading Refinement
CNN (MS-CaRe-CNN), a 2-stage CNN cascade that receives multi-sequence data and
generates predictions of the anatomical structures of interest without
considering tissue viability at Stage 1. The prediction of Stage 1 is then
further refined in Stage 2, where the model additionally distinguishes
myocardial tissue based on viability, i.e. healthy, scarred and edema regions.
Our proposed method is set up as a 5-fold ensemble and semantically segments
scar tissue achieving 62.31% DSC and 82.65% precision, as well as 63.78% DSC
and 87.69% precision for the combined scar and edema region. These promising
results for such small and challenging structures confirm that MS-CaRe-CNN is
well-suited to generate semantic segmentations to assess the viability of
myocardial tissue, enabling downstream tasks like personalized therapy
planning.",http://arxiv.org/pdf/2409.12792v1,,False
Algorithmic and High-Frequency Trading Problems for Semi-Markov and Hawkes Jump-Diffusion Models,19/09/2024,"Luca Lalor, Anatoliy Swishchuk","Algorithmic and High-Frequency trading (HFT) has become one of the main ways
to complete transactions in many of today's major financial markets, with these
transactions taking place inside what is called the limit order book (LOB).
Developing sophisticated trading algorithms that accurately mimic LOB data is
therefore a major topic in this area. In recent times, it has been proven that
LOB data often follows non-Markovian dynamics, thus, we believe these models
more accurately describe how the LOB would evolve. In this paper, we consider
acquisition and liquidation problems for semi-Markov and Hawkes jump-diffusion
models. We begin by developing jump-diffusion models to capture these dynamics
and then proceed to use diffusion approximations for the jump parts. The
optimal solutions to these trading problems are formulated under the stochastic
optimal control framework and via numerical methods. Strategy simulations for
the acquisition and liquidation problems are considered as well, where we show
sample price paths for our price processes, average traded prices, inventory
and trading speed paths. This analysis gives a general picture of how one could
analyse how these strategies could perform under our more general price
processes.",http://arxiv.org/pdf/2409.12776v1,,False
SeqRisk: Transformer-augmented latent variable model for improved survival prediction with longitudinal data,19/09/2024,"Mine Öğretir, Miika Koskinen, Juha Sinisalo, Risto Renkonen, Harri Lähdesmäki","In healthcare, risk assessment of different patient outcomes has for long
time been based on survival analysis, i.e.\ modeling time-to-event
associations. However, conventional approaches rely on data from a single
time-point, making them suboptimal for fully leveraging longitudinal patient
history and capturing temporal regularities. Focusing on clinical real-world
data and acknowledging its challenges, we utilize latent variable models to
effectively handle irregular, noisy, and sparsely observed longitudinal data.
We propose SeqRisk, a method that combines variational autoencoder (VAE) or
longitudinal VAE (LVAE) with a transformer encoder and Cox proportional hazards
module for risk prediction. SeqRisk captures long-range interactions, improves
patient trajectory representations, enhances predictive accuracy and
generalizability, as well as provides partial explainability for sample
population characteristics in attempts to identify high-risk patients. We
demonstrate that SeqRisk performs competitively compared to existing approaches
on both simulated and real-world datasets.",http://arxiv.org/pdf/2409.12709v1,,False
PersonaFlow: Boosting Research Ideation with LLM-Simulated Expert Personas,19/09/2024,"Yiren Liu, Pranav Sharma, Mehul Jitendra Oswal, Haijun Xia, Yun Huang","Developing novel interdisciplinary research ideas often requires discussions
and feedback from experts across different domains. However, obtaining timely
inputs is challenging due to the scarce availability of domain experts. Recent
advances in Large Language Model (LLM) research have suggested the feasibility
of utilizing LLM-simulated expert personas to support research ideation. In
this study, we introduce PersonaFlow, an LLM-based system using persona
simulation to support the ideation stage of interdisciplinary scientific
discovery. Our findings indicate that using multiple personas during ideation
significantly enhances user-perceived quality of outcomes (e.g., relevance of
critiques, creativity of research questions) without increasing cognitive load.
We also found that users' persona customization interactions significantly
improved their sense of control and recall of generated ideas. Based on the
findings, we discuss highlighting ethical concerns, including potential
over-reliance and cognitive biases, and suggest design implications for
leveraging LLM-simulated expert personas to support research ideation when
human expertise is inaccessible.",http://arxiv.org/pdf/2409.12538v1,,False
SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference,19/09/2024,"Zhen Chen, Xingjian Luo, Jinlin Wu, Long Bai, Zhen Lei, Hongliang Ren, Sebastien Ourselin, Hongbin Liu","Surgical phase recognition is critical for assisting surgeons in
understanding surgical videos. Existing studies focused more on online surgical
phase recognition, by leveraging preceding frames to predict the current frame.
Despite great progress, they formulated the task as a series of frame-wise
classification, which resulted in a lack of global context of the entire
procedure and incoherent predictions. Moreover, besides online analysis,
accurate offline surgical phase recognition is also in significant clinical
need for retrospective analysis, and existing online algorithms do not fully
analyze the entire video, thereby limiting accuracy in offline analysis. To
overcome these challenges and enhance both online and offline inference
capabilities, we propose a universal Surgical Phase Localization Network, named
SurgPLAN++, with the principle of temporal detection. To ensure a global
understanding of the surgical procedure, we devise a phase localization
strategy for SurgPLAN++ to predict phase segments across the entire video
through phase proposals. For online analysis, to generate high-quality phase
proposals, SurgPLAN++ incorporates a data augmentation strategy to extend the
streaming video into a pseudo-complete video through mirroring,
center-duplication, and down-sampling. For offline analysis, SurgPLAN++
capitalizes on its global phase prediction framework to continuously refine
preceding predictions during each online inference step, thereby significantly
improving the accuracy of phase recognition. We perform extensive experiments
to validate the effectiveness, and our SurgPLAN++ achieves remarkable
performance in both online and offline modes, which outperforms
state-of-the-art methods. The source code is available at
https://github.com/lxj22/SurgPLAN-Plus.",http://arxiv.org/pdf/2409.12467v1,,False
Channel-Aware Domain-Adaptive Generative Adversarial Network for Robust Speech Recognition,19/09/2024,"Chien-Chun Wang, Li-Wei Chen, Cheng-Kang Chou, Hung-Shin Lee, Berlin Chen, Hsin-Min Wang","While pre-trained automatic speech recognition (ASR) systems demonstrate
impressive performance on matched domains, their performance often degrades
when confronted with channel mismatch stemming from unseen recording
environments and conditions. To mitigate this issue, we propose a novel
channel-aware data simulation method for robust ASR training. Our method
harnesses the synergistic power of channel-extractive techniques and generative
adversarial networks (GANs). We first train a channel encoder capable of
extracting embeddings from arbitrary audio. On top of this, channel embeddings
are extracted using a minimal amount of target-domain data and used to guide a
GAN-based speech synthesizer. This synthesizer generates speech that faithfully
preserves the phonetic content of the input while mimicking the channel
characteristics of the target domain. We evaluate our method on the challenging
Hakka Across Taiwan (HAT) and Taiwanese Across Taiwan (TAT) corpora, achieving
relative character error rate (CER) reductions of 20.02% and 9.64%,
respectively, compared to the baselines. These results highlight the efficacy
of our channel-aware data simulation method for bridging the gap between
source- and target-domain acoustics.",http://arxiv.org/pdf/2409.12386v1,,False
