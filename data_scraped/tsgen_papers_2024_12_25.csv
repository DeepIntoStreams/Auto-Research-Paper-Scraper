Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Efficient Aircraft Design Optimization Using Multi-Fidelity Models and Multi-fidelity Physics Informed Neural Networks,24/12/2024,Apurba Sarker,"Aircraft design optimization traditionally relies on computationally
expensive simulation techniques such as Finite Element Method (FEM) and Finite
Volume Method (FVM), which, while accurate, can significantly slow down the
design iteration process. The challenge lies in reducing the computational
complexity while maintaining high accuracy for quick evaluations of multiple
design alternatives. This research explores advanced methods, including
surrogate models, reduced-order models (ROM), and multi-fidelity machine
learning techniques, to achieve more efficient aircraft design evaluations.
Specifically, the study investigates the application of Multi-fidelity
Physics-Informed Neural Networks (MPINN) and autoencoders for manifold
alignment, alongside the potential of Generative Adversarial Networks (GANs)
for refining design geometries. Through a proof-of-concept task, the research
demonstrates the ability to predict high-fidelity results from low-fidelity
simulations, offering a path toward faster and more cost effective aircraft
design iterations.",http://arxiv.org/pdf/2412.18564v1,,False
Exploring Flexible Scenario Generation in Godot Simulator,24/12/2024,"Daniel Peraltai, Xin Qin","Cyber-physical systems (CPS) combine cyber and physical components engineered
to make decisions and interact within dynamic environments. Ensuring the safety
of CPS is of great importance, requiring extensive testing across diverse and
complex scenarios. To generate as many testing scenarios as possible, previous
efforts have focused on describing scenarios using formal languages to generate
scenes. In this paper, we introduce an alternative approach: reconstructing
scenes inside the open-source game engine, Godot. We have developed a pipeline
that enables the reconstruction of testing scenes directly from provided images
of scenarios. These reconstructed scenes can then be deployed within simulated
environments to assess a CPS. This approach offers a scalable and flexible
solution for testing CPS in realistic environments.",http://arxiv.org/pdf/2412.18408v1,,False
Generalized Mean Absolute Directional Loss as a Solution to Overfitting and High Transaction Costs in Machine Learning Models Used in High-Frequency Algorithmic Investment Strategies,24/12/2024,"Jakub Michańków, Paweł Sakowski, Robert Ślepaczuk","Regardless of the selected asset class and the level of model complexity
(Transformer versus LSTM versus Perceptron/RNN), the GMADL loss function
produces superior results than standard MSE-type loss functions and has better
numerical properties in the context of optimization than MADL. Better results
mean the possibility of achieving a higher risk-weighted return based on buy
and sell signals built on forecasts generated by a given theoretical model
estimated using the GMADL versus MSE or MADL function. In practice, GMADL
solves the problem of selecting the most preferable feature in both
classification and regression problems, improving the performance of each
estimation. What is important is that, through additional parameterization,
GMADL also solves the problem of optimizing investment systems on
high-frequency data in such a way that they focus on strategy variants that
contain fewer transactions so that transaction costs do not reduce the
effectiveness of a given strategy to zero. Moreover, the implementation
leverages state-of-the-art machine learning tools, including frameworks for
hyperparameter tuning, architecture testing, and walk-forward optimization,
ensuring robust and scalable solutions for real-world algorithmic trading.",http://arxiv.org/pdf/2412.18405v1,,False
Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors,24/12/2024,"Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang","Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.",http://arxiv.org/pdf/2412.18370v1,,False
Conditional Deep Canonical Time Warping,24/12/2024,"Afek Steinberg, Ran Eisenberg, Ofir Lindenbaum","Temporal alignment of sequences is a fundamental challenge in many
applications, such as computer vision and bioinformatics, where local time
shifting needs to be accounted for. Misalignment can lead to poor model
generalization, especially in high-dimensional sequences. Existing methods
often struggle with optimization when dealing with high-dimensional sparse
data, falling into poor alignments. Feature selection is frequently used to
enhance model performance for sparse data. However, a fixed set of selected
features would not generally work for dynamically changing sequences and would
need to be modified based on the state of the sequence. Therefore, modifying
the selected feature based on contextual input would result in better
alignment. Our suggested method, Conditional Deep Canonical Temporal Time
Warping (CDCTW), is designed for temporal alignment in sparse temporal data to
address these challenges. CDCTW enhances alignment accuracy for high
dimensional time-dependent views be performing dynamic time warping on data
embedded in maximally correlated subspace which handles sparsity with novel
feature selection method. We validate the effectiveness of CDCTW through
extensive experiments on various datasets, demonstrating superior performance
over previous techniques.",http://arxiv.org/pdf/2412.18234v1,,False
U-Mamba-Net: A highly efficient Mamba-based U-net style network for noisy and reverberant speech separation,24/12/2024,"Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Hiroaki Kudo","The topic of speech separation involves separating mixed speech with multiple
overlapping speakers into several streams, with each stream containing speech
from only one speaker. Many highly effective models have emerged and
proliferated rapidly over time. However, the size and computational load of
these models have also increased accordingly. This is a disaster for the
community, as researchers need more time and computational resources to
reproduce and compare existing models. In this paper, we propose U-mamba-net: a
lightweight Mamba-based U-style model for speech separation in complex
environments. Mamba is a state space sequence model that incorporates feature
selection capabilities. U-style network is a fully convolutional neural network
whose symmetric contracting and expansive paths are able to learn
multi-resolution features. In our work, Mamba serves as a feature filter,
alternating with U-Net. We test the proposed model on Libri2mix. The results
show that U-Mamba-Net achieves improved performance with quite low
computational cost.",http://arxiv.org/pdf/2412.18217v1,,False
Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs Algorithms,24/12/2024,"Zhuohuan Hu, Richard Yu, Zizhou Zhang, Haoran Zheng, Qianying Liu, Yining Zhou","This paper leverages machine learning algorithms to forecast and analyze
financial time series. The process begins with a denoising autoencoder to
filter out random noise fluctuations from the main contract price data. Then,
one-dimensional convolution reduces the dimensionality of the filtered data and
extracts key information. The filtered and dimensionality-reduced price data is
fed into a GANs network, and its output serve as input of a fully connected
network. Through cross-validation, a model is trained to capture features that
precede large price fluctuations. The model predicts the likelihood and
direction of significant price changes in real-time price sequences, placing
trades at moments of high prediction accuracy. Empirical results demonstrate
that using autoencoders and convolution to filter and denoise financial data,
combined with GANs, achieves a certain level of predictive performance,
validating the capabilities of machine learning algorithms to discover
underlying patterns in financial sequences. Keywords - CNN;GANs;
Cryptocurrency; Prediction.",http://arxiv.org/pdf/2412.18202v1,,False
Robustness-aware Automatic Prompt Optimization,24/12/2024,"Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan Yang, Yongfeng Zhang","The performance of Large Language Models (LLMs) is based on the quality of
the prompts and the semantic and structural integrity information of the input
data. However, current prompt generation methods primarily focus on generating
prompts for clean input data, often overlooking the impact of perturbed inputs
on prompt performance. To address this limitation, we propose BATprompt (By
Adversarial Training prompt), a novel method for prompt generation designed to
withstand input perturbations (such as typos in the input). Inspired by
adversarial training techniques, BATprompt demonstrates strong performance on a
variety of perturbed tasks through a two-step process: adversarial perturbation
and iterative optimization on unperturbed input via LLM. Unlike conventional
adversarial attack methods, BATprompt avoids reliance on real gradients or
model parameters. Instead, it leverages the advanced reasoning, language
understanding and self reflection capabilities of LLMs to simulate gradients,
guiding the generation of adversarial perturbations and optimizing prompt
performance. In our experiments, we evaluate BATprompt on multiple datasets
across both language understanding and generation tasks. The results indicate
that BATprompt outperforms existing prompt generation methods, delivering
superior robustness and performance under diverse perturbation scenarios.",http://arxiv.org/pdf/2412.18196v1,,False
"Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence",24/12/2024,"Yinbin Han, Meisam Razaviyayn, Renyuan Xu","Diffusion models have emerged as powerful tools for generative modeling,
demonstrating exceptional capability in capturing target data distributions
from large datasets. However, fine-tuning these massive models for specific
downstream tasks, constraints, and human preferences remains a critical
challenge. While recent advances have leveraged reinforcement learning
algorithms to tackle this problem, much of the progress has been empirical,
with limited theoretical understanding. To bridge this gap, we propose a
stochastic control framework for fine-tuning diffusion models. Building on
denoising diffusion probabilistic models as the pre-trained reference dynamics,
our approach integrates linear dynamics control with Kullback-Leibler
regularization. We establish the well-posedness and regularity of the
stochastic control problem and develop a policy iteration algorithm (PI-FT) for
numerical solution. We show that PI-FT achieves global convergence at a linear
rate. Unlike existing work that assumes regularities throughout training, we
prove that the control and value sequences generated by the algorithm maintain
the regularity. Additionally, we explore extensions of our framework to
parametric settings and continuous-time formulations.",http://arxiv.org/pdf/2412.18164v1,,False
scReader: Prompting Large Language Models to Interpret scRNA-seq Data,24/12/2024,"Cong Li, Qingqing Long, Yuanchun Zhou, Meng Xiao","Large language models (LLMs) have demonstrated remarkable advancements,
primarily due to their capabilities in modeling the hidden relationships within
text sequences. This innovation presents a unique opportunity in the field of
life sciences, where vast collections of single-cell omics data from multiple
species provide a foundation for training foundational models. However, the
challenge lies in the disparity of data scales across different species,
hindering the development of a comprehensive model for interpreting genetic
data across diverse organisms. In this study, we propose an innovative hybrid
approach that integrates the general knowledge capabilities of LLMs with
domain-specific representation models for single-cell omics data
interpretation. We begin by focusing on genes as the fundamental unit of
representation. Gene representations are initialized using functional
descriptions, leveraging the strengths of mature language models such as
LLaMA-2. By inputting single-cell gene-level expression data with prompts, we
effectively model cellular representations based on the differential expression
levels of genes across various species and cell types. In the experiments, we
constructed developmental cells from humans and mice, specifically targeting
cells that are challenging to annotate. We evaluated our methodology through
basic tasks such as cell annotation and visualization analysis. The results
demonstrate the efficacy of our approach compared to other methods using LLMs,
highlighting significant improvements in accuracy and interoperability. Our
hybrid approach enhances the representation of single-cell data and offers a
robust framework for future research in cross-species genetic analysis.",http://arxiv.org/pdf/2412.18156v1,,False
Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner,24/12/2024,Aizierjiang Aiersilan,"Motion planning is a crucial component in autonomous driving.
State-of-the-art motion planners are trained on meticulously curated datasets,
which are not only expensive to annotate but also insufficient in capturing
rarely seen critical scenarios. Failing to account for such scenarios poses a
significant risk to motion planners and may lead to incidents during testing.
An intuitive solution is to manually compose such scenarios by programming and
executing a simulator (e.g., CARLA). However, this approach incurs substantial
human costs. Motivated by this, we propose an inexpensive method for generating
diverse critical traffic scenarios to train more robust motion planners. First,
we represent traffic scenarios as scripts, which are then used by the simulator
to generate traffic scenarios. Next, we develop a method that accepts
user-specified text descriptions, which a Large Language Model (LLM) translates
into scripts using in-context learning. The output scripts are sent to the
simulator that produces the corresponding traffic scenarios. As our method can
generate abundant safety-critical traffic scenarios, we use them as synthetic
training data for motion planners. To demonstrate the value of generated
scenarios, we train existing motion planners on our synthetic data, real-world
datasets, and a combination of both. Our experiments show that motion planners
trained with our data significantly outperform those trained solely on
real-world data, showing the usefulness of our synthetic data and the
effectiveness of our data generation method. Our source code is available at
https://ezharjan.github.io/AutoSceneGen.",http://arxiv.org/pdf/2412.18086v1,,False
