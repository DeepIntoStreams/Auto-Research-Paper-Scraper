Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
A Lightweight Method to Disrupt Memorized Sequences in LLM,07/02/2025,"Parjanya Prajakta Prashant, Kaustubh Ponkshe, Babak Salimi","Large language models (LLMs) demonstrate impressive capabilities across many
tasks yet risk reproducing copyrighted content verbatim, raising legal and
ethical concerns. Although methods like differential privacy or neuron editing
can reduce memorization, they typically require costly retraining or direct
access to model weights and may degrade performance. To address these
challenges, we propose TokenSwap, a lightweight, post-hoc approach that
replaces the probabilities of grammar-related tokens with those from a small
auxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercial
grade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our method
effectively reduces well-known cases of memorized generation by upto 10x with
little to no impact on downstream tasks. Our approach offers a uniquely
accessible and effective solution to users of real-world systems.",http://arxiv.org/pdf/2502.05159v1,,False
Distinguishing Cause from Effect with Causal Velocity Models,07/02/2025,"Johnny Xi, Hugh Dance, Peter Orbanz, Benjamin Bloem-Reddy","Bivariate structural causal models (SCM) are often used to infer causal
direction by examining their goodness-of-fit under restricted model classes. In
this paper, we describe a parametrization of bivariate SCMs in terms of a
causal velocity by viewing the cause variable as time in a dynamical system.
The velocity implicitly defines counterfactual curves via the solution of
initial value problems where the observation specifies the initial condition.
Using tools from measure transport, we obtain a unique correspondence between
SCMs and the score function of the generated distribution via its causal
velocity. Based on this, we derive an objective function that directly
regresses the velocity against the score function, the latter of which can be
estimated non-parametrically from observational data. We use this to develop a
method for bivariate causal discovery that extends beyond known model classes
such as additive or location scale noise, and that requires no assumptions on
the noise distributions. When the score is estimated well, the objective is
also useful for detecting model non-identifiability and misspecification. We
present positive results in simulation and benchmark experiments where many
existing methods fail, and perform ablation studies to examine the method's
sensitivity to accurate score estimation.",http://arxiv.org/pdf/2502.05122v1,,False
Optimizing Wireless Resource Management and Synchronization in Digital Twin Networks,07/02/2025,"Hanzhi Yu, Yuchen Liu, Zhaohui Yang, Haijian Sun, Mingzhe Chen","In this paper, we investigate an accurate synchronization between a physical
network and its digital network twin (DNT), which serves as a virtual
representation of the physical network. The considered network includes a set
of base stations (BSs) that must allocate its limited spectrum resources to
serve a set of users while also transmitting its partially observed physical
network information to a cloud server to generate the DNT. Since the DNT can
predict the physical network status based on its historical status, the BSs may
not need to send their physical network information at each time slot, allowing
them to conserve spectrum resources to serve the users. However, if the DNT
does not receive the physical network information of the BSs over a large time
period, the DNT's accuracy in representing the physical network may degrade. To
this end, each BS must decide when to send the physical network information to
the cloud server to update the DNT, while also determining the spectrum
resource allocation policy for both DNT synchronization and serving the users.
We formulate this resource allocation task as an optimization problem, aiming
to maximize the total data rate of all users while minimizing the
asynchronization between the physical network and the DNT. To address this
problem, we propose a method based on the GRUs and the value decomposition
network (VDN). Simulation results show that our GRU and VDN based algorithm
improves the weighted sum of data rates and the similarity between the status
of the DNT and the physical network by up to 28.96%, compared to a baseline
method combining GRU with the independent Q learning.",http://arxiv.org/pdf/2502.05116v1,,False
Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types,07/02/2025,"Muhammad Umair Danish, Katarina Grolinger","Consumer energy forecasting is essential for managing energy consumption and
planning, directly influencing operational efficiency, cost reduction,
personalized energy management, and sustainability efforts. In recent years,
deep learning techniques, especially LSTMs and transformers, have been greatly
successful in the field of energy consumption forecasting. Nevertheless, these
techniques have difficulties in capturing complex and sudden variations, and,
moreover, they are commonly examined only on a specific type of consumer (e.g.,
only offices, only schools). Consequently, this paper proposes HyperEnergy, a
consumer energy forecasting strategy that leverages hypernetworks for improved
modeling of complex patterns applicable across a diversity of consumers.
Hypernetwork is responsible for predicting the parameters of the primary
prediction network, in our case LSTM. A learnable adaptable kernel, comprised
of polynomial and radial basis function kernels, is incorporated to enhance
performance. The proposed HyperEnergy was evaluated on diverse consumers
including, student residences, detached homes, a home with electric vehicle
charging, and a townhouse. Across all consumer types, HyperEnergy consistently
outperformed 10 other techniques, including state-of-the-art models such as
LSTM, AttentionLSTM, and transformer.",http://arxiv.org/pdf/2502.05104v1,10.1109/TPWRD.2024.3486010,False
Time Series Analysis of Rankings: A GARCH-Type Approach,07/02/2025,"Luiza Piancastelli, Wagner Barreto-Souza","Ranking data are frequently obtained nowadays but there are still scarce
methods for treating these data when temporally observed. The present paper
contributes to this topic by proposing and developing novel models for handling
time series of ranking data. We introduce a class of time-varying ranking
models inspired by the Generalized AutoRegressive Conditional
Heteroskedasticity (GARCH) models. More specifically, the temporal dynamics are
defined by the conditional distribution of the current ranking given the past
rankings, which are assumed to follow a Mallows distribution, which implicitly
depends on a distance. Then, autoregressive and feedback components are
incorporated into the model through the conditional expectation of the
associated distances. Theoretical properties of our ranking GARCH models such
as stationarity and ergodicity are established. The estimation of parameters is
performed via maximum likelihood estimation when data is fully observed. We
develop a Monte Carlo Expectation-Maximisation algorithm to deal with cases
involving missing data. Monte Carlo simulation studies are presented to study
the performance of the proposed estimators under both non-missing and missing
data scenarios. A real data application about the weekly ranking of
professional tennis players from 2015 to 2019 is presented under our proposed
ranking GARCH models.",http://arxiv.org/pdf/2502.05102v1,,False
Noise Sensitivity of Hierarchical Functions and Deep Learning Lower Bounds in General Product Measures,07/02/2025,"Rupert Li, Elchanan Mossel","Recent works explore deep learning's success by examining functions or data
with hierarchical structure. Complementarily, research on gradient descent
performance for deep nets has shown that noise sensitivity of functions under
independent and identically distributed (i.i.d.) Bernoulli inputs establishes
learning complexity bounds. This paper aims to bridge these research streams by
demonstrating that functions constructed through repeated composition of
non-linear functions are noise sensitive under general product measures.",http://arxiv.org/pdf/2502.05073v1,,False
Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures,07/02/2025,"Denis Korolev, Tim Schmidt, Dinesh K. Natarajan, Stefano Cassola, David May, Miro Duhovic, Michael Hintermüller","This study introduces a hybrid machine learning-based scale-bridging
framework for predicting the permeability of fibrous textile structures. By
addressing the computational challenges inherent to multiscale modeling, the
proposed approach evaluates the efficiency and accuracy of different
scale-bridging methodologies combining traditional surrogate models and even
integrating physics-informed neural networks (PINNs) with numerical solvers,
enabling accurate permeability predictions across micro- and mesoscales. Four
methodologies were evaluated: Single Scale Method (SSM), Simple Upscaling
Method (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM,
the simplest method, neglects microscale permeability and exhibited
permeability values deviating by up to 150\% of the FRM model, which was taken
as ground truth at an equivalent lower fiber volume content. SUM improved
predictions by considering uniform microscale permeability, yielding closer
values under similar conditions, but still lacked structural variability. The
SBM method, incorporating segment-based microscale permeability assignments,
showed significant enhancements, achieving almost equivalent values while
maintaining computational efficiency and modeling runtimes of ~45 minutes per
simulation. In contrast, FRM, which provides the highest fidelity by fully
resolving microscale and mesoscale geometries, required up to 270 times more
computational time than SSM, with model files exceeding 300 GB. Additionally, a
hybrid dual-scale solver incorporating PINNs has been developed and shows the
potential to overcome generalization errors and the problem of data scarcity of
the data-driven surrogate approaches. The hybrid framework advances
permeability modelling by balancing computational cost and prediction
reliability, laying the foundation for further applications in fibrous
composite manufacturing.",http://arxiv.org/pdf/2502.05044v1,,False
Leveraging a Simulator for Learning Causal Representations from Post-Treatment Covariates for CATE,07/02/2025,"Lokesh Nagalapatti, Pranava Singhal, Avishek Ghosh, Sunita Sarawagi","Treatment effect estimation involves assessing the impact of different
treatments on individual outcomes. Current methods estimate Conditional Average
Treatment Effect (CATE) using observational datasets where covariates are
collected before treatment assignment and outcomes are observed afterward,
under assumptions like positivity and unconfoundedness. In this paper, we
address a scenario where both covariates and outcomes are gathered after
treatment. We show that post-treatment covariates render CATE unidentifiable,
and recovering CATE requires learning treatment-independent causal
representations. Prior work shows that such representations can be learned
through contrastive learning if counterfactual supervision is available in
observational data. However, since counterfactuals are rare, other works have
explored using simulators that offer synthetic counterfactual supervision. Our
goal in this paper is to systematically analyze the role of simulators in
estimating CATE. We analyze the CATE error of several baselines and highlight
their limitations. We then establish a generalization bound that characterizes
the CATE error from jointly training on real and simulated distributions, as a
function of the real-simulator mismatch. Finally, we introduce SimPONet, a
novel method whose loss function is inspired from our generalization bound. We
further show how SimPONet adjusts the simulator's influence on the learning
objective based on the simulator's relevance to the CATE task. We experiment
with various DGPs, by systematically varying the real-simulator distribution
gap to evaluate SimPONet's efficacy against state-of-the-art CATE baselines.",http://arxiv.org/pdf/2502.05037v1,,False
Stability and performance guarantees for misspecified multivariate score-driven filters,07/02/2025,"Simon Donker van Heel, Rutger-Jan Lange, Dick van Dijk, Bram van Os","We consider the problem of tracking latent time-varying parameter vectors
under model misspecification. We analyze implicit and explicit score-driven
(ISD and ESD) filters, which update a prediction of the parameters using the
gradient of the logarithmic observation density (i.e., the score). In the ESD
filter, the score is computed using the predicted parameter values, whereas in
the ISD filter, the score is evaluated using the new, updated parameter values.
For both filter types, we derive novel sufficient conditions for the
exponential stability (i.e., invertibility) of the filtered parameter path and
existence of a finite mean squared error (MSE) bound with respect to the
pseudo-true parameter path. In addition, we present expressions for
finite-sample and asymptotic MSE bounds. Our performance guarantees rely on
mild moment conditions on the data-generating process, while our stability
result is entirely agnostic about the true process. As a result, our primary
conditions depend only on the characteristics of the filter; hence, they are
verifiable in practice. Concavity of the postulated log density combined with
simple parameter restrictions is sufficient (but not necessary) for ISD-filter
stability, whereas ESD-filter stability additionally requires the score to be
Lipschitz continuous. Extensive simulation studies validate our theoretical
findings and demonstrate the enhanced stability and improved performance of ISD
over ESD filters. An empirical application to U.S. Treasury-bill rates confirms
the practical relevance of our contribution.",http://arxiv.org/pdf/2502.05021v1,,False
Seasonal Station-Keeping of Short Duration High Altitude Balloons using Deep Reinforcement Learning,07/02/2025,"Tristan K. Schuler, Chinthan Prasad, Georgiy Kiselev, Donald Sofge","Station-Keeping short-duration high-altitude balloons (HABs) in a region of
interest is a challenging path-planning problem due to partially observable,
complex, and dynamic wind flows. Deep reinforcement learning is a popular
strategy for solving the station-keeping problem. A custom simulation
environment was developed to train and evaluate Deep Q-Learning (DQN) for
short-duration HAB agents in the simulation. To train the agents on realistic
winds, synthetic wind forecasts were generated from aggregated historical
radiosonde data to apply horizontal kinematics to simulated agents. The
synthetic forecasts were closely correlated with ECWMF ERA5 Reanalysis
forecasts, providing a realistic simulated wind field and seasonal and
altitudinal variances between the wind models. DQN HAB agents were then trained
and evaluated across different seasonal months. To highlight differences and
trends in months with vastly different wind fields, a Forecast Score algorithm
was introduced to independently classify forecasts based on wind diversity, and
trends between station-keeping success and the Forecast Score were evaluated
across all seasons.",http://arxiv.org/pdf/2502.05014v1,,False
DE-PADA: Personalized Augmentation and Domain Adaptation for ECG Biometrics Across Physiological States,07/02/2025,"Amro Abu Saleh, Elliot Sprecher, Kfir Y. Levy, Daniel H. Lange","Electrocardiogram (ECG)-based biometrics offer a promising method for user
identification, combining intrinsic liveness detection with morphological
uniqueness. However, elevated heart rates introduce significant physiological
variability, posing challenges to pattern recognition systems and leading to a
notable performance gap between resting and post-exercise conditions.
Addressing this gap is critical for advancing ECG-based biometric systems for
real-world applications. We propose DE-PADA, a Dual Expert model with
Personalized Augmentation and Domain Adaptation, designed to enhance robustness
across diverse physiological states. The model is trained primarily on
resting-state data from the evaluation dataset, without direct exposure to
their exercise data. To address variability, DE-PADA incorporates ECG-specific
innovations, including heartbeat segmentation into the PQRS interval, known for
its relative temporal consistency, and the heart rate-sensitive ST interval,
enabling targeted feature extraction tailored to each region's unique
characteristics. Personalized augmentation simulates subject-specific T-wave
variability across heart rates using individual T-wave peak predictions to
adapt augmentation ranges. Domain adaptation further improves generalization by
leveraging auxiliary data from supplementary subjects used exclusively for
training, including both resting and exercise conditions. Experiments on the
University of Toronto ECG Database demonstrate the model's effectiveness.
DE-PADA achieves relative improvements in post-exercise identification rates of
26.75% in the initial recovery phase and 11.72% in the late recovery phase,
while maintaining a 98.12% identification rate in the sitting position. These
results highlight DE-PADA's ability to address intra-subject variability and
enhance the robustness of ECG-based biometric systems across diverse
physiological states.",http://arxiv.org/pdf/2502.04973v1,,False
Towards Smarter Sensing: 2D Clutter Mitigation in RL-Driven Cognitive MIMO Radar,07/02/2025,"Adam Umra, Aya Mostafa Ahmed, Aydin Sezgin","Motivated by the growing interest in integrated sensing and communication for
6th generation (6G) networks, this paper presents a cognitive Multiple-Input
Multiple-Output (MIMO) radar system enhanced by reinforcement learning (RL) for
robust multitarget detection in dynamic environments. The system employs a
planar array configuration and adapts its transmitted waveforms and beamforming
patterns to optimize detection performance in the presence of unknown
two-dimensional (2D) disturbances. A robust Wald-type detector is integrated
with a SARSA-based RL algorithm, enabling the radar to learn and adapt to
complex clutter environments modeled by a 2D autoregressive process. Simulation
results demonstrate significant improvements in detection probability compared
to omnidirectional methods, particularly for low Signal-to-Noise Ratio (SNR)
targets masked by clutter.",http://arxiv.org/pdf/2502.04967v1,,False
Generative-enhanced optimization for knapsack problems: an industry-relevant study,07/02/2025,"Yelyzaveta Vodovozova, Abhishek Awasthi, Caitlin Jones, Joseph Doetsch, Karen Wintersperger, Florian Krellner, Carlos A. Riofrío","Optimization is a crucial task in various industries such as logistics,
aviation, manufacturing, chemical, pharmaceutical, and insurance, where finding
the best solution to a problem can result in significant cost savings and
increased efficiency. Tensor networks (TNs) have gained prominence in recent
years in modeling classical systems with quantum-inspired approaches. More
recently, TN generative-enhanced optimization (TN-GEO) has been proposed as a
strategy which uses generative modeling to efficiently sample valid solutions
with respect to certain constraints of optimization problems. Moreover, it has
been shown that symmetric TNs (STNs) can encode certain constraints of
optimization problems, thus aiding in their solution process. In this work, we
investigate the applicability of TN- and STN-GEO to an industry relevant
problem class, a multi-knapsack problem, in which each object must be assigned
to an available knapsack. We detail a prescription for practitioners to use the
TN-and STN-GEO methodology and study its scaling behavior and dependence on its
hyper-parameters. We benchmark 60 different problem instances and find that
TN-GEO and STN-GEO produce results of similar quality to simulated annealing.",http://arxiv.org/pdf/2502.04928v1,,False
Cached Multi-Lora Composition for Multi-Concept Image Generation,07/02/2025,"Xiandong Zou, Mingzhu Shen, Christos-Savvas Bouganis, Yiren Zhao","Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in
text-to-image models, enabling precise rendering of multiple distinct elements,
such as characters and styles, in multi-concept image generation. However,
current approaches face significant challenges when composing these LoRAs for
multi-concept image generation, resulting in diminished generated image
quality. In this paper, we initially investigate the role of LoRAs in the
denoising process through the lens of the Fourier frequency domain. Based on
the hypothesis that applying multiple LoRAs could lead to ""semantic conflicts"",
we find that certain LoRAs amplify high-frequency features such as edges and
textures, whereas others mainly focus on low-frequency elements, including the
overall structure and smooth color gradients. Building on these insights, we
devise a frequency domain based sequencing strategy to determine the optimal
order in which LoRAs should be integrated during inference. This strategy
offers a methodical and generalizable solution compared to the naive
integration commonly found in existing LoRA fusion techniques. To fully
leverage our proposed LoRA order sequence determination method in multi-LoRA
composition tasks, we introduce a novel, training-free framework, Cached
Multi-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while
maintaining cohesive image generation. With its flexible backbone for
multi-LoRA fusion and a non-uniform caching strategy tailored to individual
LoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRA
composition and improve computational efficiency. Our experimental evaluations
demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion
methods by a significant margin -- it achieves an average improvement of
$2.19\%$ in CLIPScore, and $11.25\%$ in MLLM win rate compared to LoraHub, LoRA
Composite, and LoRA Switch.",http://arxiv.org/pdf/2502.04923v1,,False
Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects,07/02/2025,"Levente Zólyomi, Tianze Wang, Sofiane Ennadir, Oleg Smirnov, Lele Cao","The proliferation of digital interactions across diverse domains, such as
healthcare, e-commerce, gaming, and finance, has resulted in the generation of
vast volumes of event stream (ES) data. ES data comprises continuous sequences
of timestamped events that encapsulate detailed contextual information relevant
to each domain. While ES data holds significant potential for extracting
actionable insights and enhancing decision-making, its effective utilization is
hindered by challenges such as the scarcity of labeled data and the fragmented
nature of existing research efforts. Self-Supervised Learning (SSL) has emerged
as a promising paradigm to address these challenges by enabling the extraction
of meaningful representations from unlabeled ES data. In this survey, we
systematically review and synthesize SSL methodologies tailored for ES modeling
across multiple domains, bridging the gaps between domain-specific approaches
that have traditionally operated in isolation. We present a comprehensive
taxonomy of SSL techniques, encompassing both predictive and contrastive
paradigms, and analyze their applicability and effectiveness within different
application contexts. Furthermore, we identify critical gaps in current
research and propose a future research agenda aimed at developing scalable,
domain-agnostic SSL frameworks for ES modeling. By unifying disparate research
efforts and highlighting cross-domain synergies, this survey aims to accelerate
innovation, improve reproducibility, and expand the applicability of SSL to
diverse real-world ES challenges.",http://arxiv.org/pdf/2502.04899v1,,False
Describing Nonstationary Data Streams in Frequency Domain,07/02/2025,Joanna Komorniczak,"Concept drift is among the primary challenges faced by the data stream
processing methods. The drift detection strategies, designed to counteract the
negative consequences of such changes, often rely on analyzing the problem
metafeatures. This work presents the Frequency Filtering Metadescriptor -- a
tool for characterizing the data stream that searches for the informative
frequency components visible in the sample's feature vector. The frequencies
are filtered according to their variance across all available data batches. The
presented solution is capable of generating a metadescription of the data
stream, separating chunks into groups describing specific concepts on its
basis, and visualizing the frequencies in the original spatial domain. The
experimental analysis compared the proposed solution with two state-of-the-art
strategies and with the PCA baseline in the post-hoc concept identification
task. The research is followed by the identification of concepts in the
real-world data streams. The generalization in the frequency domain adapted in
the proposed solution allows to capture the complex feature dependencies as a
reduced number of frequency components, while maintaining the semantic meaning
of data.",http://arxiv.org/pdf/2502.04813v1,,False
"STRIDE: Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion",07/02/2025,"Zhenwei Wu, Jinxiong Lu, Yuxiao Chen, Yunxin Liu, Yueting Zhuang, Luhui Hu","Humanoid robotics presents significant challenges in artificial intelligence,
requiring precise coordination and control of high-degree-of-freedom systems.
Designing effective reward functions for deep reinforcement learning (DRL) in
this domain remains a critical bottleneck, demanding extensive manual effort,
domain expertise, and iterative refinement. To overcome these challenges, we
introduce STRIDE, a novel framework built on agentic engineering to automate
reward design, DRL training, and feedback optimization for humanoid robot
locomotion tasks. By combining the structured principles of agentic engineering
with large language models (LLMs) for code-writing, zero-shot generation, and
in-context optimization, STRIDE generates, evaluates, and iteratively refines
reward functions without relying on task-specific prompts or templates. Across
diverse environments featuring humanoid robot morphologies, STRIDE outperforms
the state-of-the-art reward design framework EUREKA, achieving significant
improvements in efficiency and task performance. Using STRIDE-generated
rewards, simulated humanoid robots achieve sprint-level locomotion across
complex terrains, highlighting its ability to advance DRL workflows and
humanoid robotics research.",http://arxiv.org/pdf/2502.04692v1,,False
Capturing Extreme Events in Turbulence using an Extreme Variational Autoencoder (xVAE),07/02/2025,"Likun Zhang, Kiran Bhaganagar, Christopher K. Wikle","Turbulent flow fields are characterized by extreme events that are
statistically intermittent and carry a significant amount of energy and
physical importance. To emulate these flows, we introduce the extreme
variational Autoencoder (xVAE), which embeds a max-infinitely divisible process
with heavy-tailed distributions into a standard VAE framework, enabling
accurate modeling of extreme events. xVAEs are neural network models that
reduce system dimensionality by learning non-linear latent representations of
data. We demonstrate the effectiveness of xVAE in large-eddy simulation data of
wildland fire plumes, where intense heat release and complex plume-atmosphere
interactions generate extreme turbulence. Comparisons with the commonly used
Proper Orthogonal Decomposition (POD) modes show that xVAE is more robust in
capturing extreme values and provides a powerful uncertainty quantification
framework using variational Bayes. Additionally, xVAE enables analysis of the
so-called copulas of fields to assess risks associated with rare events while
rigorously accounting for uncertainty, such as simultaneous exceedances of high
thresholds across multiple locations. The proposed approach provides a new
direction for studying realistic turbulent flows, such as high-speed
aerodynamics, space propulsion, and atmospheric and oceanic systems that are
characterized by extreme events.",http://arxiv.org/pdf/2502.04685v1,,False
G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models,07/02/2025,"Mengdi Liu, Zhangyang Gao, Hong Chang, Stan Z. Li, Shiguang Shan, Xinlin Chen","Discovering the genotype-phenotype relationship is crucial for genetic
engineering, which will facilitate advances in fields such as crop breeding,
conservation biology, and personalized medicine. Current research usually
focuses on single species and small datasets due to limitations in phenotypic
data collection, especially for traits that require visual assessments or
physical measurements. Deciphering complex and composite phenotypes, such as
morphology, from genetic data at scale remains an open question. To break
through traditional generic models that rely on simplified assumptions, this
paper introduces G2PDiffusion, the first-of-its-kind diffusion model designed
for genotype-to-phenotype generation across multiple species. Specifically, we
use images to represent morphological phenotypes across species and redefine
phenotype prediction as conditional image generation. To this end, this paper
introduces an environment-enhanced DNA sequence conditioner and trains a stable
diffusion model with a novel alignment method to improve genotype-to-phenotype
consistency. Extensive experiments demonstrate that our approach enhances
phenotype prediction accuracy across species, capturing subtle genetic
variations that contribute to observable traits.",http://arxiv.org/pdf/2502.04684v1,,False
The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance,07/02/2025,"Mohammad Reza Rezaei, Adji Bousso Dieng","Current state-of-the-art dynamical models, such as Mamba, assume the same
level of noisiness for all elements of a given sequence, which limits their
performance on noisy temporal data. In this paper, we introduce the
$\alpha$-Alternator, a novel generative model for time-dependent data that
dynamically adapts to the complexity introduced by varying noise levels in
sequences. The $\alpha$-Alternator leverages the Vendi Score (VS), a flexible
similarity-based diversity metric, to adjust, at each time step $t$, the
influence of the sequence element at time $t$ and the latent representation of
the dynamics up to that time step on the predicted future dynamics. This
influence is captured by a parameter that is learned and shared across all
sequences in a given dataset. The sign of this parameter determines the
direction of influence. A negative value indicates a noisy dataset, where a
sequence element that increases the VS is considered noisy, and the model
relies more on the latent history when processing that element. Conversely,
when the parameter is positive, a sequence element that increases the VS is
considered informative, and the $\alpha$-Alternator relies more on this new
input than on the latent history when updating its predicted latent dynamics.
The $\alpha$-Alternator is trained using a combination of observation masking
and Alternator loss minimization. Masking simulates varying noise levels in
sequences, enabling the model to be more robust to these fluctuations and
improving its performance in trajectory prediction, imputation, and
forecasting. Our experimental results demonstrate that the $\alpha$-Alternator
outperforms both Alternators and state-of-the-art state-space models across
neural decoding and time-series forecasting benchmarks.",http://arxiv.org/pdf/2502.04593v1,,False
