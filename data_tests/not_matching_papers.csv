Title,Arxiv Code,Abstract
Multi-level B�zier extraction of truncated hierarchical B-splines for isogeometric analysis,2308.09506,"Multivariate B-splines and Non-uniform rational B-splines (NURBS) lack adaptivity due to their tensor product structure. Truncated hierarchical B-splines (THB-splines) provide a solution for this. THB-splines organize the parameter space into a hierarchical structure, which enables efficient approximation and representation of functions with different levels of detail. The truncation mechanism ensures the partition of unity property of B-splines and defines a more scattered set of basis functions without overlapping on the multi-level spline space. Transferring these multi-level splines into B�zier elements representation facilitates straightforward incorporation into existing finite element (FE) codes. By separating the multi-level extraction of the THB-splines from the standard B�zier extraction, a more general independent framework applicable to any sequence of nested spaces is created. The operators for the multi-level structure of THB-splines and the operators of B�zier extraction are constructed in a local approach. Adjusting the operators for the multi-level structure from an element point of view and multiplying with the B�zier extraction operators of those elements, a direct map between B�zier elements and a hierarchical structure is obtained. The presented implementation involves the use of an open-source Octave/MATLAB isogeometric analysis (IGA) code called GeoPDEs. A basic Poisson problem is presented to investigate the performance of multi-level B�zier extraction compared to a standard THB-spline approach."
WISK: A Workload-aware Learned Index for Spatial Keyword Queries,2302.14287,"Spatial objects often come with textual information, such as Points of Interest (POIs) with their descriptions, which are referred to as geo-textual data. To retrieve such data, spatial keyword queries that take into account both spatial proximity and textual relevance have been extensively studied. Existing indexes designed for spatial keyword queries are mostly built based on the geo-textual data without considering the distribution of queries already received. However, previous studies have shown that utilizing the known query distribution can improve the index structure for future query processing. In this paper, we propose WISK, a learned index for spatial keyword queries, which self-adapts for optimizing querying costs given a query workload. One key challenge is how to utilize both structured spatial attributes and unstructured textual information during learning the index. We first divide the data objects into partitions, aiming to minimize the processing costs of the given query workload. We prove the NP-hardness of the partitioning problem and propose a machine learning model to find the optimal partitions. Then, to achieve more pruning power, we build a hierarchical structure based on the generated partitions in a bottom-up manner with a reinforcement learning-based approach. We conduct extensive experiments on real-world datasets and query workloads with various distributions, and the results show that WISK outperforms all competitors, achieving up to 8x speedup in querying time with comparable storage overhead."
Reconstructing Volatility: Pricing of Index Options under Rough Volatility,2212.07817,"In previous works Avellaneda et al. pioneered the pricing and hedging of index options - products highly sensitive to implied volatility and correlation assumptions - with large deviations methods, assuming local volatility dynamics for all components of the index. We here present an extension applicable to non-Markovian dynamics and in particular the case of rough volatility dynamics."
Rough volatility: fact or artefact?,2203.1382,"We investigate the statistical evidence for the use of `rough' fractional processes with Hurst exponent H<0.5 for the modeling of volatility of financial assets, using a model-free approach. We introduce a non-parametric method for estimating the roughness of a function based on discrete sample, using the concept of normalized p-th variation along a sequence of partitions. We investigate the finite sample performance of our estimator for measuring the roughness of sample paths of stochastic processes using detailed numerical experiments based on sample paths of fractional Brownian motion and other fractional processes. We then apply this method to estimate the roughness of realized volatility signals based on high-frequency observations. Detailed numerical experiments based on stochastic volatility models show that, even when the instantaneous volatility has diffusive dynamics with the same roughness as Brownian motion, the realized volatility exhibits rough behaviour corresponding to a Hurst exponent significantly smaller than 0.5. Comparison of roughness estimates for realized and instantaneous volatility in fractional volatility models with different values of Hurst exponent shows that, irrespective of the roughness of the spot volatility process, realized volatility always exhibits `rough' behaviour with an apparent Hurst index H?�<0.5. These results suggest that the origin of the roughness observed in realized volatility time-series lies in the microstructure noise rather than the volatility process itself."
Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin,2401.04702,"We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least 200 weeks with an exponent approximately equal to 0.9, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between 0.3 and 2.5 depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to ?1.5, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time. "
Decentralised Finance and Automated Market Making: Execution and Speculation,2307.03499,"Automated market makers (AMMs) are a new prototype of trading venues which are revolutionising the way market participants interact. At present, the majority of AMMs are constant function market makers (CFMMs) where a deterministic trading function determines how markets are cleared. A distinctive characteristic of CFMMs is that execution costs are given by a closed-form function of price, liquidity, and transaction size. This gives rise to a new class of trading problems. We focus on constant product market makers and show how to optimally trade a large position in an asset and how to execute statistical arbitrages based on market signals. We employ stochastic optimal control tools to devise two strategies. One strategy is based on the dynamics of prices in competing venues and assumes constant liquidity in the AMM. The other strategy assumes that AMM prices are efficient and liquidity is stochastic. We use Uniswap v3 data to study price, liquidity, and trading cost dynamics, and to motivate the models. Finally, we perform consecutive runs of in-sample estimation of model parameters and out-of-sample liquidation and arbitrage strategies to showcase the performance of the strategies. "
Simulation and Calibration of a Fully Bayesian Marked Multidimensional Hawkes Process with Dissimilar Decays,1803.04654,"We propose a simulation method for multidimensional Hawkes processes based on superposition theory of point processes. This formulation allows us to design efficient simulations for Hawkes processes with differing exponentially decaying intensities. We demonstrate that inter-arrival times can be decomposed into simpler auxiliary variables that can be sampled directly, giving exact simulation with no approximation. We establish that the auxiliary variables provides information on the parent process for each event time. The algorithm correctness is shown by verifying the simulated intensities with their theoretical moments. A modular inference procedure consisting of Gibbs samplers through the auxiliary variable augmentation and adaptive rejection sampling is presented. Finally, we compare our proposed simulation method against existing methods, and find significant improvement in terms of algorithm speed. Our inference algorithm is used to discover the strengths of mutually excitations in real dark networks."
