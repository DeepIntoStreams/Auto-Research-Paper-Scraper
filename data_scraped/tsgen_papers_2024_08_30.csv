Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
"Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming",29/08/2024,"Zhifei Xie, Changqiao Wu","Recent advances in language models have achieved significant progress.
GPT-4o, as a new milestone, has enabled real-time conversations with humans,
demonstrating near-human natural fluency. Such human-computer interaction
necessitates models with the capability to perform reasoning directly with the
audio modality and generate output in streaming. However, this remains beyond
the reach of current academic models, as they typically depend on extra TTS
systems for speech synthesis, resulting in undesirable latency. This paper
introduces the Mini-Omni, an audio-based end-to-end conversational model,
capable of real-time speech interaction. To achieve this capability, we propose
a text-instructed speech generation method, along with batch-parallel
strategies during inference to further boost the performance. Our method also
helps to retain the original model's language capabilities with minimal
degradation, enabling other works to establish real-time interaction
capabilities. We call this training method ""Any Model Can Talk"". We also
introduce the VoiceAssistant-400K dataset to fine-tune models optimized for
speech output. To our best knowledge, Mini-Omni is the first fully end-to-end,
open-source model for real-time speech interaction, offering valuable potential
for future research.",http://arxiv.org/pdf/2408.16725v1,,False
Towards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods,29/08/2024,"Rodrigo Diaz, Carlos De La Vega Martin, Mark Sandler","This paper presents an examination of State Space Models (SSM) and
Koopman-based deep learning methods for modelling the dynamics of both linear
and non-linear stiff strings. Through experiments with datasets generated under
different initial conditions and sample rates, we assess the capacity of these
models to accurately model the complex behaviours observed in string dynamics.
Our findings indicate that our proposed Koopman-based model performs as well as
or better than other existing approaches in non-linear cases for long-sequence
modelling.
  We inform the design of these architectures with the structure of the
problems at hand. Although challenges remain in extending model predictions
beyond the training horizon (i.e., extrapolation), the focus of our
investigation lies in the models' ability to generalise across different
initial conditions within the training time interval. This research contributes
insights into the physical modelling of dynamical systems (in particular those
addressing musical acoustics) by offering a comparative overview of these and
previous methods and introducing innovative strategies for model improvement.
Our results highlight the efficacy of these models in simulating non-linear
dynamics and emphasise their wide-ranging applicability in accurately modelling
dynamical systems over extended sequences.",http://arxiv.org/pdf/2408.16650v1,,False
DriveGenVLM: Real-world Video Generation for Vision Language Model based Autonomous Driving,29/08/2024,"Yongjie Fu, Anmol Jain, Xuan Di, Xu Chen, Zhaobin Mo","The advancement of autonomous driving technologies necessitates increasingly
sophisticated methods for understanding and predicting real-world scenarios.
Vision language models (VLMs) are emerging as revolutionary tools with
significant potential to influence autonomous driving. In this paper, we
propose the DriveGenVLM framework to generate driving videos and use VLMs to
understand them. To achieve this, we employ a video generation framework
grounded in denoising diffusion probabilistic models (DDPM) aimed at predicting
real-world video sequences. We then explore the adequacy of our generated
videos for use in VLMs by employing a pre-trained model known as Efficient
In-context Learning on Egocentric Videos (EILEV). The diffusion model is
trained with the Waymo open dataset and evaluated using the Fr\'echet Video
Distance (FVD) score to ensure the quality and realism of the generated videos.
Corresponding narrations are provided by EILEV for these generated videos,
which may be beneficial in the autonomous driving domain. These narrations can
enhance traffic scene understanding, aid in navigation, and improve planning
capabilities. The integration of video generation with VLMs in the DriveGenVLM
framework represents a significant step forward in leveraging advanced AI
models to address complex challenges in autonomous driving.",http://arxiv.org/pdf/2408.16647v1,,False
LLMs generate structurally realistic social networks but overestimate political homophily,29/08/2024,"Serina Chang, Alicja Chaszczewicz, Emma Wang, Maya Josifovska, Emma Pierson, Jure Leskovec","Generating social networks is essential for many applications, such as
epidemic modeling and social simulations. Prior approaches either involve deep
learning models, which require many observed networks for training, or stylized
models, which are limited in their realism and flexibility. In contrast, LLMs
offer the potential for zero-shot and flexible network generation. However, two
key questions are: (1) are LLM's generated networks realistic, and (2) what are
risks of bias, given the importance of demographics in forming social ties? To
answer these questions, we develop three prompting methods for network
generation and compare the generated networks to real social networks. We find
that more realistic networks are generated with ""local"" methods, where the LLM
constructs relations for one persona at a time, compared to ""global"" methods
that construct the entire network at once. We also find that the generated
networks match real networks on many characteristics, including density,
clustering, community structure, and degree. However, we find that LLMs
emphasize political homophily over all other types of homophily and
overestimate political homophily relative to real-world measures.",http://arxiv.org/pdf/2408.16629v1,,False
Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation,29/08/2024,Christian D. Blakely,"We construct a two-layered model for learning and generating sequential data
that is both computationally fast and competitive with vanilla Tsetlin
machines, adding numerous advantages. Through the use of hyperdimensional
vector computing (HVC) algebras and Tsetlin machine clause structures, we
demonstrate that the combination of both inherits the generality of data
encoding and decoding of HVC with the fast interpretable nature of Tsetlin
machines to yield a powerful machine learning model. We apply the approach in
two areas, namely in forecasting, generating new sequences, and classification.
For the latter, we derive results for the entire UCR Time Series Archive and
compare with the standard benchmarks to see how well the method competes in
time series classification.",http://arxiv.org/pdf/2408.16620v1,,False
Blending Low and High-Level Semantics of Time Series for Better Masked Time Series Generation,29/08/2024,"Johan Vik Mathisen, Erlend Lokna, Daesoo Lee, Erlend Aune","State-of-the-art approaches in time series generation (TSG), such as
TimeVQVAE, utilize vector quantization-based tokenization to effectively model
complex distributions of time series. These approaches first learn to transform
time series into a sequence of discrete latent vectors, and then a prior model
is learned to model the sequence. The discrete latent vectors, however, only
capture low-level semantics (\textit{e.g.,} shapes). We hypothesize that
higher-fidelity time series can be generated by training a prior model on more
informative discrete latent vectors that contain both low and high-level
semantics (\textit{e.g.,} characteristic dynamics). In this paper, we introduce
a novel framework, termed NC-VQVAE, to integrate self-supervised learning into
those TSG methods to derive a discrete latent space where low and high-level
semantics are captured. Our experimental results demonstrate that NC-VQVAE
results in a considerable improvement in the quality of synthetic samples.",http://arxiv.org/pdf/2408.16613v1,,False
Flexible framework for generating synthetic electrocardiograms and photoplethysmograms,29/08/2024,"Katri Karhinoja, Antti Vasankari, Jukka-Pekka Sirki√§, Antti Airola, David Wong, Matti Kaisti","By generating synthetic biosignals, the quantity and variety of health data
can be increased. This is especially useful when training machine learning
models by enabling data augmentation and introduction of more physiologically
plausible variation to the data. For these purposes, we have developed a
synthetic biosignal model for two signal modalities, electrocardiography (ECG)
and photoplethysmography (PPG). The model produces realistic signals that
account for physiological effects such as breathing modulation and changes in
heart rate due to physical stress. Arrhythmic signals can be generated with
beat intervals extracted from real measurements. The model also includes a
flexible approach to adding different kinds of noise and signal artifacts. The
noise is generated from power spectral densities extracted from both measured
noisy signals and modeled power spectra. Importantly, the model also
automatically produces labels for noise, segmentation (e.g. P and T waves, QRS
complex, for electrocardiograms), and artifacts. We assessed how this
comprehensive model can be used in practice to improve the performance of
models trained on ECG or PPG data. For example, we trained an LSTM to detect
ECG R-peaks using both real ECG signals from the MIT-BIH arrythmia set and our
new generator. The F1 score of the model was 0.83 using real data, in
comparison to 0.98 using our generator. In addition, the model can be used for
example in signal segmentation, quality detection and bench-marking detection
algorithms. The model code has been released in
\url{https://github.com/UTU-Health-Research/framework_for_synthetic_biosignals}",http://arxiv.org/pdf/2408.16291v1,,False
Enhancing Customer Churn Prediction in Telecommunications: An Adaptive Ensemble Learning Approach,29/08/2024,"Mohammed Affan Shaikhsurab, Pramod Magadum","Customer churn, the discontinuation of services by existing customers, poses
a significant challenge to the telecommunications industry. This paper proposes
a novel adaptive ensemble learning framework for highly accurate customer churn
prediction. The framework integrates multiple base models, including XGBoost,
LightGBM, LSTM, a Multi-Layer Perceptron (MLP) neural network, and Support
Vector Machine (SVM). These models are strategically combined using a stacking
ensemble method, further enhanced by meta-feature generation from base model
predictions. A rigorous data preprocessing pipeline, coupled with a
multi-faceted feature engineering approach, optimizes model performance. The
framework is evaluated on three publicly available telecom churn datasets,
demonstrating substantial accuracy improvements over state-of-the-art
techniques. The research achieves a remarkable 99.28% accuracy, signifying a
major advancement in churn prediction.The implications of this research for
developing proactive customer retention strategies withinthe telecommunications
industry are discussed.",http://arxiv.org/pdf/2408.16284v1,,False
Iterated Energy-based Flow Matching for Sampling from Boltzmann Densities,29/08/2024,"Dongyeop Woo, Sungsoo Ahn","In this work, we consider the problem of training a generator from
evaluations of energy functions or unnormalized densities. This is a
fundamental problem in probabilistic inference, which is crucial for scientific
applications such as learning the 3D coordinate distribution of a molecule. To
solve this problem, we propose iterated energy-based flow matching (iEFM), the
first off-policy approach to train continuous normalizing flow (CNF) models
from unnormalized densities. We introduce the simulation-free energy-based flow
matching objective, which trains the model to predict the Monte Carlo
estimation of the marginal vector field constructed from known energy
functions. Our framework is general and can be extended to variance-exploding
(VE) and optimal transport (OT) conditional probability paths. We evaluate iEFM
on a two-dimensional Gaussian mixture model (GMM) and an eight-dimensional
four-particle double-well potential (DW-4) energy function. Our results
demonstrate that iEFM outperforms existing methods, showcasing its potential
for efficient and scalable probabilistic modeling in complex high-dimensional
systems.",http://arxiv.org/pdf/2408.16249v1,,False
Large-Scale Multi-omic Biosequence Transformers for Modeling Peptide-Nucleotide Interactions,29/08/2024,"Sully F. Chen, Robert J. Steele, Beakal Lemeneh, Shivanand P. Lad, Eric Oermann","The transformer architecture has revolutionized bioinformatics and driven
progress in the understanding and prediction of the properties of biomolecules.
Almost all research on large-scale biosequence transformers has focused on one
domain at a time (single-omic), usually nucleotides or peptides. These models
have seen incredible success in downstream tasks in each domain and have
achieved particularly noteworthy breakthroughs in sequences of peptides and
structural modeling. However, these single-omic models are naturally incapable
of modeling multi-omic tasks, one of the most biologically critical being
nucleotide-peptide interactions.
  We present our work training the first multi-omic nucleotide-peptide
foundation models. We show that these multi-omic models (MOMs) can learn joint
representations between various single-omic distributions that are emergently
consistent with the Central Dogma of molecular biology, despite only being
trained on unlabeled biosequences. We further demonstrate that MOMs can be
fine-tuned to achieve state-of-the-art results on peptide-nucleotide
interaction tasks, namely predicting the change in Gibbs free energy
({\Delta}G) of the binding interaction between a given oligonucleotide and
peptide, as well as the effect on this binding interaction due to mutations in
the oligonucleotide sequence ({\Delta}{\Delta}G).
  Remarkably, we show that multi-omic biosequence transformers emergently learn
useful structural information without any prior structural training, allowing
us to predict which peptide residues are most involved in the
peptide-nucleotide binding interaction. Lastly, we provide evidence that
multi-omic biosequence models are non-inferior to foundation models trained on
single-omics distributions, suggesting a more generalized or foundational
approach to building these models.",http://arxiv.org/pdf/2408.16245v1,,False
Targeted Cause Discovery with Data-Driven Learning,29/08/2024,"Jang-Hyun Kim, Claudia Skok Gibbs, Sangdoo Yun, Hyun Oh Song, Kyunghyun Cho","We propose a novel machine learning approach for inferring causal variables
of a target variable from observations. Our goal is to identify both direct and
indirect causes within a system, thereby efficiently regulating the target
variable when the difficulty and cost of intervening on each causal variable
vary. Our method employs a neural network trained to identify causality through
supervised learning on simulated data. By implementing a local-inference
strategy, we achieve linear complexity with respect to the number of variables,
efficiently scaling up to thousands of variables. Empirical results demonstrate
the effectiveness of our method in identifying causal relationships within
large-scale gene regulatory networks, outperforming existing causal discovery
methods that primarily focus on direct causality. We validate our model's
generalization capability across novel graph structures and generating
mechanisms, including gene regulatory networks of E. coli and the human K562
cell line. Implementation codes are available at
https://github.com/snu-mllab/Targeted-Cause-Discovery.",http://arxiv.org/pdf/2408.16218v1,,False
The Application of Machine Learning in Tidal Evolution Simulation of Star-Planet Systems,29/08/2024,"Shuaishuai Guo, Jianheng Guo, KaiFan Ji, Hui Liu, Lei Xing","With the release of a large amount of astronomical data, an increasing number
of close-in hot Jupiters have been discovered. Calculating their evolutionary
curves using star-planet interaction models presents a challenge. To expedite
the generation of evolutionary curves for these close-in hot Jupiter systems,
we utilized tidal interaction models established on MESA to create 15,745
samples of star-planet systems and 7,500 samples of stars. Additionally, we
employed a neural network (Multi-Layer Perceptron - MLP) to predict the
evolutionary curves of the systems, including stellar effective temperature,
radius, stellar rotation period, and planetary orbital period. The median
relative errors of the predicted evolutionary curves were found to be 0.15%,
0.43%, 2.61%, and 0.57%, respectively. Furthermore, the speed at which we
generate evolutionary curves exceeds that of model-generated curves by more
than four orders of magnitude. We also extracted features of planetary
migration states and utilized lightGBM to classify the samples into 6
categories for prediction. We found that by combining three types that undergo
long-term double synchronization into one label, the classifier effectively
recognized these features. Apart from systems experiencing long-term double
synchronization, the median relative errors of the predicted evolutionary
curves were all below 4%. Our work provides an efficient method to save
significant computational resources and time with minimal loss in accuracy.
This research also lays the foundation for analyzing the evolutionary
characteristics of systems under different migration states, aiding in the
understanding of the underlying physical mechanisms of such systems. Finally,
to a large extent, our approach could replace the calculations of theoretical
models.",http://arxiv.org/pdf/2408.16212v1,,False
