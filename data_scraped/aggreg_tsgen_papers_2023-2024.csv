Title,Publication Date,Author(s),Abstract,Link,DOI
Non-intrusive Water Usage Classification Considering Limited Training Data,02/01/2023,"Pavlos Pavlou, Stelios Vrachimis, Demetrios G. Eliades, Marios M. Polycarpou","Smart metering of domestic water consumption to continuously monitor the
usage of different appliances has been shown to have an impact on people's
behavior towards water conservation. However, the installation of multiple
sensors to monitor each appliance currently has a high initial cost and as a
result, monitoring consumption from different appliances using sensors is not
cost-effective. To address this challenge, studies have focused on analyzing
measurements of the total domestic consumption using Machine Learning (ML)
methods, to disaggregate water usage into each appliance. Identifying which
appliances are in use through ML is challenging since their operation may be
overlapping, while specific appliances may operate with intermittent flow,
making individual consumption events hard to distinguish. Moreover, ML
approaches require large amounts of labeled input data to train their models,
which are typically not available for a single household, while usage
characteristics may vary in different regions. In this work, we initially
propose a data model that generates synthetic time series based on regional
water usage characteristics and resolution to overcome the need for a large
training dataset with real labeled data. The method requires a small number of
real labeled data from the studied region. Following this, we propose a new
algorithm for classifying single and overlapping household water usage events,
using the total domestic consumption measurements.",http://arxiv.org/pdf/2301.03457v1,
State and parameter learning with PaRIS particle Gibbs,02/01/2023,"Gabriel Cardoso, Yazid Janati El Idrissi, Sylvain Le Corff, Eric Moulines, Jimmy Olsson","Non-linear state-space models, also known as general hidden Markov models,
are ubiquitous in statistical machine learning, being the most classical
generative models for serial data and sequences in general. The particle-based,
rapid incremental smoother PaRIS is a sequential Monte Carlo (SMC) technique
allowing for efficient online approximation of expectations of additive
functionals under the smoothing distribution in these models. Such expectations
appear naturally in several learning contexts, such as likelihood estimation
(MLE) and Markov score climbing (MSC). PARIS has linear computational
complexity, limited memory requirements and comes with non-asymptotic bounds,
convergence results and stability guarantees. Still, being based on
self-normalised importance sampling, the PaRIS estimator is biased. Our first
contribution is to design a novel additive smoothing algorithm, the Parisian
particle Gibbs PPG sampler, which can be viewed as a PaRIS algorithm driven by
conditional SMC moves, resulting in bias-reduced estimates of the targeted
quantities. We substantiate the PPG algorithm with theoretical results,
including new bounds on bias and variance as well as deviation inequalities.
Our second contribution is to apply PPG in a learning framework, covering MLE
and MSC as special examples. In this context, we establish, under standard
assumptions, non-asymptotic bounds highlighting the value of bias reduction and
the implicit Rao--Blackwellization of PPG. These are the first non-asymptotic
results of this kind in this setting. We illustrate our theoretical results
with numerical experiments supporting our claims.",http://arxiv.org/pdf/2301.00900v1,
On the causality-preservation capabilities of generative modelling,03/01/2023,"Yves-Cédric Bauwelinckx, Jan Dhaene, Tim Verdonck, Milan van den Heuvel","Modeling lies at the core of both the financial and the insurance industry
for a wide variety of tasks. The rise and development of machine learning and
deep learning models have created many opportunities to improve our modeling
toolbox. Breakthroughs in these fields often come with the requirement of large
amounts of data. Such large datasets are often not publicly available in
finance and insurance, mainly due to privacy and ethics concerns. This lack of
data is currently one of the main hurdles in developing better models. One
possible option to alleviating this issue is generative modeling. Generative
models are capable of simulating fake but realistic-looking data, also referred
to as synthetic data, that can be shared more freely. Generative Adversarial
Networks (GANs) is such a model that increases our capacity to fit very
high-dimensional distributions of data. While research on GANs is an active
topic in fields like computer vision, they have found limited adoption within
the human sciences, like economics and insurance. Reason for this is that in
these fields, most questions are inherently about identification of causal
effects, while to this day neural networks, which are at the center of the GAN
framework, focus mostly on high-dimensional correlations. In this paper we
study the causal preservation capabilities of GANs and whether the produced
synthetic data can reliably be used to answer causal questions. This is done by
performing causal analyses on the synthetic data, produced by a GAN, with
increasingly more lenient assumptions. We consider the cross-sectional case,
the time series case and the case with a complete structural model. It is shown
that in the simple cross-sectional scenario where correlation equals causation
the GAN preserves causality, but that challenges arise for more advanced
analyses.",http://arxiv.org/pdf/2301.01109v1,
Neural SDEs for Conditional Time Series Generation and the Signature-Wasserstein-1 metric,03/01/2023,"Pere Díaz Lozano, Toni Lozano Bagén, Josep Vives","(Conditional) Generative Adversarial Networks (GANs) have found great success
in recent years, due to their ability to approximate (conditional)
distributions over extremely high dimensional spaces. However, they are highly
unstable and computationally expensive to train, especially in the time series
setting. Recently, it has been proposed the use of a key object in rough path
theory, called the signature of a path, which is able to convert the min-max
formulation given by the (conditional) GAN framework into a classical
minimization problem. However, this method is extremely expensive in terms of
memory cost, sometimes even becoming prohibitive. To overcome this, we propose
the use of \textit{Conditional Neural Stochastic Differential Equations}, which
have a constant memory cost as a function of depth, being more memory efficient
than traditional deep learning architectures. We empirically test that this
proposed model is more efficient than other classical approaches, both in terms
of memory cost and computational time, and that it usually outperforms them in
terms of performance.",http://arxiv.org/pdf/2301.01315v1,
Zen: LSTM-based generation of individual spatiotemporal cellular traffic with interactions,05/01/2023,"Anne Josiane Kouam, Aline Carneiro Viana, Alain Tchana","Domain-wide recognized by their high value in human presence and activity
studies, cellular network datasets (i.e., Charging Data Records, named CdRs),
however, present accessibility, usability, and privacy issues, restricting
their exploitation and research reproducibility.This paper tackles such
challenges by modeling Cdrs that fulfill real-world data attributes. Our
designed framework, named Zen follows a four-fold methodology related to (i)
the LTSM-based modeling of users' traffic behavior, (ii) the realistic and
flexible emulation of spatiotemporal mobility behavior, (iii) the structure of
lifelike cellular network infrastructure and social interactions, and (iv) the
combination of the three previous modules into realistic Cdrs traces with an
individual basis, realistically. Results show that Zen's first and third models
accurately capture individual and global distributions of a fully anonymized
real-world Cdrs dataset, while the second model is consistent with the
literature's revealed features in human mobility. Finally, we validate Zen Cdrs
ability of reproducing daily cellular behaviors of the urban population and its
usefulness in practical networking applications such as dynamic population
tracing, Radio Access Network's power savings, and anomaly detection as
compared to real-world CdRs.",http://arxiv.org/pdf/2301.02059v1,
Multi-Genre Music Transformer -- Composing Full Length Musical Piece,06/01/2023,Abhinav Kaushal Keshari,"In the task of generating music, the art factor plays a big role and is a
great challenge for AI. Previous work involving adversarial training to produce
new music pieces and modeling the compatibility of variety in music (beats,
tempo, musical stems) demonstrated great examples of learning this task. Though
this was limited to generating mashups or learning features from tempo and key
distributions to produce similar patterns. Compound Word Transformer was able
to represent music generation task as a sequence generation challenge involving
musical events defined by compound words. These musical events give a more
accurate description of notes progression, chord change, harmony and the art
factor. The objective of the project is to implement a Multi-Genre Transformer
which learns to produce music pieces through more adaptive learning process
involving more challenging task where genres or form of the composition is also
considered. We built a multi-genre compound word dataset, implemented a linear
transformer which was trained on this dataset. We call this Multi-Genre
Transformer, which was able to generate full length new musical pieces which is
diverse and comparable to original tracks. The model trains 2-5 times faster
than other models discussed.",http://arxiv.org/pdf/2301.02385v1,
Continuous Trajectory Generation Based on Two-Stage GAN,16/01/2023,"Wenjun Jiang, Wayne Xin Zhao, Jingyuan Wang, Jiawei Jiang","Simulating the human mobility and generating large-scale trajectories are of
great use in many real-world applications, such as urban planning, epidemic
spreading analysis, and geographic privacy protect. Although many previous
works have studied the problem of trajectory generation, the continuity of the
generated trajectories has been neglected, which makes these methods useless
for practical urban simulation scenarios. To solve this problem, we propose a
novel two-stage generative adversarial framework to generate the continuous
trajectory on the road network, namely TS-TrajGen, which efficiently integrates
prior domain knowledge of human mobility with model-free learning paradigm.
Specifically, we build the generator under the human mobility hypothesis of the
A* algorithm to learn the human mobility behavior. For the discriminator, we
combine the sequential reward with the mobility yaw reward to enhance the
effectiveness of the generator. Finally, we propose a novel two-stage
generation process to overcome the weak point of the existing stochastic
generation process. Extensive experiments on two real-world datasets and two
case studies demonstrate that our framework yields significant improvements
over the state-of-the-art methods.",http://arxiv.org/pdf/2301.07103v1,
Causal Recurrent Variational Autoencoder for Medical Time Series Generation,16/01/2023,"Hongming Li, Shujian Yu, Jose Principe","We propose causal recurrent variational autoencoder (CR-VAE), a novel
generative model that is able to learn a Granger causal graph from a
multivariate time series x and incorporates the underlying causal mechanism
into its data generation process. Distinct to the classical recurrent VAEs, our
CR-VAE uses a multi-head decoder, in which the $p$-th head is responsible for
generating the $p$-th dimension of $\mathbf{x}$ (i.e., $\mathbf{x}^p$). By
imposing a sparsity-inducing penalty on the weights (of the decoder) and
encouraging specific sets of weights to be zero, our CR-VAE learns a sparse
adjacency matrix that encodes causal relations between all pairs of variables.
Thanks to this causal matrix, our decoder strictly obeys the underlying
principles of Granger causality, thereby making the data generating process
transparent. We develop a two-stage approach to train the overall objective.
Empirically, we evaluate the behavior of our model in synthetic data and two
real-world human brain datasets involving, respectively, the
electroencephalography (EEG) signals and the functional magnetic resonance
imaging (fMRI) data. Our model consistently outperforms state-of-the-art time
series generative models both qualitatively and quantitatively. Moreover, it
also discovers a faithful causal graph with similar or improved accuracy over
existing Granger causality-based causal inference methods. Code of CR-VAE is
publicly available at https://github.com/hongmingli1995/CR-VAE.",http://arxiv.org/pdf/2301.06574v1,
Diffusion-based Conditional ECG Generation with Structured State Space Models,19/01/2023,"Juan Miguel Lopez Alcaraz, Nils Strodthoff","Synthetic data generation is a promising solution to address privacy issues
with the distribution of sensitive health data. Recently, diffusion models have
set new standards for generative models for different data modalities. Also
very recently, structured state space models emerged as a powerful modeling
paradigm to capture long-term dependencies in time series. We put forward
SSSD-ECG, as the combination of these two technologies, for the generation of
synthetic 12-lead electrocardiograms conditioned on more than 70 ECG
statements. Due to a lack of reliable baselines, we also propose conditional
variants of two state-of-the-art unconditional generative models. We thoroughly
evaluate the quality of the generated samples, by evaluating pretrained
classifiers on the generated data and by evaluating the performance of a
classifier trained only on synthetic data, where SSSD-ECG clearly outperforms
its GAN-based competitors. We demonstrate the soundness of our approach through
further experiments, including conditional class interpolation and a clinical
Turing test demonstrating the high quality of the SSSD-ECG samples across a
wide range of conditions.",http://arxiv.org/pdf/2301.08227v2,
Regular Time-series Generation using SGM,20/01/2023,"Haksoo Lim, Minjung Kim, Sewon Park, Noseong Park","Score-based generative models (SGMs) are generative models that are in the
spotlight these days. Time-series frequently occurs in our daily life, e.g.,
stock data, climate data, and so on. Especially, time-series forecasting and
classification are popular research topics in the field of machine learning.
SGMs are also known for outperforming other generative models. As a result, we
apply SGMs to synthesize time-series data by learning conditional score
functions. We propose a conditional score network for the time-series
generation domain. Furthermore, we also derive the loss function between the
score matching and the denoising score matching in the time-series generation
domain. Finally, we achieve state-of-the-art results on real-world datasets in
terms of sampling diversity and quality.",http://arxiv.org/pdf/2301.08518v1,
ECGAN: Self-supervised generative adversarial network for electrocardiography,23/01/2023,"Lorenzo Simone, Davide Bacciu","High-quality synthetic data can support the development of effective
predictive models for biomedical tasks, especially in rare diseases or when
subject to compelling privacy constraints. These limitations, for instance,
negatively impact open access to electrocardiography datasets about
arrhythmias. This work introduces a self-supervised approach to the generation
of synthetic electrocardiography time series which is shown to promote
morphological plausibility. Our model (ECGAN) allows conditioning the
generative process for specific rhythm abnormalities, enhancing synchronization
and diversity across samples with respect to literature models. A dedicated
sample quality assessment framework is also defined, leveraging arrhythmia
classifiers. The empirical results highlight a substantial improvement against
state-of-the-art generative models for sequences and audio synthesis.",http://arxiv.org/pdf/2301.09496v1,
A Denoising Diffusion Model for Fluid Field Prediction,27/01/2023,"Gefan Yang, Stefan Sommer","We propose a novel denoising diffusion generative model for predicting
nonlinear fluid fields named FluidDiff. By performing a diffusion process, the
model is able to learn a complex representation of the high-dimensional dynamic
system, and then Langevin sampling is used to generate predictions for the flow
state under specified initial conditions. The model is trained with finite,
discrete fluid simulation data. We demonstrate that our model has the capacity
to model the distribution of simulated training data and that it gives accurate
predictions on the test data. Without encoded prior knowledge of the underlying
physical system, it shares competitive performance with other deep learning
models for fluid prediction, which is promising for investigation on new
computational fluid dynamics methods.",http://arxiv.org/pdf/2301.11661v2,
Effect of temporal resolution on the reproduction of chaotic dynamics via reservoir computing,27/01/2023,"Kohei Tsuchiyama, André Röhm, Takatomo Mihana, Ryoichi Horisaki, Makoto Naruse","Reservoir computing is a machine learning paradigm that uses a structure
called a reservoir, which has nonlinearities and short-term memory. In recent
years, reservoir computing has expanded to new functions such as the autonomous
generation of chaotic time series, as well as time series prediction and
classification. Furthermore, novel possibilities have been demonstrated, such
as inferring the existence of previously unseen attractors. Sampling, in
contrast, has a strong influence on such functions. Sampling is indispensable
in a physical reservoir computer that uses an existing physical system as a
reservoir because the use of an external digital system for the data input is
usually inevitable. This study analyzes the effect of sampling on the ability
of reservoir computing to autonomously regenerate chaotic time series. We
found, as expected, that excessively coarse sampling degrades the system
performance, but also that excessively dense sampling is unsuitable. Based on
quantitative indicators that capture the local and global characteristics of
attractors, we identify a suitable window of the sampling frequency and discuss
its underlying mechanisms.",http://arxiv.org/pdf/2302.10761v2,10.1063/5.0143846
Minimizing Trajectory Curvature of ODE-based Generative Models,27/01/2023,"Sangyun Lee, Beomsu Kim, Jong Chul Ye","Recent ODE/SDE-based generative models, such as diffusion models, rectified
flows, and flow matching, define a generative process as a time reversal of a
fixed forward process. Even though these models show impressive performance on
large-scale datasets, numerical simulation requires multiple evaluations of a
neural network, leading to a slow sampling speed. We attribute the reason to
the high curvature of the learned generative trajectories, as it is directly
related to the truncation error of a numerical solver. Based on the
relationship between the forward process and the curvature, here we present an
efficient method of training the forward process to minimize the curvature of
generative trajectories without any ODE/SDE simulation. Experiments show that
our method achieves a lower curvature than previous models and, therefore,
decreased sampling costs while maintaining competitive performance. Code is
available at https://github.com/sangyun884/fast-ode.",http://arxiv.org/pdf/2301.12003v3,
Approximating DTW with a convolutional neural network on EEG data,30/01/2023,"Hugo Lerogeron, Romain Picot-Clemente, Alain Rakotomamonjy, Laurent Heutte","Dynamic Time Wrapping (DTW) is a widely used algorithm for measuring
similarities between two time series. It is especially valuable in a wide
variety of applications, such as clustering, anomaly detection, classification,
or video segmentation, where the time-series have different timescales, are
irregularly sampled, or are shifted. However, it is not prone to be considered
as a loss function in an end-to-end learning framework because of its
non-differentiability and its quadratic temporal complexity. While
differentiable variants of DTW have been introduced by the community, they
still present some drawbacks: computing the distance is still expensive and
this similarity tends to blur some differences in the time-series. In this
paper, we propose a fast and differentiable approximation of DTW by comparing
two architectures: the first one for learning an embedding in which the
Euclidean distance mimics the DTW, and the second one for directly predicting
the DTW output using regression. We build the former by training a siamese
neural network to regress the DTW value between two time-series. Depending on
the nature of the activation function, this approximation naturally supports
differentiation, and it is efficient to compute. We show, in a time-series
retrieval context on EEG datasets, that our methods achieve at least the same
level of accuracy as other DTW main approximations with higher computational
efficiency. We also show that it can be used to learn in an end-to-end setting
on long time series by proposing generative models of EEGs.",http://arxiv.org/pdf/2301.12873v1,
CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,30/01/2023,"Mengyun Qiao, Shuo Wang, Huaqi Qiu, Antonio de Marvao, Declan P. O'Regan, Daniel Rueckert, Wenjia Bai","Two key questions in cardiac image analysis are to assess the anatomy and
motion of the heart from images; and to understand how they are associated with
non-imaging clinical factors such as gender, age and diseases. While the first
question can often be addressed by image segmentation and motion tracking
algorithms, our capability to model and to answer the second question is still
limited. In this work, we propose a novel conditional generative model to
describe the 4D spatio-temporal anatomy of the heart and its interaction with
non-imaging clinical factors. The clinical factors are integrated as the
conditions of the generative modelling, which allows us to investigate how
these factors influence the cardiac anatomy. We evaluate the model performance
in mainly two tasks, anatomical sequence completion and sequence generation.
The model achieves a high performance in anatomical sequence completion,
comparable to or outperforming other state-of-the-art generative models. In
terms of sequence generation, given clinical conditions, the model can generate
realistic synthetic 4D sequential anatomies that share similar distributions
with the real data.",http://arxiv.org/pdf/2301.13098v3,10.1109/TMI.2023.3331982
Quantum Boltzmann Machines: Applications in Quantitative Finance,30/01/2023,Cameron Perot,"In this thesis we explore using the D-Wave Advantage 4.1 quantum annealer to
sample from quantum Boltzmann distributions and train quantum Boltzmann
machines (QBMs). We focus on the real-world problem of using QBMs as generative
models to produce synthetic foreign exchange market data and analyze how the
results stack up against classical models based on restricted Boltzmann
machines (RBMs). Additionally, we study a small 12-qubit problem which we use
to compare samples obtained from the Advantage 4.1 with theory, and in the
process gain vital insights into how well the Advantage 4.1 can sample quantum
Boltzmann random variables and be used to train QBMs. Through this, we are able
to show that the Advantage 4.1 can sample classical Boltzmann random variables
to some extent, but is limited in its ability to sample from quantum Boltzmann
distributions. Our findings indicate that QBMs trained using the Advantage 4.1
are much noisier than those trained using simulations and struggle to perform
at the same level as classical RBMs. However, there is the potential for QBMs
to outperform classical RBMs if future generation annealers can generate
samples closer to the desired theoretical distributions.",http://arxiv.org/pdf/2301.13295v1,
An Comparative Analysis of Different Pitch and Metrical Grid Encoding Methods in the Task of Sequential Music Generation,31/01/2023,"Yuqiang Li, Shengchen Li, George Fazekas","Pitch and meter are two fundamental music features for symbolic music
generation tasks, where researchers usually choose different encoding methods
depending on specific goals. However, the advantages and drawbacks of different
encoding methods have not been frequently discussed. This paper presents a
integrated analysis of the influence of two low-level feature, pitch and meter,
on the performance of a token-based sequential music generation model. First,
the commonly used MIDI number encoding and a less used class-octave encoding
are compared. Second, an dense intra-bar metric grid is imposed to the encoded
sequence as auxiliary features. Different complexity and resolutions of the
metric grid are compared. For complexity, the single token approach and the
multiple token approach are compared; for grid resolution, 0 (ablation), 1
(bar-level), 4 (downbeat-level) 12, (8th-triplet-level) up to 64
(64th-note-grid-level) are compared; for duration resolution, 4, 8, 12 and 16
subdivisions per beat are compared. All different encodings are tested on
separately trained Transformer-XL models for a melody generation task.
Regarding distribution similarity of several objective evaluation metrics to
the test dataset, results suggest that the class-octave encoding significantly
outperforms the taken-for-granted MIDI encoding on pitch-related metrics; finer
grids and multiple-token grids improve the rhythmic quality, but also suffer
from over-fitting at early training stage. Results display a general phenomenon
of over-fitting from two aspects, the pitch embedding space and the test loss
of the single-token grid encoding. From a practical perspective, we both
demonstrate the feasibility and raise the concern of easy over-fitting problem
of using smaller networks and lower embedding dimensions on the generation
task. The findings can also contribute to futural models in terms of feature
engineering.",http://arxiv.org/pdf/2301.13383v1,
Transport with Support: Data-Conditional Diffusion Bridges,31/01/2023,"Ella Tamir, Martin Trapp, Arno Solin","The dynamic Schr\""odinger bridge problem provides an appealing setting for
solving constrained time-series data generation tasks posed as optimal
transport problems. It consists of learning non-linear diffusion processes
using efficient iterative solvers. Recent works have demonstrated
state-of-the-art results (eg. in modelling single-cell embryo RNA sequences or
sampling from complex posteriors) but are limited to learning bridges with only
initial and terminal constraints. Our work extends this paradigm by proposing
the Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and
optimal control into learning the diffusion process, enabling the generation of
constrained stochastic processes governed by sparse observations at
intermediate stages and terminal constraints. We assess the effectiveness of
our method on synthetic and real-world data generation tasks and we show that
the ISB generalises well to high-dimensional data, is computationally
efficient, and provides accurate estimates of the marginals at intermediate and
terminal times.",http://arxiv.org/pdf/2301.13636v2,
"A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic Time-Series Data, Application in Combined Sewer Flow Prediction",31/01/2023,"Amin E. Bakhshipour, Alireza Koochali, Ulrich Dittmer, Ali Haghighi, Sheraz Ahmad, Andreas Dengel","Despite various breakthroughs in machine learning and data analysis
techniques for improving smart operation and management of urban water
infrastructures, some key limitations obstruct this progress. Among these
shortcomings, the absence of freely available data due to data privacy or high
costs of data gathering and the nonexistence of adequate rare or extreme events
in the available data plays a crucial role. Here, Generative Adversarial
Networks (GANs) can help overcome these challenges. In machine learning,
generative models are a class of methods capable of learning data distribution
to generate artificial data. In this study, we developed a GAN model to
generate synthetic time series to balance our limited recorded time series data
and improve the accuracy of a data-driven model for combined sewer flow
prediction. We considered the sewer system of a small town in Germany as the
test case. Precipitation and inflow to the storage tanks are used for the
Data-Driven model development. The aim is to predict the flow using
precipitation data and examine the impact of data augmentation using synthetic
data in model performance. Results show that GAN can successfully generate
synthetic time series from real data distribution, which helps more accurate
peak flow prediction. However, the model without data augmentation works better
for dry weather prediction. Therefore, an ensemble model is suggested to
combine the advantages of both models.",http://arxiv.org/pdf/2301.13733v1,10.4995/WDSA-CCWI2022.2022.14699
Distributed Traffic Synthesis and Classification in Edge Networks: A Federated Self-supervised Learning Approach,01/02/2023,"Yong Xiao, Rong Xia, Yingyu Li, Guangming Shi, Diep N. Nguyen, Dinh Thai Hoang, Dusit Niyato, Marwan Krunz","With the rising demand for wireless services and increased awareness of the
need for data protection, existing network traffic analysis and management
architectures are facing unprecedented challenges in classifying and
synthesizing the increasingly diverse services and applications. This paper
proposes FS-GAN, a federated self-supervised learning framework to support
automatic traffic analysis and synthesis over a large number of heterogeneous
datasets. FS-GAN is composed of multiple distributed Generative Adversarial
Networks (GANs), with a set of generators, each being designed to generate
synthesized data samples following the distribution of an individual service
traffic, and each discriminator being trained to differentiate the synthesized
data samples and the real data samples of a local dataset. A federated
learning-based framework is adopted to coordinate local model training
processes of different GANs across different datasets. FS-GAN can classify data
of unknown types of service and create synthetic samples that capture the
traffic distribution of the unknown types. We prove that FS-GAN can minimize
the Jensen-Shannon Divergence (JSD) between the distribution of real data
across all the datasets and that of the synthesized data samples. FS-GAN also
maximizes the JSD among the distributions of data samples created by different
generators, resulting in each generator producing synthetic data samples that
follow the same distribution as one particular service type. Extensive
simulation results show that the classification accuracy of FS-GAN achieves
over 20% improvement in average compared to the state-of-the-art
clustering-based traffic analysis algorithms. FS-GAN also has the capability to
synthesize highly complex mixtures of traffic types without requiring any
human-labeled data samples.",http://arxiv.org/pdf/2302.00207v1,10.1109/TMC.2023.3240821
Learning PDE Solution Operator for Continuous Modeling of Time-Series,02/02/2023,"Yesom Park, Jaemoo Choi, Changyeon Yoon, Chang hoon Song, Myungjoo Kang","Learning underlying dynamics from data is important and challenging in many
real-world scenarios. Incorporating differential equations (DEs) to design
continuous networks has drawn much attention recently, however, most prior
works make specific assumptions on the type of DEs, making the model
specialized for particular problems. This work presents a partial differential
equation (PDE) based framework which improves the dynamics modeling capability.
Building upon the recent Fourier neural operator, we propose a neural operator
that can handle time continuously without requiring iterative operations or
specific grids of temporal discretization. A theoretical result demonstrating
its universality is provided. We also uncover an intrinsic property of neural
operators that improves data efficiency and model generalization by ensuring
stability. Our model achieves superior accuracy in dealing with time-dependent
PDEs compared to existing models. Furthermore, several numerical pieces of
evidence validate that our method better represents a wide range of dynamics
and outperforms state-of-the-art DE-based models in real-time-series
applications. Our framework opens up a new way for a continuous representation
of neural networks that can be readily adopted for real-world applications.",http://arxiv.org/pdf/2302.00854v1,
SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling,02/02/2023,"Jiaxiang Dong, Haixu Wu, Haoran Zhang, Li Zhang, Jianmin Wang, Mingsheng Long","Time series analysis is widely used in extensive areas. Recently, to reduce
labeling expenses and benefit various tasks, self-supervised pre-training has
attracted immense interest. One mainstream paradigm is masked modeling, which
successfully pre-trains deep models by learning to reconstruct the masked
content based on the unmasked part. However, since the semantic information of
time series is mainly contained in temporal variations, the standard way of
randomly masking a portion of time points will seriously ruin vital temporal
variations of time series, making the reconstruction task too difficult to
guide representation learning. We thus present SimMTM, a Simple pre-training
framework for Masked Time-series Modeling. By relating masked modeling to
manifold learning, SimMTM proposes to recover masked time points by the
weighted aggregation of multiple neighbors outside the manifold, which eases
the reconstruction task by assembling ruined but complementary temporal
variations from multiple masked series. SimMTM further learns to uncover the
local structure of the manifold, which is helpful for masked modeling.
Experimentally, SimMTM achieves state-of-the-art fine-tuning performance
compared to the most advanced time series pre-training methods in two canonical
time series analysis tasks: forecasting and classification, covering both in-
and cross-domain settings.",http://arxiv.org/pdf/2302.00861v4,
SDYN-GANs: Adversarial Learning Methods for Multistep Generative Models for General Order Stochastic Dynamics,07/02/2023,"Panos Stinis, Constantinos Daskalakis, Paul J. Atzberger","We introduce adversarial learning methods for data-driven generative modeling
of the dynamics of $n^{th}$-order stochastic systems. Our approach builds on
Generative Adversarial Networks (GANs) with generative model classes based on
stable $m$-step stochastic numerical integrators. We introduce different
formulations and training methods for learning models of stochastic dynamics
based on observation of trajectory samples. We develop approaches using
discriminators based on Maximum Mean Discrepancy (MMD), training protocols
using conditional and marginal distributions, and methods for learning dynamic
responses over different time-scales. We show how our approaches can be used
for modeling physical systems to learn force-laws, damping coefficients, and
noise-related parameters. The adversarial learning approaches provide methods
for obtaining stable generative models for dynamic tasks including long-time
prediction and developing simulations for stochastic systems.",http://arxiv.org/pdf/2302.03663v1,
Learning to Simulate Daily Activities via Modeling Dynamic Human Needs,09/02/2023,"Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, Yong Li","Daily activity data that records individuals' various types of activities in
daily life are widely used in many applications such as activity scheduling,
activity recommendation, and policymaking. Though with high value, its
accessibility is limited due to high collection costs and potential privacy
issues. Therefore, simulating human activities to produce massive high-quality
data is of great importance to benefit practical applications. However,
existing solutions, including rule-based methods with simplified assumptions of
human behavior and data-driven methods directly fitting real-world data, both
cannot fully qualify for matching reality. In this paper, motivated by the
classic psychological theory, Maslow's need theory describing human motivation,
we propose a knowledge-driven simulation framework based on generative
adversarial imitation learning. To enhance the fidelity and utility of the
generated activity data, our core idea is to model the evolution of human needs
as the underlying mechanism that drives activity generation in the simulation
model. Specifically, this is achieved by a hierarchical model structure that
disentangles different need levels, and the use of neural stochastic
differential equations that successfully captures piecewise-continuous
characteristics of need dynamics. Extensive experiments demonstrate that our
framework outperforms the state-of-the-art baselines in terms of data fidelity
and utility. Besides, we present the insightful interpretability of the need
modeling. The code is available at https://github.com/tsinghua-fib-lab/SAND.",http://arxiv.org/pdf/2302.10897v1,10.1145/3543507.3583276
cGAN-Based High Dimensional IMU Sensor Data Generation for Enhanced Human Activity Recognition in Therapeutic Activities,16/02/2023,"Mohammad Mohammadzadeh, Ali Ghadami, Alireza Taheri, Saeed Behzadipour","Human activity recognition is a core technology for applications such as
rehabilitation, health monitoring, and human-computer interactions. Wearable
devices, especially IMU sensors, provide rich features of human movements at a
reasonable cost, which can be leveraged in activity recognition. Developing a
robust classifier for activity recognition has always been of interest to
researchers. One major problem is that there is usually a deficit of training
data, which makes developing deep classifiers difficult and sometimes
impossible. In this work, a novel GAN network called TheraGAN was developed to
generate IMU signals associated with rehabilitation activities. The generated
signal comprises data from a 6-channel IMU, i.e., angular velocities and linear
accelerations. Also, introducing simple activities simplified the generation
process for activities of varying lengths. To evaluate the generated signals,
several qualitative and quantitative studies were conducted, including
perceptual similarity analysis, comparing manually extracted features to those
from real data, visual inspection, and an investigation into how the generated
data affects the performance of three deep classifiers trained on the generated
and real data. The results showed that the generated signals closely mimicked
the real signals, and adding generated data resulted in a significant
improvement in the performance of all tested networks. Among the tested
networks, the LSTM classifier demonstrated the most significant improvement,
achieving a 13.27% boost, effectively addressing the challenge of data
scarcity. This shows the validity of the generated data as well as TheraGAN as
a tool to build more robust classifiers in case of imbalanced and insufficient
data problems.",http://arxiv.org/pdf/2302.07998v2,
Redes Generativas Adversarias (GAN) Fundamentos Teóricos y Aplicaciones,18/02/2023,Jordi de la Torre,"Generative adversarial networks (GANs) are a method based on the training of
two neural networks, one called generator and the other discriminator,
competing with each other to generate new instances that resemble those of the
probability distribution of the training data. GANs have a wide range of
applications in fields such as computer vision, semantic segmentation, time
series synthesis, image editing, natural language processing, and image
generation from text, among others. Generative models model the probability
distribution of a data set, but instead of providing a probability value, they
generate new instances that are close to the original distribution. GANs use a
learning scheme that allows the defining attributes of the probability
distribution to be encoded in a neural network, allowing instances to be
generated that resemble the original probability distribution. This article
presents the theoretical foundations of this type of network as well as the
basic architecture schemes and some of its applications. This article is in
Spanish to facilitate the arrival of this scientific knowledge to the
Spanish-speaking community.",http://arxiv.org/pdf/2302.09346v1,
DINOISER: Diffused Conditional Sequence Learning by Manipulating Noises,20/02/2023,"Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Mingxuan Wang","While diffusion models have achieved great success in generating continuous
signals such as images and audio, it remains elusive for diffusion models in
learning discrete sequence data like natural languages. Although recent
advances circumvent this challenge of discreteness by embedding discrete tokens
as continuous surrogates, they still fall short of satisfactory generation
quality. To understand this, we first dive deep into the denoised training
protocol of diffusion-based sequence generative models and determine their
three severe problems, i.e., 1) failing to learn, 2) lack of scalability, and
3) neglecting source conditions. We argue that these problems can be boiled
down to the pitfall of the not completely eliminated discreteness in the
embedding space, and the scale of noises is decisive herein. In this paper, we
introduce DINOISER to facilitate diffusion models for sequence generation by
manipulating noises. We propose to adaptively determine the range of sampled
noise scales for counter-discreteness training; and encourage the proposed
diffused sequence learner to leverage source conditions with amplified noise
scales during inference. Experiments show that DINOISER enables consistent
improvement over the baselines of previous diffusion-based sequence generative
models on several conditional sequence modeling benchmarks thanks to both
effective training and inference strategies. Analyses further verify that
DINOISER can make better use of source conditions to govern its generative
process.",http://arxiv.org/pdf/2302.10025v2,
Creating Disasters: Recession Forecasting with GAN-Generated Synthetic Time Series Data,21/02/2023,Sam Dannels,"A common problem when forecasting rare events, such as recessions, is limited
data availability. Recent advancements in deep learning and generative
adversarial networks (GANs) make it possible to produce high-fidelity synthetic
data in large quantities. This paper uses a model called DoppelGANger, a GAN
tailored to producing synthetic time series data, to generate synthetic
Treasury yield time series and associated recession indicators. It is then
shown that short-range forecasting performance for Treasury yields is improved
for models trained on synthetic data relative to models trained only on real
data. Finally, synthetic recession conditions are produced and used to train
classification models to predict the probability of a future recession. It is
shown that training models on synthetic recessions can improve a model's
ability to predict future recessions over a model trained only on real data.",http://arxiv.org/pdf/2302.10490v1,
Task-Oriented Prediction and Communication Co-Design for Haptic Communications,21/02/2023,"Burak Kizilkaya, Changyang She, Guodong Zhao, Muhammad Ali Imran","Prediction has recently been considered as a promising approach to meet
low-latency and high-reliability requirements in long-distance haptic
communications. However, most of the existing methods did not take features of
tasks and the relationship between prediction and communication into account.
In this paper, we propose a task-oriented prediction and communication
co-design framework, where the reliability of the system depends on prediction
errors and packet losses in communications. The goal is to minimize the
required radio resources subject to the low-latency and high-reliability
requirements of various tasks. Specifically, we consider the just noticeable
difference (JND) as a performance metric for the haptic communication system.
We collect experiment data from a real-world teleoperation testbed and use
time-series generative adversarial networks (TimeGAN) to generate a large
amount of synthetic data. This allows us to obtain the relationship between the
JND threshold, prediction horizon, and the overall reliability including
communication reliability and prediction reliability. We take 5G New Radio as
an example to demonstrate the proposed framework and optimize bandwidth
allocation and data rates of devices. Our numerical and experimental results
show that the proposed framework can reduce wireless resource consumption up to
77.80% compared with a task-agnostic benchmark.",http://arxiv.org/pdf/2302.11064v1,
Imputing Knowledge Tracing Data with Subject-Based Training via LSTM Variational Autoencoders Frameworks,24/02/2023,"Jia Tracy Shen, Dongwon Lee","The issue of missing data poses a great challenge on boosting performance and
application of deep learning models in the {\em Knowledge Tracing} (KT)
problem. However, there has been the lack of understanding on the issue in the
literature. %are not sufficient studies tackling this problem. In this work, to
address this challenge, we adopt a subject-based training method to split and
impute data by student IDs instead of row number splitting which we call
non-subject based training. The benefit of subject-based training can retain
the complete sequence for each student and hence achieve efficient training.
Further, we leverage two existing deep generative frameworks, namely
variational Autoencoders (VAE) and Longitudinal Variational Autoencoders (LVAE)
frameworks and build LSTM kernels into them to form LSTM-VAE and LSTM LVAE
(noted as VAE and LVAE for simplicity) models to generate quality data. In
LVAE, a Gaussian Process (GP) model is trained to disentangle the correlation
between the subject (i.e., student) descriptor information (e.g., age, gender)
and the latent space. The paper finally compare the model performance between
training the original data and training the data imputed with generated data
from non-subject based model VAE-NS and subject-based training models (i.e.,
VAE and LVAE). We demonstrate that the generated data from LSTM-VAE and
LSTM-LVAE can boost the original model performance by about 50%. Moreover, the
original model just needs 10% more student data to surpass the original
performance if the prediction model is small and 50\% more data if the
prediction model is large with our proposed frameworks.",http://arxiv.org/pdf/2302.12910v1,
Spatial-temporal Transformer-guided Diffusion based Data Augmentation for Efficient Skeleton-based Action Recognition,26/02/2023,"Yifan Jiang, Han Chen, Hanseok Ko","Recently, skeleton-based human action has become a hot research topic because
the compact representation of human skeletons brings new blood to this research
domain. As a result, researchers began to notice the importance of using RGB or
other sensors to analyze human action by extracting skeleton information.
Leveraging the rapid development of deep learning (DL), a significant number of
skeleton-based human action approaches have been presented with fine-designed
DL structures recently. However, a well-trained DL model always demands
high-quality and sufficient data, which is hard to obtain without costing high
expenses and human labor. In this paper, we introduce a novel data augmentation
method for skeleton-based action recognition tasks, which can effectively
generate high-quality and diverse sequential actions. In order to obtain
natural and realistic action sequences, we propose denoising diffusion
probabilistic models (DDPMs) that can generate a series of synthetic action
sequences, and their generation process is precisely guided by a
spatial-temporal transformer (ST-Trans). Experimental results show that our
method outperforms the state-of-the-art (SOTA) motion generation approaches on
different naturality and diversity metrics. It proves that its high-quality
synthetic data can also be effectively deployed to existing action recognition
models with significant performance improvement.",http://arxiv.org/pdf/2302.13434v2,
A Brief Survey on the Approximation Theory for Sequence Modelling,27/02/2023,"Haotian Jiang, Qianxiao Li, Zhong Li, Shida Wang","We survey current developments in the approximation theory of sequence
modelling in machine learning. Particular emphasis is placed on classifying
existing results for various model architectures through the lens of classical
approximation paradigms, and the insights one can gain from these results. We
also outline some future research directions towards building a theory of
sequence modelling.",http://arxiv.org/pdf/2302.13752v1,
Stock Broad-Index Trend Patterns Learning via Domain Knowledge Informed Generative Network,27/02/2023,"Jingyi Gu, Fadi P. Deek, Guiling Wang","Predicting the Stock movement attracts much attention from both industry and
academia. Despite such significant efforts, the results remain unsatisfactory
due to the inherently complicated nature of the stock market driven by factors
including supply and demand, the state of the economy, the political climate,
and even irrational human behavior. Recently, Generative Adversarial Networks
(GAN) have been extended for time series data; however, robust methods are
primarily for synthetic series generation, which fall short for appropriate
stock prediction. This is because existing GANs for stock applications suffer
from mode collapse and only consider one-step prediction, thus underutilizing
the potential of GAN. Furthermore, merging news and market volatility are
neglected in current GANs. To address these issues, we exploit expert domain
knowledge in finance and, for the first time, attempt to formulate stock
movement prediction into a Wasserstein GAN framework for multi-step prediction.
We propose IndexGAN, which includes deliberate designs for the inherent
characteristics of the stock market, leverages news context learning to
thoroughly investigate textual information and develop an attentive seq2seq
learning network that captures the temporal dependency among stock prices,
news, and market sentiment. We also utilize the critic to approximate the
Wasserstein distance between actual and predicted sequences and develop a
rolling strategy for deployment that mitigates noise from the financial market.
Extensive experiments are conducted on real-world broad-based indices,
demonstrating the superior performance of our architecture over other
state-of-the-art baselines, also validating all its contributing components.",http://arxiv.org/pdf/2302.14164v1,
FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs,01/03/2023,"Vedant Choudhary, Sebastian Jaimungal, Maxime Bergeron","We introduce a new approach for generating sequences of implied volatility
(IV) surfaces across multiple assets that is faithful to historical prices. We
do so using a combination of functional data analysis and neural stochastic
differential equations (SDEs) combined with a probability integral transform
penalty to reduce model misspecification. We demonstrate that learning the
joint dynamics of IV surfaces and prices produces market scenarios that are
consistent with historical features and lie within the sub-manifold of surfaces
that are essentially free of static arbitrage. Finally, we demonstrate that
delta hedging using the simulated surfaces generates profit and loss (P&L)
distributions that are consistent with realised P&Ls.",http://arxiv.org/pdf/2303.00859v4,
GlucoSynth: Generating Differentially-Private Synthetic Glucose Traces,02/03/2023,"Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Joost van der Linden, Lu Feng, Tianhao Wang, David Evans","We focus on the problem of generating high-quality, private synthetic glucose
traces, a task generalizable to many other time series sources. Existing
methods for time series data synthesis, such as those using Generative
Adversarial Networks (GANs), are not able to capture the innate characteristics
of glucose data and cannot provide any formal privacy guarantees without
severely degrading the utility of the synthetic data. In this paper we present
GlucoSynth, a novel privacy-preserving GAN framework to generate synthetic
glucose traces. The core intuition behind our approach is to conserve
relationships amongst motifs (glucose events) within the traces, in addition to
temporal dynamics. Our framework incorporates differential privacy mechanisms
to provide strong formal privacy guarantees. We provide a comprehensive
evaluation on the real-world utility of the data using 1.2 million glucose
traces; GlucoSynth outperforms all previous methods in its ability to generate
high-quality synthetic glucose traces with strong privacy guarantees.",http://arxiv.org/pdf/2303.01621v4,
Synthetic Data Generator for Adaptive Interventions in Global Health,03/03/2023,"Aditya Rastogi, Juan Francisco Garamendi, Ana Fernández del Río, Anna Guitart, Moiz Hassan Khan, Dexian Tang, África Periáñez","Artificial Intelligence and digital health have the potential to transform
global health. However, having access to representative data to test and
validate algorithms in realistic production environments is essential. We
introduce HealthSyn, an open-source synthetic data generator of user behavior
for testing reinforcement learning algorithms in the context of mobile health
interventions. The generator utilizes Markov processes to generate diverse user
actions, with individual user behavioral patterns that can change in reaction
to personalized interventions (i.e., reminders, recommendations, and
incentives). These actions are translated into actual logs using an ML-purposed
data schema specific to the mobile health application functionality included
with HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain
user metrics. The generated data, which is based on real-world behaviors and
simulation techniques, can be used to develop, test, and evaluate, both ML
algorithms in research and end-to-end operational RL-based intervention
delivery frameworks.",http://arxiv.org/pdf/2303.01954v3,
Synthetic ECG Signal Generation using Probabilistic Diffusion Models,04/03/2023,"Edmond Adib, Amanda Fernandez, Fatemeh Afghah, John Jeff Prevost","Deep learning image processing models have had remarkable success in recent
years in generating high quality images. Particularly, the Improved Denoising
Diffusion Probabilistic Models (DDPM) have shown superiority in image quality
to the state-of-the-art generative models, which motivated us to investigate
their capability in the generation of the synthetic electrocardiogram (ECG)
signals. In this work, synthetic ECG signals are generated by the Improved DDPM
and by the Wasserstein GAN with Gradient Penalty (WGAN-GP) models and then
compared. To this end, we devise a pipeline to utilize DDPM in its original
$2D$ form. First, the $1D$ ECG time series data are embedded into the $2D$
space, for which we employed the Gramian Angular Summation/Difference Fields
(GASF/GADF) as well as Markov Transition Fields (MTF) to generate three $2D$
matrices from each ECG time series, which when put together, form a $3$-channel
$2D$ datum. Then $2D$ DDPM is used to generate $2D$ $3$-channel synthetic ECG
images. The $1D$ ECG signals are created by de-embedding the $2D$ generated
image files back into the $1D$ space. This work focuses on unconditional models
and the generation of \emph{Normal Sinus Beat} ECG signals exclusively, where
the Normal Sinus Beat class from the MIT-BIH Arrhythmia dataset is used in the
training phase. The \emph{quality}, \emph{distribution}, and the
\emph{authenticity} of the generated ECG signals by each model are
quantitatively evaluated and compared. Our results show that in the proposed
pipeline and in the particular setting of this paper, the WGAN-GP model is
consistently superior to DDPM in all the considered metrics.",http://arxiv.org/pdf/2303.02475v4,
HARDC : A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN,06/03/2023,"Md Shofiqul Islam, Khondokar Fida Hasan, Sunjida Sultana, Shahadat Uddin, Pietro Lio, Julian M. W. Quinn, Mohammad Ali Moni","In this paper have developed a novel hybrid hierarchical attention-based
bidirectional recurrent neural network with dilated CNN (HARDC) method for
arrhythmia classification. This solves problems that arise when traditional
dilated convolutional neural network (CNN) models disregard the correlation
between contexts and gradient dispersion. The proposed HARDC fully exploits the
dilated CNN and bidirectional recurrent neural network unit (BiGRU-BiLSTM)
architecture to generate fusion features. As a result of incorporating both
local and global feature information and an attention mechanism, the model's
performance for prediction is improved.By combining the fusion features with a
dilated CNN and a hierarchical attention mechanism, the trained HARDC model
showed significantly improved classification results and interpretability of
feature extraction on the PhysioNet 2017 challenge dataset. Sequential Z-Score
normalization, filtering, denoising, and segmentation are used to prepare the
raw data for analysis. CGAN (Conditional Generative Adversarial Network) is
then used to generate synthetic signals from the processed data. The
experimental results demonstrate that the proposed HARDC model significantly
outperforms other existing models, achieving an accuracy of 99.60\%, F1 score
of 98.21\%, a precision of 97.66\%, and recall of 99.60\% using MIT-BIH
generated ECG. In addition, this approach substantially reduces run time when
using dilated CNN compared to normal convolution. Overall, this hybrid model
demonstrates an innovative and cost-effective strategy for ECG signal
compression and high-performance ECG recognition. Our results indicate that an
automated and highly computed method to classify multiple types of arrhythmia
signals holds considerable promise.",http://arxiv.org/pdf/2303.06020v1,10.1016/j.neunet.2023.03.004
Variational Inference for Neyman-Scott Processes,07/03/2023,"Chengkuan Hong, Christian R. Shelton","Neyman-Scott processes (NSPs) have been applied across a range of fields to
model points or temporal events with a hierarchy of clusters. Markov chain
Monte Carlo (MCMC) is typically used for posterior sampling in the model.
However, MCMC's mixing time can cause the resulting inference to be slow, and
thereby slow down model learning and prediction. We develop the first
variational inference (VI) algorithm for NSPs, and give two examples of
suitable variational posterior point process distributions. Our method
minimizes the inclusive Kullback-Leibler (KL) divergence for VI to obtain the
variational parameters. We generate samples from the approximate posterior
point processes much faster than MCMC, as we can directly estimate the
approximate posterior point processes without any MCMC steps or gradient
descent. We include synthetic and real-world data experiments that demonstrate
our VI algorithm achieves better prediction performance than MCMC when
computational time is limited.",http://arxiv.org/pdf/2303.03701v1,
Speech Modeling with a Hierarchical Transformer Dynamical VAE,07/03/2023,"Xiaoyu Lin, Xiaoyu Bie, Simon Leglaive, Laurent Girin, Xavier Alameda-Pineda","The dynamical variational autoencoders (DVAEs) are a family of
latent-variable deep generative models that extends the VAE to model a sequence
of observed data and a corresponding sequence of latent vectors. In almost all
the DVAEs of the literature, the temporal dependencies within each sequence and
across the two sequences are modeled with recurrent neural networks. In this
paper, we propose to model speech signals with the Hierarchical Transformer
DVAE (HiT-DVAE), which is a DVAE with two levels of latent variable
(sequence-wise and frame-wise) and in which the temporal dependencies are
implemented with the Transformer architecture. We show that HiT-DVAE
outperforms several other DVAEs for speech spectrogram modeling, while enabling
a simpler training procedure, revealing its high potential for downstream
low-level speech processing tasks such as speech enhancement.",http://arxiv.org/pdf/2303.09404v2,
Extrapolative Controlled Sequence Generation via Iterative Refinement,08/03/2023,"Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P. Parikh","We study the problem of extrapolative controlled generation, i.e., generating
sequences with attribute values beyond the range seen in training. This task is
of significant importance in automated design, especially drug discovery, where
the goal is to design novel proteins that are \textit{better} (e.g., more
stable) than existing sequences. Thus, by definition, the target sequences and
their attribute values are out of the training distribution, posing challenges
to existing methods that aim to directly generate the target sequence. Instead,
in this work, we propose Iterative Controlled Extrapolation (ICE) which
iteratively makes local edits to a sequence to enable extrapolation. We train
the model on synthetically generated sequence pairs that demonstrate small
improvement in the attribute value. Results on one natural language task
(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV
fitness) show that ICE considerably outperforms state-of-the-art approaches
despite its simplicity. Our code and models are available at:
https://github.com/vishakhpk/iter-extrapolation.",http://arxiv.org/pdf/2303.04562v3,
Vector Quantized Time Series Generation with a Bidirectional Prior Model,08/03/2023,"Daesoo Lee, Sara Malacarne, Erlend Aune","Time series generation (TSG) studies have mainly focused on the use of
Generative Adversarial Networks (GANs) combined with recurrent neural network
(RNN) variants. However, the fundamental limitations and challenges of training
GANs still remain. In addition, the RNN-family typically has difficulties with
temporal consistency between distant timesteps. Motivated by the successes in
the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our
knowledge, that uses vector quantization (VQ) techniques to address the TSG
problem. Moreover, the priors of the discrete latent spaces are learned with
bidirectional transformer models that can better capture global temporal
consistency. We also propose VQ modeling in a time-frequency domain, separated
into low-frequency (LF) and high-frequency (HF). This allows us to retain
important characteristics of the time series and, in turn, generate new
synthetic signals that are of better quality, with sharper changes in
modularity, than its competing TSG methods. Our experimental evaluation is
conducted on all datasets from the UCR archive, using well-established metrics
in the IMG literature, such as Fr\'echet inception distance and inception
scores. Our implementation on GitHub:
\url{https://github.com/ML4ITS/TimeVQVAE}.",http://arxiv.org/pdf/2303.04743v3,
Machine Learning Enhanced Hankel Dynamic-Mode Decomposition,11/03/2023,"Christopher W. Curtis, D. Jay Alford-Lago, Erik Bollt, Andrew Tuma","While the acquisition of time series has become more straightforward,
developing dynamical models from time series is still a challenging and
evolving problem domain. Within the last several years, to address this
problem, there has been a merging of machine learning tools with what is called
the dynamic mode decomposition (DMD). This general approach has been shown to
be an especially promising avenue for accurate model development. Building on
this prior body of work, we develop a deep learning DMD based method which
makes use of the fundamental insight of Takens' Embedding Theorem to build an
adaptive learning scheme that better approximates higher dimensional and
chaotic dynamics. We call this method the Deep Learning Hankel DMD (DLHDMD). We
likewise explore how our method learns mappings which tend, after successful
training, to significantly change the mutual information between dimensions in
the dynamics. This appears to be a key feature in enhancing the DMD overall,
and it should help provide further insight for developing other deep learning
methods for time series analysis and model generation.",http://arxiv.org/pdf/2303.06289v3,
Generative Adversarial Networks for Scintillation Signal Simulation in EXO-200,11/03/2023,"S. Li, I. Ostrovskiy, Z. Li, L. Yang, S. Al Kharusi, G. Anton, I. Badhrees, P. S. Barbeau, D. Beck, V. Belov, T. Bhatta, M. Breidenbach, T. Brunner, G. F. Cao, W. R. Cen, C. Chambers, B. Cleveland, M. Coon, A. Craycraft, T. Daniels, L. Darroch, S. J. Daugherty, J. Davis, S. Delaquis, A. Der Mesrobian-Kabakian, R. DeVoe, J. Dilling, A. Dolgolenko, M. J. Dolinski, J. Echevers, W. Fairbank Jr., D. Fairbank, J. Farine, S. Feyzbakhsh, P. Fierlinger, Y. S. Fu, D. Fudenberg, P. Gautam, R. Gornea, G. Gratta, C. Hall, E. V. Hansen, J. Hoessl, P. Hufschmidt, M. Hughes, A. Iverson, A. Jamil, C. Jessiman, M. J. Jewell, A. Johnson, A. Karelin, L. J. Kaufman, T. Koffas, R. Krücken, A. Kuchenkov, K. S. Kumar, Y. Lan, A. Larson, B. G. Lenardo, D. S. Leonard, G. S. Li, C. Licciardi, Y. H. Lin, R. MacLellan, T. McElroy, T. Michel, B. Mong, D. C. Moore, K. Murray, O. Njoya, O. Nusair, A. Odian, A. Perna, A. Piepke, A. Pocar, F. Retière, A. L. Robinson, P. C. Rowson, J. Runge, S. Schmidt, D. Sinclair, K. Skarpaas, A. K. Soma, V. Stekhanov, M. Tarka, S. Thibado, J. Todd, T. Tolba, T. I. Totev, R. Tsang","Generative Adversarial Networks trained on samples of simulated or actual
events have been proposed as a way of generating large simulated datasets at a
reduced computational cost. In this work, a novel approach to perform the
simulation of photodetector signals from the time projection chamber of the
EXO-200 experiment is demonstrated. The method is based on a Wasserstein
Generative Adversarial Network - a deep learning technique allowing for
implicit non-parametric estimation of the population distribution for a given
set of objects. Our network is trained on real calibration data using raw
scintillation waveforms as input. We find that it is able to produce
high-quality simulated waveforms an order of magnitude faster than the
traditional simulation approach and, importantly, generalize from the training
sample and discern salient high-level features of the data. In particular, the
network correctly deduces position dependency of scintillation light response
in the detector and correctly recognizes dead photodetector channels. The
network output is then integrated into the EXO-200 analysis framework to show
that the standard EXO-200 reconstruction routine processes the simulated
waveforms to produce energy distributions comparable to that of real waveforms.
Finally, the remaining discrepancies and potential ways to improve the approach
further are highlighted.",http://arxiv.org/pdf/2303.06311v2,10.1088/1748-0221/18/06/P06005
Delay-SDE-net: A deep learning approach for time series modelling with memory and uncertainty estimates,14/03/2023,"Mari Dahl Eggen, Alise Danielle Midtfjord","To model time series accurately is important within a wide range of fields.
As the world is generally too complex to be modelled exactly, it is often
meaningful to assess the probability of a dynamical system to be in a specific
state. This paper presents the Delay-SDE-net, a neural network model based on
stochastic delay differential equations (SDDEs). The use of SDDEs with multiple
delays as modelling framework makes it a suitable model for time series with
memory effects, as it includes memory through previous states of the system.
The stochastic part of the Delay-SDE-net provides a basis for estimating
uncertainty in modelling, and is split into two neural networks to account for
aleatoric and epistemic uncertainty. The uncertainty is provided instantly,
making the model suitable for applications where time is sparse. We derive the
theoretical error of the Delay-SDE-net and analyze the convergence rate
numerically. At comparisons with similar models, the Delay-SDE-net has
consistently the best performance, both in predicting time series values and
uncertainties.",http://arxiv.org/pdf/2303.08587v1,
Generating synthetic multi-dimensional molecular-mediator time series data for artificial intelligence-based disease trajectory forecasting and drug development digital twins: Considerations,16/03/2023,"Gary An, Chase Cockrell","The use of synthetic data is recognized as a crucial step in the development
of neural network-based Artificial Intelligence (AI) systems. While the methods
for generating synthetic data for AI applications in other domains have a role
in certain biomedical AI systems, primarily related to image processing, there
is a critical gap in the generation of time series data for AI tasks where it
is necessary to know how the system works. This is most pronounced in the
ability to generate synthetic multi-dimensional molecular time series data
(SMMTSD); this is the type of data that underpins research into biomarkers and
mediator signatures for forecasting various diseases and is an essential
component of the drug development pipeline. We argue the insufficiency of
statistical and data-centric machine learning (ML) means of generating this
type of synthetic data is due to a combination of factors: perpetual data
sparsity due to the Curse of Dimensionality, the inapplicability of the Central
Limit Theorem, and the limits imposed by the Causal Hierarchy Theorem.
Alternatively, we present a rationale for using complex multi-scale
mechanism-based simulation models, constructed and operated on to account for
epistemic incompleteness and the need to provide maximal expansiveness in
concordance with the Principle of Maximal Entropy. These procedures provide for
the generation of SMMTD that minimizes the known shortcomings associated with
neural network AI systems, namely overfitting and lack of generalizability. The
generation of synthetic data that accounts for the identified factors of
multi-dimensional time series data is an essential capability for the
development of mediator-biomarker based AI forecasting systems, and therapeutic
control development and optimization through systems like Drug Development
Digital Twins.",http://arxiv.org/pdf/2303.09056v1,
Synthetic Health-related Longitudinal Data with Mixed-type Variables Generated using Diffusion Models,22/03/2023,"Nicholas I-Hsien Kuo, Louisa Jorm, Sebastiano Barbieri","This paper presents a novel approach to simulating electronic health records
(EHRs) using diffusion probabilistic models (DPMs). Specifically, we
demonstrate the effectiveness of DPMs in synthesising longitudinal EHRs that
capture mixed-type variables, including numeric, binary, and categorical
variables. To our knowledge, this represents the first use of DPMs for this
purpose. We compared our DPM-simulated datasets to previous state-of-the-art
results based on generative adversarial networks (GANs) for two clinical
applications: acute hypotension and human immunodeficiency virus (ART for HIV).
Given the lack of similar previous studies in DPMs, a core component of our
work involves exploring the advantages and caveats of employing DPMs across a
wide range of aspects. In addition to assessing the realism of the synthetic
datasets, we also trained reinforcement learning (RL) agents on the synthetic
data to evaluate their utility for supporting the development of downstream
machine learning models. Finally, we estimated that our DPM-simulated datasets
are secure and posed a low patient exposure risk for public access.",http://arxiv.org/pdf/2303.12281v1,
Anomaly Detection in Aeronautics Data with Quantum-compatible Discrete Deep Generative Model,22/03/2023,"Thomas Templin, Milad Memarzadeh, Walter Vinci, P. Aaron Lott, Ata Akbari Asanjan, Anthony Alexiades Armenakas, Eleanor Rieffel","Deep generative learning cannot only be used for generating new data with
statistical characteristics derived from input data but also for anomaly
detection, by separating nominal and anomalous instances based on their
reconstruction quality. In this paper, we explore the performance of three
unsupervised deep generative models -- variational autoencoders (VAEs) with
Gaussian, Bernoulli, and Boltzmann priors -- in detecting anomalies in
flight-operations data of commercial flights consisting of multivariate time
series. We devised two VAE models with discrete latent variables (DVAEs), one
with a factorized Bernoulli prior and one with a restricted Boltzmann machine
(RBM) as prior, because of the demand for discrete-variable models in
machine-learning applications and because the integration of quantum devices
based on two-level quantum systems requires such models. The DVAE with RBM
prior, using a relatively simple -- and classically or quantum-mechanically
enhanceable -- sampling technique for the evolution of the RBM's negative
phase, performed better than the Bernoulli DVAE and on par with the Gaussian
model, which has a continuous latent space. Our studies demonstrate the
competitiveness of a discrete deep generative model with its Gaussian
counterpart on anomaly-detection tasks. Moreover, the DVAE model with RBM prior
can be easily integrated with quantum sampling by outsourcing its generative
process to measurements of quantum states obtained from a quantum annealer or
gate-model device.",http://arxiv.org/pdf/2303.12302v1,
TSI-GAN: Unsupervised Time Series Anomaly Detection using Convolutional Cycle-Consistent Generative Adversarial Networks,22/03/2023,"Shyam Sundar Saravanan, Tie Luo, Mao Van Ngo","Anomaly detection is widely used in network intrusion detection, autonomous
driving, medical diagnosis, credit card frauds, etc. However, several key
challenges remain open, such as lack of ground truth labels, presence of
complex temporal patterns, and generalizing over different datasets. This paper
proposes TSI-GAN, an unsupervised anomaly detection model for time-series that
can learn complex temporal patterns automatically and generalize well, i.e., no
need for choosing dataset-specific parameters, making statistical assumptions
about underlying data, or changing model architectures. To achieve these goals,
we convert each input time-series into a sequence of 2D images using two
encoding techniques with the intent of capturing temporal patterns and various
types of deviance. Moreover, we design a reconstructive GAN that uses
convolutional layers in an encoder-decoder network and employs
cycle-consistency loss during training to ensure that inverse mappings are
accurate as well. In addition, we also instrument a Hodrick-Prescott filter in
post-processing to mitigate false positives. We evaluate TSI-GAN using 250
well-curated and harder-than-usual datasets and compare with 8 state-of-the-art
baseline methods. The results demonstrate the superiority of TSI-GAN to all the
baselines, offering an overall performance improvement of 13% and 31% over the
second-best performer MERLIN and the third-best performer LSTM-AE,
respectively.",http://arxiv.org/pdf/2303.12952v1,
Variational Inference for Longitudinal Data Using Normalizing Flows,24/03/2023,"Clément Chadebec, Stéphanie Allassonnière","This paper introduces a new latent variable generative model able to handle
high dimensional longitudinal data and relying on variational inference. The
time dependency between the observations of an input sequence is modelled using
normalizing flows over the associated latent variables. The proposed method can
be used to generate either fully synthetic longitudinal sequences or
trajectories that are conditioned on several data in a sequence and
demonstrates good robustness properties to missing data. We test the model on 6
datasets of different complexity and show that it can achieve better likelihood
estimates than some competitors as well as more reliable missing data
imputation. A code is made available at
\url{https://github.com/clementchadebec/variational_inference_for_longitudinal_data}.",http://arxiv.org/pdf/2303.14220v1,
The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers,27/03/2023,"Valentin Macé, Raphaël Boige, Felix Chalumeau, Thomas Pierrot, Guillaume Richard, Nicolas Perrin-Gilbert","In the context of neuroevolution, Quality-Diversity algorithms have proven
effective in generating repertoires of diverse and efficient policies by
relying on the definition of a behavior space. A natural goal induced by the
creation of such a repertoire is trying to achieve behaviors on demand, which
can be done by running the corresponding policy from the repertoire. However,
in uncertain environments, two problems arise. First, policies can lack
robustness and repeatability, meaning that multiple episodes under slightly
different conditions often result in very different behaviors. Second, due to
the discrete nature of the repertoire, solutions vary discontinuously. Here we
present a new approach to achieve behavior-conditioned trajectory generation
based on two mechanisms: First, MAP-Elites Low-Spread (ME-LS), which constrains
the selection of solutions to those that are the most consistent in the
behavior space. Second, the Quality-Diversity Transformer (QDT), a
Transformer-based model conditioned on continuous behavior descriptors, which
trains on a dataset generated by policies from a ME-LS repertoire and learns to
autoregressively generate sequences of actions that achieve target behaviors.
Results show that ME-LS produces consistent and robust policies, and that its
combination with the QDT yields a single policy capable of achieving diverse
behaviors on demand with high accuracy.",http://arxiv.org/pdf/2303.16207v3,10.1145/3583131.3590433
From Private to Public: Benchmarking GANs in the Context of Private Time Series Classification,28/03/2023,"Dominique Mercier, Andreas Dengel, Sheraz Ahmed","Deep learning has proven to be successful in various domains and for
different tasks. However, when it comes to private data several restrictions
are making it difficult to use deep learning approaches in these application
fields. Recent approaches try to generate data privately instead of applying a
privacy-preserving mechanism directly, on top of the classifier. The solution
is to create public data from private data in a manner that preserves the
privacy of the data. In this work, two very prominent GAN-based architectures
were evaluated in the context of private time series classification. In
contrast to previous work, mostly limited to the image domain, the scope of
this benchmark was the time series domain. The experiments show that especially
GSWGAN performs well across a variety of public datasets outperforming the
competitor DPWGAN. An analysis of the generated datasets further validates the
superiority of GSWGAN in the context of time series generation.",http://arxiv.org/pdf/2303.15916v2,10.1007/s10489-024-05671-z
Predictive Context-Awareness for Full-Immersive Multiuser Virtual Reality with Redirected Walking,31/03/2023,"Filip Lemic, Jakob Struye, Thomas Van Onsem, Jeroen Famaey, Xavier Costa Perez","The advancement of Virtual Reality (VR) technology is focused on improving
its immersiveness, supporting multiuser Virtual Experiences (VEs), and enabling
users to move freely within their VEs while remaining confined to specialized
VR setups through Redirected Walking (RDW). To meet their extreme data-rate and
latency requirements, future VR systems will require supporting wireless
networking infrastructures operating in millimeter Wave (mmWave) frequencies
that leverage highly directional communication in both transmission and
reception through beamforming and beamsteering. We propose the use of
predictive context-awareness to optimize transmitter and receiver-side
beamforming and beamsteering. By predicting users' short-term lateral movements
in multiuser VR setups with Redirected Walking (RDW), transmitter-side
beamforming and beamsteering can be optimized through Line-of-Sight (LoS)
""tracking"" in the users' directions. At the same time, predictions of
short-term orientational movements can be utilized for receiver-side
beamforming for coverage flexibility enhancements. We target two open problems
in predicting these two context information instances: i) predicting lateral
movements in multiuser VR settings with RDW, and ii) generating synthetic head
rotation datasets for training orientational movements predictors. Our
experimental results demonstrate that Long Short-Term Memory (LSTM) networks
feature promising accuracy in predicting lateral movements, and
context-awareness stemming from VEs further enhances this accuracy.
Additionally, we show that a TimeGAN-based approach for orientational data
generation can create synthetic samples that closely match experimentally
obtained ones.",http://arxiv.org/pdf/2303.17907v4,
Controllable Motion Synthesis and Reconstruction with Autoregressive Diffusion Models,03/04/2023,"Wenjie Yin, Ruibo Tu, Hang Yin, Danica Kragic, Hedvig Kjellström, Mårten Björkman","Data-driven and controllable human motion synthesis and prediction are active
research areas with various applications in interactive media and social
robotics. Challenges remain in these fields for generating diverse motions
given past observations and dealing with imperfect poses. This paper introduces
MoDiff, an autoregressive probabilistic diffusion model over motion sequences
conditioned on control contexts of other modalities. Our model integrates a
cross-modal Transformer encoder and a Transformer-based decoder, which are
found effective in capturing temporal correlations in motion and control
modalities. We also introduce a new data dropout method based on the diffusion
forward process to provide richer data representations and robust generation.
We demonstrate the superior performance of MoDiff in controllable motion
synthesis for locomotion with respect to two baselines and show the benefits of
diffusion data dropout for robust synthesis and reconstruction of high-fidelity
motion close to recorded data.",http://arxiv.org/pdf/2304.04681v1,
ChiroDiff: Modelling chirographic data with Diffusion Models,07/04/2023,"Ayan Das, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yi-Zhe Song","Generative modelling over continuous-time geometric constructs, a.k.a such as
handwriting, sketches, drawings etc., have been accomplished through
autoregressive distributions. Such strictly-ordered discrete factorization
however falls short of capturing key properties of chirographic data -- it
fails to build holistic understanding of the temporal concept due to one-way
visibility (causality). Consequently, temporal data has been modelled as
discrete token sequences of fixed sampling rate instead of capturing the true
underlying concept. In this paper, we introduce a powerful model-class namely
""Denoising Diffusion Probabilistic Models"" or DDPMs for chirographic data that
specifically addresses these flaws. Our model named ""ChiroDiff"", being
non-autoregressive, learns to capture holistic concepts and therefore remains
resilient to higher temporal sampling rate up to a good extent. Moreover, we
show that many important downstream utilities (e.g. conditional sampling,
creative mixing) can be flexibly implemented using ChiroDiff. We further show
some unique use-cases like stochastic vectorization, de-noising/healing,
abstraction are also possible with this model-class. We perform quantitative
and qualitative evaluation of our framework on relevant datasets and found it
to be better or on par with competing approaches.",http://arxiv.org/pdf/2304.03785v1,
Generative modeling for time series via Schr{ö}dinger bridge,11/04/2023,"Mohamed Hamdouche, Pierre Henry-Labordere, Huyên Pham","We propose a novel generative model for time series based on Schr{\""o}dinger
bridge (SB) approach. This consists in the entropic interpolation via optimal
transport between a reference probability measure on path space and a target
measure consistent with the joint data distribution of the time series. The
solution is characterized by a stochastic differential equation on finite
horizon with a path-dependent drift function, hence respecting the temporal
dynamics of the time series distribution. We can estimate the drift function
from data samples either by kernel regression methods or with LSTM neural
networks, and the simulation of the SB diffusion yields new synthetic data
samples of the time series. The performance of our generative model is
evaluated through a series of numerical experiments. First, we test with a toy
autoregressive model, a GARCH Model, and the example of fractional Brownian
motion, and measure the accuracy of our algorithm with marginal and temporal
dependencies metrics. Next, we use our SB generated synthetic samples for the
application to deep hedging on real-data sets. Finally, we illustrate the SB
approach for generating sequence of images.",http://arxiv.org/pdf/2304.05093v1,
Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models,18/04/2023,"Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, Karsten Kreis","Latent Diffusion Models (LDMs) enable high-quality image synthesis while
avoiding excessive compute demands by training a diffusion model in a
compressed lower-dimensional latent space. Here, we apply the LDM paradigm to
high-resolution video generation, a particularly resource-intensive task. We
first pre-train an LDM on images only; then, we turn the image generator into a
video generator by introducing a temporal dimension to the latent space
diffusion model and fine-tuning on encoded image sequences, i.e., videos.
Similarly, we temporally align diffusion model upsamplers, turning them into
temporally consistent video super resolution models. We focus on two relevant
real-world applications: Simulation of in-the-wild driving data and creative
content creation with text-to-video modeling. In particular, we validate our
Video LDM on real driving videos of resolution 512 x 1024, achieving
state-of-the-art performance. Furthermore, our approach can easily leverage
off-the-shelf pre-trained image LDMs, as we only need to train a temporal
alignment model in that case. Doing so, we turn the publicly available,
state-of-the-art text-to-image LDM Stable Diffusion into an efficient and
expressive text-to-video model with resolution up to 1280 x 2048. We show that
the temporal layers trained in this way generalize to different fine-tuned
text-to-image LDMs. Utilizing this property, we show the first results for
personalized text-to-video generation, opening exciting directions for future
content creation. Project page:
https://research.nvidia.com/labs/toronto-ai/VideoLDM/",http://arxiv.org/pdf/2304.08818v2,
Martingale Posterior Neural Processes,19/04/2023,"Hyungi Lee, Eunggu Yun, Giung Nam, Edwin Fong, Juho Lee","A Neural Process (NP) estimates a stochastic process implicitly defined with
neural networks given a stream of data, rather than pre-specifying priors
already known, such as Gaussian processes. An ideal NP would learn everything
from data without any inductive biases, but in practice, we often restrict the
class of stochastic processes for the ease of estimation. One such restriction
is the use of a finite-dimensional latent variable accounting for the
uncertainty in the functions drawn from NPs. Some recent works show that this
can be improved with more ""data-driven"" source of uncertainty such as
bootstrapping. In this work, we take a different approach based on the
martingale posterior, a recently developed alternative to Bayesian inference.
For the martingale posterior, instead of specifying prior-likelihood pairs, a
predictive distribution for future data is specified. Under specific conditions
on the predictive distribution, it can be shown that the uncertainty in the
generated future data actually corresponds to the uncertainty of the implicitly
defined Bayesian posteriors. Based on this result, instead of assuming any form
of the latent variables, we equip a NP with a predictive distribution
implicitly defined with neural networks and use the corresponding martingale
posteriors as the source of uncertainty. The resulting model, which we name as
Martingale Posterior Neural Process (MPNP), is demonstrated to outperform
baselines on various tasks.",http://arxiv.org/pdf/2304.09431v1,
BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis,21/04/2023,"Angela Castillo, Maria Escobar, Guillaume Jeanneret, Albert Pumarola, Pablo Arbeláez, Ali Thabet, Artsiom Sanakoyeu","Mixed reality applications require tracking the user's full-body motion to
enable an immersive experience. However, typical head-mounted devices can only
track head and hand movements, leading to a limited reconstruction of full-body
motion due to variability in lower body configurations. We propose BoDiffusion
-- a generative diffusion model for motion synthesis to tackle this
under-constrained reconstruction problem. We present a time and space
conditioning scheme that allows BoDiffusion to leverage sparse tracking inputs
while generating smooth and realistic full-body motion sequences. To the best
of our knowledge, this is the first approach that uses the reverse diffusion
process to model full-body tracking as a conditional sequence generation task.
We conduct experiments on the large-scale motion-capture dataset AMASS and show
that our approach outperforms the state-of-the-art approaches by a significant
margin in terms of full-body motion realism and joint reconstruction error.",http://arxiv.org/pdf/2304.11118v1,
Conditional Denoising Diffusion for Sequential Recommendation,22/04/2023,"Yu Wang, Zhiwei Liu, Liangwei Yang, Philip S. Yu","Generative models have attracted significant interest due to their ability to
handle uncertainty by learning the inherent data distributions. However, two
prominent generative models, namely Generative Adversarial Networks (GANs) and
Variational AutoEncoders (VAEs), exhibit challenges that impede achieving
optimal performance in sequential recommendation tasks. Specifically, GANs
suffer from unstable optimization, while VAEs are prone to posterior collapse
and over-smoothed generations. The sparse and noisy nature of sequential
recommendation further exacerbates these issues. In response to these
limitations, we present a conditional denoising diffusion model, which includes
a sequence encoder, a cross-attentive denoising decoder, and a step-wise
diffuser. This approach streamlines the optimization and generation process by
dividing it into easier and tractable steps in a conditional autoregressive
manner. Furthermore, we introduce a novel optimization schema that incorporates
both cross-divergence loss and contrastive loss. This novel training schema
enables the model to generate high-quality sequence/item representations and
meanwhile precluding collapse. We conducted comprehensive experiments on four
benchmark datasets, and the superior performance achieved by our model attests
to its efficacy.",http://arxiv.org/pdf/2304.11433v1,
DiffESM: Conditional Emulation of Earth System Models with Diffusion Models,23/04/2023,"Seth Bassetti, Brian Hutchinson, Claudia Tebaldi, Ben Kravitz","Earth System Models (ESMs) are essential tools for understanding the impact
of human actions on Earth's climate. One key application of these models is
studying extreme weather events, such as heat waves or dry spells, which have
significant socioeconomic and environmental consequences. However, the
computational demands of running a sufficient number of simulations to analyze
the risks are often prohibitive. In this paper we demonstrate that diffusion
models -- a class of generative deep learning models -- can effectively emulate
the spatio-temporal trends of ESMs under previously unseen climate scenarios,
while only requiring a small fraction of the computational resources. We
present a diffusion model that is conditioned on monthly averages of
temperature or precipitation on a $96 \times 96$ global grid, and produces
daily values that are both realistic and consistent with those averages. Our
results show that the output from our diffusion model closely matches the
spatio-temporal behavior of the ESM it emulates in terms of the frequency of
phenomena such as heat waves, dry spells, or rainfall intensity.",http://arxiv.org/pdf/2304.11699v1,
Controlled physics-informed data generation for deep learning-based remaining useful life prediction under unseen operation conditions,23/04/2023,"Jiawei Xiong, Olga Fink, Jian Zhou, Yizhong Ma","Limited availability of representative time-to-failure (TTF) trajectories
either limits the performance of deep learning (DL)-based approaches on
remaining useful life (RUL) prediction in practice or even precludes their
application. Generating synthetic data that is physically plausible is a
promising way to tackle this challenge. In this study, a novel hybrid framework
combining the controlled physics-informed data generation approach with a deep
learning-based prediction model for prognostics is proposed. In the proposed
framework, a new controlled physics-informed generative adversarial network
(CPI-GAN) is developed to generate synthetic degradation trajectories that are
physically interpretable and diverse. Five basic physics constraints are
proposed as the controllable settings in the generator. A physics-informed loss
function with penalty is designed as the regularization term, which ensures
that the changing trend of system health state recorded in the synthetic data
is consistent with the underlying physical laws. Then, the generated synthetic
data is used as input of the DL-based prediction model to obtain the RUL
estimations. The proposed framework is evaluated based on new Commercial
Modular Aero-Propulsion System Simulation (N-CMAPSS), a turbofan engine
prognostics dataset where a limited avail-ability of TTF trajectories is
assumed. The experimental results demonstrate that the proposed framework is
able to generate synthetic TTF trajectories that are consistent with underlying
degradation trends. The generated trajectories enable to significantly improve
the accuracy of RUL predictions.",http://arxiv.org/pdf/2304.11702v2,10.1016/j.ymssp.2023.110359
Directed Chain Generative Adversarial Networks,25/04/2023,"Ming Min, Ruimeng Hu, Tomoyuki Ichiba","Real-world data can be multimodal distributed, e.g., data describing the
opinion divergence in a community, the interspike interval distribution of
neurons, and the oscillators natural frequencies. Generating multimodal
distributed real-world data has become a challenge to existing generative
adversarial networks (GANs). For example, neural stochastic differential
equations (Neural SDEs), treated as infinite-dimensional GANs, have
demonstrated successful performance mainly in generating unimodal time series
data. In this paper, we propose a novel time series generator, named directed
chain GANs (DC-GANs), which inserts a time series dataset (called a
neighborhood process of the directed chain or input) into the drift and
diffusion coefficients of the directed chain SDEs with distributional
constraints. DC-GANs can generate new time series of the same distribution as
the neighborhood process, and the neighborhood process will provide the key
step in learning and generating multimodal distributed time series. The
proposed DC-GANs are examined on four datasets, including two stochastic models
from social sciences and computational neuroscience, and two real-world
datasets on stock prices and energy consumption. To our best knowledge, DC-GANs
are the first work that can generate multimodal time series data and
consistently outperforms state-of-the-art benchmarks with respect to measures
of distribution, data similarity, and predictive ability.",http://arxiv.org/pdf/2304.13131v2,
Diffusion Models for Time Series Applications: A Survey,01/05/2023,"Lequan Lin, Zhengkun Li, Ruikun Li, Xuliang Li, Junbin Gao","Diffusion models, a family of generative models based on deep learning, have
become increasingly prominent in cutting-edge machine learning research. With a
distinguished performance in generating samples that resemble the observed
data, diffusion models are widely used in image, video, and text synthesis
nowadays. In recent years, the concept of diffusion has been extended to time
series applications, and many powerful models have been developed. Considering
the deficiency of a methodical summary and discourse on these models, we
provide this survey as an elementary resource for new researchers in this area
and also an inspiration to motivate future research. For better understanding,
we include an introduction about the basics of diffusion models. Except for
this, we primarily focus on diffusion-based methods for time series
forecasting, imputation, and generation, and present them respectively in three
individual sections. We also compare different methods for the same application
and highlight their connections if applicable. Lastly, we conclude the common
limitation of diffusion-based methods and highlight potential future research
directions.",http://arxiv.org/pdf/2305.00624v1,
IoTFlowGenerator: Crafting Synthetic IoT Device Traffic Flows for Cyber Deception,01/05/2023,"Joseph Bao, Murat Kantarcioglu, Yevgeniy Vorobeychik, Charles Kamhoua","Over the years, honeypots emerged as an important security tool to understand
attacker intent and deceive attackers to spend time and resources. Recently,
honeypots are being deployed for Internet of things (IoT) devices to lure
attackers, and learn their behavior. However, most of the existing IoT
honeypots, even the high interaction ones, are easily detected by an attacker
who can observe honeypot traffic due to lack of real network traffic
originating from the honeypot. This implies that, to build better honeypots and
enhance cyber deception capabilities, IoT honeypots need to generate realistic
network traffic flows. To achieve this goal, we propose a novel deep learning
based approach for generating traffic flows that mimic real network traffic due
to user and IoT device interactions. A key technical challenge that our
approach overcomes is scarcity of device-specific IoT traffic data to
effectively train a generator. We address this challenge by leveraging a core
generative adversarial learning algorithm for sequences along with domain
specific knowledge common to IoT devices. Through an extensive experimental
evaluation with 18 IoT devices, we demonstrate that the proposed synthetic IoT
traffic generation tool significantly outperforms state of the art sequence and
packet generators in remaining indistinguishable from real traffic even to an
adaptive attacker.",http://arxiv.org/pdf/2305.00925v1,
AQ-GT: a Temporally Aligned and Quantized GRU-Transformer for Co-Speech Gesture Synthesis,02/05/2023,"Hendric Voß, Stefan Kopp","The generation of realistic and contextually relevant co-speech gestures is a
challenging yet increasingly important task in the creation of multimodal
artificial agents. Prior methods focused on learning a direct correspondence
between co-speech gesture representations and produced motions, which created
seemingly natural but often unconvincing gestures during human assessment. We
present an approach to pre-train partial gesture sequences using a generative
adversarial network with a quantization pipeline. The resulting codebook
vectors serve as both input and output in our framework, forming the basis for
the generation and reconstruction of gestures. By learning the mapping of a
latent space representation as opposed to directly mapping it to a vector
representation, this framework facilitates the generation of highly realistic
and expressive gestures that closely replicate human movement and behavior,
while simultaneously avoiding artifacts in the generation process. We evaluate
our approach by comparing it with established methods for generating co-speech
gestures as well as with existing datasets of human behavior. We also perform
an ablation study to assess our findings. The results show that our approach
outperforms the current state of the art by a clear margin and is partially
indistinguishable from human gesturing. We make our data pipeline and the
generation framework publicly available.",http://arxiv.org/pdf/2305.01241v2,
Copula Variational LSTM for High-dimensional Cross-market Multivariate Dependence Modeling,09/05/2023,"Jia Xu, Longbing Cao","We address an important yet challenging problem - modeling high-dimensional
dependencies across multivariates such as financial indicators in heterogeneous
markets. In reality, a market couples and influences others over time, and the
financial variables of a market are also coupled. We make the first attempt to
integrate variational sequential neural learning with copula-based dependence
modeling to characterize both temporal observable and latent variable-based
dependence degrees and structures across non-normal multivariates. Our
variational neural network WPVC-VLSTM models variational sequential dependence
degrees and structures across multivariate time series by variational long
short-term memory networks and regular vine copula. The regular vine copula
models nonnormal and long-range distributional couplings across multiple
dynamic variables. WPVC-VLSTM is verified in terms of both technical
significance and portfolio forecasting performance. It outperforms benchmarks
including linear models, stochastic volatility models, deep neural networks,
and variational recurrent networks in cross-market portfolio forecasting.",http://arxiv.org/pdf/2305.08778v1,
IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers,11/05/2023,"Jingge Xiao, Leonie Basso, Wolfgang Nejdl, Niloy Ganguly, Sandipan Sikdar","Continuous-time models such as Neural ODEs and Neural Flows have shown
promising results in analyzing irregularly sampled time series frequently
encountered in electronic health records. Based on these models, time series
are typically processed with a hybrid of an initial value problem (IVP) solver
and a recurrent neural network within the variational autoencoder architecture.
Sequentially solving IVPs makes such models computationally less efficient. In
this paper, we propose to model time series purely with continuous processes
whose state evolution can be approximated directly by IVPs. This eliminates the
need for recurrent computation and enables multiple states to evolve in
parallel. We further fuse the encoder and decoder with one IVP solver utilizing
its invertibility, which leads to fewer parameters and faster convergence.
Experiments on three real-world datasets show that the proposed method can
systematically outperform its predecessors, achieve state-of-the-art results,
and have significant advantages in terms of data efficiency.",http://arxiv.org/pdf/2305.06741v3,
Provably Convergent Schrödinger Bridge with Applications to Probabilistic Time Series Imputation,12/05/2023,"Yu Chen, Wei Deng, Shikai Fang, Fengpei Li, Nicole Tianjiao Yang, Yikai Zhang, Kashif Rasul, Shandian Zhe, Anderson Schneider, Yuriy Nevmyvaka","The Schr\""odinger bridge problem (SBP) is gaining increasing attention in
generative modeling and showing promising potential even in comparison with the
score-based generative models (SGMs). SBP can be interpreted as an
entropy-regularized optimal transport problem, which conducts projections onto
every other marginal alternatingly. However, in practice, only approximated
projections are accessible and their convergence is not well understood. To
fill this gap, we present a first convergence analysis of the Schr\""odinger
bridge algorithm based on approximated projections. As for its practical
applications, we apply SBP to probabilistic time series imputation by
generating missing values conditioned on observed data. We show that optimizing
the transport cost improves the performance and the proposed algorithm achieves
the state-of-the-art result in healthcare and environmental data while
exhibiting the advantage of exploring both temporal and feature patterns in
probabilistic time series imputation.",http://arxiv.org/pdf/2305.07247v4,
Latent Processes Identification From Multi-View Time Series,14/05/2023,"Zenan Huang, Haobo Wang, Junbo Zhao, Nenggan Zheng","Understanding the dynamics of time series data typically requires identifying
the unique latent factors for data generation, \textit{a.k.a.}, latent
processes identification. Driven by the independent assumption, existing works
have made great progress in handling single-view data. However, it is a
non-trivial problem that extends them to multi-view time series data because of
two main challenges: (i) the complex data structure, such as temporal
dependency, can result in violation of the independent assumption; (ii) the
factors from different views are generally overlapped and are hard to be
aggregated to a complete set. In this work, we propose a novel framework MuLTI
that employs the contrastive learning technique to invert the data generative
process for enhanced identifiability. Additionally, MuLTI integrates a
permutation mechanism that merges corresponding overlapped variables by the
establishment of an optimal transport formula. Extensive experimental results
on synthetic and real-world datasets demonstrate the superiority of our method
in recovering identifiable latent variables on multi-view time series.",http://arxiv.org/pdf/2305.08164v1,
Smart Home Energy Management: VAE-GAN synthetic dataset generator and Q-learning,14/05/2023,"Mina Razghandi, Hao Zhou, Melike Erol-Kantarci, Damla Turgut","Recent years have noticed an increasing interest among academia and industry
towards analyzing the electrical consumption of residential buildings and
employing smart home energy management systems (HEMS) to reduce household
energy consumption and costs. HEMS has been developed to simulate the
statistical and functional properties of actual smart grids. Access to publicly
available datasets is a major challenge in this type of research. The potential
of artificial HEMS applications will be further enhanced with the development
of time series that represent different operating conditions of the synthetic
systems. In this paper, we propose a novel variational auto-encoder-generative
adversarial network (VAE-GAN) technique for generating time-series data on
energy consumption in smart homes. We also explore how the generative model
performs when combined with a Q-learning-based HEMS. We tested the online
performance of Q-learning-based HEMS with real-world smart home data. To test
the generated dataset, we measure the Kullback-Leibler (KL) divergence, maximum
mean discrepancy (MMD), and the Wasserstein distance between the probability
distributions of the real and synthetic data. Our experiments show that
VAE-GAN-generated synthetic data closely matches the real data distribution.
Finally, we show that the generated data allows for the training of a
higher-performance Q-learning-based HEMS compared to datasets generated with
baseline approaches.",http://arxiv.org/pdf/2305.08885v1,
Generative Model-based Simulation of Driver Behavior when Using Control Input Interface for Teleoperated Driving in Unstructured Canyon Terrains,17/05/2023,"Hyeonggeun Yun, Younggeol Cho, Jinwon Lee, Arim Ha, Jihyeok Yun","Unmanned ground vehicles (UGVs) in unstructured environments mostly operate
through teleoperation. To enable stable teleoperated driving in unstructured
environments, some research has suggested driver assistance and evaluation
methods that involve user studies, which can be costly and require lots of time
and effort. A simulation model-based approach has been proposed to complement
the user study; however, the models on teleoperated driving do not account for
unstructured environments. Our proposed solution involves simulation models of
teleoperated driving for drivers that utilize a deep generative model.
Initially, we build a teleoperated driving simulator to imitate unstructured
environments based on previous research and collect driving data from drivers.
Then, we design and implement the simulation models based on a conditional
variational autoencoder (CVAE). Our evaluation results demonstrate that the
proposed teleoperated driving model can generate data by simulating the driver
appropriately in unstructured canyon terrains.",http://arxiv.org/pdf/2305.09874v1,
Dirichlet Diffusion Score Model for Biological Sequence Generation,18/05/2023,"Pavel Avdeyev, Chenlai Shi, Yuhao Tan, Kseniia Dudnyk, Jian Zhou","Designing biological sequences is an important challenge that requires
satisfying complex constraints and thus is a natural problem to address with
deep generative modeling. Diffusion generative models have achieved
considerable success in many applications. Score-based generative stochastic
differential equations (SDE) model is a continuous-time diffusion model
framework that enjoys many benefits, but the originally proposed SDEs are not
naturally designed for modeling discrete data. To develop generative SDE models
for discrete data such as biological sequences, here we introduce a diffusion
process defined in the probability simplex space with stationary distribution
being the Dirichlet distribution. This makes diffusion in continuous space
natural for modeling discrete data. We refer to this approach as Dirchlet
diffusion score model. We demonstrate that this technique can generate samples
that satisfy hard constraints using a Sudoku generation task. This generative
model can also solve Sudoku, including hard puzzles, without additional
training. Finally, we applied this approach to develop the first human promoter
DNA sequence design model and showed that designed sequences share similar
properties with natural promoter sequences.",http://arxiv.org/pdf/2305.10699v2,
TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series,19/05/2023,"Alexander Nikitin, Letizia Iannucci, Samuel Kaski","Temporally indexed data are essential in a wide range of fields and of
interest to machine learning researchers. Time series data, however, are often
scarce or highly sensitive, which precludes the sharing of data between
researchers and industrial organizations and the application of existing and
new data-intensive ML methods. A possible solution to this bottleneck is to
generate synthetic data. In this work, we introduce Time Series Generative
Modeling (TSGM), an open-source framework for the generative modeling of
synthetic time series. TSGM includes a broad repertoire of machine learning
methods: generative models, probabilistic, and simulator-based approaches. The
framework enables users to evaluate the quality of the produced data from
different angles: similarity, downstream effectiveness, predictive consistency,
diversity, and privacy. The framework is extensible, which allows researchers
to rapidly implement their own methods and compare them in a shareable
environment. TSGM was tested on open datasets and in production and proved to
be beneficial in both cases. Additionally to the library, the project allows
users to employ command line interfaces for synthetic data generation which
lowers the entry threshold for those without a programming background.",http://arxiv.org/pdf/2305.11567v2,
PCF-GAN: generating sequential data via the characteristic function of measures on the path space,21/05/2023,"Hang Lou, Siran Li, Hao Ni","Generating high-fidelity time series data using generative adversarial
networks (GANs) remains a challenging task, as it is difficult to capture the
temporal dependence of joint probability distributions induced by time-series
data. Towards this goal, a key step is the development of an effective
discriminator to distinguish between time series distributions. We propose the
so-called PCF-GAN, a novel GAN that incorporates the path characteristic
function (PCF) as the principled representation of time series distribution
into the discriminator to enhance its generative performance. On the one hand,
we establish theoretical foundations of the PCF distance by proving its
characteristicity, boundedness, differentiability with respect to generator
parameters, and weak continuity, which ensure the stability and feasibility of
training the PCF-GAN. On the other hand, we design efficient initialisation and
optimisation schemes for PCFs to strengthen the discriminative power and
accelerate training efficiency. To further boost the capabilities of complex
time series generation, we integrate the auto-encoder structure via sequential
embedding into the PCF-GAN, which provides additional reconstruction
functionality. Extensive numerical experiments on various datasets demonstrate
the consistently superior performance of PCF-GAN over state-of-the-art
baselines, in both generation and reconstruction quality. Code is available at
https://github.com/DeepIntoStreams/PCF-GAN.",http://arxiv.org/pdf/2305.12511v2,
CoMusion: Towards Consistent Stochastic Human Motion Prediction via Motion Diffusion,21/05/2023,"Jiarui Sun, Girish Chowdhary","Stochastic Human Motion Prediction (HMP) aims to predict multiple possible
future human pose sequences from observed ones. Most prior works learn motion
distributions through encoding-decoding in the latent space, which does not
preserve motion's spatial-temporal structure. While effective, these methods
often require complex, multi-stage training and yield predictions that are
inconsistent with the provided history and can be physically unrealistic. To
address these issues, we propose CoMusion, a single-stage, end-to-end
diffusion-based stochastic HMP framework. CoMusion is inspired from the insight
that a smooth future pose initialization improves prediction performance, a
strategy not previously utilized in stochastic models but evidenced in
deterministic works. To generate such initialization, CoMusion's motion
predictor starts with a Transformer-based network for initial reconstruction of
corrupted motion. Then, a graph convolutional network (GCN) is employed to
refine the prediction considering past observations in the discrete cosine
transformation (DCT) space. Our method, facilitated by the Transformer-GCN
module design and a proposed variance scheduler, excels in predicting accurate,
realistic, and consistent motions, while maintaining appropriate diversity.
Experimental results on benchmark datasets demonstrate that CoMusion surpasses
prior methods across metrics, while demonstrating superior generation quality.
Our Code is released at https://github.com/jsun57/CoMusion/ .",http://arxiv.org/pdf/2305.12554v3,
Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes,21/05/2023,"Zheng Dong, Zekai Fan, Shixiang Zhu","Point processes offer a versatile framework for sequential event modeling.
However, the computational challenges and constrained representational power of
the existing point process models have impeded their potential for wider
applications. This limitation becomes especially pronounced when dealing with
event data that is associated with multi-dimensional or high-dimensional marks
such as texts or images. To address this challenge, this study proposes a novel
event-generation framework for modeling point processes with high-dimensional
marks. We aim to capture the distribution of events without explicitly
specifying the conditional intensity or probability density function. Instead,
we use a conditional generator that takes the history of events as input and
generates the high-quality subsequent event that is likely to occur given the
prior observations. The proposed framework offers a host of benefits, including
considerable representational power to capture intricate dynamics in multi- or
even high-dimensional event space, as well as exceptional efficiency in
learning the model and generating samples. Our numerical results demonstrate
superior performance compared to other state-of-the-art baselines.",http://arxiv.org/pdf/2305.12569v3,
Sample and Predict Your Latent: Modality-free Sequential Disentanglement via Contrastive Estimation,25/05/2023,"Ilan Naiman, Nimrod Berman, Omri Azencot","Unsupervised disentanglement is a long-standing challenge in representation
learning. Recently, self-supervised techniques achieved impressive results in
the sequential setting, where data is time-dependent. However, the latter
methods employ modality-based data augmentations and random sampling or solve
auxiliary tasks. In this work, we propose to avoid that by generating,
sampling, and comparing empirical distributions from the underlying variational
model. Unlike existing work, we introduce a self-supervised sequential
disentanglement framework based on contrastive estimation with no external
signals, while using common batch sizes and samples from the latent space
itself. In practice, we propose a unified, efficient, and easy-to-code sampling
strategy for semantically similar and dissimilar views of the data. We evaluate
our approach on video, audio, and time series benchmarks. Our method presents
state-of-the-art results in comparison to existing techniques. The code is
available at https://github.com/azencot-group/SPYL.",http://arxiv.org/pdf/2305.15924v1,
Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders,25/05/2023,"Ali Siahkoohi, Rudy Morel, Randall Balestriero, Erwan Allys, Grégory Sainton, Taichi Kawamura, Maarten V. de Hoop","Unsupervised source separation involves unraveling an unknown set of source
signals recorded through a mixing operator, with limited prior knowledge about
the sources, and only access to a dataset of signal mixtures. This problem is
inherently ill-posed and is further challenged by the variety of timescales
exhibited by sources in time series data from planetary space missions. As
such, a systematic multi-scale unsupervised approach is needed to identify and
separate sources at different timescales. Existing methods typically rely on a
preselected window size that determines their operating timescale, limiting
their capacity to handle multi-scale sources. To address this issue, we propose
an unsupervised multi-scale clustering and source separation framework by
leveraging wavelet scattering spectra that provide a low-dimensional
representation of stochastic processes, capable of distinguishing between
different non-Gaussian stochastic processes. Nested within this representation
space, we develop a factorial variational autoencoder that is trained to
probabilistically cluster sources at different timescales. To perform source
separation, we use samples from clusters at multiple timescales obtained via
the factorial variational autoencoder as prior information and formulate an
optimization problem in the wavelet scattering spectra representation space.
When applied to the entire seismic dataset recorded during the NASA InSight
mission on Mars, containing sources varying greatly in timescale, our approach
disentangles such different sources, e.g., minute-long transient one-sided
pulses (known as ""glitches"") and structured ambient noises resulting from
atmospheric activities that typically last for tens of minutes, and provides an
opportunity to conduct further investigations into the isolated sources.",http://arxiv.org/pdf/2305.16189v4,
Non-adversarial training of Neural SDEs with signature kernel scores,25/05/2023,"Zacharia Issa, Blanka Horvath, Maud Lemercier, Cristopher Salvi","Neural SDEs are continuous-time generative models for sequential data.
State-of-the-art performance for irregular time series generation has been
previously obtained by training these models adversarially as GANs. However, as
typical for GAN architectures, training is notoriously unstable, often suffers
from mode collapse, and requires specialised techniques such as weight clipping
and gradient penalty to mitigate these issues. In this paper, we introduce a
novel class of scoring rules on pathspace based on signature kernels and use
them as objective for training Neural SDEs non-adversarially. By showing strict
properness of such kernel scores and consistency of the corresponding
estimators, we provide existence and uniqueness guarantees for the minimiser.
With this formulation, evaluating the generator-discriminator pair amounts to
solving a system of linear path-dependent PDEs which allows for
memory-efficient adjoint-based backpropagation. Moreover, because the proposed
kernel scores are well-defined for paths with values in infinite dimensional
spaces of functions, our framework can be easily extended to generate
spatiotemporal data. Our procedure permits conditioning on a rich variety of
market conditions and significantly outperforms alternative ways of training
Neural SDEs on a variety of tasks including the simulation of rough volatility
models, the conditional probabilistic forecasts of real-world forex pairs where
the conditioning variable is an observed past trajectory, and the mesh-free
generation of limit order book dynamics.",http://arxiv.org/pdf/2305.16274v1,
Revisiting Structured Variational Autoencoders,25/05/2023,"Yixiu Zhao, Scott W. Linderman","Structured variational autoencoders (SVAEs) combine probabilistic graphical
model priors on latent variables, deep neural networks to link latent variables
to observed data, and structure-exploiting algorithms for approximate posterior
inference. These models are particularly appealing for sequential data, where
the prior can capture temporal dependencies. However, despite their conceptual
elegance, SVAEs have proven difficult to implement, and more general approaches
have been favored in practice. Here, we revisit SVAEs using modern machine
learning tools and demonstrate their advantages over more general alternatives
in terms of both accuracy and efficiency. First, we develop a modern
implementation for hardware acceleration, parallelization, and automatic
differentiation of the message passing algorithms at the core of the SVAE.
Second, we show that by exploiting structure in the prior, the SVAE learns more
accurate models and posterior distributions, which translate into improved
performance on prediction tasks. Third, we show how the SVAE can naturally
handle missing data, and we leverage this ability to develop a novel,
self-supervised training approach. Altogether, these results show that the time
is ripe to revisit structured variational autoencoders.",http://arxiv.org/pdf/2305.16543v1,
Evaluating generation of chaotic time series by convolutional generative adversarial networks,26/05/2023,"Yuki Tanaka, Yutaka Yamaguti","To understand the ability and limitations of convolutional neural networks to
generate time series that mimic complex temporal signals, we trained a
generative adversarial network consisting of deep convolutional networks to
generate chaotic time series and used nonlinear time series analysis to
evaluate the generated time series. A numerical measure of determinism and the
Lyapunov exponent, a measure of trajectory instability, showed that the
generated time series well reproduce the chaotic properties of the original
time series. However, error distribution analyses showed that large errors
appeared at a low but non-negligible rate. Such errors would not be expected if
the distribution were assumed to be exponential.",http://arxiv.org/pdf/2305.16729v2,10.14495/jsiaml.15.117
Implicit Transfer Operator Learning: Multiple Time-Resolution Surrogates for Molecular Dynamics,29/05/2023,"Mathias Schreiner, Ole Winther, Simon Olsson","Computing properties of molecular systems rely on estimating expectations of
the (unnormalized) Boltzmann distribution. Molecular dynamics (MD) is a broadly
adopted technique to approximate such quantities. However, stable simulations
rely on very small integration time-steps ($10^{-15}\,\mathrm{s}$), whereas
convergence of some moments, e.g. binding free energy or rates, might rely on
sampling processes on time-scales as long as $10^{-1}\, \mathrm{s}$, and these
simulations must be repeated for every molecular system independently. Here, we
present Implict Transfer Operator (ITO) Learning, a framework to learn
surrogates of the simulation process with multiple time-resolutions. We
implement ITO with denoising diffusion probabilistic models with a new SE(3)
equivariant architecture and show the resulting models can generate
self-consistent stochastic dynamics across multiple time-scales, even when the
system is only partially observed. Finally, we present a coarse-grained
CG-SE3-ITO model which can quantitatively model all-atom molecular dynamics
using only coarse molecular representations. As such, ITO provides an important
step towards multiple time- and space-resolution acceleration of MD. Code is
available at
\href{https://github.com/olsson-group/ito}{https://github.com/olsson-group/ito}.",http://arxiv.org/pdf/2305.18046v2,
From Zero to Turbulence: Generative Modeling for 3D Flow Simulation,29/05/2023,"Marten Lienen, David Lüdke, Jan Hansen-Palmus, Stephan Günnemann","Simulations of turbulent flows in 3D are one of the most expensive
simulations in computational fluid dynamics (CFD). Many works have been written
on surrogate models to replace numerical solvers for fluid flows with faster,
learned, autoregressive models. However, the intricacies of turbulence in three
dimensions necessitate training these models with very small time steps, while
generating realistic flow states requires either long roll-outs with many steps
and significant error accumulation or starting from a known, realistic flow
state - something we aimed to avoid in the first place. Instead, we propose to
approach turbulent flow simulation as a generative task directly learning the
manifold of all possible turbulent flow states without relying on any initial
flow state. For our experiments, we introduce a challenging 3D turbulence
dataset of high-resolution flows and detailed vortex structures caused by
various objects and derive two novel sample evaluation metrics for turbulent
flows. On this dataset, we show that our generative model captures the
distribution of turbulent flows caused by unseen objects and generates
high-quality, realistic samples amenable for downstream applications without
access to any initial state.",http://arxiv.org/pdf/2306.01776v3,
Networked Time Series Imputation via Position-aware Graph Enhanced Variational Autoencoders,29/05/2023,"Dingsu Wang, Yuchen Yan, Ruizhong Qiu, Yada Zhu, Kaiyu Guan, Andrew J Margenot, Hanghang Tong","Multivariate time series (MTS) imputation is a widely studied problem in
recent years. Existing methods can be divided into two main groups, including
(1) deep recurrent or generative models that primarily focus on time series
features, and (2) graph neural networks (GNNs) based models that utilize the
topological information from the inherent graph structure of MTS as relational
inductive bias for imputation. Nevertheless, these methods either neglect
topological information or assume the graph structure is fixed and accurately
known. Thus, they fail to fully utilize the graph dynamics for precise
imputation in more challenging MTS data such as networked time series (NTS),
where the underlying graph is constantly changing and might have missing edges.
In this paper, we propose a novel approach to overcome these limitations.
First, we define the problem of imputation over NTS which contains missing
values in both node time series features and graph structures. Then, we design
a new model named PoGeVon which leverages variational autoencoder (VAE) to
predict missing values over both node time series features and graph
structures. In particular, we propose a new node position embedding based on
random walk with restart (RWR) in the encoder with provable higher expressive
power compared with message-passing based graph neural networks (GNNs). We
further design a decoder with 3-stage predictions from the perspective of
multi-task learning to impute missing values in both time series and graph
structures reciprocally. Experiment results demonstrate the effectiveness of
our model over baselines.",http://arxiv.org/pdf/2305.18612v2,10.1145/3580305.3599444
Unsupervised Statistical Feature-Guided Diffusion Model for Sensor-based Human Activity Recognition,30/05/2023,"Si Zuo, Vitor Fortes Rey, Sungho Suh, Stephan Sigg, Paul Lukowicz","Human activity recognition (HAR) from on-body sensors is a core functionality
in many AI applications: from personal health, through sports and wellness to
Industry 4.0. A key problem holding up progress in wearable sensor-based HAR,
compared to other ML areas, such as computer vision, is the unavailability of
diverse and labeled training data. Particularly, while there are innumerable
annotated images available in online repositories, freely available sensor data
is sparse and mostly unlabeled. We propose an unsupervised statistical
feature-guided diffusion model specifically optimized for wearable sensor-based
human activity recognition with devices such as inertial measurement unit (IMU)
sensors. The method generates synthetic labeled time-series sensor data without
relying on annotated training data. Thereby, it addresses the scarcity and
annotation difficulties associated with real-world sensor data. By conditioning
the diffusion model on statistical information such as mean, standard
deviation, Z-score, and skewness, we generate diverse and representative
synthetic sensor data. We conducted experiments on public human activity
recognition datasets and compared the method to conventional oversampling and
state-of-the-art generative adversarial network methods. Experimental results
demonstrate that this can improve the performance of human activity recognition
and outperform existing techniques.",http://arxiv.org/pdf/2306.05285v2,
Inverse Approximation Theory for Nonlinear Recurrent Neural Networks,30/05/2023,"Shida Wang, Zhong Li, Qianxiao Li","We prove an inverse approximation theorem for the approximation of nonlinear
sequence-to-sequence relationships using recurrent neural networks (RNNs). This
is a so-called Bernstein-type result in approximation theory, which deduces
properties of a target function under the assumption that it can be effectively
approximated by a hypothesis space. In particular, we show that nonlinear
sequence relationships that can be stably approximated by nonlinear RNNs must
have an exponential decaying memory structure - a notion that can be made
precise. This extends the previously identified curse of memory in linear RNNs
into the general nonlinear setting, and quantifies the essential limitations of
the RNN architecture for learning sequential relationships with long-term
memory. Based on the analysis, we propose a principled reparameterization
method to overcome the limitations. Our theoretical results are confirmed by
numerical experiments. The code has been released in
https://github.com/radarFudan/Curse-of-memory",http://arxiv.org/pdf/2305.19190v4,
Testing for the Markov Property in Time Series via Deep Conditional Generative Learning,30/05/2023,"Yunzhe Zhou, Chengchun Shi, Lexin Li, Qiwei Yao","The Markov property is widely imposed in analysis of time series data.
Correspondingly, testing the Markov property, and relatedly, inferring the
order of a Markov model, are of paramount importance. In this article, we
propose a nonparametric test for the Markov property in high-dimensional time
series via deep conditional generative learning. We also apply the test
sequentially to determine the order of the Markov model. We show that the test
controls the type-I error asymptotically, and has the power approaching one.
Our proposal makes novel contributions in several ways. We utilize and extend
state-of-the-art deep generative learning to estimate the conditional density
functions, and establish a sharp upper bound on the approximation error of the
estimators. We derive a doubly robust test statistic, which employs a
nonparametric estimation but achieves a parametric convergence rate. We further
adopt sample splitting and cross-fitting to minimize the conditions required to
ensure the consistency of the test. We demonstrate the efficacy of the test
through both simulations and the three data applications.",http://arxiv.org/pdf/2305.19244v1,
Neural Markov Jump Processes,31/05/2023,"Patrick Seifner, Ramses J. Sanchez","Markov jump processes are continuous-time stochastic processes with a wide
range of applications in both natural and social sciences. Despite their
widespread use, inference in these models is highly non-trivial and typically
proceeds via either Monte Carlo or expectation-maximization methods. In this
work we introduce an alternative, variational inference algorithm for Markov
jump processes which relies on neural ordinary differential equations, and is
trainable via back-propagation. Our methodology learns neural, continuous-time
representations of the observed data, that are used to approximate the initial
distribution and time-dependent transition probability rates of the posterior
Markov jump process. The time-independent rates of the prior process are in
contrast trained akin to generative adversarial networks. We test our approach
on synthetic data sampled from ground-truth Markov jump processes, experimental
switching ion channel data and molecular dynamics simulations. Source code to
reproduce our experiments is available online.",http://arxiv.org/pdf/2305.19744v1,
MetaDiffuser: Diffusion Model as Conditional Planner for Offline Meta-RL,31/05/2023,"Fei Ni, Jianye Hao, Yao Mu, Yifu Yuan, Yan Zheng, Bin Wang, Zhixuan Liang","Recently, diffusion model shines as a promising backbone for the sequence
modeling paradigm in offline reinforcement learning(RL). However, these works
mostly lack the generalization ability across tasks with reward or dynamics
change. To tackle this challenge, in this paper we propose a task-oriented
conditioned diffusion planner for offline meta-RL(MetaDiffuser), which
considers the generalization problem as conditional trajectory generation task
with contextual representation. The key is to learn a context conditioned
diffusion model which can generate task-oriented trajectories for planning
across diverse tasks. To enhance the dynamics consistency of the generated
trajectories while encouraging trajectories to achieve high returns, we further
design a dual-guided module in the sampling process of the diffusion model. The
proposed framework enjoys the robustness to the quality of collected warm-start
data from the testing task and the flexibility to incorporate with different
task representation method. The experiment results on MuJoCo benchmarks show
that MetaDiffuser outperforms other strong offline meta-RL baselines,
demonstrating the outstanding conditional generation ability of diffusion
architecture.",http://arxiv.org/pdf/2305.19923v1,
Interactive Character Control with Auto-Regressive Motion Diffusion Models,01/06/2023,"Yi Shi, Jingbo Wang, Xuekun Jiang, Bingkun Lin, Bo Dai, Xue Bin Peng","Real-time character control is an essential component for interactive
experiences, with a broad range of applications, including physics simulations,
video games, and virtual reality. The success of diffusion models for image
synthesis has led to the use of these models for motion synthesis. However, the
majority of these motion diffusion models are primarily designed for offline
applications, where space-time models are used to synthesize an entire sequence
of frames simultaneously with a pre-specified length. To enable real-time
motion synthesis with diffusion model that allows time-varying controls, we
propose A-MDM (Auto-regressive Motion Diffusion Model). Our conditional
diffusion model takes an initial pose as input, and auto-regressively generates
successive motion frames conditioned on the previous frame. Despite its
streamlined network architecture, which uses simple MLPs, our framework is
capable of generating diverse, long-horizon, and high-fidelity motion
sequences. Furthermore, we introduce a suite of techniques for incorporating
interactive controls into A-MDM, such as task-oriented sampling, in-painting,
and hierarchical reinforcement learning. These techniques enable a pre-trained
A-MDM to be efficiently adapted for a variety of new downstream tasks. We
conduct a comprehensive suite of experiments to demonstrate the effectiveness
of A-MDM, and compare its performance against state-of-the-art auto-regressive
methods.",http://arxiv.org/pdf/2306.00416v4,
Inference and Sampling of Point Processes from Diffusion Excursions,01/06/2023,"Ali Hasan, Yu Chen, Yuting Ng, Mohamed Abdelghani, Anderson Schneider, Vahid Tarokh","Point processes often have a natural interpretation with respect to a
continuous process. We propose a point process construction that describes
arrival time observations in terms of the state of a latent diffusion process.
In this framework, we relate the return times of a diffusion in a continuous
path space to new arrivals of the point process. This leads to a continuous
sample path that is used to describe the underlying mechanism generating the
arrival distribution. These models arise in many disciplines, such as financial
settings where actions in a market are determined by a hidden continuous price
or in neuroscience where a latent stimulus generates spike trains. Based on the
developments in It\^o's excursion theory, we propose methods for inferring and
sampling from the point process derived from the latent diffusion process. We
illustrate the approach with numerical examples using both simulated and real
data. The proposed methods and framework provide a basis for interpreting point
processes through the lens of diffusions.",http://arxiv.org/pdf/2306.00762v1,
Hierarchical Attention Encoder Decoder,01/06/2023,Asier Mujika,"Recent advances in large language models have shown that autoregressive
modeling can generate complex and novel sequences that have many real-world
applications. However, these models must generate outputs autoregressively,
which becomes time-consuming when dealing with long sequences. Hierarchical
autoregressive approaches that compress data have been proposed as a solution,
but these methods still generate outputs at the original data frequency,
resulting in slow and memory-intensive models. In this paper, we propose a
model based on the Hierarchical Recurrent Encoder Decoder (HRED) architecture.
This model independently encodes input sub-sequences without global context,
processes these sequences using a lower-frequency model, and decodes outputs at
the original data frequency. By interpreting the encoder as an implicitly
defined embedding matrix and using sampled softmax estimation, we develop a
training algorithm that can train the entire model without a high-frequency
decoder, which is the most memory and compute-intensive part of hierarchical
approaches. In a final, brief phase, we train the decoder to generate data at
the original granularity. Our algorithm significantly reduces memory
requirements for training autoregressive models and it also improves the total
training wall-clock time.",http://arxiv.org/pdf/2306.01070v1,
GAT-GAN : A Graph-Attention-based Time-Series Generative Adversarial Network,03/06/2023,"Srikrishna Iyer, Teng Teck Hou","Generative Adversarial Networks (GANs) have proven to be a powerful tool for
generating realistic synthetic data. However, traditional GANs often struggle
to capture complex relationships between features which results in generation
of unrealistic multivariate time-series data. In this paper, we propose a
Graph-Attention-based Generative Adversarial Network (GAT-GAN) that explicitly
includes two graph-attention layers, one that learns temporal dependencies
while the other captures spatial relationships. Unlike RNN-based GANs that
struggle with modeling long sequences of data points, GAT-GAN generates long
time-series data of high fidelity using an adversarially trained autoencoder
architecture. Our empirical evaluations, using a variety of real-time-series
datasets, show that our framework consistently outperforms state-of-the-art
benchmarks based on \emph{Frechet Transformer distance} and \emph{Predictive
score}, that characterizes (\emph{Fidelity, Diversity}) and \emph{predictive
performance} respectively. Moreover, we introduce a Frechet Inception
distance-like (FID) metric for time-series data called Frechet Transformer
distance (FTD) score (lower is better), to evaluate the quality and variety of
generated data. We also found that low FTD scores correspond to the
best-performing downstream predictive experiments. Hence, FTD scores can be
used as a standardized metric to evaluate synthetic time-series data.",http://arxiv.org/pdf/2306.01999v1,
PV Fleet Modeling via Smooth Periodic Gaussian Copula,05/06/2023,"Mehmet G. Ogut, Bennet Meyers, Stephen P. Boyd","We present a method for jointly modeling power generation from a fleet of
photovoltaic (PV) systems. We propose a white-box method that finds a function
that invertibly maps vector time-series data to independent and identically
distributed standard normal variables. The proposed method, based on a novel
approach for fitting a smooth, periodic copula transform to data, captures many
aspects of the data such as diurnal variation in the distribution of power
output, dependencies among different PV systems, and dependencies across time.
It consists of interpretable steps and is scalable to many systems. The
resulting joint probability model of PV fleet output across systems and time
can be used to generate synthetic data, impute missing data, perform anomaly
detection, and make forecasts. In this paper, we explain the method and
demonstrate these applications.",http://arxiv.org/pdf/2307.00004v1,
Origin-Destination Network Generation via Gravity-Guided GAN,06/06/2023,"Can Rong, Huandong Wang, Yong Li","Origin-destination (OD) flow, which contains valuable population mobility
information including direction and volume, is critical in many urban
applications, such as urban planning, transportation management, etc. However,
OD data is not always easy to access due to high costs or privacy concerns.
Therefore, we must consider generating OD through mathematical models. Existing
works utilize physics laws or machine learning (ML) models to build the
association between urban structures and OD flows while these two kinds of
methods suffer from the limitation of over-simplicity and poor generalization
ability, respectively. In this paper, we propose to adopt physics-informed ML
paradigm, which couple the physics scientific knowledge and data-driven ML
methods, to construct a model named Origin-Destination Generation Networks
(ODGN) for better population mobility modeling by leveraging the complementary
strengths of combining physics and ML methods. Specifically, we first build a
Multi-view Graph Attention Networks (MGAT) to capture the urban features of
every region and then use a gravity-guided predictor to obtain OD flow between
every two regions. Furthermore, we use a conditional GAN training strategy and
design a sequence-based discriminator to consider the overall topological
features of OD as a network. Extensive experiments on real-world datasets have
been done to demonstrate the superiority of our proposed method compared with
baselines.",http://arxiv.org/pdf/2306.03390v1,
PlayBest: Professional Basketball Player Behavior Synthesis via Planning with Diffusion,07/06/2023,"Xiusi Chen, Wei-Yao Wang, Ziniu Hu, David Reynoso, Kun Jin, Mingyan Liu, P. Jeffrey Brantingham, Wei Wang","Dynamically planning in complex systems has been explored to improve
decision-making in various domains. Professional basketball serves as a
compelling example of a dynamic spatio-temporal game, encompassing
context-dependent decision-making. However, processing the diverse on-court
signals and navigating the vast space of potential actions and outcomes make it
difficult for existing approaches to swiftly identify optimal strategies in
response to evolving circumstances. In this study, we formulate the sequential
decision-making process as a conditional trajectory generation process. Based
on the formulation, we introduce PlayBest (PLAYer BEhavior SynThesis), a method
to improve player decision-making. We extend the diffusion probabilistic model
to learn challenging environmental dynamics from historical National Basketball
Association (NBA) player motion tracking data. To incorporate data-driven
strategies, an auxiliary value function is trained with corresponding rewards.
To accomplish reward-guided trajectory generation, we condition the diffusion
model on the value function via classifier-guided sampling. We validate the
effectiveness of PlayBest through simulation studies, contrasting the generated
trajectories with those employed by professional basketball teams. Our results
reveal that the model excels at generating reasonable basketball trajectories
that produce efficient plays. Moreover, the synthesized play strategies exhibit
an alignment with professional tactics, highlighting the model's capacity to
capture the intricate dynamics of basketball games.",http://arxiv.org/pdf/2306.04090v3,
A Comprehensive Survey on Generative Diffusion Models for Structured Data,07/06/2023,"Heejoon Koo, To Eun Kim","In recent years, generative diffusion models have achieved a rapid paradigm
shift in deep generative models by showing groundbreaking performance across
various applications. Meanwhile, structured data, encompassing tabular and time
series data, has been received comparatively limited attention from the deep
learning research community, despite its omnipresence and extensive
applications. Thus, there is still a lack of literature and its reviews on
structured data modelling via diffusion models, compared to other data
modalities such as visual and textual data. To address this gap, we present a
comprehensive review of recently proposed diffusion models in the field of
structured data. First, this survey provides a concise overview of the
score-based diffusion model theory, subsequently proceeding to the technical
descriptions of the majority of pioneering works that used structured data in
both data-driven general tasks and domain-specific applications. Thereafter, we
analyse and discuss the limitations and challenges shown in existing works and
suggest potential research directions. We hope this review serves as a catalyst
for the research community, promoting developments in generative diffusion
models for structured data.",http://arxiv.org/pdf/2306.04139v2,
Complexity-aware Large Scale Origin-Destination Network Generation via Diffusion Model,08/06/2023,"Can Rong, Jingtao Ding, Zhicheng Liu, Yong Li","The Origin-Destination~(OD) networks provide an estimation of the flow of
people from every region to others in the city, which is an important research
topic in transportation, urban simulation, etc. Given structural regional urban
features, generating the OD network has become increasingly appealing to many
researchers from diverse domains. However, existing works are limited in
independent generation of each OD pair, i.e., flow of people from one region to
another, overlooking the relations within the overall network. In this paper,
we instead propose to generate the OD network, and design a graph denoising
diffusion method to learn the conditional joint probability distribution of the
nodes and edges within the OD network given city characteristics at region
level. To overcome the learning difficulty of the OD networks covering over
thousands of regions, we decompose the original one-shot generative modeling of
the diffusion model into two cascaded stages, corresponding to the generation
of network topology and the weights of edges, respectively. To further
reproduce important network properties contained in the city-wide OD network,
we design an elaborated graph denoising network structure including a node
property augmentation module and a graph transformer backbone. Empirical
experiments on data collected in three large US cities have verified that our
method can generate OD matrices for new cities with network statistics
remarkably similar with the ground truth, further achieving superior
outperformance over competitive baselines in terms of the generation realism.",http://arxiv.org/pdf/2306.04873v2,
Instructed Diffuser with Temporal Condition Guidance for Offline Reinforcement Learning,08/06/2023,"Jifeng Hu, Yanchao Sun, Sili Huang, SiYuan Guo, Hechang Chen, Li Shen, Lichao Sun, Yi Chang, Dacheng Tao","Recent works have shown the potential of diffusion models in computer vision
and natural language processing. Apart from the classical supervised learning
fields, diffusion models have also shown strong competitiveness in
reinforcement learning (RL) by formulating decision-making as sequential
generation. However, incorporating temporal information of sequential data and
utilizing it to guide diffusion models to perform better generation is still an
open challenge. In this paper, we take one step forward to investigate
controllable generation with temporal conditions that are refined from temporal
information. We observe the importance of temporal conditions in sequential
generation in sufficient explorative scenarios and provide a comprehensive
discussion and comparison of different temporal conditions. Based on the
observations, we propose an effective temporally-conditional diffusion model
coined Temporally-Composable Diffuser (TCD), which extracts temporal
information from interaction sequences and explicitly guides generation with
temporal conditions. Specifically, we separate the sequences into three parts
according to time expansion and identify historical, immediate, and prospective
conditions accordingly. Each condition preserves non-overlapping temporal
information of sequences, enabling more controllable generation when we jointly
use them to guide the diffuser. Finally, we conduct extensive experiments and
analysis to reveal the favorable applicability of TCD in offline RL tasks,
where our method reaches or matches the best performance compared with prior
SOTA baselines.",http://arxiv.org/pdf/2306.04875v1,
Non-autoregressive Conditional Diffusion Models for Time Series Prediction,08/06/2023,"Lifeng Shen, James Kwok","Recently, denoising diffusion models have led to significant breakthroughs in
the generation of images, audio and text. However, it is still an open question
on how to adapt their strong modeling ability to model time series. In this
paper, we propose TimeDiff, a non-autoregressive diffusion model that achieves
high-quality time series prediction with the introduction of two novel
conditioning mechanisms: future mixup and autoregressive initialization.
Similar to teacher forcing, future mixup allows parts of the ground-truth
future predictions for conditioning, while autoregressive initialization helps
better initialize the model with basic time series patterns such as short-term
trends. Extensive experiments are performed on nine real-world datasets.
Results show that TimeDiff consistently outperforms existing time series
diffusion models, and also achieves the best overall performance across a
variety of the existing strong baselines (including transformers and FiLM).",http://arxiv.org/pdf/2306.05043v1,
SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking,08/06/2023,"Chris Cundy, Stefano Ermon","In many domains, autoregressive models can attain high likelihood on the task
of predicting the next observation. However, this maximum-likelihood (MLE)
objective does not necessarily match a downstream use-case of autoregressively
generating high-quality sequences. The MLE objective weights sequences
proportionally to their frequency under the data distribution, with no guidance
for the model's behaviour out of distribution (OOD): leading to compounding
error during autoregressive generation. In order to address this compounding
error problem, we formulate sequence generation as an imitation learning (IL)
problem. This allows us to minimize a variety of divergences between the
distribution of sequences generated by an autoregressive model and sequences
from a dataset, including divergences with weight on OOD generated sequences.
The IL framework also allows us to incorporate backtracking by introducing a
backspace action into the generation process. This further mitigates the
compounding error problem by allowing the model to revert a sampled token if it
takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented
without adversarial training or architectural changes. We identify the
SequenceMatch-$\chi^2$ divergence as a more suitable training objective for
autoregressive models which are used for generation. We show that empirically,
SequenceMatch training leads to improvements over MLE on text generation with
language models and arithmetic.",http://arxiv.org/pdf/2306.05426v3,
Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models,09/06/2023,"Siyan Zhao, Aditya Grover","Reinforcement learning presents an attractive paradigm to reason about
several distinct aspects of sequential decision making, such as specifying
complex goals, planning future observations and actions, and critiquing their
utilities. However, the combined integration of these capabilities poses
competing algorithmic challenges in retaining maximal expressivity while
allowing for flexibility in modeling choices for efficient learning and
inference. We present Decision Stacks, a generative framework that decomposes
goal-conditioned policy agents into 3 generative modules. These modules
simulate the temporal evolution of observations, rewards, and actions via
independent generative models that can be learned in parallel via teacher
forcing. Our framework guarantees both expressivity and flexibility in
designing individual modules to account for key factors such as architectural
bias, optimization objective and dynamics, transferrability across domains, and
inference speed. Our empirical results demonstrate the effectiveness of
Decision Stacks for offline policy optimization for several MDP and POMDP
environments, outperforming existing methods and enabling flexible generative
decision making.",http://arxiv.org/pdf/2306.06253v2,
SARN: Structurally-Aware Recurrent Network for Spatio-Temporal Disaggregation,09/06/2023,"Bin Han, Bill Howe","Open data is frequently released spatially aggregated, usually to comply with
privacy policies. But coarse, heterogeneous aggregations complicate learning
and integration for downstream AI/ML systems. In this work, we consider models
to disaggregate spatio-temporal data from a low-resolution, irregular partition
(e.g., census tract) to a high-resolution, irregular partition (e.g., city
block). We propose an overarching model named the Structurally-Aware Recurrent
Network (SARN), which integrates structurally-aware spatial attention (SASA)
layers into the Gated Recurrent Unit (GRU) model. The spatial attention layers
capture spatial interactions among regions, while the gated recurrent module
captures the temporal dependencies. Each SASA layer calculates both global and
structural attention -- global attention facilitates comprehensive interactions
between different geographic levels, while structural attention leverages the
containment relationship between different geographic levels (e.g., a city
block being wholly contained within a census tract) to ensure coherent and
consistent results. For scenarios with limited historical training data, we
explore transfer learning and show that a model pre-trained on one city
variable can be fine-tuned for another city variable using only a few hundred
samples. Evaluating these techniques on two mobility datasets, we find that on
both datasets, SARN significantly outperforms other neural models (5% and 1%)
and typical heuristic methods (40% and 14%), enabling us to generate realistic,
high-quality fine-grained data for downstream applications.",http://arxiv.org/pdf/2306.07292v4,
Explaining a machine learning decision to physicians via counterfactuals,10/06/2023,"Supriya Nagesh, Nina Mishra, Yonatan Naamad, James M. Rehg, Mehul A. Shah, Alexei Wagner","Machine learning models perform well on several healthcare tasks and can help
reduce the burden on the healthcare system. However, the lack of explainability
is a major roadblock to their adoption in hospitals. \textit{How can the
decision of an ML model be explained to a physician?} The explanations
considered in this paper are counterfactuals (CFs), hypothetical scenarios that
would have resulted in the opposite outcome. Specifically, time-series CFs are
investigated, inspired by the way physicians converse and reason out decisions
`I would have given the patient a vasopressor if their blood pressure was lower
and falling'. Key properties of CFs that are particularly meaningful in
clinical settings are outlined: physiological plausibility, relevance to the
task and sparse perturbations. Past work on CF generation does not satisfy
these properties, specifically plausibility in that realistic time-series CFs
are not generated. A variational autoencoder (VAE)-based approach is proposed
that captures these desired properties. The method produces CFs that improve on
prior approaches quantitatively (more plausible CFs as evaluated by their
likelihood w.r.t original data distribution, and 100$\times$ faster at
generating CFs) and qualitatively (2$\times$ more plausible and relevant) as
evaluated by three physicians.",http://arxiv.org/pdf/2306.06325v1,
Latent Dynamical Implicit Diffusion Processes,12/06/2023,Mohammad R. Rezaei,"Latent dynamical models are commonly used to learn the distribution of a
latent dynamical process that represents a sequence of noisy data samples.
However, producing samples from such models with high fidelity is challenging
due to the complexity and variability of latent and observation dynamics.
Recent advances in diffusion-based generative models, such as DDPM and NCSN,
have shown promising alternatives to state-of-the-art latent generative models,
such as Neural ODEs, RNNs, and Normalizing flow networks, for generating
high-quality sequential samples from a prior distribution. However, their
application in modeling sequential data with latent dynamical models is yet to
be explored. Here, we propose a novel latent variable model named latent
dynamical implicit diffusion processes (LDIDPs), which utilizes implicit
diffusion processes to sample from dynamical latent processes and generate
sequential observation samples accordingly. We tested LDIDPs on synthetic and
simulated neural decoding problems. We demonstrate that LDIDPs can accurately
learn the dynamics over latent dimensions. Furthermore, the implicit sampling
method allows for the computationally efficient generation of high-quality
sequential data samples from the latent and observation spaces.",http://arxiv.org/pdf/2306.07077v2,
Unbiased Learning of Deep Generative Models with Structured Discrete Representations,14/06/2023,"Harry Bendekgey, Gabriel Hope, Erik B. Sudderth","By composing graphical models with deep learning architectures, we learn
generative models with the strengths of both frameworks. The structured
variational autoencoder (SVAE) inherits structure and interpretability from
graphical models, and flexible likelihoods for high-dimensional data from deep
learning, but poses substantial optimization challenges. We propose novel
algorithms for learning SVAEs, and are the first to demonstrate the SVAE's
ability to handle multimodal uncertainty when data is missing by incorporating
discrete latent variables. Our memory-efficient implicit differentiation scheme
makes the SVAE tractable to learn via gradient descent, while demonstrating
robustness to incomplete optimization. To more rapidly learn accurate graphical
model parameters, we derive a method for computing natural gradients without
manual derivations, which avoids biases found in prior work. These optimization
innovations enable the first comparisons of the SVAE to state-of-the-art time
series models, where the SVAE performs competitively while learning
interpretable and structured discrete data representations.",http://arxiv.org/pdf/2306.08230v2,
Anticipatory Music Transformer,14/06/2023,"John Thickstun, David Hall, Chris Donahue, Percy Liang","We introduce anticipation: a method for constructing a controllable
generative model of a temporal point process (the event process) conditioned
asynchronously on realizations of a second, correlated process (the control
process). We achieve this by interleaving sequences of events and controls,
such that controls appear following stopping times in the event sequence. This
work is motivated by problems arising in the control of symbolic music
generation. We focus on infilling control tasks, whereby the controls are a
subset of the events themselves, and conditional generation completes a
sequence of events given the fixed control events. We train anticipatory
infilling models using the large and diverse Lakh MIDI music dataset. These
models match the performance of autoregressive models for prompted music
generation, with the additional capability to perform infilling control tasks,
including accompaniment. Human evaluators report that an anticipatory model
produces accompaniments with similar musicality to even music composed by
humans over a 20-second clip.",http://arxiv.org/pdf/2306.08620v2,
Spatiotemporal-Augmented Graph Neural Networks for Human Mobility Simulation,15/06/2023,"Yu Wang, Tongya Zheng, Shunyu Liu, Zunlei Feng, Kaixuan Chen, Yunzhi Hao, Mingli Song","Human mobility patterns have shown significant applications in
policy-decision scenarios and economic behavior researches. The human mobility
simulation task aims to generate human mobility trajectories given a small set
of trajectory data, which have aroused much concern due to the scarcity and
sparsity of human mobility data. Existing methods mostly rely on the static
relationships of locations, while largely neglect the dynamic spatiotemporal
effects of locations. On the one hand, spatiotemporal correspondences of visit
distributions reveal the spatial proximity and the functionality similarity of
locations. On the other hand, the varying durations in different locations
hinder the iterative generation process of the mobility trajectory. Therefore,
we propose a novel framework to model the dynamic spatiotemporal effects of
locations, namely SpatioTemporal-Augmented gRaph neural networks (STAR). The
STAR framework designs various spatiotemporal graphs to capture the
spatiotemporal correspondences and builds a novel dwell branch to simulate the
varying durations in locations, which is finally optimized in an adversarial
manner. The comprehensive experiments over four real datasets for the human
mobility simulation have verified the superiority of STAR to state-of-the-art
methods. Our code is available at https://github.com/Star607/STAR-TKDE.",http://arxiv.org/pdf/2306.09381v3,
Probabilistic Learning of Multivariate Time Series with Temporal Irregularity,15/06/2023,"Yijun Li, Cheuk Hang Leung, Qi Wu","Multivariate sequential data collected in practice often exhibit temporal
irregularities, including nonuniform time intervals and component misalignment.
However, if uneven spacing and asynchrony are endogenous characteristics of the
data rather than a result of insufficient observation, the information content
of these irregularities plays a defining role in characterizing the
multivariate dependence structure. Existing approaches for probabilistic
forecasting either overlook the resulting statistical heterogeneities, are
susceptible to imputation biases, or impose parametric assumptions on the data
distribution. This paper proposes an end-to-end solution that overcomes these
limitations by allowing the observation arrival times to play the central role
of model construction, which is at the core of temporal irregularities. To
acknowledge temporal irregularities, we first enable unique hidden states for
components so that the arrival times can dictate when, how, and which hidden
states to update. We then develop a conditional flow representation to
non-parametrically represent the data distribution, which is typically
non-Gaussian, and supervise this representation by carefully factorizing the
log-likelihood objective to select conditional information that facilitates
capturing time variation and path dependency. The broad applicability and
superiority of the proposed solution are confirmed by comparing it with
existing approaches through ablation studies and testing on real-world
datasets.",http://arxiv.org/pdf/2306.09147v2,
Generating Oscillation Activity with Echo State Network to Mimic the Behavior of a Simple Central Pattern Generator,19/06/2023,"Tham Yik Foong, Danilo Vasconcellos Vargas","This paper presents a method for reproducing a simple central pattern
generator (CPG) using a modified Echo State Network (ESN). Conventionally, the
dynamical reservoir needs to be damped to stabilize and preserve memory.
However, we find that a reservoir that develops oscillatory activity without
any external excitation can mimic the behaviour of a simple CPG in biological
systems. We define the specific neuron ensemble required for generating
oscillations in the reservoir and demonstrate how adjustments to the leaking
rate, spectral radius, topology, and population size can increase the
probability of reproducing these oscillations. The results of the experiments,
conducted on the time series simulation tasks, demonstrate that the ESN is able
to generate the desired waveform without any input. This approach offers a
promising solution for the development of bio-inspired controllers for robotic
systems.",http://arxiv.org/pdf/2306.10927v1,
Using Motif Transitions for Temporal Graph Generation,19/06/2023,"Penghang Liu, A. Erdem Sarıyüce","Graph generative models are highly important for sharing surrogate data and
benchmarking purposes. Real-world complex systems often exhibit dynamic nature,
where the interactions among nodes change over time in the form of a temporal
network. Most temporal network generation models extend the static graph
generation models by incorporating temporality in the generation process. More
recently, temporal motifs are used to generate temporal networks with better
success. However, existing models are often restricted to a small set of
predefined motif patterns due to the high computational cost of counting
temporal motifs. In this work, we develop a practical temporal graph generator,
Motif Transition Model (MTM), to generate synthetic temporal networks with
realistic global and local features. Our key idea is modeling the arrival of
new events as temporal motif transition processes. We first calculate the
transition properties from the input graph and then simulate the motif
transition processes based on the transition probabilities and transition
rates. We demonstrate that our model consistently outperforms the baselines
with respect to preserving various global and local temporal graph statistics
and runtime performance.",http://arxiv.org/pdf/2306.11190v1,10.1145/3580305.3599540
"Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events",20/06/2023,"Matthew B. A. McDermott, Bret Nestor, Peniel Argaw, Isaac Kohane","Generative, pre-trained transformers (GPTs, a.k.a. ""Foundation Models"") have
reshaped natural language processing (NLP) through their versatility in diverse
downstream tasks. However, their potential extends far beyond NLP. This paper
provides a software utility to help realize this potential, extending the
applicability of GPTs to continuous-time sequences of complex events with
internal dependencies, such as medical record datasets. Despite their
potential, the adoption of foundation models in these domains has been hampered
by the lack of suitable tools for model construction and evaluation. To bridge
this gap, we introduce Event Stream GPT (ESGPT), an open-source library
designed to streamline the end-to-end process for building GPTs for
continuous-time event sequences. ESGPT allows users to (1) build flexible,
foundation-model scale input datasets by specifying only a minimal
configuration file, (2) leverage a Hugging Face compatible modeling API for
GPTs over this modality that incorporates intra-event causal dependency
structures and autoregressive generation capabilities, and (3) evaluate models
via standardized processes that can assess few and even zero-shot performance
of pre-trained models on user-specified fine-tuning tasks.",http://arxiv.org/pdf/2306.11547v2,
"Conditional Generators for Limit Order Book Environments: Explainability, Challenges, and Robustness",22/06/2023,"Andrea Coletta, Joseph Jerome, Rahul Savani, Svitlana Vyetrenko","Limit order books are a fundamental and widespread market mechanism. This
paper investigates the use of conditional generative models for order book
simulation. For developing a trading agent, this approach has drawn recent
attention as an alternative to traditional backtesting due to its ability to
react to the presence of the trading agent. Using a state-of-the-art CGAN (from
Coletta et al. (2022)), we explore its dependence upon input features, which
highlights both strengths and weaknesses. To do this, we use ""adversarial
attacks"" on the model's features and its mechanism. We then show how these
insights can be used to improve the CGAN, both in terms of its realism and
robustness. We finish by laying out a roadmap for future work.",http://arxiv.org/pdf/2306.12806v1,
TNPAR: Topological Neural Poisson Auto-Regressive Model for Learning Granger Causal Structure from Event Sequences,25/06/2023,"Yuequn Liu, Ruichu Cai, Wei Chen, Jie Qiao, Yuguang Yan, Zijian Li, Keli Zhang, Zhifeng Hao","Learning Granger causality from event sequences is a challenging but
essential task across various applications. Most existing methods rely on the
assumption that event sequences are independent and identically distributed
(i.i.d.). However, this i.i.d. assumption is often violated due to the inherent
dependencies among the event sequences. Fortunately, in practice, we find these
dependencies can be modeled by a topological network, suggesting a potential
solution to the non-i.i.d. problem by introducing the prior topological network
into Granger causal discovery. This observation prompts us to tackle two
ensuing challenges: 1) how to model the event sequences while incorporating
both the prior topological network and the latent Granger causal structure, and
2) how to learn the Granger causal structure. To this end, we devise a unified
topological neural Poisson auto-regressive model with two processes. In the
generation process, we employ a variant of the neural Poisson process to model
the event sequences, considering influences from both the topological network
and the Granger causal structure. In the inference process, we formulate an
amortized inference algorithm to infer the latent Granger causal structure. We
encapsulate these two processes within a unified likelihood function, providing
an end-to-end framework for this task. Experiments on simulated and real-world
data demonstrate the effectiveness of our approach.",http://arxiv.org/pdf/2306.14114v2,
Variational latent discrete representation for time series modelling,27/06/2023,"Max Cohen, Maurice Charbit, Sylvain Le Corff","Discrete latent space models have recently achieved performance on par with
their continuous counterparts in deep variational inference. While they still
face various implementation challenges, these models offer the opportunity for
a better interpretation of latent spaces, as well as a more direct
representation of naturally discrete phenomena. Most recent approaches propose
to train separately very high-dimensional prior models on the discrete latent
data which is a challenging task on its own. In this paper, we introduce a
latent data model where the discrete state is a Markov chain, which allows fast
end-to-end training. The performance of our generative model is assessed on a
building management dataset and on the publicly available Electricity
Transformer Dataset.",http://arxiv.org/pdf/2306.15282v3,
MADS: Modulated Auto-Decoding SIREN for time series imputation,03/07/2023,"Tom Bamford, Elizabeth Fons, Yousef El-Laham, Svitlana Vyetrenko","Time series imputation remains a significant challenge across many fields due
to the potentially significant variability in the type of data being modelled.
Whilst traditional imputation methods often impose strong assumptions on the
underlying data generation process, limiting their applicability, researchers
have recently begun to investigate the potential of deep learning for this
task, inspired by the strong performance shown by these models in both
classification and regression problems across a range of applications. In this
work we propose MADS, a novel auto-decoding framework for time series
imputation, built upon implicit neural representations. Our method leverages
the capabilities of SIRENs for high fidelity reconstruction of signals and
irregular data, and combines it with a hypernetwork architecture which allows
us to generalise by learning a prior over the space of time series. We evaluate
our model on two real-world datasets, and show that it outperforms
state-of-the-art methods for time series imputation. On the human activity
dataset, it improves imputation performance by at least 40%, while on the air
quality dataset it is shown to be competitive across all metrics. When
evaluated on synthetic data, our model results in the best average rank across
different dataset configurations over all baselines.",http://arxiv.org/pdf/2307.00868v1,
On the Constrained Time-Series Generation Problem,04/07/2023,"Andrea Coletta, Sriram Gopalakrishan, Daniel Borrajo, Svitlana Vyetrenko","Synthetic time series are often used in practical applications to augment the
historical time series dataset for better performance of machine learning
algorithms, amplify the occurrence of rare events, and also create
counterfactual scenarios described by the time series.
Distributional-similarity (which we refer to as realism) as well as the
satisfaction of certain numerical constraints are common requirements in
counterfactual time series scenario generation requests. For instance, the US
Federal Reserve publishes synthetic market stress scenarios given by the
constrained time series for financial institutions to assess their performance
in hypothetical recessions. Existing approaches for generating constrained time
series usually penalize training loss to enforce constraints, and reject
non-conforming samples. However, these approaches would require re-training if
we change constraints, and rejection sampling can be computationally expensive,
or impractical for complex constraints. In this paper, we propose a novel set
of methods to tackle the constrained time series generation problem and provide
efficient sampling while ensuring the realism of generated time series. In
particular, we frame the problem using a constrained optimization framework and
then we propose a set of generative methods including ""GuidedDiffTime"", a
guided diffusion model to generate realistic time series. Empirically, we
evaluate our work on several datasets for financial and energy data, where
incorporating constraints is critical. We show that our approaches outperform
existing work both qualitatively and quantitatively. Most importantly, we show
that our ""GuidedDiffTime"" model is the only solution where re-training is not
necessary for new constraints, resulting in a significant carbon footprint
reduction, up to 92% w.r.t. existing deep learning methods.",http://arxiv.org/pdf/2307.01717v2,
Simulation-free Schrödinger bridges via score and flow matching,07/07/2023,"Alexander Tong, Nikolay Malkin, Kilian Fatras, Lazar Atanackovic, Yanlei Zhang, Guillaume Huguet, Guy Wolf, Yoshua Bengio","We present simulation-free score and flow matching ([SF]$^2$M), a
simulation-free objective for inferring stochastic dynamics given unpaired
samples drawn from arbitrary source and target distributions. Our method
generalizes both the score-matching loss used in the training of diffusion
models and the recently proposed flow matching loss used in the training of
continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic
generative modeling as a Schr\""odinger bridge problem. It relies on static
entropy-regularized optimal transport, or a minibatch approximation, to
efficiently learn the SB without simulating the learned stochastic process. We
find that [SF]$^2$M is more efficient and gives more accurate solutions to the
SB problem than simulation-based methods from prior work. Finally, we apply
[SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably,
[SF]$^2$M is the first method to accurately model cell dynamics in high
dimensions and can recover known gene regulatory networks from simulated data.
Our code is available in the TorchCFM package at
https://github.com/atong01/conditional-flow-matching.",http://arxiv.org/pdf/2307.03672v3,
Learning Behavioral Representations of Routines From Large-scale Unlabeled Wearable Time-series Data Streams using Hawkes Point Process,10/07/2023,"Tiantian Feng, Brandon M Booth, Shrikanth Narayanan","Continuously-worn wearable sensors enable researchers to collect copious
amounts of rich bio-behavioral time series recordings of real-life activities
of daily living, offering unprecedented opportunities to infer novel human
behavior patterns during daily routines. Existing approaches to routine
discovery through bio-behavioral data rely either on pre-defined notions of
activities or use additional non-behavioral measurements as contexts, such as
GPS location or localization within the home, presenting risks to user privacy.
In this work, we propose a novel wearable time-series mining framework, Hawkes
point process On Time series clusters for ROutine Discovery (HOT-ROD), for
uncovering behavioral routines from completely unlabeled wearable recordings.
We utilize a covariance-based method to generate time-series clusters and
discover routines via the Hawkes point process learning algorithm. We
empirically validate our approach for extracting routine behaviors using a
completely unlabeled time-series collected continuously from over 100
individuals both in and outside of the workplace during a period of ten weeks.
Furthermore, we demonstrate this approach intuitively captures daily
transitional relationships between physical activity states without using prior
knowledge. We also show that the learned behavioral patterns can assist in
illuminating an individual's personality and affect.",http://arxiv.org/pdf/2307.04445v1,
Effective Latent Differential Equation Models via Attention and Multiple Shooting,11/07/2023,"Germán Abrevaya, Mahta Ramezanian-Panahi, Jean-Christophe Gagnon-Audet, Pablo Polosecki, Irina Rish, Silvina Ponce Dawson, Guillermo Cecchi, Guillaume Dumas","Scientific Machine Learning (SciML) is a burgeoning field that
synergistically combines domain-aware and interpretable models with agnostic
machine learning techniques. In this work, we introduce GOKU-UI, an evolution
of the SciML generative model GOKU-nets. GOKU-UI not only broadens the original
model's spectrum to incorporate other classes of differential equations, such
as Stochastic Differential Equations (SDEs), but also integrates attention
mechanisms and a novel multiple shooting training strategy in the latent space.
These modifications have led to a significant increase in its performance in
both reconstruction and forecast tasks, as demonstrated by our evaluation of
simulated and empirical data. Specifically, GOKU-UI outperformed all baseline
models on synthetic datasets even with a training set 16-fold smaller,
underscoring its remarkable data efficiency. Furthermore, when applied to
empirical human brain data, while incorporating stochastic Stuart-Landau
oscillators into its dynamical core, our proposed enhancements markedly
increased the model's effectiveness in capturing complex brain dynamics. This
augmented version not only surpassed all baseline methods in the reconstruction
task, but also demonstrated lower prediction error of future brain activity up
to 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded
whole-brain dynamics into a latent representation, learning a low-dimensional
dynamical system model that could offer insights into brain functionality and
open avenues for practical applications such as the classification of mental
states or psychiatric conditions. Ultimately, our research provides further
impetus for the field of Scientific Machine Learning, showcasing the potential
for advancements when established scientific insights are interwoven with
modern machine learning.",http://arxiv.org/pdf/2307.05735v3,
Learning Stochastic Dynamical Systems as an Implicit Regularization with Graph Neural Networks,12/07/2023,"Jin Guo, Ting Gao, Yufu Lan, Peng Zhang, Sikun Yang, Jinqiao Duan","Stochastic Gumbel graph networks are proposed to learn high-dimensional time
series, where the observed dimensions are often spatially correlated. To that
end, the observed randomness and spatial-correlations are captured by learning
the drift and diffusion terms of the stochastic differential equation with a
Gumble matrix embedding, respectively. In particular, this novel framework
enables us to investigate the implicit regularization effect of the noise terms
in S-GGNs. We provide a theoretical guarantee for the proposed S-GGNs by
deriving the difference between the two corresponding loss functions in a small
neighborhood of weight. Then, we employ Kuramoto's model to generate data for
comparing the spectral density from the Hessian Matrix of the two loss
functions. Experimental results on real-world data, demonstrate that S-GGNs
exhibit superior convergence, robustness, and generalization, compared with
state-of-the-arts.",http://arxiv.org/pdf/2307.06097v1,
Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems,13/07/2023,"Ainesh Bakshi, Allen Liu, Ankur Moitra, Morris Yau","Recently Chen and Poor initiated the study of learning mixtures of linear
dynamical systems. While linear dynamical systems already have wide-ranging
applications in modeling time-series data, using mixture models can lead to a
better fit or even a richer understanding of underlying subpopulations
represented in the data. In this work we give a new approach to learning
mixtures of linear dynamical systems that is based on tensor decompositions. As
a result, our algorithm succeeds without strong separation conditions on the
components, and can be used to compete with the Bayes optimal clustering of the
trajectories. Moreover our algorithm works in the challenging
partially-observed setting. Our starting point is the simple but powerful
observation that the classic Ho-Kalman algorithm is a close relative of modern
tensor decomposition methods for learning latent variable models. This gives us
a playbook for how to extend it to work with more complicated generative
models.",http://arxiv.org/pdf/2307.06538v2,
Tapestry of Time and Actions: Modeling Human Activity Sequences using Temporal Point Process Flows,13/07/2023,"Vinayak Gupta, Srikanta Bedathur","Human beings always engage in a vast range of activities and tasks that
demonstrate their ability to adapt to different scenarios. Any human activity
can be represented as a temporal sequence of actions performed to achieve a
certain goal. Unlike the time series datasets extracted from electronics or
machines, these action sequences are highly disparate in their nature -- the
time to finish a sequence of actions can vary between different persons.
Therefore, understanding the dynamics of these sequences is essential for many
downstream tasks such as activity length prediction, goal prediction, next
action recommendation, etc. Existing neural network-based approaches that learn
a continuous-time activity sequence (or CTAS) are limited to the presence of
only visual data or are designed specifically for a particular task, i.e.,
limited to next action or goal prediction. In this paper, we present ProActive,
a neural marked temporal point process (MTPP) framework for modeling the
continuous-time distribution of actions in an activity sequence while
simultaneously addressing three high-impact problems -- next action prediction,
sequence-goal prediction, and end-to-end sequence generation. Specifically, we
utilize a self-attention module with temporal normalizing flows to model the
influence and the inter-arrival times between actions in a sequence. In
addition, we propose a novel addition over the ProActive model that can handle
variations in the order of actions, i.e., different methods of achieving a
given goal. We demonstrate that this variant can learn the order in which the
person or actor prefers to do their actions. Extensive experiments on sequences
derived from three activity recognition datasets show the significant accuracy
boost of ProActive over the state-of-the-art in terms of action and goal
prediction, and the first-ever application of end-to-end action sequence
generation.",http://arxiv.org/pdf/2307.10305v1,
High-Rate Phase Association with Travel Time Neural Fields,14/07/2023,"Cheng Shi, Giulio Poggiali, Chris Marone, Maarten V. de Hoop, Ivan Dokmanić","Earthquake science and seismology rely on the ability to associate seismic
waves with their originating earthquakes. Earthquake detection algorithms based
on deep learning have progressed rapidly and now routinely detect
microearthquakes with unprecedented clarity, providing information about fault
dynamics on increasingly finer spatiotemporal scales. However, this
densification of detections can overwhelm existing techniques for phase
association which rely on fixed wave speed models and associate events one by
one. These methods fail when the event rates become high or where the 4D
complexity of elastic wave speeds cannot be ignored. Here, we introduce HARPA,
a deep learning solution to this problem. HARPA is a high-rate association
framework which incorporates wave physics by leveraging deep generative models
and travel time neural fields. Instead of associating events one by one, it
lifts arrival sequences to probability distributions and compares them using an
optimal transport metric. The generative travel time neural fields are used to
estimate the wave speed simultaneously with association. HARPA outperforms
state-of-the-art association methods for both real seismic data and complex
synthetic models and paves the way for improved understanding of seismicity
while establishing a new seismic data analysis paradigm.",http://arxiv.org/pdf/2307.07572v4,
Synthetic Lagrangian Turbulence by Generative Diffusion Models,17/07/2023,"Tianyi Li, Luca Biferale, Fabio Bonaccorso, Martino Andrea Scarpolini, Michele Buzzicotti","Lagrangian turbulence lies at the core of numerous applied and fundamental
problems related to the physics of dispersion and mixing in engineering,
bio-fluids, atmosphere, oceans, and astrophysics. Despite exceptional
theoretical, numerical, and experimental efforts conducted over the past thirty
years, no existing models are capable of faithfully reproducing statistical and
topological properties exhibited by particle trajectories in turbulence. We
propose a machine learning approach, based on a state-of-the-art diffusion
model, to generate single-particle trajectories in three-dimensional turbulence
at high Reynolds numbers, thereby bypassing the need for direct numerical
simulations or experiments to obtain reliable Lagrangian data. Our model
demonstrates the ability to reproduce most statistical benchmarks across time
scales, including the fat-tail distribution for velocity increments, the
anomalous power law, and the increased intermittency around the dissipative
scale. Slight deviations are observed below the dissipative scale, particularly
in the acceleration and flatness statistics. Surprisingly, the model exhibits
strong generalizability for extreme events, producing events of higher
intensity and rarity that still match the realistic statistics. This paves the
way for producing synthetic high-quality datasets for pre-training various
downstream applications of Lagrangian turbulence.",http://arxiv.org/pdf/2307.08529v2,10.1038/s42256-024-00810-0
Sig-Splines: universal approximation and convex calibration of time series generative models,19/07/2023,"Magnus Wiese, Phillip Murray, Ralf Korn","We propose a novel generative model for multivariate discrete-time time
series data. Drawing inspiration from the construction of neural spline flows,
our algorithm incorporates linear transformations and the signature transform
as a seamless substitution for traditional neural networks. This approach
enables us to achieve not only the universality property inherent in neural
networks but also introduces convexity in the model's parameters.",http://arxiv.org/pdf/2307.09767v1,
Generative Language Models on Nucleotide Sequences of Human Genes,20/07/2023,"Musa Nuri Ihtiyar, Arzucan Ozgur","Language models, primarily transformer-based ones, obtained colossal success
in NLP. To be more precise, studies like BERT in NLU and works such as GPT-3
for NLG are very crucial. DNA sequences are very close to natural language in
terms of structure, so if the DNA-related bioinformatics domain is concerned,
discriminative models, like DNABert, exist. Yet, the generative side of the
coin is mainly unexplored to the best of our knowledge. Consequently, we
focused on developing an autoregressive generative language model like GPT-3
for DNA sequences. Because working with whole DNA sequences is challenging
without substantial computational resources, we decided to carry out our study
on a smaller scale, focusing on nucleotide sequences of human genes, unique
parts in DNA with specific functionalities, instead of the whole DNA. This
decision did not change the problem structure a lot due to the fact that both
DNA and genes can be seen as 1D sequences consisting of four different
nucleotides without losing much information and making too much simplification.
First of all, we systematically examined an almost entirely unexplored problem
and observed that RNNs performed the best while simple techniques like N-grams
were also promising. Another beneficial point was learning how to work with
generative models on languages we do not understand, unlike natural language.
How essential using real-life tasks beyond the classical metrics such as
perplexity is observed. Furthermore, checking whether the data-hungry nature of
these models can be changed through selecting a language with minimal
vocabulary size, four owing to four different types of nucleotides, is
examined. The reason for reviewing this was that choosing such a language might
make the problem easier. However, what we observed in this study was it did not
provide that much of a change in the amount of data needed.",http://arxiv.org/pdf/2307.10634v1,
"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting",21/07/2023,"Marcel Kollovieh, Abdul Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, Yuyang Wang","Diffusion models have achieved state-of-the-art performance in generative
modeling tasks across various domains. Prior works on time series diffusion
models have primarily focused on developing conditional models tailored to
specific forecasting or imputation tasks. In this work, we explore the
potential of task-agnostic, unconditional diffusion models for several time
series applications. We propose TSDiff, an unconditionally-trained diffusion
model for time series. Our proposed self-guidance mechanism enables
conditioning TSDiff for downstream tasks during inference, without requiring
auxiliary networks or altering the training procedure. We demonstrate the
effectiveness of our method on three different time series tasks: forecasting,
refinement, and synthetic data generation. First, we show that TSDiff is
competitive with several task-specific conditional forecasting methods
(predict). Second, we leverage the learned implicit probability density of
TSDiff to iteratively refine the predictions of base forecasters with reduced
computational overhead over reverse diffusion (refine). Notably, the generative
performance of the model remains intact -- downstream forecasters trained on
synthetic samples from TSDiff outperform forecasters that are trained on
samples from other state-of-the-art generative time series models, occasionally
even outperforming models trained on real data (synthesize).",http://arxiv.org/pdf/2307.11494v3,
Learning minimal representations of stochastic processes with variational autoencoders,21/07/2023,"Gabriel Fernández-Fernández, Carlo Manzo, Maciej Lewenstein, Alexandre Dauphin, Gorka Muñoz-Gil","Stochastic processes have found numerous applications in science, as they are
broadly used to model a variety of natural phenomena. Due to their intrinsic
randomness and uncertainty, they are however difficult to characterize. Here,
we introduce an unsupervised machine learning approach to determine the minimal
set of parameters required to effectively describe the dynamics of a stochastic
process. Our method builds upon an extended $\beta$-variational autoencoder
architecture. By means of simulated datasets corresponding to paradigmatic
diffusion models, we showcase its effectiveness in extracting the minimal
relevant parameters that accurately describe these dynamics. Furthermore, the
method enables the generation of new trajectories that faithfully replicate the
expected stochastic behavior. Overall, our approach enables for the autonomous
discovery of unknown parameters describing stochastic processes, hence
enhancing our comprehension of complex phenomena across various fields.",http://arxiv.org/pdf/2307.11608v2,
"TransFusion: Generating Long, High Fidelity Time Series using Diffusion Models with Transformers",24/07/2023,"Md Fahim Sikder, Resmi Ramachandranpillai, Fredrik Heintz","The generation of high-quality, long-sequenced time-series data is essential
due to its wide range of applications. In the past, standalone Recurrent and
Convolutional Neural Network-based Generative Adversarial Networks (GAN) were
used to synthesize time-series data. However, they are inadequate for
generating long sequences of time-series data due to limitations in the
architecture. Furthermore, GANs are well known for their training instability
and mode collapse problem. To address this, we propose TransFusion, a
diffusion, and transformers-based generative model to generate high-quality
long-sequence time-series data. We have stretched the sequence length to 384,
and generated high-quality synthetic data. Also, we introduce two evaluation
metrics to evaluate the quality of the synthetic data as well as its predictive
characteristics. We evaluate TransFusion with a wide variety of visual and
empirical metrics, and TransFusion outperforms the previous state-of-the-art by
a significant margin.",http://arxiv.org/pdf/2307.12667v2,
Graph-based Polyphonic Multitrack Music Generation,27/07/2023,"Emanuele Cosenza, Andrea Valenti, Davide Bacciu","Graphs can be leveraged to model polyphonic multitrack symbolic music, where
notes, chords and entire sections may be linked at different levels of the
musical hierarchy by tonal and rhythmic relationships. Nonetheless, there is a
lack of works that consider graph representations in the context of deep
learning systems for music generation. This paper bridges this gap by
introducing a novel graph representation for music and a deep Variational
Autoencoder that generates the structure and the content of musical graphs
separately, one after the other, with a hierarchical architecture that matches
the structural priors of music. By separating the structure and content of
musical graphs, it is possible to condition generation by specifying which
instruments are played at certain times. This opens the door to a new form of
human-computer interaction in the context of music co-creation. After training
the model on existing MIDI datasets, the experiments show that the model is
able to generate appealing short and long musical sequences and to
realistically interpolate between them, producing music that is tonally and
rhythmically consistent. Finally, the visualization of the embeddings shows
that the model is able to organize its latent space in accordance with known
musical concepts.",http://arxiv.org/pdf/2307.14928v1,
Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models,03/08/2023,"Joao Carvalho, An T. Le, Mark Baierl, Dorothea Koert, Jan Peters","Learning priors on trajectory distributions can help accelerate robot motion
planning optimization. Given previously successful plans, learning trajectory
generative models as priors for a new planning problem is highly desirable.
Prior works propose several ways on utilizing this prior to bootstrapping the
motion planning problem. Either sampling the prior for initializations or using
the prior distribution in a maximum-a-posterior formulation for trajectory
optimization. In this work, we propose learning diffusion models as priors. We
then can sample directly from the posterior trajectory distribution conditioned
on task goals, by leveraging the inverse denoising process of diffusion models.
Furthermore, diffusion has been recently shown to effectively encode data
multimodality in high-dimensional settings, which is particularly well-suited
for large trajectory dataset. To demonstrate our method efficacy, we compare
our proposed method - Motion Planning Diffusion - against several baselines in
simulated planar robot and 7-dof robot arm manipulator environments. To assess
the generalization capabilities of our method, we test it in environments with
previously unseen obstacles. Our experiments show that diffusion models are
strong priors to encode high-dimensional trajectory distributions of robot
motions.",http://arxiv.org/pdf/2308.01557v2,
Synthesizing Long-Term Human Motions with Diffusion Models via Coherent Sampling,03/08/2023,"Zhao Yang, Bing Su, Ji-Rong Wen","Text-to-motion generation has gained increasing attention, but most existing
methods are limited to generating short-term motions that correspond to a
single sentence describing a single action. However, when a text stream
describes a sequence of continuous motions, the generated motions corresponding
to each sentence may not be coherently linked. Existing long-term motion
generation methods face two main issues. Firstly, they cannot directly generate
coherent motions and require additional operations such as interpolation to
process the generated actions. Secondly, they generate subsequent actions in an
autoregressive manner without considering the influence of future actions on
previous ones. To address these issues, we propose a novel approach that
utilizes a past-conditioned diffusion model with two optional coherent sampling
methods: Past Inpainting Sampling and Compositional Transition Sampling. Past
Inpainting Sampling completes subsequent motions by treating previous motions
as conditions, while Compositional Transition Sampling models the distribution
of the transition as the composition of two adjacent motions guided by
different text prompts. Our experimental results demonstrate that our proposed
method is capable of generating compositional and coherent long-term 3D human
motions controlled by a user-instructed long text stream. The code is available
at
\href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}.",http://arxiv.org/pdf/2308.01850v1,
Generative Modelling of Lévy Area for High Order SDE Simulation,04/08/2023,"Andraž Jelinčič, Jiajie Tao, William F. Turner, Thomas Cass, James Foster, Hao Ni","It is well known that, when numerically simulating solutions to SDEs,
achieving a strong convergence rate better than O(\sqrt{h}) (where h is the
step size) requires the use of certain iterated integrals of Brownian motion,
commonly referred to as its ""L\'{e}vy areas"". However, these stochastic
integrals are difficult to simulate due to their non-Gaussian nature and for a
d-dimensional Brownian motion with d > 2, no fast almost-exact sampling
algorithm is known.
  In this paper, we propose L\'{e}vyGAN, a deep-learning-based model for
generating approximate samples of L\'{e}vy area conditional on a Brownian
increment. Due to our ""Bridge-flipping"" operation, the output samples match all
joint and conditional odd moments exactly. Our generator employs a tailored
GNN-inspired architecture, which enforces the correct dependency structure
between the output distribution and the conditioning variable. Furthermore, we
incorporate a mathematically principled characteristic-function based
discriminator. Lastly, we introduce a novel training mechanism termed
""Chen-training"", which circumvents the need for expensive-to-generate training
data-sets. This new training procedure is underpinned by our two main
theoretical results.
  For 4-dimensional Brownian motion, we show that L\'{e}vyGAN exhibits
state-of-the-art performance across several metrics which measure both the
joint and marginal distributions. We conclude with a numerical experiment on
the log-Heston model, a popular SDE in mathematical finance, demonstrating that
high-quality synthetic L\'{e}vy area can lead to high order weak convergence
and variance reduction when using multilevel Monte Carlo (MLMC).",http://arxiv.org/pdf/2308.02452v1,
A generative model for surrogates of spatial-temporal wildfire nowcasting,05/08/2023,"Sibo Cheng, Yike Guo, Rossella Arcucci","Recent increase in wildfires worldwide has led to the need for real-time fire
nowcasting. Physics-driven models, such as cellular automata and computational
fluid dynamics can provide high-fidelity fire spread simulations but they are
computationally expensive and time-consuming. Much effort has been put into
developing machine learning models for fire prediction. However, these models
are often region-specific and require a substantial quantity of simulation data
for training purpose. This results in a significant amount of computational
effort for different ecoregions. In this work, a generative model is proposed
using a three-dimensional Vector-Quantized Variational Autoencoders to generate
spatial-temporal sequences of unseen wildfire burned areas in a given
ecoregion. The model is tested in the ecoregion of a recent massive wildfire
event in California, known as the Chimney fire. Numerical results show that the
model succeed in generating coherent and structured fire scenarios, taking into
account the impact from geophysical variables, such as vegetation and slope.
Generated data are also used to train a surrogate model for predicting wildfire
dissemination, which has been tested on both simulation data and the real
Chimney fire event.",http://arxiv.org/pdf/2308.02810v1,
Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling,10/08/2023,"Ushnish Sengupta, Chinkuo Jao, Alberto Bernacchia, Sattar Vakili, Da-shan Shiu","Channel modelling is essential to designing modern wireless communication
systems. The increasing complexity of channel modelling and the cost of
collecting high-quality wireless channel data have become major challenges. In
this paper, we propose a diffusion model based channel sampling approach for
rapidly synthesizing channel realizations from limited data. We use a diffusion
model with a U Net based architecture operating in the frequency space domain.
To evaluate how well the proposed model reproduces the true distribution of
channels in the training dataset, two evaluation metrics are used: $i)$ the
approximate $2$-Wasserstein distance between real and generated distributions
of the normalized power spectrum in the antenna and frequency domains and $ii)$
precision and recall metric for distributions. We show that, compared to
existing GAN based approaches which suffer from mode collapse and unstable
training, our diffusion based approach trains stably and generates diverse and
high-fidelity samples from the true channel distribution. We also show that we
can pretrain the model on a simulated urban macro-cellular channel dataset and
fine-tune it on a smaller, out-of-distribution urban micro-cellular dataset,
therefore showing that it is feasible to model real world channels using
limited data with this approach.",http://arxiv.org/pdf/2308.05583v1,
Controlling Character Motions without Observable Driving Source,11/08/2023,"Weiyuan Li, Bin Dai, Ziyi Zhou, Qi Yao, Baoyuan Wang","How to generate diverse, life-like, and unlimited long head/body sequences
without any driving source? We argue that this under-investigated research
problem is non-trivial at all, and has unique technical challenges behind it.
Without semantic constraints from the driving sources, using the standard
autoregressive model to generate infinitely long sequences would easily result
in 1) out-of-distribution (OOD) issue due to the accumulated error, 2)
insufficient diversity to produce natural and life-like motion sequences and 3)
undesired periodic patterns along the time. To tackle the above challenges, we
propose a systematic framework that marries the benefits of VQ-VAE and a novel
token-level control policy trained with reinforcement learning using carefully
designed reward functions. A high-level prior model can be easily injected on
top to generate unlimited long and diverse sequences. Although we focus on no
driving sources now, our framework can be generalized for controlled synthesis
with explicit driving sources. Through comprehensive evaluations, we conclude
that our proposed framework can address all the above-mentioned challenges and
outperform other strong baselines very significantly.",http://arxiv.org/pdf/2308.06025v1,
Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data,14/08/2023,"Taizo Horikomi, Shouji Fujimoto, Atushi Ishikawa, Takayuki Mizuno","Following Mizuno, Fujimoto, and Ishikawa's research (Front. Phys. 2022), we
transpose geographical coordinates expressed in latitude and longitude into
distinctive location tokens that embody positions across varied spatial scales.
We encapsulate an individual daily trajectory as a sequence of tokens by adding
unique time interval tokens to the location tokens. Using the architecture of
an autoregressive language model, GPT-2, this sequence of tokens is trained
from scratch, allowing us to construct a deep learning model that sequentially
generates an individual daily trajectory. Environmental factors such as
meteorological conditions and individual attributes such as gender and age are
symbolized by unique special tokens, and by training these tokens and
trajectories on the GPT-2 architecture, we can generate trajectories that are
influenced by both environmental factors and individual attributes.",http://arxiv.org/pdf/2308.07940v1,
Portfolio Selection via Topological Data Analysis,15/08/2023,"Petr Sokerin, Kristian Kuznetsov, Elizaveta Makhneva, Alexey Zaytsev","Portfolio management is an essential part of investment decision-making.
However, traditional methods often fail to deliver reasonable performance. This
problem stems from the inability of these methods to account for the unique
characteristics of multivariate time series data from stock markets. We present
a two-stage method for constructing an investment portfolio of common stocks.
The method involves the generation of time series representations followed by
their subsequent clustering. Our approach utilizes features based on
Topological Data Analysis (TDA) for the generation of representations, allowing
us to elucidate the topological structure within the data. Experimental results
show that our proposed system outperforms other methods. This superior
performance is consistent over different time frames, suggesting the viability
of TDA as a powerful tool for portfolio selection.",http://arxiv.org/pdf/2308.07944v1,
Faster Training of Neural ODEs Using Gauß-Legendre Quadrature,21/08/2023,"Alexander Norcliffe, Marc Peter Deisenroth","Neural ODEs demonstrate strong performance in generative and time-series
modelling. However, training them via the adjoint method is slow compared to
discrete models due to the requirement of numerically solving ODEs. To speed
neural ODEs up, a common approach is to regularise the solutions. However, this
approach may affect the expressivity of the model; when the trajectory itself
matters, this is particularly important. In this paper, we propose an
alternative way to speed up the training of neural ODEs. The key idea is to
speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve
integrals faster than ODE-based methods while remaining memory efficient. We
also extend the idea to training SDEs using the Wong-Zakai theorem, by training
a corresponding ODE and transferring the parameters. Our approach leads to
faster training of neural ODEs, especially for large models. It also presents a
new way to train SDE-based models.",http://arxiv.org/pdf/2308.10644v1,
LongDanceDiff: Long-term Dance Generation with Conditional Diffusion Model,23/08/2023,"Siqi Yang, Zejun Yang, Zhisheng Wang","Dancing with music is always an essential human art form to express emotion.
Due to the high temporal-spacial complexity, long-term 3D realist dance
generation synchronized with music is challenging. Existing methods suffer from
the freezing problem when generating long-term dances due to error accumulation
and training-inference discrepancy. To address this, we design a conditional
diffusion model, LongDanceDiff, for this sequence-to-sequence long-term dance
generation, addressing the challenges of temporal coherency and spatial
constraint. LongDanceDiff contains a transformer-based diffusion model, where
the input is a concatenation of music, past motions, and noised future motions.
This partial noising strategy leverages the full-attention mechanism and learns
the dependencies among music and past motions. To enhance the diversity of
generated dance motions and mitigate the freezing problem, we introduce a
mutual information minimization objective that regularizes the dependency
between past and future motions. We also address common visual quality issues
in dance generation, such as foot sliding and unsmooth motion, by incorporating
spatial constraints through a Global-Trajectory Modulation (GTM) layer and
motion perceptual losses, thereby improving the smoothness and naturalness of
motion generation. Extensive experiments demonstrate a significant improvement
in our approach over the existing state-of-the-art methods. We plan to release
our codes and models soon.",http://arxiv.org/pdf/2308.11945v1,
Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network,23/08/2023,"Peer Nagy, Sascha Frey, Silvia Sapora, Kang Li, Anisoara Calinescu, Stefan Zohren, Jakob Foerster","Developing a generative model of realistic order flow in financial markets is
a challenging open problem, with numerous applications for market participants.
Addressing this, we propose the first end-to-end autoregressive generative
model that generates tokenized limit order book (LOB) messages. These messages
are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle
long sequences efficiently, the model employs simplified structured state-space
layers to process sequences of order book states and tokenized messages. Using
LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message
data, converting groups of successive digits to tokens, similar to tokenization
in large language models. Out-of-sample results show promising performance in
approximating the data distribution, as evidenced by low model perplexity.
Furthermore, the mid-price returns calculated from the generated order flow
exhibit a significant correlation with the data, indicating impressive
conditional forecast performance. Due to the granularity of generated data, and
the accuracy of the model, it offers new application areas for future work
beyond forecasting, e.g. acting as a world model in high-frequency financial
reinforcement learning applications. Overall, our results invite the use and
extension of the model in the direction of autoregressive large financial
models for the generation of high-frequency financial data and we commit to
open-sourcing our code to facilitate future research.",http://arxiv.org/pdf/2309.00638v1,
KL Convergence Guarantees for Score diffusion models under minimal data assumptions,23/08/2023,"Giovanni Conforti, Alain Durmus, Marta Gentiloni Silveri","Diffusion models are a new class of generative models that revolve around the
estimation of the score function associated with a stochastic differential
equation. Subsequent to its acquisition, the approximated score function is
then harnessed to simulate the corresponding time-reversal process, ultimately
enabling the generation of approximate data samples. Despite their evident
practical significance these models carry, a notable challenge persists in the
form of a lack of comprehensive quantitative results, especially in scenarios
involving non-regular scores and estimators. In almost all reported bounds in
Kullback Leibler (KL) divergence, it is assumed that either the score function
or its approximation is Lipschitz uniformly in time. However, this condition is
very restrictive in practice or appears to be difficult to establish. To
circumvent this issue, previous works mainly focused on establishing
convergence bounds in KL for an early stopped version of the diffusion model
and a smoothed version of the data distribution, or assuming that the data
distribution is supported on a compact manifold. These explorations have led to
interesting bounds in either Wasserstein or Fortet-Mourier metrics. However,
the question remains about the relevance of such early-stopping procedure or
compactness conditions. In particular, if there exist a natural and mild
condition ensuring explicit and sharp convergence bounds in KL. In this
article, we tackle the aforementioned limitations by focusing on score
diffusion models with fixed step size stemming from the Ornstein-Uhlenbeck
semigroup and its kinetic counterpart. Our study provides a rigorous analysis,
yielding simple, improved and sharp convergence bounds in KL applicable to any
data distribution with finite Fisher information with respect to the standard
Gaussian distribution.",http://arxiv.org/pdf/2308.12240v2,
Low-count Time Series Anomaly Detection,24/08/2023,"Philipp Renz, Kurt Cutajar, Niall Twomey, Gavin K. C. Cheung, Hanting Xie","Low-count time series describe sparse or intermittent events, which are
prevalent in large-scale online platforms that capture and monitor diverse data
types. Several distinct challenges surface when modelling low-count time
series, particularly low signal-to-noise ratios (when anomaly signatures are
provably undetectable), and non-uniform performance (when average metrics are
not representative of local behaviour). The time series anomaly detection
community currently lacks explicit tooling and processes to model and reliably
detect anomalies in these settings. We address this gap by introducing a novel
generative procedure for creating benchmark datasets comprising of low-count
time series with anomalous segments. Via a mixture of theoretical and empirical
analysis, our work explains how widely-used algorithms struggle with the
distribution overlap between normal and anomalous segments. In order to
mitigate this shortcoming, we then leverage our findings to demonstrate how
anomaly score smoothing consistently improves performance. The practical
utility of our analysis and recommendation is validated on a real-world dataset
containing sales data for retail stores.",http://arxiv.org/pdf/2308.12925v1,10.1109/MLSP55844.2023.10285979
Time-to-Pattern: Information-Theoretic Unsupervised Learning for Scalable Time Series Summarization,26/08/2023,"Alireza Ghods, Trong Nghia Hoang, Diane Cook","Data summarization is the process of generating interpretable and
representative subsets from a dataset. Existing time series summarization
approaches often search for recurring subsequences using a set of manually
devised similarity functions to summarize the data. However, such approaches
are fraught with limitations stemming from an exhaustive search coupled with a
heuristic definition of series similarity. Such approaches affect the diversity
and comprehensiveness of the generated data summaries. To mitigate these
limitations, we introduce an approach to time series summarization, called
Time-to-Pattern (T2P), which aims to find a set of diverse patterns that
together encode the most salient information, following the notion of minimum
description length. T2P is implemented as a deep generative model that learns
informative embeddings of the discrete time series on a latent space
specifically designed to be interpretable. Our synthetic and real-world
experiments reveal that T2P discovers informative patterns, even in noisy and
complex settings. Furthermore, our results also showcase the improved
performance of T2P over previous work in pattern diversity and processing
scalability, which conclusively demonstrate the algorithm's effectiveness for
time series summarization.",http://arxiv.org/pdf/2308.13722v1,
Transfusor: Transformer Diffusor for Controllable Human-like Generation of Vehicle Lane Changing Trajectories,28/08/2023,"Jiqian Dong, Sikai Chen, Samuel Labi","With ongoing development of autonomous driving systems and increasing desire
for deployment, researchers continue to seek reliable approaches for ADS
systems. The virtual simulation test (VST) has become a prominent approach for
testing autonomous driving systems (ADS) and advanced driver assistance systems
(ADAS) due to its advantages of fast execution, low cost, and high
repeatability. However, the success of these simulation-based experiments
heavily relies on the realism of the testing scenarios. It is needed to create
more flexible and high-fidelity testing scenarios in VST in order to increase
the safety and reliabilityof ADS and ADAS.To address this challenge, this paper
introduces the ""Transfusor"" model, which leverages the transformer and diffusor
models (two cutting-edge deep learning generative technologies). The primary
objective of the Transfusor model is to generate highly realistic and
controllable human-like lane-changing trajectories in highway scenarios.
Extensive experiments were carried out, and the results demonstrate that the
proposed model effectively learns the spatiotemporal characteristics of humans'
lane-changing behaviors and successfully generates trajectories that closely
mimic real-world human driving. As such, the proposed model can play a critical
role of creating more flexible and high-fidelity testing scenarios in the VST,
ultimately leading to safer and more reliable ADS and ADAS.",http://arxiv.org/pdf/2308.14943v1,
MadSGM: Multivariate Anomaly Detection with Score-based Generative Models,29/08/2023,"Haksoo Lim, Sewon Park, Minjung Kim, Jaehoon Lee, Seonkyu Lim, Noseong Park","The time-series anomaly detection is one of the most fundamental tasks for
time-series. Unlike the time-series forecasting and classification, the
time-series anomaly detection typically requires unsupervised (or
self-supervised) training since collecting and labeling anomalous observations
are difficult. In addition, most existing methods resort to limited forms of
anomaly measurements and therefore, it is not clear whether they are optimal in
all circumstances. To this end, we present a multivariate time-series anomaly
detector based on score-based generative models, called MadSGM, which considers
the broadest ever set of anomaly measurement factors: i) reconstruction-based,
ii) density-based, and iii) gradient-based anomaly measurements. We also design
a conditional score network and its denoising score matching loss for the
time-series anomaly detection. Experiments on five real-world benchmark
datasets illustrate that MadSGM achieves the most robust and accurate
predictions.",http://arxiv.org/pdf/2308.15069v1,
Learning Sequential Information in Task-based fMRI for Synthetic Data Augmentation,29/08/2023,"Jiyao Wang, Nicha C. Dvornek, Lawrence H. Staib, James S. Duncan","Insufficiency of training data is a persistent issue in medical image
analysis, especially for task-based functional magnetic resonance images (fMRI)
with spatio-temporal imaging data acquired using specific cognitive tasks. In
this paper, we propose an approach for generating synthetic fMRI sequences that
can then be used to create augmented training datasets in downstream learning
tasks. To synthesize high-resolution task-specific fMRI, we adapt the
$\alpha$-GAN structure, leveraging advantages of both GAN and variational
autoencoder models, and propose different alternatives in aggregating temporal
information. The synthetic images are evaluated from multiple perspectives
including visualizations and an autism spectrum disorder (ASD) classification
task. The results show that the synthetic task-based fMRI can provide effective
data augmentation in learning the ASD classification task.",http://arxiv.org/pdf/2308.15564v1,
Fully Embedded Time-Series Generative Adversarial Networks,30/08/2023,"Joe Beck, Subhadeep Chakraborty","Generative Adversarial Networks (GANs) should produce synthetic data that
fits the underlying distribution of the data being modeled. For real valued
time-series data, this implies the need to simultaneously capture the static
distribution of the data, but also the full temporal distribution of the data
for any potential time horizon. This temporal element produces a more complex
problem that can potentially leave current solutions under-constrained,
unstable during training, or prone to varying degrees of mode collapse. In
FETSGAN, entire sequences are translated directly to the generator's sampling
space using a seq2seq style adversarial auto encoder (AAE), where adversarial
training is used to match the training distribution in both the feature space
and the lower dimensional sampling space. This additional constraint provides a
loose assurance that the temporal distribution of the synthetic samples will
not collapse. In addition, the First Above Threshold (FAT) operator is
introduced to supplement the reconstruction of encoded sequences, which
improves training stability and the overall quality of the synthetic data being
generated. These novel contributions demonstrate a significant improvement to
the current state of the art for adversarial learners in qualitative measures
of temporal similarity and quantitative predictive ability of data generated
through FETSGAN.",http://arxiv.org/pdf/2308.15730v2,10.1007/s00521-024-09825-5
Classification of Anomalies in Telecommunication Network KPI Time Series,30/08/2023,"Korantin Bordeau-Aubert, Justin Whatley, Sylvain Nadeau, Tristan Glatard, Brigitte Jaumard","The increasing complexity and scale of telecommunication networks have led to
a growing interest in automated anomaly detection systems. However, the
classification of anomalies detected on network Key Performance Indicators
(KPI) has received less attention, resulting in a lack of information about
anomaly characteristics and classification processes. To address this gap, this
paper proposes a modular anomaly classification framework. The framework
assumes separate entities for the anomaly classifier and the detector, allowing
for a distinct treatment of anomaly detection and classification tasks on time
series. The objectives of this study are (1) to develop a time series simulator
that generates synthetic time series resembling real-world network KPI
behavior, (2) to build a detection model to identify anomalies in the time
series, (3) to build classification models that accurately categorize detected
anomalies into predefined classes (4) to evaluate the classification framework
performance on simulated and real-world network KPI time series. This study has
demonstrated the good performance of the anomaly classification models trained
on simulated anomalies when applied to real-world network time series data.",http://arxiv.org/pdf/2308.16279v1,
Zero-Shot Conditioning of Score-Based Diffusion Models by Neuro-Symbolic Constraints,31/08/2023,"Davide Scassola, Sebastiano Saccani, Ginevra Carbone, Luca Bortolussi","Score-based diffusion models have emerged as effective approaches for both
conditional and unconditional generation. Still conditional generation is based
on either a specific training of a conditional model or classifier guidance,
which requires training a noise-dependent classifier, even when a classifier
for uncorrupted data is given. We propose a method that, given a pre-trained
unconditional score-based generative model, samples from the conditional
distribution under arbitrary logical constraints, without requiring additional
training. Differently from other zero-shot techniques, that rather aim at
generating valid conditional samples, our method is designed for approximating
the true conditional distribution. Firstly, we show how to manipulate the
learned score in order to sample from an un-normalized distribution conditional
on a user-defined constraint. Then, we define a flexible and numerically stable
neuro-symbolic framework for encoding soft logical constraints. Combining these
two ingredients we obtain a general, but approximate, conditional sampling
algorithm. We further developed effective heuristics aimed at improving the
approximation. Finally, we show the effectiveness of our approach in
approximating conditional distributions for various types of constraints and
data: tabular data, images and time series.",http://arxiv.org/pdf/2308.16534v2,
Representation Learning for Sequential Volumetric Design Tasks,05/09/2023,"Md Ferdous Alam, Yi Wang, Chin-Yi Cheng, Jieliang Luo","Volumetric design, also called massing design, is the first and critical step
in professional building design which is sequential in nature. As the
volumetric design process requires careful design decisions and iterative
adjustments, the underlying sequential design process encodes valuable
information for designers. Many efforts have been made to automatically
generate reasonable volumetric designs, but the quality of the generated design
solutions varies, and evaluating a design solution requires either a
prohibitively comprehensive set of metrics or expensive human expertise. While
previous approaches focused on learning only the final design instead of
sequential design tasks, we propose to encode the design knowledge from a
collection of expert or high-performing design sequences and extract useful
representations using transformer-based models. Later we propose to utilize the
learned representations for crucial downstream applications such as design
preference evaluation and procedural design generation. We develop the
preference model by estimating the density of the learned representations
whereas we train an autoregressive transformer model for sequential design
generation. We demonstrate our ideas by leveraging a novel dataset of thousands
of sequential volumetric designs. Our preference model can compare two
arbitrarily given design sequences and is almost $90\%$ accurate in evaluation
against random design sequences. Our autoregressive model is also capable of
autocompleting a volumetric design sequence from a partial design sequence.",http://arxiv.org/pdf/2309.02583v3,
Broadband Ground Motion Synthesis via Generative Adversarial Neural Operators: Development and Validation,07/09/2023,"Yaozhong Shi, Grigorios Lavrentiadis, Domniki Asimaki, Zachary E. Ross, Kamyar Azizzadenesheli","We present a data-driven framework for ground-motion synthesis that generates
three-component acceleration time histories conditioned on moment magnitude,
rupture distance , time-average shear-wave velocity at the top $30m$
($V_{S30}$), and style of faulting. We use a Generative Adversarial Neural
Operator (GANO), a resolution invariant architecture that guarantees model
training independent of the data sampling frequency. We first present the
conditional ground-motion synthesis algorithm (cGM-GANO) and discuss its
advantages compared to previous work. We next train cGM-GANO on simulated
ground motions generated by the Southern California Earthquake Center Broadband
Platform (BBP) and on recorded KiK-net data and show that the model can learn
the overall magnitude, distance, and $V_{S30}$ scaling of effective amplitude
spectra (EAS) ordinates and pseudo-spectral accelerations (PSA). Results
specifically show that cGM-GANO produces consistent median scaling with the
training data for the corresponding tectonic environments over a wide range of
frequencies for scenarios with sufficient data coverage. For the BBP dataset,
cGM-GANO cannot learn the ground motion scaling of the stochastic frequency
components; for the KiK-net dataset, the largest misfit is observed at short
distances and for soft soil conditions due to the scarcity of such data. Except
for these conditions, the aleatory variability of EAS and PSA are captured
reasonably well. Lastly, cGM-GANO produces similar median scaling to
traditional GMMs for frequencies greater than 1Hz for both PSA and EAS but
underestimates the aleatory variability of EAS. Discrepancies in the
comparisons between the synthetic ground motions and GMMs are attributed to
inconsistencies between the training dataset and the datasets used in GMM
development. Our pilot study demonstrates GANO's potential for efficient
synthesis of broad-band ground motions",http://arxiv.org/pdf/2309.03447v3,
A Probabilistic Semi-Supervised Approach with Triplet Markov Chains,07/09/2023,"Katherine Morales, Yohan Petetin","Triplet Markov chains are general generative models for sequential data which
take into account three kinds of random variables: (noisy) observations, their
associated discrete labels and latent variables which aim at strengthening the
distribution of the observations and their associated labels. However, in
practice, we do not have at our disposal all the labels associated to the
observations to estimate the parameters of such models. In this paper, we
propose a general framework based on a variational Bayesian inference to train
parameterized triplet Markov chain models in a semi-supervised context. The
generality of our approach enables us to derive semi-supervised algorithms for
a variety of generative models for sequential Bayesian classification.",http://arxiv.org/pdf/2309.03707v1,
TSGBench: Time Series Generation Benchmark,07/09/2023,"Yihao Ang, Qiang Huang, Yifan Bao, Anthony K. H. Tung, Zhiyong Huang","Synthetic Time Series Generation (TSG) is crucial in a range of applications,
including data augmentation, anomaly detection, and privacy preservation.
Although significant strides have been made in this field, existing methods
exhibit three key limitations: (1) They often benchmark against similar model
types, constraining a holistic view of performance capabilities. (2) The use of
specialized synthetic and private datasets introduces biases and hampers
generalizability. (3) Ambiguous evaluation measures, often tied to custom
networks or downstream tasks, hinder consistent and fair comparison.
  To overcome these limitations, we introduce \textsf{TSGBench}, the inaugural
Time Series Generation Benchmark, designed for a unified and comprehensive
assessment of TSG methods. It comprises three modules: (1) a curated collection
of publicly available, real-world datasets tailored for TSG, together with a
standardized preprocessing pipeline; (2) a comprehensive evaluation measures
suite including vanilla measures, new distance-based assessments, and
visualization tools; (3) a pioneering generalization test rooted in Domain
Adaptation (DA), compatible with all methods. We have conducted comprehensive
experiments using \textsf{TSGBench} across a spectrum of ten real-world
datasets from diverse domains, utilizing ten advanced TSG methods and twelve
evaluation measures. The results highlight the reliability and efficacy of
\textsf{TSGBench} in evaluating TSG methods. Crucially, \textsf{TSGBench}
delivers a statistical analysis of the performance rankings of these methods,
illuminating their varying performance across different datasets and measures
and offering nuanced insights into the effectiveness of each method.",http://arxiv.org/pdf/2309.03755v2,
Generating drawdown-realistic financial price paths using path signatures,08/09/2023,"Emiel Lemahieu, Kris Boudt, Maarten Wyns","A novel generative machine learning approach for the simulation of sequences
of financial price data with drawdowns quantifiably close to empirical data is
introduced. Applications such as pricing drawdown insurance options or
developing portfolio drawdown control strategies call for a host of
drawdown-realistic paths. Historical scenarios may be insufficient to
effectively train and backtest the strategy, while standard parametric Monte
Carlo does not adequately preserve drawdowns. We advocate a non-parametric
Monte Carlo approach combining a variational autoencoder generative model with
a drawdown reconstruction loss function. To overcome issues of numerical
complexity and non-differentiability, we approximate drawdown as a linear
function of the moments of the path, known in the literature as path
signatures. We prove the required regularity of drawdown function and
consistency of the approximation. Furthermore, we obtain close numerical
approximations using linear regression for fractional Brownian and empirical
data. We argue that linear combinations of the moments of a path yield a
mathematically non-trivial smoothing of the drawdown function, which gives one
leeway to simulate drawdown-realistic price paths by including drawdown
evaluation metrics in the learning objective. We conclude with numerical
experiments on mixed equity, bond, real estate and commodity portfolios and
obtain a host of drawdown-realistic paths.",http://arxiv.org/pdf/2309.04507v1,
Masked Generative Modeling with Enhanced Sampling Scheme,14/09/2023,"Daesoo Lee, Erlend Aune, Sara Malacarne","This paper presents a novel sampling scheme for masked non-autoregressive
generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and
Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme
(ESS) to overcome these limitations. ESS explicitly ensures both sample
diversity and fidelity, and consists of three stages: Naive Iterative Decoding,
Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a
token set using the naive iterative decoding as proposed in MaskGIT, ensuring
sample diversity. Then, the token set undergoes the critical reverse sampling,
masking tokens leading to unrealistic samples. After that, critical resampling
reconstructs masked tokens until the final sampling step is reached to ensure
high fidelity. Critical resampling uses confidence scores obtained from a
self-Token-Critic to better measure the realism of sampled tokens, while
critical reverse sampling uses the structure of the quantized latent vector
space to discover unrealistic sample paths. We demonstrate significant
performance gains of ESS in both unconditional sampling and class-conditional
sampling using all the 128 datasets in the UCR Time Series archive.",http://arxiv.org/pdf/2309.07945v1,
Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context,14/09/2023,"Haochong Xia, Shuo Sun, Xinrun Wang, Bo An","Financial simulators play an important role in enhancing forecasting
accuracy, managing risks, and fostering strategic financial decision-making.
Despite the development of financial market simulation methodologies, existing
frameworks often struggle with adapting to specialized simulation context. We
pinpoint the challenges as i) current financial datasets do not contain context
labels; ii) current techniques are not designed to generate financial data with
context as control, which demands greater precision compared to other
modalities; iii) the inherent difficulties in generating context-aligned,
high-fidelity data given the non-stationary, noisy nature of financial data. To
address these challenges, our contributions are: i) we proposed the Contextual
Market Dataset with market dynamics, stock ticker, and history state as
context, leveraging a market dynamics modeling method that combines linear
regression and Dynamic Time Warping clustering to extract market dynamics; ii)
we present Market-GAN, a novel architecture incorporating a Generative
Adversarial Networks (GAN) for the controllable generation with context, an
autoencoder for learning low-dimension features, and supervisors for knowledge
transfer; iii) we introduce a two-stage training scheme to ensure that
Market-GAN captures the intrinsic market distribution with multiple objectives.
In the pertaining stage, with the use of the autoencoder and supervisors, we
prepare the generator with a better initialization for the adversarial training
stage. We propose a set of holistic evaluation metrics that consider alignment,
fidelity, data usability on downstream tasks, and market facts. We evaluate
Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and
showcase superior performance in comparison to 4 state-of-the-art time-series
generative models.",http://arxiv.org/pdf/2309.07708v2,
An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone,14/09/2023,"Ijaz Ul Haq, Byung Suk Lee, Donna M. Rizzo, Julia N Perdrial","This paper presents an automated machine learning framework designed to
assist hydrologists in detecting anomalies in time series data generated by
sensors in a research watershed in the northeastern United States critical
zone. The framework specifically focuses on identifying peak-pattern anomalies,
which may arise from sensor malfunctions or natural phenomena. However, the use
of classification methods for anomaly detection poses challenges, such as the
requirement for labeled data as ground truth and the selection of the most
suitable deep learning model for the given task and dataset. To address these
challenges, our framework generates labeled datasets by injecting synthetic
peak patterns into synthetically generated time series data and incorporates an
automated hyperparameter optimization mechanism. This mechanism generates an
optimized model instance with the best architectural and training parameters
from a pool of five selected models, namely Temporal Convolutional Network
(TCN), InceptionTime, MiniRocket, Residual Networks (ResNet), and Long
Short-Term Memory (LSTM). The selection is based on the user's preferences
regarding anomaly detection accuracy and computational cost. The framework
employs Time-series Generative Adversarial Networks (TimeGAN) as the synthetic
dataset generator. The generated model instances are evaluated using a
combination of accuracy and computational cost metrics, including training time
and memory, during the anomaly detection process. Performance evaluation of the
framework was conducted using a dataset from a watershed, demonstrating
consistent selection of the most fitting model instance that satisfies the
user's preferences.",http://arxiv.org/pdf/2309.07992v2,
Learning Generative Models for Lumped Rainfall-Runoff Modeling,18/09/2023,"Yang Yang, Ting Fong May Chui","This study presents a novel generative modeling approach to rainfall-runoff
modeling, focusing on the synthesis of realistic daily catchment runoff time
series in response to catchment-averaged climate forcing. Unlike traditional
process-based lumped hydrologic models that depend on predefined sets of
variables describing catchment physical properties, our approach uses a small
number of latent variables to characterize runoff generation processes. These
latent variables encapsulate the intrinsic properties of a catchment and can be
inferred from catchment climate forcing and discharge data. By sampling from
the latent variable space, the model generates runoff time series that closely
resemble real-world observations. In this study, we trained the generative
models using neural networks on data from over 3,000 global catchments and
achieved prediction accuracies comparable to current deep learning models and
various conventional lumped models, both within the catchments from the
training set and from other regions worldwide. This suggests that the runoff
generation process of catchments can be effectively captured by a
low-dimensional latent representation. Yet, challenges such as equifinality and
optimal determination of latent variables remain. Future research should focus
on refining parameter estimation methods and exploring the physical meaning of
these latent dimensions to improve model applicability and robustness. This
generative approach offers a promising alternative for hydrological modeling
that requires minimal assumptions about the physical processes of the
catchment.",http://arxiv.org/pdf/2309.09904v3,
MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation,19/09/2023,"Xinda Wu, Zhijie Huang, Kejun Zhang, Jiaxing Yu, Xu Tan, Tieyao Zhang, Zihao Wang, Lingyun Sun","Pre-trained language models have achieved impressive results in various music
understanding and generation tasks. However, existing pre-training methods for
symbolic melody generation struggle to capture multi-scale, multi-dimensional
structural information in note sequences, due to the domain knowledge
discrepancy between text and music. Moreover, the lack of available large-scale
symbolic melody datasets limits the pre-training improvement. In this paper, we
propose MelodyGLM, a multi-task pre-training framework for generating melodies
with long-term structure. We design the melodic n-gram and long span sampling
strategies to create local and global blank infilling tasks for modeling the
local and global structures in melodies. Specifically, we incorporate pitch
n-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram
blank infilling tasks for modeling the multi-dimensional structures in
melodies. To this end, we have constructed a large-scale symbolic melody
dataset, MelodyNet, containing more than 0.4 million melody pieces. MelodyNet
is utilized for large-scale pre-training and domain-specific n-gram lexicon
construction. Both subjective and objective evaluations demonstrate that
MelodyGLM surpasses the standard and previous pre-training methods. In
particular, subjective evaluations show that, on the melody continuation task,
MelodyGLM gains average improvements of 0.82, 0.87, 0.78, and 0.94 in
consistency, rhythmicity, structure, and overall quality, respectively.
Notably, MelodyGLM nearly matches the quality of human-composed melodies on the
melody inpainting task.",http://arxiv.org/pdf/2309.10738v2,
Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling,21/09/2023,"Zheng Nan, Ting Dang, Vidhyasaharan Sethu, Beena Ahmed","Connectionist temporal classification (CTC) is commonly adopted for sequence
modeling tasks like speech recognition, where it is necessary to preserve order
between the input and target sequences. However, CTC is only applied to
deterministic sequence models, where the latent space is discontinuous and
sparse, which in turn makes them less capable of handling data variability when
compared to variational models. In this paper, we integrate CTC with a
variational model and derive loss functions that can be used to train more
generalizable sequence models that preserve order. Specifically, we derive two
versions of the novel variational CTC based on two reasonable assumptions, the
first being that the variational latent variables at each time step are
conditionally independent; and the second being that these latent variables are
Markovian. We show that both loss functions allow direct optimization of the
variational lower bound for the model log-likelihood, and present
computationally tractable forms for implementing them.",http://arxiv.org/pdf/2309.11983v3,
A Diffusion-Model of Joint Interactive Navigation,21/09/2023,"Matthew Niedoba, Jonathan Wilder Lavington, Yunpeng Liu, Vasileios Lioutas, Justice Sefas, Xiaoxuan Liang, Dylan Green, Setareh Dabiri, Berend Zwartsenberg, Adam Scibior, Frank Wood","Simulation of autonomous vehicle systems requires that simulated traffic
participants exhibit diverse and realistic behaviors. The use of prerecorded
real-world traffic scenarios in simulation ensures realism but the rarity of
safety critical events makes large scale collection of driving scenarios
expensive. In this paper, we present DJINN - a diffusion based method of
generating traffic scenarios. Our approach jointly diffuses the trajectories of
all agents, conditioned on a flexible set of state observations from the past,
present, or future. On popular trajectory forecasting datasets, we report state
of the art performance on joint trajectory metrics. In addition, we demonstrate
how DJINN flexibly enables direct test-time sampling from a variety of valuable
conditional distributions including goal-based sampling, behavior-class
sampling, and scenario editing.",http://arxiv.org/pdf/2309.12508v2,
State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory,23/09/2023,"Shida Wang, Beichen Xue","State-space models have gained popularity in sequence modelling due to their
simple and efficient network structures. However, the absence of nonlinear
activation along the temporal direction limits the model's capacity. In this
paper, we prove that stacking state-space models with layer-wise nonlinear
activation is sufficient to approximate any continuous sequence-to-sequence
relationship. Our findings demonstrate that the addition of layer-wise
nonlinear activation enhances the model's capacity to learn complex sequence
patterns. Meanwhile, it can be seen both theoretically and empirically that the
state-space models do not fundamentally resolve the issue of exponential
decaying memory. Theoretical results are justified by numerical verifications.",http://arxiv.org/pdf/2309.13414v3,
ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs,23/09/2023,"Max Bagga, Hyunbae Jeon, Alex Issokson","Electrocardiography (ECG) signal generation has been heavily explored using
generative adversarial networks (GAN) because the implementation of 12-lead
ECGs is not always feasible. The GAN models have achieved remarkable results in
reproducing ECG signals but are only designed for multiple lead inputs and the
features the GAN model preserves have not been identified-limiting the
generated signals use in cardiovascular disease (CVD)-predictive models. This
paper presents ECGNet which is a procedure that generates a complete set of
12-lead ECG signals from any single lead input using a GAN framework with a
bidirectional long short-term memory (LSTM) generator and a convolutional
neural network (CNN) discriminator. Cross and auto-correlation analysis
performed on the generated signals identifies features conserved during the
signal generation-i.e., features that can characterize the unique-nature of
each signal and thus likely indicators of CVD. Finally, by using ECG signals
annotated with the CVD-indicative features detailed by the correlation analysis
as inputs for a CVD-onset-predictive CNN model, we overcome challenges
preventing the prediction of multiple-CVD targets. Our models are experimented
on 15s 12-lead ECG dataset recorded using MyoVista's wavECG. Functional outcome
data for each patient is recorded and used in the CVD-predictive model. Our
best GAN model achieves state-of-the-art accuracy with Frechet Distance (FD)
scores of 4.73, 4.89, 5.18, 4.77, 4.71, and 5.55 on the V1-V6 pre-cordial leads
respectively and shows strength in preserving the P-Q segments and R-peaks in
the generated signals. To the best of our knowledge, ECGNet is the first to
predict all of the remaining eleven leads from the input of any single lead.",http://arxiv.org/pdf/2310.03753v1,
NetDiffus: Network Traffic Generation by Diffusion Models through Time-Series Imaging,23/09/2023,"Nirhoshan Sivaroopan, Dumindu Bandara, Chamara Madarasingha, Guilluame Jourjon, Anura Jayasumana, Kanchana Thilakarathna","Network data analytics are now at the core of almost every networking
solution. Nonetheless, limited access to networking data has been an enduring
challenge due to many reasons including complexity of modern networks,
commercial sensitivity, privacy and regulatory constraints. In this work, we
explore how to leverage recent advancements in Diffusion Models (DM) to
generate synthetic network traffic data. We develop an end-to-end framework -
NetDiffus that first converts one-dimensional time-series network traffic into
two-dimensional images, and then synthesizes representative images for the
original data. We demonstrate that NetDiffus outperforms the state-of-the-art
traffic generation methods based on Generative Adversarial Networks (GANs) by
providing 66.4% increase in fidelity of the generated data and 18.1% increase
in downstream machine learning tasks. We evaluate NetDiffus on seven diverse
traffic traces and show that utilizing synthetic data significantly improves
traffic fingerprinting, anomaly detection and traffic classification.",http://arxiv.org/pdf/2310.04429v1,
Deep Generative Methods for Producing Forecast Trajectories in Power Systems,26/09/2023,"Nathan Weill, Jonathan Dumas","With the expansion of renewables in the electricity mix, power grid
variability will increase, hence a need to robustify the system to guarantee
its security. Therefore, Transport System Operators (TSOs) must conduct
analyses to simulate the future functioning of power systems. Then, these
simulations are used as inputs in decision-making processes. In this context,
we investigate using deep learning models to generate energy production and
load forecast trajectories. To capture the spatiotemporal correlations in these
multivariate time series, we adapt autoregressive networks and normalizing
flows, demonstrating their effectiveness against the current copula-based
statistical approach. We conduct extensive experiments on the French TSO RTE
wind forecast data and compare the different models with \textit{ad hoc}
evaluation metrics for time series generation.",http://arxiv.org/pdf/2309.15137v1,
ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging,28/09/2023,"Ali Ismail-Fawaz, Hassan Ismail Fawaz, François Petitjean, Maxime Devanne, Jonathan Weber, Stefano Berretti, Geoffrey I. Webb, Germain Forestier","Time series data can be found in almost every domain, ranging from the
medical field to manufacturing and wireless communication. Generating realistic
and useful exemplars and prototypes is a fundamental data analysis task. In
this paper, we investigate a novel approach to generating realistic and useful
exemplars and prototypes for time series data. Our approach uses a new form of
time series average, the ShapeDTW Barycentric Average. We therefore turn our
attention to accurately generating time series prototypes with a novel
approach. The existing time series prototyping approaches rely on the Dynamic
Time Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)
and SoftDBA. These last approaches suffer from a common problem of generating
out-of-distribution artifacts in their prototypes. This is mostly caused by the
DTW variant used and its incapability of detecting neighborhood similarities,
instead it detects absolute similarities. Our proposed method, ShapeDBA, uses
the ShapeDTW variant of DTW, that overcomes this issue. We chose time series
clustering, a popular form of time series analysis to evaluate the outcome of
ShapeDBA compared to the other prototyping approaches. Coupled with the k-means
clustering algorithm, and evaluated on a total of 123 datasets from the UCR
archive, our proposed averaging approach is able to achieve new
state-of-the-art results in terms of Adjusted Rand Index.",http://arxiv.org/pdf/2309.16353v1,
Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models,28/09/2023,"Manuel Schürch, Xiang Li, Ahmed Allam, Giulia Rathmes, Amina Mollaysa, Claudia Cavelti-Weder, Michael Krauthammer","We propose a novel framework that combines deep generative time series models
with decision theory for generating personalized treatment strategies. It
leverages historical patient trajectory data to jointly learn the generation of
realistic personalized treatment and future outcome trajectories through deep
generative time series models. In particular, our framework enables the
generation of novel multivariate treatment strategies tailored to the
personalized patient history and trained for optimal expected future outcomes
based on conditional expected utility maximization. We demonstrate our
framework by generating personalized insulin treatment strategies and blood
glucose predictions for hospitalized diabetes patients, showcasing the
potential of our approach for generating improved personalized treatment
strategies. Keywords: deep generative model, probabilistic decision support,
personalized treatment generation, insulin and blood glucose prediction",http://arxiv.org/pdf/2309.16521v2,
Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process,29/09/2023,"Zhuo Zheng, Shiqi Tian, Ailong Ma, Liangpei Zhang, Yanfei Zhong","Understanding the temporal dynamics of Earth's surface is a mission of
multi-temporal remote sensing image analysis, significantly promoted by deep
vision models with its fuel -- labeled multi-temporal images. However,
collecting, preprocessing, and annotating multi-temporal remote sensing images
at scale is non-trivial since it is expensive and knowledge-intensive. In this
paper, we present a scalable multi-temporal remote sensing change data
generator via generative modeling, which is cheap and automatic, alleviating
these problems. Our main idea is to simulate a stochastic change process over
time. We consider the stochastic change process as a probabilistic semantic
state transition, namely generative probabilistic change model (GPCM), which
decouples the complex simulation problem into two more trackable sub-problems,
\ie, change event simulation and semantic change synthesis. To solve these two
problems, we present the change generator (Changen), a GAN-based GPCM, enabling
controllable object change data generation, including customizable object
property, and change event. The extensive experiments suggest that our Changen
has superior generation capability, and the change detectors with Changen
pre-training exhibit excellent transferability to real-world change datasets.",http://arxiv.org/pdf/2309.17031v1,
Pre-training Contextual Location Embeddings in Personal Trajectories via Efficient Hierarchical Location Representations,02/10/2023,"Chung Park, Taesan Kim, Junui Hong, Minsung Choi, Jaegul Choo","Pre-training the embedding of a location generated from human mobility data
has become a popular method for location based services. In practice, modeling
the location embedding is too expensive, due to the large number of locations
to be trained in situations with fine-grained resolution or extensive target
regions. Previous studies have handled less than ten thousand distinct
locations, which is insufficient in the real-world applications. To tackle this
problem, we propose a Geo-Tokenizer, designed to efficiently reduce the number
of locations to be trained by representing a location as a combination of
several grids at different scales. In the Geo-Tokenizer, a grid at a larger
scale shares the common set of grids at smaller scales, which is a key factor
in reducing the size of the location vocabulary. The sequences of locations
preprocessed with the Geo-Tokenizer are utilized by a causal location embedding
model to capture the temporal dependencies of locations. This model dynamically
calculates the embedding vector of a target location, which varies depending on
its trajectory. In addition, to efficiently pre-train the location embedding
model, we propose the Hierarchical Auto-regressive Location Model objective to
effectively train decomposed locations in the Geo-Tokenizer. We conducted
experiments on two real-world user trajectory datasets using our pre-trained
location model. The experimental results show that our model significantly
improves the performance of downstream tasks with fewer model parameters
compared to existing location embedding methods.",http://arxiv.org/pdf/2310.01252v1,
Sequential Data Generation with Groupwise Diffusion Process,02/10/2023,"Sangyun Lee, Gayoung Lee, Hyunsu Kim, Junho Kim, Youngjung Uh","We present the Groupwise Diffusion Model (GDM), which divides data into
multiple groups and diffuses one group at one time interval in the forward
diffusion process. GDM generates data sequentially from one group at one time
interval, leading to several interesting properties. First, as an extension of
diffusion models, GDM generalizes certain forms of autoregressive models and
cascaded diffusion models. As a unified framework, GDM allows us to investigate
design choices that have been overlooked in previous works, such as
data-grouping strategy and order of generation. Furthermore, since one group of
the initial noise affects only a certain group of the generated data, latent
space now possesses group-wise interpretable meaning. We can further extend GDM
to the frequency domain where the forward process sequentially diffuses each
group of frequency components. Dividing the frequency bands of the data as
groups allows the latent variables to become a hierarchical representation
where individual groups encode data at different levels of abstraction. We
demonstrate several applications of such representation including
disentanglement of semantic attributes, image editing, and generating
variations.",http://arxiv.org/pdf/2310.01400v1,
"Home Electricity Data Generator (HEDGE): An open-access tool for the generation of electric vehicle, residential demand, and PV generation profiles",02/10/2023,"Flora Charbonnier, Thomas Morstyn, Malcolm McCulloch","In this paper, we present the Home Electricity Data Generator (HEDGE), an
open-access tool for the random generation of realistic residential energy
data. HEDGE generates realistic daily profiles of residential PV generation,
household electric loads, and electric vehicle consumption and at-home
availability, based on real-life UK datasets. The lack of usable data is a
major hurdle for research on residential distributed energy resources
characterisation and coordination, especially when using data-driven methods
such as machine learning-based forecasting and reinforcement learning-based
control. A key issue is that while large data banks are available, they are not
in a usable format, and numerous subsequent days of data for a given single
home are unavailable. We fill these gaps with the open-access HEDGE tool which
generates data sequences of energy data for several days in a way that is
consistent for single homes, both in terms of profile magnitude and behavioural
clusters. From raw datasets, pre-processing steps are conducted, including
filling in incomplete data sequences and clustering profiles into behaviour
clusters. Generative adversarial networks (GANs) are then trained to generate
realistic synthetic data representative of each behaviour groups consistent
with real-life behavioural and physical patterns.",http://arxiv.org/pdf/2310.01661v1,
CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery,03/10/2023,"Yuxiao Cheng, Ziqian Wang, Tingxiong Xiao, Qin Zhong, Jinli Suo, Kunlun He","Time-series causal discovery (TSCD) is a fundamental problem of machine
learning. However, existing synthetic datasets cannot properly evaluate or
predict the algorithms' performance on real data. This study introduces the
CausalTime pipeline to generate time-series that highly resemble the real data
and with ground truth causal graphs for quantitative performance evaluation.
The pipeline starts from real observations in a specific scenario and produces
a matching benchmark dataset. Firstly, we harness deep neural networks along
with normalizing flow to accurately capture realistic dynamics. Secondly, we
extract hypothesized causal graphs by performing importance analysis on the
neural network or leveraging prior knowledge. Thirdly, we derive the ground
truth causal graphs by splitting the causal model into causal term, residual
term, and noise term. Lastly, using the fitted network and the derived causal
graph, we generate corresponding versatile time-series proper for algorithm
assessment. In the experiments, we validate the fidelity of the generated data
through qualitative and quantitative experiments, followed by a benchmarking of
existing TSCD algorithms using these generated datasets. CausalTime offers a
feasible solution to evaluating TSCD algorithms in real applications and can be
generalized to a wide range of fields. For easy use of the proposed approach,
we also provide a user-friendly website, hosted on www.causaltime.cc.",http://arxiv.org/pdf/2310.01753v1,
DON-LSTM: Multi-Resolution Learning with DeepONets and Long Short-Term Memory Neural Networks,03/10/2023,"Katarzyna Michałowska, Somdatta Goswami, George Em Karniadakis, Signe Riemer-Sørensen","Deep operator networks (DeepONets, DONs) offer a distinct advantage over
traditional neural networks in their ability to be trained on multi-resolution
data. This property becomes especially relevant in real-world scenarios where
high-resolution measurements are difficult to obtain, while low-resolution data
is more readily available. Nevertheless, DeepONets alone often struggle to
capture and maintain dependencies over long sequences compared to other
state-of-the-art algorithms. We propose a novel architecture, named DON-LSTM,
which extends the DeepONet with a long short-term memory network (LSTM).
Combining these two architectures, we equip the network with explicit
mechanisms to leverage multi-resolution data, as well as capture temporal
dependencies in long sequences. We test our method on long-time-evolution
modeling of multiple non-linear systems and show that the proposed
multi-resolution DON-LSTM achieves significantly lower generalization error and
requires fewer high-resolution samples compared to its vanilla counterparts.",http://arxiv.org/pdf/2310.02491v1,
Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs,04/10/2023,"Ilan Naiman, N. Benjamin Erichson, Pu Ren, Michael W. Mahoney, Omri Azencot","Generating realistic time series data is important for many engineering and
scientific applications. Existing work tackles this problem using generative
adversarial networks (GANs). However, GANs are unstable during training, and
they can suffer from mode collapse. While variational autoencoders (VAEs) are
known to be more robust to the these issues, they are (surprisingly) less
considered for time series generation. In this work, we introduce Koopman VAE
(KoVAE), a new generative framework that is based on a novel design for the
model prior, and that can be optimized for either regular and irregular
training data. Inspired by Koopman theory, we represent the latent conditional
prior dynamics using a linear map. Our approach enhances generative modeling
with two desired features: (i) incorporating domain knowledge can be achieved
by leveraging spectral tools that prescribe constraints on the eigenvalues of
the linear map; and (ii) studying the qualitative behavior and stability of the
system can be performed using tools from dynamical systems theory. Our results
show that KoVAE outperforms state-of-the-art GAN and VAE methods across several
challenging synthetic and real-world time series generation benchmarks. Whether
trained on regular or irregular data, KoVAE generates time series that improve
both discriminative and predictive metrics. We also present visual evidence
suggesting that KoVAE learns probability density functions that better
approximate the empirical ground truth distribution.",http://arxiv.org/pdf/2310.02619v2,
Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data,04/10/2023,"Rabia Gondur, Usama Bin Sikandar, Evan Schaffer, Mikio Christian Aoi, Stephen L Keeley","Characterizing the relationship between neural population activity and
behavioral data is a central goal of neuroscience. While latent variable models
(LVMs) are successful in describing high-dimensional time-series data, they are
typically only designed for a single type of data, making it difficult to
identify structure shared across different experimental data modalities. Here,
we address this shortcoming by proposing an unsupervised LVM which extracts
temporally evolving shared and independent latents for distinct, simultaneously
recorded experimental modalities. We do this by combining Gaussian Process
Factor Analysis (GPFA), an interpretable LVM for neural spiking data with
temporally smooth latent space, with Gaussian Process Variational Autoencoders
(GP-VAEs), which similarly use a GP prior to characterize correlations in a
latent space, but admit rich expressivity due to a deep neural network mapping
to observations. We achieve interpretability in our model by partitioning
latent variability into components that are either shared between or
independent to each modality. We parameterize the latents of our model in the
Fourier domain, and show improved latent identification using this approach
over standard GP-VAE methods. We validate our model on simulated multi-modal
data consisting of Poisson spike counts and MNIST images that scale and rotate
smoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to
not only identify the shared and independent latent structure across modalities
accurately, but provides good reconstructions of both images and neural rates
on held-out trials. Finally, we demonstrate our framework on two real world
multi-modal experimental settings: Drosophila whole-brain calcium imaging
alongside tracked limb positions, and Manduca sexta spike train measurements
from ten wing muscles as the animal tracks a visual stimulus.",http://arxiv.org/pdf/2310.03111v1,
Deep Generative Models of Music Expectation,05/10/2023,"Ninon Lizé Masclef, T. Anderson Keller","A prominent theory of affective response to music revolves around the
concepts of surprisal and expectation. In prior work, this idea has been
operationalized in the form of probabilistic models of music which allow for
precise computation of song (or note-by-note) probabilities, conditioned on a
'training set' of prior musical or cultural experiences. To date, however,
these models have been limited to compute exact probabilities through
hand-crafted features or restricted to linear models which are likely not
sufficient to represent the complex conditional distributions present in music.
In this work, we propose to use modern deep probabilistic generative models in
the form of a Diffusion Model to compute an approximate likelihood of a musical
input sequence. Unlike prior work, such a generative model parameterized by
deep neural networks is able to learn complex non-linear features directly from
a training set itself. In doing so, we expect to find that such models are able
to more accurately represent the 'surprisal' of music for human listeners. From
the literature, it is known that there is an inverted U-shaped relationship
between surprisal and the amount human subjects 'like' a given song. In this
work we show that pre-trained diffusion models indeed yield musical surprisal
values which exhibit a negative quadratic relationship with measured subject
'liking' ratings, and that the quality of this relationship is competitive with
state of the art methods such as IDyOM. We therefore present this model a
preliminary step in developing modern deep generative models of music
expectation and subjective likability.",http://arxiv.org/pdf/2310.03500v1,
Successive Data Injection in Conditional Quantum GAN Applied to Time Series Anomaly Detection,08/10/2023,"Benjamin Kalfon, Soumaya Cherkaoui, Jean-Frédéric Laprade, Ola Ahmad, Shengrui Wang","Classical GAN architectures have shown interesting results for solving
anomaly detection problems in general and for time series anomalies in
particular, such as those arising in communication networks. In recent years,
several quantum GAN architectures have been proposed in the literature. When
detecting anomalies in time series using QGANs, huge challenges arise due to
the limited number of qubits compared to the size of the data. To address these
challenges, we propose a new high-dimensional encoding approach, named
Successive Data Injection (SuDaI). In this approach, we explore a larger
portion of the quantum state than that in the conventional angle encoding, the
method used predominantly in the literature, through repeated data injections
into the quantum state. SuDaI encoding allows us to adapt the QGAN for anomaly
detection with network data of a much higher dimensionality than with the
existing known QGANs implementations. In addition, SuDaI encoding applies to
other types of high-dimensional time series and can be used in contexts beyond
anomaly detection and QGANs, opening up therefore multiple fields of
application.",http://arxiv.org/pdf/2310.05307v1,
DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection,13/10/2023,"Chaocheng Yang, Tingyin Wang, Xuanhui Yan","Anomaly detection in multivariate time series has emerged as a crucial
challenge in time series research, with significant research implications in
various fields such as fraud detection, fault diagnosis, and system state
estimation. Reconstruction-based models have shown promising potential in
recent years for detecting anomalies in time series data. However, due to the
rapid increase in data scale and dimensionality, the issues of noise and Weak
Identity Mapping (WIM) during time series reconstruction have become
increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic
Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and
Denoising Diffusion Model, creating a new framework for multivariate time
series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).
The ADNM module is introduced to mitigate information leakage between input and
output features during data reconstruction, thereby alleviating the problem of
WIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs
the Transformer as an internal neural network structure for Denoising Diffusion
Model. It learns the stepwise generation process of time series data to model
the probability distribution of the data, capturing normal data patterns and
progressively restoring time series data by removing noise, resulting in a
clear recovery of anomalies. To the best of our knowledge, this is the first
model that combines Denoising Diffusion Model and the Transformer for
multivariate time series anomaly detection. Experimental evaluations were
conducted on five publicly available multivariate time series anomaly detection
datasets. The results demonstrate that the model effectively identifies
anomalies in time series data, achieving state-of-the-art performance in
anomaly detection.",http://arxiv.org/pdf/2310.08800v2,
CoCoFormer: A controllable feature-rich polyphonic music generation method,15/10/2023,"Jiuyang Zhou, Tengfei Niu, Hong Zhu, Xingping Wang","This paper explores the modeling method of polyphonic music sequence. Due to
the great potential of Transformer models in music generation, controllable
music generation is receiving more attention. In the task of polyphonic music,
current controllable generation research focuses on controlling the generation
of chords, but lacks precise adjustment for the controllable generation of
choral music textures. This paper proposed Condition Choir Transformer
(CoCoFormer) which controls the output of the model by controlling the chord
and rhythm inputs at a fine-grained level. In this paper, the self-supervised
method improves the loss function and performs joint training through
conditional control input and unconditional input training. In order to
alleviate the lack of diversity on generated samples caused by the teacher
forcing training, this paper added an adversarial training method. CoCoFormer
enhances model performance with explicit and implicit inputs to chords and
rhythms. In this paper, the experiments proves that CoCoFormer has reached the
current better level than current models. On the premise of specifying the
polyphonic music texture, the same melody can also be generated in a variety of
ways.",http://arxiv.org/pdf/2310.09843v2,
Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation,15/10/2023,"Chengwei Qin, Chen Chen, Shafiq Joty","Lifelong sequence generation (LSG), a problem in continual learning, aims to
continually train a model on a sequence of generation tasks to learn constantly
emerging new generation patterns while avoiding the forgetting of previous
knowledge. Existing LSG methods mainly focus on maintaining old knowledge while
paying little attention to knowledge transfer across tasks. In contrast, humans
can better learn new tasks by leveraging previously acquired knowledge from
similar tasks. Inspired by the learning paradigm of humans, we propose Dynamic
Module Expansion and Adaptation (DMEA), which enables the model to dynamically
determine the architecture for acquiring new knowledge based on task
correlation and select the most similar previous tasks to facilitate adaptation
to new tasks. In addition, as the learning process can easily be biased towards
the current task which might cause more severe forgetting of previously learned
knowledge, we propose dynamic gradient scaling to balance the learning of the
current task and replayed tasks. With extensive experiments, we demonstrate
that DMEA can consistently outperform existing methods in different LSG
settings.",http://arxiv.org/pdf/2310.09886v4,
Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook,16/10/2023,"Ming Jin, Qingsong Wen, Yuxuan Liang, Chaoli Zhang, Siqiao Xue, Xue Wang, James Zhang, Yi Wang, Haifeng Chen, Xiaoli Li, Shirui Pan, Vincent S. Tseng, Yu Zheng, Lei Chen, Hui Xiong","Temporal data, notably time series and spatio-temporal data, are prevalent in
real-world applications. They capture dynamic system measurements and are
produced in vast quantities by both physical and virtual sensors. Analyzing
these data types is vital to harnessing the rich information they encompass and
thus benefits a wide range of downstream tasks. Recent advances in large
language and other foundational models have spurred increased use of these
models in time series and spatio-temporal data mining. Such methodologies not
only enable enhanced pattern recognition and reasoning across diverse domains
but also lay the groundwork for artificial general intelligence capable of
comprehending and processing common temporal data. In this survey, we offer a
comprehensive and up-to-date review of large models tailored (or adapted) for
time series and spatio-temporal data, spanning four key facets: data types,
model categories, model scopes, and application areas/tasks. Our objective is
to equip practitioners with the knowledge to develop applications and further
research in this underexplored domain. We primarily categorize the existing
literature into two major clusters: large models for time series analysis
(LM4TS) and spatio-temporal data mining (LM4STD). On this basis, we further
classify research based on model scopes (i.e., general vs. domain-specific) and
application areas/tasks. We also provide a comprehensive collection of
pertinent resources, including datasets, model assets, and useful tools,
categorized by mainstream applications. This survey coalesces the latest
strides in large model-centric research on time series and spatio-temporal
data, underscoring the solid foundations, current advances, practical
applications, abundant resources, and future research opportunities.",http://arxiv.org/pdf/2310.10196v2,
Learning Recurrent Models with Temporally Local Rules,20/10/2023,"Azwar Abdulsalam, Joseph G. Makin","Fitting generative models to sequential data typically involves two recursive
computations through time, one forward and one backward. The latter could be a
computation of the loss gradient (as in backpropagation through time), or an
inference algorithm (as in the RTS/Kalman smoother). The backward pass in
particular is computationally expensive (since it is inherently serial and
cannot exploit GPUs), and difficult to map onto biological processes.
Work-arounds have been proposed; here we explore a very different one:
requiring the generative model to learn the joint distribution over current and
previous states, rather than merely the transition probabilities. We show on
toy datasets that different architectures employing this principle can learn
aspects of the data typically requiring the backward pass.",http://arxiv.org/pdf/2310.13284v1,
Composer Style-specific Symbolic Music Generation Using Vector Quantized Discrete Diffusion Models,21/10/2023,"Jincheng Zhang, György Fazekas, Charalampos Saitis","Emerging Denoising Diffusion Probabilistic Models (DDPM) have become
increasingly utilised because of promising results they have achieved in
diverse generative tasks with continuous data, such as image and sound
synthesis. Nonetheless, the success of diffusion models has not been fully
extended to discrete symbolic music. We propose to combine a vector quantized
variational autoencoder (VQ-VAE) and discrete diffusion models for the
generation of symbolic music with desired composer styles. The trained VQ-VAE
can represent symbolic music as a sequence of indexes that correspond to
specific entries in a learned codebook. Subsequently, a discrete diffusion
model is used to model the VQ-VAE's discrete latent space. The diffusion model
is trained to generate intermediate music sequences consisting of codebook
indexes, which are then decoded to symbolic music using the VQ-VAE's decoder.
The evaluation results demonstrate our model can generate symbolic music with
target composer styles that meet the given conditions with a high accuracy of
72.36%. Our code is available at
https://github.com/jinchengzhanggg/VQVAE-Diffusion.",http://arxiv.org/pdf/2310.14044v2,
Reliable Generation of Privacy-preserving Synthetic Electronic Health Record Time Series via Diffusion Models,23/10/2023,"Muhang Tian, Bernie Chen, Allan Guo, Shiyi Jiang, Anru R. Zhang","Electronic Health Records (EHRs) are rich sources of patient-level data,
offering valuable resources for medical data analysis. However, privacy
concerns often restrict access to EHRs, hindering downstream analysis. Current
EHR de-identification methods are flawed and can lead to potential privacy
leakage. Additionally, existing publicly available EHR databases are limited,
preventing the advancement of medical research using EHR. This study aims to
overcome these challenges by generating realistic and privacy-preserving
synthetic electronic health records (EHRs) time series efficiently. We
introduce a new method for generating diverse and realistic synthetic EHR time
series data using Denoising Diffusion Probabilistic Models (DDPM). We conducted
experiments on six databases: Medical Information Mart for Intensive Care III
and IV (MIMIC-III/IV), the eICU Collaborative Research Database (eICU), and
non-EHR datasets on Stocks and Energy. We compared our proposed method with
eight existing methods. Our results demonstrate that our approach significantly
outperforms all existing methods in terms of data fidelity while requiring less
training effort. Additionally, data generated by our method yields a lower
discriminative accuracy compared to other baseline methods, indicating the
proposed method can generate data with less privacy risk. The proposed
diffusion-model-based method can reliably and efficiently generate synthetic
EHR time series, which facilitates the downstream medical data analysis. Our
numerical results show the superiority of the proposed method over all other
existing methods.",http://arxiv.org/pdf/2310.15290v6,
Improving Diffusion Models for ECG Imputation with an Augmented Template Prior,24/10/2023,"Alexander Jenkins, Zehua Chen, Fu Siong Ng, Danilo Mandic","Pulsative signals such as the electrocardiogram (ECG) are extensively
collected as part of routine clinical care. However, noisy and poor-quality
recordings are a major issue for signals collected using mobile health systems,
decreasing the signal quality, leading to missing values, and affecting
automated downstream tasks. Recent studies have explored the imputation of
missing values in ECG with probabilistic time-series models. Nevertheless, in
comparison with the deterministic models, their performance is still limited,
as the variations across subjects and heart-beat relationships are not
explicitly considered in the training objective. In this work, to improve the
imputation and forecasting accuracy for ECG with probabilistic models, we
present a template-guided denoising diffusion probabilistic model (DDPM),
PulseDiff, which is conditioned on an informative prior for a range of health
conditions. Specifically, 1) we first extract a subject-level pulsative
template from the observed values to use as an informative prior of the missing
values, which personalises the prior; 2) we then add beat-level stochastic
shift terms to augment the prior, which considers variations in the position
and amplitude of the prior at each beat; 3) we finally design a confidence
score to consider the health condition of the subject, which ensures our prior
is provided safely. Experiments with the PTBXL dataset reveal that PulseDiff
improves the performance of two strong DDPM baseline models, CSDI and
SSSD$^{S4}$, verifying that our method guides the generation of DDPMs while
managing the uncertainty. When combined with SSSD$^{S4}$, PulseDiff outperforms
the leading deterministic model for short-interval missing data and is
comparable for long-interval data loss.",http://arxiv.org/pdf/2310.15742v2,
TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories,24/10/2023,"Travers Rhodes, Daniel D. Lee","Human demonstrations of trajectories are an important source of training data
for many machine learning problems. However, the difficulty of collecting human
demonstration data for complex tasks makes learning efficient representations
of those trajectories challenging. For many problems, such as for dexterous
manipulation, the exact timings of the trajectories should be factored from
their spatial path characteristics. In this work, we propose TimewarpVAE, a
fully differentiable manifold-learning algorithm that incorporates Dynamic Time
Warping (DTW) to simultaneously learn both timing variations and latent factors
of spatial variation. We show how the TimewarpVAE algorithm learns appropriate
time alignments and meaningful representations of spatial variations in
handwriting and fork manipulation datasets. Our results have lower spatial
reconstruction test error than baseline approaches and the learned
low-dimensional representations can be used to efficiently generate
semantically meaningful novel trajectories. We demonstrate the utility of our
algorithm to generate novel high-speed trajectories for a robotic arm.",http://arxiv.org/pdf/2310.16027v2,
Score Matching-based Pseudolikelihood Estimation of Neural Marked Spatio-Temporal Point Process with Uncertainty Quantification,25/10/2023,"Zichong Li, Qunzhi Xu, Zhenghao Xu, Yajun Mei, Tuo Zhao, Hongyuan Zha","Spatio-temporal point processes (STPPs) are potent mathematical tools for
modeling and predicting events with both temporal and spatial features. Despite
their versatility, most existing methods for learning STPPs either assume a
restricted form of the spatio-temporal distribution, or suffer from inaccurate
approximations of the intractable integral in the likelihood training
objective. These issues typically arise from the normalization term of the
probability density function. Moreover, current techniques fail to provide
uncertainty quantification for model predictions, such as confidence intervals
for the predicted event's arrival time and confidence regions for the event's
location, which is crucial given the considerable randomness of the data. To
tackle these challenges, we introduce SMASH: a Score MAtching-based
pSeudolikeliHood estimator for learning marked STPPs with uncertainty
quantification. Specifically, our framework adopts a normalization-free
objective by estimating the pseudolikelihood of marked STPPs through
score-matching and offers uncertainty quantification for the predicted event
time, location and mark by computing confidence regions over the generated
samples. The superior performance of our proposed framework is demonstrated
through extensive experiments in both event prediction and uncertainty
quantification.",http://arxiv.org/pdf/2310.16310v1,
SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process,25/10/2023,"Zichong Li, Yanbo Xu, Simiao Zuo, Haoming Jiang, Chao Zhang, Tuo Zhao, Hongyuan Zha","Transformer Hawkes process models have shown to be successful in modeling
event sequence data. However, most of the existing training methods rely on
maximizing the likelihood of event sequences, which involves calculating some
intractable integral. Moreover, the existing methods fail to provide
uncertainty quantification for model predictions, e.g., confidence intervals
for the predicted event's arrival time. To address these issues, we propose
SMURF-THP, a score-based method for learning Transformer Hawkes process and
quantifying prediction uncertainty. Specifically, SMURF-THP learns the score
function of events' arrival time based on a score-matching objective that
avoids the intractable computation. With such a learned score function, we can
sample arrival time of events from the predictive distribution. This naturally
allows for the quantification of uncertainty by computing confidence intervals
over the generated samples. We conduct extensive experiments in both event type
prediction and uncertainty quantification of arrival time. In all the
experiments, SMURF-THP outperforms existing likelihood-based methods in
confidence calibration while exhibiting comparable prediction accuracy.",http://arxiv.org/pdf/2310.16336v1,
MIM-GAN-based Anomaly Detection for Multivariate Time Series Data,26/10/2023,"Shan Lu, Zhicheng Dong, Donghong Cai, Fang Fang, Dongcai Zhao","The loss function of Generative adversarial network(GAN) is an important
factor that affects the quality and diversity of the generated samples for
anomaly detection. In this paper, we propose an unsupervised multiple time
series anomaly detection algorithm based on the GAN with message importance
measure(MIM-GAN). In particular, the time series data is divided into
subsequences using a sliding window. Then a generator and a discriminator
designed based on the Long Short-Term Memory (LSTM) are employed to capture the
temporal correlations of the time series data. To avoid the local optimal
solution of loss function and the model collapse, we introduce an exponential
information measure into the loss function of GAN. Additionally, a discriminant
reconstruction score consisting on discrimination and reconstruction loss is
taken into account. The global optimal solution for the loss function is
derived and the model collapse is proved to be avoided in our proposed
MIM-GAN-based anomaly detection algorithm. Experimental results show that the
proposed MIM-GAN-based anomaly detection algorithm has superior performance in
terms of precision, recall, and F1 score.",http://arxiv.org/pdf/2310.18257v1,
Deep Kalman Filters Can Filter,30/10/2023,"Blanka Hovart, Anastasis Kratsios, Yannick Limmer, Xuwei Yang","Deep Kalman filters (DKFs) are a class of neural network models that generate
Gaussian probability measures from sequential data. Though DKFs are inspired by
the Kalman filter, they lack concrete theoretical ties to the stochastic
filtering problem, thus limiting their applicability to areas where traditional
model-based filters have been used, e.g.\ model calibration for bond and option
prices in mathematical finance. We address this issue in the mathematical
foundations of deep learning by exhibiting a class of continuous-time DKFs
which can approximately implement the conditional law of a broad class of
non-Markovian and conditionally Gaussian signal processes given noisy
continuous-times measurements. Our approximation results hold uniformly over
sufficiently regular compact subsets of paths, where the approximation error is
quantified by the worst-case 2-Wasserstein distance computed uniformly over the
given compact set of paths.",http://arxiv.org/pdf/2310.19603v1,
Convolutional State Space Models for Long-Range Spatiotemporal Modeling,30/10/2023,"Jimmy T. H. Smith, Shalini De Mello, Jan Kautz, Scott W. Linderman, Wonmin Byeon","Effectively modeling long spatiotemporal sequences is challenging due to the
need to model complex spatial correlations and long-range temporal dependencies
simultaneously. ConvLSTMs attempt to address this by updating tensor-valued
states with recurrent neural networks, but their sequential computation makes
them slow to train. In contrast, Transformers can process an entire
spatiotemporal sequence, compressed into tokens, in parallel. However, the cost
of attention scales quadratically in length, limiting their scalability to
longer sequences. Here, we address the challenges of prior methods and
introduce convolutional state space models (ConvSSM) that combine the tensor
modeling ideas of ConvLSTM with the long sequence modeling approaches of state
space methods such as S4 and S5. First, we demonstrate how parallel scans can
be applied to convolutional recurrences to achieve subquadratic parallelization
and fast autoregressive generation. We then establish an equivalence between
the dynamics of ConvSSMs and SSMs, which motivates parameterization and
initialization strategies for modeling long-range dependencies. The result is
ConvS5, an efficient ConvSSM variant for long-range spatiotemporal modeling.
ConvS5 significantly outperforms Transformers and ConvLSTM on a long horizon
Moving-MNIST experiment while training 3X faster than ConvLSTM and generating
samples 400X faster than Transformers. In addition, ConvS5 matches or exceeds
the performance of state-of-the-art methods on challenging DMLab, Minecraft and
Habitat prediction benchmarks and enables new directions for modeling long
spatiotemporal sequences.",http://arxiv.org/pdf/2310.19694v1,
Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data,31/10/2023,"Antonis Antoniades, Yiyi Yu, Joseph Canzano, William Wang, Spencer LaVere Smith","State-of-the-art systems neuroscience experiments yield large-scale
multimodal data, and these data sets require new tools for analysis. Inspired
by the success of large pretrained models in vision and language domains, we
reframe the analysis of large-scale, cellular-resolution neuronal spiking data
into an autoregressive spatiotemporal generation problem. Neuroformer is a
multimodal, multitask generative pretrained transformer (GPT) model that is
specifically designed to handle the intricacies of data in systems
neuroscience. It scales linearly with feature size, can process an arbitrary
number of modalities, and is adaptable to downstream tasks, such as predicting
behavior. We first trained Neuroformer on simulated datasets, and found that it
both accurately predicted simulated neuronal circuit activity, and also
intrinsically inferred the underlying neural circuit connectivity, including
direction. When pretrained to decode neural responses, the model predicted the
behavior of a mouse with only few-shot fine-tuning, suggesting that the model
begins learning how to do so directly from the neural representations
themselves, without any explicit supervision. We used an ablation study to show
that joint training on neuronal responses and behavior boosted performance,
highlighting the model's ability to associate behavioral and neural
representations in an unsupervised manner. These findings show that Neuroformer
can analyze neural datasets and their emergent properties, informing the
development of models and hypotheses associated with the brain.",http://arxiv.org/pdf/2311.00136v4,
Enhancing Algorithm Performance Understanding through tsMorph: Generating Semi-Synthetic Time Series for Robust Forecasting Evaluation,03/12/2023,"Moisés Santos, André de Carvalho, Carlos Soares","Time series forecasting is a subject of significant scientific and industrial
importance. Despite the widespread utilization of forecasting methods, there is
a dearth of research aimed at comprehending the conditions under which these
methods yield favorable or unfavorable performances. Empirical studies,
although common, are challenged by the limited availability of time series
datasets, restricting the extraction of reliable insights. To address this
limitation, we present tsMorph, a tool for generating semi-synthetic time
series through dataset morphing. tsMorph works by creating a sequence of
datasets from two original datasets. The characteristics of the generated
datasets progressively depart from those of one of the datasets and converge
toward the attributes of the other dataset. This method provides a valuable
alternative for obtaining substantial datasets. In this paper, we show the
benefits of tsMorph by assessing the predictive performance of the Long
Short-Term Memory Network and DeepAR forecasting algorithms. The time series
used for the experiments comes from the NN5 Competition. The experimental
results provide important insights. Notably, the performances of the two
algorithms improve proportionally with the frequency of the time series. These
experiments confirm that tsMorph can be an effective tool for better
understanding the behavior of forecasting algorithms, delivering a pathway to
overcoming the limitations posed by empirical studies and enabling more
extensive and reliable experiments.",http://arxiv.org/pdf/2312.01344v2,
Learn2Extend: Extending sequences by retaining their statistical properties with mixture models,03/12/2023,"Dimitris Vartziotis, George Dasoulas, Florian Pausinger","This paper addresses the challenge of extending general finite sequences of
real numbers within a subinterval of the real line, maintaining their inherent
statistical properties by employing machine learning. Our focus lies on
preserving the gap distribution and pair correlation function of these point
sets. Leveraging advancements in deep learning applied to point processes, this
paper explores the use of an auto-regressive \textit{Sequence Extension Mixture
Model} (SEMM) for extending finite sequences, by estimating directly the
conditional density, instead of the intensity function. We perform comparative
experiments on multiple types of point processes, including Poisson, locally
attractive, and locally repelling sequences, and we perform a case study on the
prediction of Riemann $\zeta$ function zeroes. The results indicate that the
proposed mixture model outperforms traditional neural network architectures in
sequence extension with the retention of statistical properties. Given this
motivation, we showcase the capabilities of a mixture model to extend
sequences, maintaining specific statistical properties, i.e. the gap
distribution, and pair correlation indicators.",http://arxiv.org/pdf/2312.01507v1,
DiffusionPhase: Motion Diffusion in Frequency Domain,07/12/2023,"Weilin Wan, Yiming Huang, Shutong Wu, Taku Komura, Wenping Wang, Dinesh Jayaraman, Lingjie Liu","In this study, we introduce a learning-based method for generating
high-quality human motion sequences from text descriptions (e.g., ``A person
walks forward""). Existing techniques struggle with motion diversity and smooth
transitions in generating arbitrary-length motion sequences, due to limited
text-to-motion datasets and the pose representations used that often lack
expressiveness or compactness. To address these issues, we propose the first
method for text-conditioned human motion generation in the frequency domain of
motions. We develop a network encoder that converts the motion space into a
compact yet expressive parameterized phase space with high-frequency details
encoded, capturing the local periodicity of motions in time and space with high
accuracy. We also introduce a conditional diffusion model for predicting
periodic motion parameters based on text descriptions and a start pose,
efficiently achieving smooth transitions between motion sequences associated
with different text descriptions. Experiments demonstrate that our approach
outperforms current methods in generating a broader variety of high-quality
motions, and synthesizing long sequences with natural transitions.",http://arxiv.org/pdf/2312.04036v1,
Jointly spatial-temporal representation learning for individual trajectories,07/12/2023,"Fei Huang, Jianrong Lv, Yang Yue","Individual trajectories, rich in human-environment interaction information
across space and time, serve as vital inputs for geospatial foundation models
(GeoFMs). However, existing attempts at learning trajectory representations
have overlooked the implicit spatial-temporal dependency within trajectories,
failing to encode such dependency in a deep learning-friendly format. That
poses a challenge in obtaining general-purpose trajectory representations.
Therefore, this paper proposes a spatial-temporal joint representation learning
method (ST-GraphRL) to formalize learnable spatial-temporal dependencies into
trajectory representations. The proposed ST-GraphRL consists of three
compositions: (i) a weighted directed spatial-temporal graph to explicitly
construct mobility interactions in both space and time dimensions; (ii) a
two-stage jointly encoder (i.e., decoupling and fusion), to learn entangled
spatial-temporal dependencies by independently decomposing and jointly
aggregating space and time information; (iii) a decoder guides ST-GraphRL to
learn explicit mobility regularities by simulating the spatial-temporal
distributions of trajectories. Tested on three real-world human mobility
datasets, the proposed ST-GraphRL outperformed all the baseline models in
predicting movement spatial-temporal distributions and preserving trajectory
similarity with high spatial-temporal correlations. Analyzing spatial-temporal
features presented in latent space validates that ST-GraphRL understands
spatial-temporal patterns. This study may also benefit representation learnings
of other geospatial data to achieve general-purpose data representations and
advance GeoFMs development.",http://arxiv.org/pdf/2312.04055v2,
Trajeglish: Traffic Modeling as Next-Token Prediction,07/12/2023,"Jonah Philion, Xue Bin Peng, Sanja Fidler","A longstanding challenge for self-driving development is simulating dynamic
driving scenarios seeded from recorded driving logs. In pursuit of this
functionality, we apply tools from discrete sequence modeling to model how
vehicles, pedestrians and cyclists interact in driving scenarios. Using a
simple data-driven tokenization scheme, we discretize trajectories to
centimeter-level resolution using a small vocabulary. We then model the
multi-agent sequence of discrete motion tokens with a GPT-like encoder-decoder
that is autoregressive in time and takes into account intra-timestep
interaction between agents. Scenarios sampled from our model exhibit
state-of-the-art realism; our model tops the Waymo Sim Agents Benchmark,
surpassing prior work along the realism meta metric by 3.3% and along the
interaction metric by 9.9%. We ablate our modeling choices in full autonomy and
partial autonomy settings, and show that the representations learned by our
model can quickly be adapted to improve performance on nuScenes. We
additionally evaluate the scalability of our model with respect to parameter
count and dataset size, and use density estimates from our model to quantify
the saliency of context length and intra-timestep interaction for the traffic
modeling task.",http://arxiv.org/pdf/2312.04535v2,
Micro-Macro Consistency in Multiscale Modeling: Score-Based Model Assisted Sampling of Fast/Slow Dynamical Systems,10/12/2023,"Ellis R. Crabtree, Juan M. Bello-Rivas, Ioannis G. Kevrekidis","A valuable step in the modeling of multiscale dynamical systems in fields
such as computational chemistry, biology, materials science and more, is the
representative sampling of the phase space over long timescales of interest;
this task is not, however, without challenges. For example, the long term
behavior of a system with many degrees of freedom often cannot be efficiently
computationally explored by direct dynamical simulation; such systems can often
become trapped in local free energy minima. In the study of physics-based
multi-time-scale dynamical systems, techniques have been developed for
enhancing sampling in order to accelerate exploration beyond free energy
barriers. On the other hand, in the field of Machine Learning, a generic goal
of generative models is to sample from a target density, after training on
empirical samples from this density. Score based generative models (SGMs) have
demonstrated state-of-the-art capabilities in generating plausible data from
target training distributions. Conditional implementations of such generative
models have been shown to exhibit significant parallels with long-established
-- and physics based -- solutions to enhanced sampling. These physics-based
methods can then be enhanced through coupling with the ML generative models,
complementing the strengths and mitigating the weaknesses of each technique. In
this work, we show that that SGMs can be used in such a coupling framework to
improve sampling in multiscale dynamical systems.",http://arxiv.org/pdf/2312.05715v2,
ConSequence: Synthesizing Logically Constrained Sequences for Electronic Health Record Generation,10/12/2023,"Brandon Theodorou, Shrusti Jain, Cao Xiao, Jimeng Sun","Generative models can produce synthetic patient records for analytical tasks
when real data is unavailable or limited. However, current methods struggle
with adhering to domain-specific knowledge and removing invalid data. We
present ConSequence, an effective approach to integrating domain knowledge into
sequential generative neural network outputs. Our rule-based formulation
includes temporal aggregation and antecedent evaluation modules, ensured by an
efficient matrix multiplication formulation, to satisfy hard and soft logical
constraints across time steps. Existing constraint methods often fail to
guarantee constraint satisfaction, lack the ability to handle temporal
constraints, and hinder the learning and computational efficiency of the model.
In contrast, our approach efficiently handles all types of constraints with
guaranteed logical coherence. We demonstrate ConSequence's effectiveness in
generating electronic health records, outperforming competitors in achieving
complete temporal and spatial constraint satisfaction without compromising
runtime performance or generative quality. Specifically, ConSequence
successfully prevents all rule violations while improving the model quality in
reducing its test perplexity by 5% and incurring less than a 13% slowdown in
generation speed compared to an unconstrained model.",http://arxiv.org/pdf/2312.05964v2,
Predictive variational autoencoder for learning robust representations of time-series data,12/12/2023,"Julia Huiming Wang, Dexter Tsin, Tatiana Engel","Variational autoencoders (VAEs) have been used extensively to discover
low-dimensional latent factors governing neural activity and animal behavior.
However, without careful model selection, the uncovered latent factors may
reflect noise in the data rather than true underlying features, rendering such
representations unsuitable for scientific interpretation. Existing solutions to
this problem involve introducing additional measured variables or data
augmentations specific to a particular data type. We propose a VAE architecture
that predicts the next point in time and show that it mitigates the learning of
spurious features. In addition, we introduce a model selection metric based on
smoothness over time in the latent space. We show that together these two
constraints on VAEs to be smooth over time produce robust latent
representations and faithfully recover latent factors on synthetic datasets.",http://arxiv.org/pdf/2312.06932v1,
Generating High-Resolution Regional Precipitation Using Conditional Diffusion Model,12/12/2023,"Naufal Shidqi, Chaeyoon Jeong, Sungwon Park, Elke Zeller, Arjun Babu Nellikkattil, Karandeep Singh","Climate downscaling is a crucial technique within climate research, serving
to project low-resolution (LR) climate data to higher resolutions (HR).
Previous research has demonstrated the effectiveness of deep learning for
downscaling tasks. However, most deep learning models for climate downscaling
may not perform optimally for high scaling factors (i.e., 4x, 8x) due to their
limited ability to capture the intricate details required for generating HR
climate data. Furthermore, climate data behaves differently from image data,
necessitating a nuanced approach when employing deep generative models. In
response to these challenges, this paper presents a deep generative model for
downscaling climate data, specifically precipitation on a regional scale. We
employ a denoising diffusion probabilistic model (DDPM) conditioned on multiple
LR climate variables. The proposed model is evaluated using precipitation data
from the Community Earth System Model (CESM) v1.2.2 simulation. Our results
demonstrate significant improvements over existing baselines, underscoring the
effectiveness of the conditional diffusion model in downscaling climate data.",http://arxiv.org/pdf/2312.07112v1,
A multi-sourced data and agent-based approach for complementing Time Use Surveys in the context of residential human activity and load curve simulation,13/12/2023,"Mathieu Schumann, Quentin Reynaud, François Sempé, Julien Guibourdenche, Jean-Baptiste Ly, Nicolas Sabouret","To address the major issues associated with using Time-Use Survey (TUS) for
simulating residential load curves, we present the SMACH approach, which
combines qualitative and quantitative data with agent-based simulation. Our
model consists of autonomous agents assigned with daily tasks. The agents try
to accomplish their assigned tasks to the best of their abilities. Quantitative
data are used to generate tasks assignments. Qualitative studies allow us to
define how agents select, based on plausible cognitive principles, the tasks to
accomplish depending on the context. Our results show a better representation
of weekdays and weekends, a more flexible association of tasks with appliances,
and an improved simulation of load curves compared to real data. Highlights
$\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in
activity and energy simulation $\bullet$ Presentation of complementary data
both qualitative and quantitative used to complement TUS data $\bullet$
Proposition of an agent-based approach that balances these limitations",http://arxiv.org/pdf/2312.07966v1,
Time Series Diffusion Method: A Denoising Diffusion Probabilistic Model for Vibration Signal Generation,13/12/2023,"Haiming Yi, Lei Hou, Yuhong Jin, Nasser A. Saeed, Ali Kandil, Hao Duan","Diffusion models have demonstrated powerful data generation capabilities in
various research fields such as image generation. However, in the field of
vibration signal generation, the criteria for evaluating the quality of the
generated signal are different from that of image generation and there is a
fundamental difference between them. At present, there is no research on the
ability of diffusion model to generate vibration signal. In this paper, a Time
Series Diffusion Method (TSDM) is proposed for vibration signal generation,
leveraging the foundational principles of diffusion models. The TSDM uses an
improved U-net architecture with attention block, ResBlock and TimeEmbedding to
effectively segment and extract features from one-dimensional time series data.
It operates based on forward diffusion and reverse denoising processes for
time-series generation. Experimental validation is conducted using
single-frequency, multi-frequency datasets, and bearing fault datasets. The
results show that TSDM can accurately generate the single-frequency and
multi-frequency features in the time series and retain the basic frequency
features for the diffusion generation results of the bearing fault series. It
is also found that the original DDPM could not generate high quality vibration
signals, but the improved U-net in TSDM, which applied the combination of
attention block and ResBlock, could effectively improve the quality of
vibration signal generation. Finally, TSDM is applied to the small sample fault
diagnosis of three public bearing fault datasets, and the results show that the
accuracy of small sample fault diagnosis of the three datasets is improved by
32.380%, 18.355% and 9.298% at most, respectively.",http://arxiv.org/pdf/2312.07981v2,10.1016/j.ymssp.2024.111481
World Models via Policy-Guided Trajectory Diffusion,13/12/2023,"Marc Rigter, Jun Yamada, Ingmar Posner","World models are a powerful tool for developing intelligent agents. By
predicting the outcome of a sequence of actions, world models enable policies
to be optimised via on-policy reinforcement learning (RL) using synthetic data,
i.e. in ""in imagination"". Existing world models are autoregressive in that they
interleave predicting the next state with sampling the next action from the
policy. Prediction error inevitably compounds as the trajectory length grows.
In this work, we propose a novel world modelling approach that is not
autoregressive and generates entire on-policy trajectories in a single pass
through a diffusion model. Our approach, Policy-Guided Trajectory Diffusion
(PolyGRAD), leverages a denoising model in addition to the gradient of the
action distribution of the policy to diffuse a trajectory of initially random
states and actions into an on-policy synthetic trajectory. We analyse the
connections between PolyGRAD, score-based generative models, and
classifier-guided diffusion models. Our results demonstrate that PolyGRAD
outperforms state-of-the-art baselines in terms of trajectory prediction error
for short trajectories, with the exception of autoregressive diffusion. For
short trajectories, PolyGRAD obtains similar errors to autoregressive
diffusion, but with lower computational requirements. For long trajectories,
PolyGRAD obtains comparable performance to baselines. Our experiments
demonstrate that PolyGRAD enables performant policies to be trained via
on-policy RL in imagination for MuJoCo continuous control domains. Thus,
PolyGRAD introduces a new paradigm for accurate on-policy world modelling
without autoregressive sampling.",http://arxiv.org/pdf/2312.08533v4,
Deep Generative Models for Detector Signature Simulation: A Taxonomic Review,15/12/2023,"Baran Hashemi, Claudius Krause","In modern collider experiments, the quest to explore fundamental interactions
between elementary particles has reached unparalleled levels of precision.
Signatures from particle physics detectors are low-level objects (such as
energy depositions or tracks) encoding the physics of collisions (the final
state particles of hard scattering interactions). The complete simulation of
them in a detector is a computational and storage-intensive task. To address
this computational bottleneck in particle physics, alternative approaches have
been developed, introducing additional assumptions and trade off accuracy for
speed.The field has seen a surge in interest in surrogate modeling the detector
simulation, fueled by the advancements in deep generative models. These models
aim to generate responses that are statistically identical to the observed
data. In this paper, we conduct a comprehensive and exhaustive taxonomic review
of the existing literature on the simulation of detector signatures from both
methodological and application-wise perspectives. Initially, we formulate the
problem of detector signature simulation and discuss its different variations
that can be unified. Next, we classify the state-of-the-art methods into five
distinct categories based on their underlying model architectures, summarizing
their respective generation strategies. Finally, we shed light on the
challenges and opportunities that lie ahead in detector signature simulation,
setting the stage for future research and development.",http://arxiv.org/pdf/2312.09597v2,10.1016/j.revip.2024.100092
Variational excess risk bound for general state space models,15/12/2023,"Élisabeth Gassiat, Sylvain Le Corff","In this paper, we consider variational autoencoders (VAE) for general state
space models. We consider a backward factorization of the variational
distributions to analyze the excess risk associated with VAE. Such backward
factorizations were recently proposed to perform online variational learning
and to obtain upper bounds on the variational estimation error. When
independent trajectories of sequences are observed and under strong mixing
assumptions on the state space model and on the variational distribution, we
provide an oracle inequality explicit in the number of samples and in the
length of the observation sequences. We then derive consequences of this
theoretical result. In particular, when the data distribution is given by a
state space model, we provide an upper bound for the Kullback-Leibler
divergence between the data distribution and its estimator and between the
variational posterior and the estimated state space posterior
distributions.Under classical assumptions, we prove that our results can be
applied to Gaussian backward kernels built with dense and recurrent neural
networks.",http://arxiv.org/pdf/2312.09607v1,
Probabilistic learning of the Purkinje network from the electrocardiogram,15/12/2023,"Felipe Álvarez-Barrientos, Mariana Salinas-Camus, Simone Pezzuto, Francisco Sahli Costabal","The identification of the Purkinje conduction system in the heart is a
challenging task, yet essential for a correct definition of cardiac digital
twins for precision cardiology. Here, we propose a probabilistic approach for
identifying the Purkinje network from non-invasive clinical data such as the
standard electrocardiogram (ECG). We use cardiac imaging to build an
anatomically accurate model of the ventricles; we algorithmically generate a
rule-based Purkinje network tailored to the anatomy; we simulate physiological
electrocardiograms with a fast model; we identify the geometrical and
electrical parameters of the Purkinje-ECG model with Bayesian optimization and
approximate Bayesian computation. The proposed approach is inherently
probabilistic and generates a population of plausible Purkinje networks, all
fitting the ECG within a given tolerance. In this way, we can estimate the
uncertainty of the parameters, thus providing reliable predictions. We test our
methodology in physiological and pathological scenarios, showing that we are
able to accurately recover the ECG with our model. We propagate the uncertainty
in the Purkinje network parameters in a simulation of conduction system pacing
therapy. Our methodology is a step forward in creation of digital twins from
non-invasive data in precision medicine. An open source implementation can be
found at http://github.com/fsahli/purkinje-learning",http://arxiv.org/pdf/2312.09887v1,
MusER: Musical Element-Based Regularization for Generating Symbolic Music with Emotion,16/12/2023,"Shulei Ji, Xinyu Yang","Generating music with emotion is an important task in automatic music
generation, in which emotion is evoked through a variety of musical elements
(such as pitch and duration) that change over time and collaborate with each
other. However, prior research on deep learning-based emotional music
generation has rarely explored the contribution of different musical elements
to emotions, let alone the deliberate manipulation of these elements to alter
the emotion of music, which is not conducive to fine-grained element-level
control over emotions. To address this gap, we present a novel approach
employing musical element-based regularization in the latent space to
disentangle distinct elements, investigate their roles in distinguishing
emotions, and further manipulate elements to alter musical emotions.
Specifically, we propose a novel VQ-VAE-based model named MusER. MusER
incorporates a regularization loss to enforce the correspondence between the
musical element sequences and the specific dimensions of latent variable
sequences, providing a new solution for disentangling discrete sequences.
Taking advantage of the disentangled latent vectors, a two-level decoding
strategy that includes multiple decoders attending to latent vectors with
different semantics is devised to better predict the elements. By visualizing
latent space, we conclude that MusER yields a disentangled and interpretable
latent space and gain insights into the contribution of distinct elements to
the emotional dimensions (i.e., arousal and valence). Experimental results
demonstrate that MusER outperforms the state-of-the-art models for generating
emotional music in both objective and subjective evaluation. Besides, we
rearrange music through element transfer and attempt to alter the emotion of
music by transferring emotion-distinguishable elements.",http://arxiv.org/pdf/2312.10307v2,
Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs,16/12/2023,"Kevin Course, Prasanth B. Nair","We consider the problem of inferring latent stochastic differential equations
(SDEs) with a time and memory cost that scales independently with the amount of
data, the total length of the time series, and the stiffness of the approximate
differential equations. This is in stark contrast to typical methods for
inferring latent differential equations which, despite their constant memory
cost, have a time complexity that is heavily dependent on the stiffness of the
approximate differential equation. We achieve this computational advancement by
removing the need to solve differential equations when approximating gradients
using a novel amortization strategy coupled with a recently derived
reparametrization of expectations under linear SDEs. We show that, in practice,
this allows us to achieve similar performance to methods based on adjoint
sensitivities with more than an order of magnitude fewer evaluations of the
model in training.",http://arxiv.org/pdf/2312.10550v1,
Time-Transformer: Integrating Local and Global Features for Better Time Series Generation,18/12/2023,"Yuansan Liu, Sudanthi Wijewickrema, Ang Li, Christofer Bester, Stephen O'Leary, James Bailey","Generating time series data is a promising approach to address data
deficiency problems. However, it is also challenging due to the complex
temporal properties of time series data, including local correlations as well
as global dependencies. Most existing generative models have failed to
effectively learn both the local and global properties of time series data. To
address this open problem, we propose a novel time series generative model
named 'Time-Transformer AAE', which consists of an adversarial autoencoder
(AAE) and a newly designed architecture named 'Time-Transformer' within the
decoder. The Time-Transformer first simultaneously learns local and global
features in a layer-wise parallel design, combining the abilities of Temporal
Convolutional Networks and Transformer in extracting local features and global
dependencies respectively. Second, a bidirectional cross attention is proposed
to provide complementary guidance across the two branches and achieve proper
fusion between local and global features. Experimental results demonstrate that
our model can outperform existing state-of-the-art models in 5 out of 6
datasets, specifically on those with data containing both global and local
properties. Furthermore, we highlight our model's advantage on handling this
kind of data via an artificial dataset. Finally, we show our model's ability to
address a real-world problem: data augmentation to support learning with small
datasets and imbalanced datasets.",http://arxiv.org/pdf/2312.11714v3,
Online Variational Sequential Monte Carlo,19/12/2023,"Alessandro Mastrototaro, Jimmy Olsson","Being the most classical generative model for serial data, state-space models
(SSM) are fundamental in AI and statistical machine learning. In SSM, any form
of parameter learning or latent state inference typically involves the
computation of complex latent-state posteriors. In this work, we build upon the
variational sequential Monte Carlo (VSMC) method, which provides
computationally efficient and accurate model parameter estimation and Bayesian
latent-state inference by combining particle methods and variational inference.
While standard VSMC operates in the offline mode, by re-processing repeatedly a
given batch of data, we distribute the approximation of the gradient of the
VSMC surrogate ELBO in time using stochastic approximation, allowing for online
learning in the presence of streams of data. This results in an algorithm,
online VSMC, that is capable of performing efficiently, entirely on-the-fly,
both parameter estimation and particle proposal adaptation. In addition, we
provide rigorous theoretical results describing the algorithm's convergence
properties as the number of data tends to infinity as well as numerical
illustrations of its excellent convergence properties and usefulness also in
batch-processing settings.",http://arxiv.org/pdf/2312.12616v3,
Class Conditional Time Series Generation with Structured Noise Space GAN,20/12/2023,"Hamidreza Gholamrezaei, Alireza Koochali, Andreas Dengel, Sheraz Ahmed","This paper introduces Structured Noise Space GAN (SNS-GAN), a novel approach
in the field of generative modeling specifically tailored for class-conditional
generation in both image and time series data. It addresses the challenge of
effectively integrating class labels into generative models without requiring
structural modifications to the network. The SNS-GAN method embeds class
conditions within the generator's noise space, simplifying the training process
and enhancing model versatility. The model's efficacy is demonstrated through
qualitative validations in the image domain and superior performance in time
series generation compared to baseline models. This research opens new avenues
for the application of GANs in various domains, including but not limited to
time series and image data generation.",http://arxiv.org/pdf/2312.12946v1,
Neural Stochastic Differential Equations with Change Points: A Generative Adversarial Approach,20/12/2023,"Zhongchang Sun, Yousef El-Laham, Svitlana Vyetrenko","Stochastic differential equations (SDEs) have been widely used to model real
world random phenomena. Existing works mainly focus on the case where the time
series is modeled by a single SDE, which might be restrictive for modeling time
series with distributional shift. In this work, we propose a change point
detection algorithm for time series modeled as neural SDEs. Given a time series
dataset, the proposed method jointly learns the unknown change points and the
parameters of distinct neural SDE models corresponding to each change point.
Specifically, the SDEs are learned under the framework of generative
adversarial networks (GANs) and the change points are detected based on the
output of the GAN discriminator in a forward pass. At each step of the proposed
algorithm, the change points and the SDE model parameters are updated in an
alternating fashion. Numerical results on both synthetic and real datasets are
provided to validate the performance of our algorithm in comparison to
classical change point detection benchmarks, standard GAN-based neural SDEs,
and other state-of-the-art deep generative models for time series data.",http://arxiv.org/pdf/2312.13152v2,
Behaviour Modelling of Social Animals via Causal Structure Discovery and Graph Neural Networks,21/12/2023,"Gaël Gendron, Yang Chen, Mitchell Rogers, Yiping Liu, Mihailo Azhar, Shahrokh Heidari, David Arturo Soriano Valdez, Kobe Knowles, Padriac O'Leary, Simon Eyre, Michael Witbrock, Gillian Dobbie, Jiamou Liu, Patrice Delmas","Better understanding the natural world is a crucial task with a wide range of
applications. In environments with close proximity between humans and animals,
such as zoos, it is essential to better understand the causes behind animal
behaviour and what interventions are responsible for changes in their
behaviours. This can help to predict unusual behaviours, mitigate detrimental
effects and increase the well-being of animals. There has been work on
modelling the dynamics behind swarms of birds and insects but the complex
social behaviours of mammalian groups remain less explored. In this work, we
propose a method to build behavioural models using causal structure discovery
and graph neural networks for time series. We apply this method to a mob of
meerkats in a zoo environment and study its ability to predict future actions
and model the behaviour distribution at an individual-level and at a group
level. We show that our method can match and outperform standard deep learning
architectures and generate more realistic data, while using fewer parameters
and providing increased interpretability.",http://arxiv.org/pdf/2312.14333v1,
Non-Denoising Forward-Time Diffusions,22/12/2023,Stefano Peluchetti,"The scope of this paper is generative modeling through diffusion processes.
An approach falling within this paradigm is the work of Song et al. (2021),
which relies on a time-reversal argument to construct a diffusion process
targeting the desired data distribution. We show that the time-reversal
argument, common to all denoising diffusion probabilistic modeling proposals,
is not necessary. We obtain diffusion processes targeting the desired data
distribution by taking appropriate mixtures of diffusion bridges. The resulting
transport is exact by construction, allows for greater flexibility in choosing
the dynamics of the underlying diffusion, and can be approximated by means of a
neural network via novel training objectives. We develop a unifying view of the
drift adjustments corresponding to our and to time-reversal approaches and make
use of this representation to inspect the inner workings of diffusion-based
generative models. Finally, we leverage on scalable simulation and inference
techniques common in spatial statistics to move beyond fully factorial
distributions in the underlying diffusion dynamics. The methodological advances
contained in this work contribute toward establishing a general framework for
generative modeling based on diffusion processes.",http://arxiv.org/pdf/2312.14589v1,
Time-changed normalizing flows for accurate SDE modeling,22/12/2023,"Naoufal El Bekri, Lucas Drumetz, Franck Vermet","The generative paradigm has become increasingly important in machine learning
and deep learning models. Among popular generative models are normalizing
flows, which enable exact likelihood estimation by transforming a base
distribution through diffeomorphic transformations. Extending the normalizing
flow framework to handle time-indexed flows gave dynamic normalizing flows, a
powerful tool to model time series, stochastic processes, and neural stochastic
differential equations (SDEs). In this work, we propose a novel variant of
dynamic normalizing flows, a Time Changed Normalizing Flow (TCNF), based on
time deformation of a Brownian motion which constitutes a versatile and
extensive family of Gaussian processes. This approach enables us to effectively
model some SDEs, that cannot be modeled otherwise, including standard ones such
as the well-known Ornstein-Uhlenbeck process, and generalizes prior
methodologies, leading to improved results and better inference and prediction
capability.",http://arxiv.org/pdf/2312.14698v2,
Probabilistic Modeling for Sequences of Sets in Continuous-Time,22/12/2023,"Yuxin Chang, Alex Boyd, Padhraic Smyth","Neural marked temporal point processes have been a valuable addition to the
existing toolbox of statistical parametric models for continuous-time event
data. These models are useful for sequences where each event is associated with
a single item (a single type of event or a ""mark"") -- but such models are not
suited for the practical situation where each event is associated with a set of
items. In this work, we develop a general framework for modeling set-valued
data in continuous-time, compatible with any intensity-based recurrent neural
point process model. In addition, we develop inference methods that can use
such models to answer probabilistic queries such as ""the probability of item
$A$ being observed before item $B$,"" conditioned on sequence history. Computing
exact answers for such queries is generally intractable for neural models due
to both the continuous-time nature of the problem setting and the
combinatorially-large space of potential outcomes for each event. To address
this, we develop a class of importance sampling methods for querying with
set-based sequences and demonstrate orders-of-magnitude improvements in
efficiency over direct sampling via systematic experiments with four real-world
datasets. We also illustrate how to use this framework to perform model
selection using likelihoods that do not involve one-step-ahead prediction.",http://arxiv.org/pdf/2312.15045v3,
A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs,26/12/2023,"Sikun Yang, Hongyuan Zha","Continuously-observed event occurrences, often exhibit self- and
mutually-exciting effects, which can be well modeled using temporal point
processes. Beyond that, these event dynamics may also change over time, with
certain periodic trends. We propose a novel variational auto-encoder to capture
such a mixture of temporal dynamics. More specifically, the whole time interval
of the input sequence is partitioned into a set of sub-intervals. The event
dynamics are assumed to be stationary within each sub-interval, but could be
changing across those sub-intervals. In particular, we use a sequential latent
variable model to learn a dependency graph between the observed dimensions, for
each sub-interval. The model predicts the future event times, by using the
learned dependency graph to remove the noncontributing influences of past
events. By doing so, the proposed model demonstrates its higher accuracy in
predicting inter-event times and event types for several real-world event
sequences, compared with existing state of the art neural point processes.",http://arxiv.org/pdf/2312.16083v2,
Sensor Data Simulation for Anomaly Detection of the Elderly Living Alone,28/12/2023,"Kai Tanaka, Mineichi Kudo, Keigo Kimura","With the increase of the number of elderly people living alone around the
world, there is a growing demand for sensor-based detection of anomalous
behaviors. Although smart homes with ambient sensors could be useful for
detecting such anomalies, there is a problem of lack of sufficient real data
for developing detection algorithms. For coping with this problem, several
sensor data simulators have been proposed, but they have not been able to model
appropriately the long-term transitions and correlations between anomalies that
exist in reality. In this paper, therefore, we propose a novel sensor data
simulator that can model these factors in generation of sensor data. Anomalies
considered in this study were classified into three types of \textit{state
anomalies}, \textit{activity anomalies}, and \textit{moving anomalies}. The
simulator produces 10 years data in 100 min. including six anomalies, two for
each type. Numerical evaluations show that this simulator is superior to the
past simulators in the sense that it simulates well day-to-day variations of
real data.",http://arxiv.org/pdf/2312.16852v1,10.1109/JIOT.2024.3421548
Synthetic Data Applications in Finance,29/12/2023,"Vamsi K. Potluru, Daniel Borrajo, Andrea Coletta, Niccolò Dalmasso, Yousef El-Laham, Elizabeth Fons, Mohsen Ghassemi, Sriram Gopalakrishnan, Vikesh Gosai, Eleonora Kreačić, Ganapathy Mani, Saheed Obitayo, Deepak Paramanand, Natraj Raman, Mikhail Solonin, Srijan Sood, Svitlana Vyetrenko, Haibei Zhu, Manuela Veloso, Tucker Balch","Synthetic data has made tremendous strides in various commercial settings
including finance, healthcare, and virtual reality. We present a broad overview
of prototypical applications of synthetic data in the financial sector and in
particular provide richer details for a few select ones. These cover a wide
variety of data modalities including tabular, time-series, event-series, and
unstructured arising from both markets and retail financial applications. Since
finance is a highly regulated industry, synthetic data is a potential approach
for dealing with issues related to privacy, fairness, and explainability.
Various metrics are utilized in evaluating the quality and effectiveness of our
approaches in these applications. We conclude with open directions in synthetic
data in the context of the financial domain.",http://arxiv.org/pdf/2401.00081v2,
WildGEN: Long-horizon Trajectory Generation for Wildlife,30/12/2023,"Ali Al-Lawati, Elsayed Eshra, Prasenjit Mitra","Trajectory generation is an important concern in pedestrian, vehicle, and
wildlife movement studies. Generated trajectories help enrich the training
corpus in relation to deep learning applications, and may be used to facilitate
simulation tasks. This is especially significant in the wildlife domain, where
the cost of obtaining additional real data can be prohibitively expensive,
time-consuming, and bear ethical considerations. In this paper, we introduce
WildGEN: a conceptual framework that addresses this challenge by employing a
Variational Auto-encoders (VAEs) based method for the acquisition of movement
characteristics exhibited by wild geese over a long horizon using a sparse set
of truth samples. A subsequent post-processing step of the generated
trajectories is performed based on smoothing filters to reduce excessive
wandering. Our evaluation is conducted through visual inspection and the
computation of the Hausdorff distance between the generated and real
trajectories. In addition, we utilize the Pearson Correlation Coefficient as a
way to measure how realistic the trajectories are based on the similarity of
clusters evaluated on the generated and real trajectories.",http://arxiv.org/pdf/2401.05421v1,
Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective,01/01/2024,"Din-Yin Hsieh, Chi-Hua Wang, Guang Cheng","Exploring generative model training for synthetic tabular data, specifically
in sequential contexts such as credit card transaction data, presents
significant challenges. This paper addresses these challenges, focusing on
attaining both high fidelity to actual data and optimal utility for machine
learning tasks. We introduce five pre-processing schemas to enhance the
training of the Conditional Probabilistic Auto-Regressive Model (CPAR),
demonstrating incremental improvements in the synthetic data's fidelity and
utility. Upon achieving satisfactory fidelity levels, our attention shifts to
training fraud detection models tailored for time-series data, evaluating the
utility of the synthetic data. Our findings offer valuable insights and
practical guidelines for synthetic data practitioners in the finance sector,
transitioning from real to synthetic datasets for training purposes, and
illuminating broader methodologies for synthesizing credit card transaction
time series.",http://arxiv.org/pdf/2401.00965v1,
Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences,03/01/2024,"Piotr Skalski, David Sutton, Stuart Burrell, Iker Perez, Jason Wong","Machine learning models underpin many modern financial systems for use cases
such as fraud detection and churn prediction. Most are based on supervised
learning with hand-engineered features, which relies heavily on the
availability of labelled data. Large self-supervised generative models have
shown tremendous success in natural language processing and computer vision,
yet so far they haven't been adapted to multivariate time series of financial
transactions. In this paper, we present a generative pretraining method that
can be used to obtain contextualised embeddings of financial transactions.
Benchmarks on public datasets demonstrate that it outperforms state-of-the-art
self-supervised methods on a range of downstream tasks. We additionally perform
large-scale pretraining of an embedding model using a corpus of data from 180
issuing banks containing 5.1 billion transactions and apply it to the card
fraud detection problem on hold-out datasets. The embedding model significantly
improves value detection rate at high precision thresholds and transfers well
to out-of-domain distributions.",http://arxiv.org/pdf/2401.01641v2,10.1145/3604237.3626850
Representation Learning of Multivariate Time Series using Attention and Adversarial Training,03/01/2024,"Leon Scharwächter, Sebastian Otte","A critical factor in trustworthy machine learning is to develop robust
representations of the training data. Only under this guarantee methods are
legitimate to artificially generate data, for example, to counteract imbalanced
datasets or provide counterfactual explanations for blackbox decision-making
systems. In recent years, Generative Adversarial Networks (GANs) have shown
considerable results in forming stable representations and generating realistic
data. While many applications focus on generating image data, less effort has
been made in generating time series data, especially multivariate signals. In
this work, a Transformer-based autoencoder is proposed that is regularized
using an adversarial training scheme to generate artificial multivariate time
series signals. The representation is evaluated using t-SNE visualizations,
Dynamic Time Warping (DTW) and Entropy scores. Our results indicate that the
generated signals exhibit higher similarity to an exemplary dataset than using
a convolutional network approach.",http://arxiv.org/pdf/2401.01987v2,
Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection,07/01/2024,"Zhangkai Wu, Longbing Cao, Qi Zhang, Junxian Zhou, Hui Chen","Due to their unsupervised training and uncertainty estimation, deep
Variational Autoencoders (VAEs) have become powerful tools for
reconstruction-based Time Series Anomaly Detection (TSAD). Existing VAE-based
TSAD methods, either statistical or deep, tune meta-priors to estimate the
likelihood probability for effectively capturing spatiotemporal dependencies in
the data. However, these methods confront the challenge of inherent data
scarcity, which is often the case in anomaly detection tasks. Such scarcity
easily leads to latent holes, discontinuous regions in latent space, resulting
in non-robust reconstructions on these discontinuous spaces. We propose a novel
generative framework that combines VAEs with self-supervised learning (SSL) to
address this issue.",http://arxiv.org/pdf/2401.03341v1,
scDiffusion: conditional generation of high-quality single-cell data using diffusion model,08/01/2024,"Erpai Luo, Minsheng Hao, Lei Wei, Xuegong Zhang","Single-cell RNA sequencing (scRNA-seq) data are important for studying the
laws of life at single-cell level. However, it is still challenging to obtain
enough high-quality scRNA-seq data. To mitigate the limited availability of
data, generative models have been proposed to computationally generate
synthetic scRNA-seq data. Nevertheless, the data generated with current models
are not very realistic yet, especially when we need to generate data with
controlled conditions. In the meantime, the Diffusion models have shown their
power in generating data at high fidelity, providing a new opportunity for
scRNA-seq generation.
  In this study, we developed scDiffusion, a generative model combining
diffusion model and foundation model to generate high-quality scRNA-seq data
with controlled conditions. We designed multiple classifiers to guide the
diffusion process simultaneously, enabling scDiffusion to generate data under
multiple condition combinations. We also proposed a new control strategy called
Gradient Interpolation. This strategy allows the model to generate continuous
trajectories of cell development from a given cell state.
  Experiments showed that scDiffusion can generate single-cell gene expression
data closely resembling real scRNA-seq data. Also, scDiffusion can
conditionally produce data on specific cell types including rare cell types.
Furthermore, we could use the multiple-condition generation of scDiffusion to
generate cell type that was out of the training data. Leveraging the Gradient
Interpolation strategy, we generated a continuous developmental trajectory of
mouse embryonic cells. These experiments demonstrate that scDiffusion is a
powerful tool for augmenting the real scRNA-seq data and can provide insights
into cell fate research.",http://arxiv.org/pdf/2401.03968v2,
Generative adversarial wavelet neural operator: Application to fault detection and isolation of multivariate time series data,08/01/2024,"Jyoti Rani, Tapas Tripura, Hariprasad Kodamana, Souvik Chakraborty","Fault detection and isolation in complex systems are critical to ensure
reliable and efficient operation. However, traditional fault detection methods
often struggle with issues such as nonlinearity and multivariate
characteristics of the time series variables. This article proposes a
generative adversarial wavelet neural operator (GAWNO) as a novel unsupervised
deep learning approach for fault detection and isolation of multivariate time
series processes.The GAWNO combines the strengths of wavelet neural operators
and generative adversarial networks (GANs) to effectively capture both the
temporal distributions and the spatial dependencies among different variables
of an underlying system. The approach of fault detection and isolation using
GAWNO consists of two main stages. In the first stage, the GAWNO is trained on
a dataset of normal operating conditions to learn the underlying data
distribution. In the second stage, a reconstruction error-based threshold
approach using the trained GAWNO is employed to detect and isolate faults based
on the discrepancy values. We validate the proposed approach using the
Tennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant
(WWTP) and N2O emissions named as WWTPN2O datasets. Overall, we showcase that
the idea of harnessing the power of wavelet analysis, neural operators, and
generative models in a single framework to detect and isolate faults has shown
promising results compared to various well-established baselines in the
literature.",http://arxiv.org/pdf/2401.04004v1,
IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records,09/01/2024,"Ghadeer O. Ghosheh, Jin Li, Tingting Zhu","Electronic Health Records present a valuable modality for driving
personalized medicine, where treatment is tailored to fit individual-level
differences. For this purpose, many data-driven machine learning and
statistical models rely on the wealth of longitudinal EHRs to study patients'
physiological and treatment effects. However, longitudinal EHRs tend to be
sparse and highly missing, where missingness could also be informative and
reflect the underlying patient's health status. Therefore, the success of
data-driven models for personalized medicine highly depends on how the EHR data
is represented from physiological data, treatments, and the missing values in
the data. To this end, we propose a novel deep-learning model that learns the
underlying patient dynamics over time across multivariate data to generate
personalized realistic values conditioning on an individual's demographic
characteristics and treatments. Our proposed model, IGNITE (Individualized
GeNeration of Imputations in Time-series Electronic health records), utilises a
conditional dual-variational autoencoder augmented with dual-stage attention to
generate missing values for an individual. In IGNITE, we further propose a
novel individualized missingness mask (IMM), which helps our model generate
values based on the individual's observed data and missingness patterns. We
further extend the use of IGNITE from imputing missingness to a personalized
data synthesizer, where it generates missing EHRs that were never observed
prior or even generates new patients for various applications. We validate our
model on three large publicly available datasets and show that IGNITE
outperforms state-of-the-art approaches in missing data reconstruction and task
prediction.",http://arxiv.org/pdf/2401.04402v2,
A Physics-informed machine learning model for time-dependent wave runup prediction,12/01/2024,"Saeed Saviz Naeini, Reda Snaiki","Wave runup is a critical factor affecting coastal flooding, shoreline
changes, and damage to coastal structures. Climate change is also expected to
amplify wave runup's impact on coastal areas. Therefore, fast and accurate wave
runup estimation is essential for effective coastal engineering design and
management. However, predicting the time-dependent wave runup is challenging
due to the intrinsic nonlinearities and non-stationarity of the process, even
with the use of the most advanced machine learning techniques. In this study, a
physics-informed machine learning-based approach is proposed to efficiently and
accurately simulate time-series wave runup. The methodology combines the
computational efficiency of the Surfbeat (XBSB) mode with the accuracy of the
nonhydrostatic (XBNH) mode of the XBeach model. Specifically, a conditional
generative adversarial network (cGAN) is used to map the image representation
of wave runup from XBSB to the corresponding image from XBNH. These images are
generated by first converting wave runup signals into time-frequency scalograms
and then transforming them into image representations. The cGAN model achieves
improved performance in image-to-image mapping tasks by incorporating
physics-based knowledge from XBSB. After training the model, the high-fidelity
XBNH-based scalograms can be predicted, which are then employed to reconstruct
the time-series wave runup using the inverse wavelet transform. The simulation
results underscore the efficiency and robustness of the proposed model in
predicting wave runup, suggesting its potential value for applications in risk
assessment and management.",http://arxiv.org/pdf/2401.08684v1,
BioDiffusion: A Versatile Diffusion Model for Biomedical Signal Synthesis,12/01/2024,"Xiaomin Li, Mykhailo Sakevych, Gentry Atkinson, Vangelis Metsis","Machine learning tasks involving biomedical signals frequently grapple with
issues such as limited data availability, imbalanced datasets, labeling
complexities, and the interference of measurement noise. These challenges often
hinder the optimal training of machine learning algorithms. Addressing these
concerns, we introduce BioDiffusion, a diffusion-based probabilistic model
optimized for the synthesis of multivariate biomedical signals. BioDiffusion
demonstrates excellence in producing high-fidelity, non-stationary,
multivariate signals for a range of tasks including unconditional,
label-conditional, and signal-conditional generation. Leveraging these
synthesized signals offers a notable solution to the aforementioned challenges.
Our research encompasses both qualitative and quantitative assessments of the
synthesized data quality, underscoring its capacity to bolster accuracy in
machine learning tasks tied to biomedical signals. Furthermore, when juxtaposed
with current leading time-series generative models, empirical evidence suggests
that BioDiffusion outperforms them in biomedical signal generation quality.",http://arxiv.org/pdf/2401.10282v2,
Distilling Event Sequence Knowledge From Large Language Models,14/01/2024,"Somin Wadhwa, Oktie Hassanzadeh, Debarun Bhattacharjya, Ken Barker, Jian Ni","Event sequence models have been found to be highly effective in the analysis
and prediction of events. Building such models requires availability of
abundant high-quality event sequence data. In certain applications, however,
clean structured event sequences are not available, and automated sequence
extraction results in data that is too noisy and incomplete. In this work, we
explore the use of Large Language Models (LLMs) to generate event sequences
that can effectively be used for probabilistic event model construction. This
can be viewed as a mechanism of distilling event sequence knowledge from LLMs.
Our approach relies on a Knowledge Graph (KG) of event concepts with partial
causal relations to guide the generative language model for causal event
sequence generation. We show that our approach can generate high-quality event
sequences, filling a knowledge gap in the input KG. Furthermore, we explore how
the generated sequences can be leveraged to discover useful and more complex
structured knowledge from pattern mining and probabilistic event models. We
release our sequence generation code and evaluation framework, as well as
corpus of event sequence data.",http://arxiv.org/pdf/2401.07237v3,
Multi-view MidiVAE: Fusing Track- and Bar-view Representations for Long Multi-track Symbolic Music Generation,15/01/2024,"Zhiwei Lin, Jun Chen, Boshi Tang, Binzhu Sha, Jing Yang, Yaolong Ju, Fan Fan, Shiyin Kang, Zhiyong Wu, Helen Meng","Variational Autoencoders (VAEs) constitute a crucial component of neural
symbolic music generation, among which some works have yielded outstanding
results and attracted considerable attention. Nevertheless, previous VAEs still
encounter issues with overly long feature sequences and generated results lack
contextual coherence, thus the challenge of modeling long multi-track symbolic
music still remains unaddressed. To this end, we propose Multi-view MidiVAE, as
one of the pioneers in VAE methods that effectively model and generate long
multi-track symbolic music. The Multi-view MidiVAE utilizes the two-dimensional
(2-D) representation, OctupleMIDI, to capture relationships among notes while
reducing the feature sequences length. Moreover, we focus on instrumental
characteristics and harmony as well as global and local information about the
musical composition by employing a hybrid variational encoding-decoding
strategy to integrate both Track- and Bar-view MidiVAE features. Objective and
subjective experimental results on the CocoChorales dataset demonstrate that,
compared to the baseline, Multi-view MidiVAE exhibits significant improvements
in terms of modeling long multi-track symbolic music.",http://arxiv.org/pdf/2401.07532v1,
Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets,17/01/2024,"Timothée Fabre, Ioane Muni Toke","We propose a novel approach to marked Hawkes kernel inference which we name
the moment-based neural Hawkes estimation method. Hawkes processes are fully
characterized by their first and second order statistics through a Fredholm
integral equation of the second kind. Using recent advances in solving partial
differential equations with physics-informed neural networks, we provide a
numerical procedure to solve this integral equation in high dimension. Together
with an adapted training pipeline, we give a generic set of hyperparameters
that produces robust results across a wide range of kernel shapes. We conduct
an extensive numerical validation on simulated data. We finally propose two
applications of the method to the analysis of the microstructure of
cryptocurrency markets. In a first application we extract the influence of
volume on the arrival rate of BTC-USD trades and in a second application we
analyze the causality relationships and their directions amongst a universe of
15 cryptocurrency pairs in a centralized exchange.",http://arxiv.org/pdf/2401.09361v3,
Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review,18/01/2024,"Lars Ericson, Xuejun Zhu, Xusi Han, Rao Fu, Shuang Li, Steve Guo, Ping Hu","In the financial services industry, forecasting the risk factor distribution
conditional on the history and the current market environment is the key to
market risk modeling in general and value at risk (VaR) model in particular. As
one of the most widely adopted VaR models in commercial banks, Historical
simulation (HS) uses the empirical distribution of daily returns in a
historical window as the forecast distribution of risk factor returns in the
next day. The objectives for financial time series generation are to generate
synthetic data paths with good variety, and similar distribution and dynamics
to the original historical data. In this paper, we apply multiple existing deep
generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for
conditional time series generation, and propose and test two new methods for
conditional multi-step time series generation, namely Encoder-Decoder CGAN and
Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a
set of KPIs to measure the quality of the generated time series for financial
modeling. The KPIs cover distribution distance, autocorrelation and
backtesting. All models (HS, parametric and neural networks) are tested on both
historical USD yield curve data and additional data simulated from GARCH and
CIR processes. The study shows that top performing models are HS, GARCH and
CWGAN models. Future research directions in this area are also discussed.",http://arxiv.org/pdf/2401.10370v1,
CaRiNG: Learning Temporal Causal Representation under Non-Invertible Generation Process,25/01/2024,"Guangyi Chen, Yifan Shen, Zhenhao Chen, Xiangchen Song, Yuewen Sun, Weiran Yao, Xiao Liu, Kun Zhang","Identifying the underlying time-delayed latent causal processes in sequential
data is vital for grasping temporal dynamics and making downstream reasoning.
While some recent methods can robustly identify these latent causal variables,
they rely on strict assumptions about the invertible generation process from
latent variables to observed data. However, these assumptions are often hard to
satisfy in real-world applications containing information loss. For instance,
the visual perception process translates a 3D space into 2D images, or the
phenomenon of persistence of vision incorporates historical data into current
perceptions. To address this challenge, we establish an identifiability theory
that allows for the recovery of independent latent components even when they
come from a nonlinear and non-invertible mix. Using this theory as a
foundation, we propose a principled approach, CaRiNG, to learn the CAusal
RepresentatIon of Non-invertible Generative temporal data with identifiability
guarantees. Specifically, we utilize temporal context to recover lost latent
information and apply the conditions in our theory to guide the training
process. Through experiments conducted on synthetic datasets, we validate that
our CaRiNG method reliably identifies the causal process, even when the
generation process is non-invertible. Moreover, we demonstrate that our
approach considerably improves temporal understanding and reasoning in
practical applications.",http://arxiv.org/pdf/2401.14535v2,
Discovering group dynamics in coordinated time series via hierarchical recurrent switching-state models,26/01/2024,"Michael T. Wojnowicz, Kaitlin Gili, Preetish Rath, Eric Miller, Jeffrey Miller, Clifford Hancock, Meghan O'Donovan, Seth Elkin-Frankston, Tad T. Brunyé, Michael C. Hughes","We seek a computationally efficient model for a collection of time series
arising from multiple interacting entities (a.k.a. ""agents""). Recent models of
spatiotemporal patterns across individuals fail to incorporate explicit
system-level collective behavior that can influence the trajectories of
individual entities. To address this gap in the literature, we present a new
hierarchical switching-state model that can be trained in an unsupervised
fashion to simultaneously learn both system-level and individual-level
dynamics. We employ a latent system-level discrete state Markov chain that
provides top-down influence on latent entity-level chains which in turn govern
the emission of each observed time series. Recurrent feedback from the
observations to the latent chains at both entity and system levels allows
recent situational context to inform how dynamics unfold at all levels in
bottom-up fashion. We hypothesize that including both top-down and bottom-up
influences on group dynamics will improve interpretability of the learned
dynamics and reduce error when forecasting. Our hierarchical switching
recurrent dynamical model can be learned via closed-form variational coordinate
ascent updates to all latent chains that scale linearly in the number of
entities. This is asymptotically no more costly than fitting a separate model
for each entity. Analysis of both synthetic data and real basketball team
movements suggests our lean parametric model can achieve competitive forecasts
compared to larger neural network models that require far more computational
resources. Further experiments on soldier data as well as a synthetic task with
64 cooperating entities show how our approach can yield interpretable insights
about team dynamics over time.",http://arxiv.org/pdf/2401.14973v2,
MLEM: Generative and Contrastive Learning as Distinct Modalities for Event Sequences,29/01/2024,"Viktor Moskvoretskii, Dmitry Osin, Egor Shvetsov, Igor Udovichenko, Maxim Zhelnin, Andrey Dukhovny, Anna Zhimerikina, Evgeny Burnaev","This study explores the application of self-supervised learning techniques
for event sequences. It is a key modality in various applications such as
banking, e-commerce, and healthcare. However, there is limited research on
self-supervised learning for event sequences, and methods from other domains
like images, texts, and speech may not easily transfer. To determine the most
suitable approach, we conduct a detailed comparative analysis of previously
identified best-performing methods. We find that neither the contrastive nor
generative method is superior. Our assessment includes classifying event
sequences, predicting the next event, and evaluating embedding quality. These
results further highlight the potential benefits of combining both methods.
Given the lack of research on hybrid models in this domain, we initially adapt
the baseline model from another domain. However, upon observing its
underperformance, we develop a novel method called the Multimodal-Learning
Event Model (MLEM). MLEM treats contrastive learning and generative modeling as
distinct yet complementary modalities, aligning their embeddings. The results
of our study demonstrate that combining contrastive and generative approaches
into one procedure with MLEM achieves superior performance across multiple
metrics.",http://arxiv.org/pdf/2401.15935v4,
cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and Glitch Generation,29/01/2024,"Tom Dooney, Lyana Curier, Daniel Tan, Melissa Lopez, Chris Van Den Broeck, Stefano Bromuri","Simulating realistic time-domain observations of gravitational waves (GWs)
and GW detector glitches can help in advancing GW data analysis. Simulated data
can be used in downstream tasks by augmenting datasets for signal searches,
balancing data sets for machine learning, and validating detection schemes. In
this work, we present Conditional Derivative GAN (cDVGAN), a novel conditional
model in the Generative Adversarial Network framework for simulating multiple
classes of time-domain observations that represent gravitational waves (GWs)
and detector glitches. cDVGAN can also generate generalized hybrid samples that
span the variation between classes through interpolation in the conditioned
class vector. cDVGAN introduces an additional player into the typical 2-player
adversarial game of GANs, where an auxiliary discriminator analyzes the
first-order derivative time-series. Our results show that this provides
synthetic data that better captures the features of the original data. cDVGAN
conditions on three classes, two denoised from LIGO blip and tomte glitch
events from its 3rd observing run (O3), and the third representing binary black
hole (BBH) mergers. Our proposed cDVGAN outperforms 4 different baseline GAN
models in replicating the features of the three classes. Specifically, our
experiments show that training convolutional neural networks (CNNs) with our
cDVGAN-generated data improves the detection of samples embedded in detector
noise beyond the synthetic data from other state-of-the-art GAN models. Our
best synthetic dataset yields as much as a 4.2% increase in
area-under-the-curve (AUC) performance compared to synthetic datasets from
baseline GANs. Moreover, training the CNN with hybrid samples from our cDVGAN
outperforms CNNs trained only on the standard classes, when identifying real
samples embedded in LIGO detector background (4% AUC improvement for cDVGAN).",http://arxiv.org/pdf/2401.16356v5,
Fully Data-Driven Model for Increasing Sampling Rate Frequency of Seismic Data using Super-Resolution Generative Adversarial Networks,31/01/2024,"Navid Gholizadeh, Javad Katebi","High-quality data is one of the key requirements for any engineering
application. In earthquake engineering practice, accurate data is pivotal in
predicting the response of structure or damage detection process in an
Structural Health Monitoring (SHM) application with less uncertainty. However,
obtaining high-resolution data is fraught with challenges, such as significant
costs, extensive data channels, and substantial storage requirements. To
address these challenges, this study employs super-resolution generative
adversarial networks (SRGANs) to improve the resolution of time-history data
such as the data obtained by a sensor network in an SHM application, marking
the first application of SRGANs in earthquake engineering domain. The
time-series data are transformed into RGB values, converting raw data into
images. SRGANs are then utilized to upscale these low-resolution images,
thereby enhancing the overall sensor resolution. This methodology not only
offers potential reductions in data storage requirements but also simplifies
the sensor network, which could result in lower installation and maintenance
costs. The proposed SRGAN method is rigorously evaluated using real seismic
data, and its performance is compared with traditional enhancement techniques.
The findings of this study pave the way for cost-effective and efficient
improvements in the resolution of sensors used in SHM systems, with promising
implications for the safety and sustainability of infrastructures worldwide.",http://arxiv.org/pdf/2402.00153v1,
Cumulative Distribution Function based General Temporal Point Processes,01/02/2024,"Maolin Wang, Yu Pan, Zenglin Xu, Ruocheng Guo, Xiangyu Zhao, Wanyu Wang, Yiqi Wang, Zitao Liu, Langming Liu","Temporal Point Processes (TPPs) hold a pivotal role in modeling event
sequences across diverse domains, including social networking and e-commerce,
and have significantly contributed to the advancement of recommendation systems
and information retrieval strategies. Through the analysis of events such as
user interactions and transactions, TPPs offer valuable insights into
behavioral patterns, facilitating the prediction of future trends. However,
accurately forecasting future events remains a formidable challenge due to the
intricate nature of these patterns. The integration of Neural Networks with
TPPs has ushered in the development of advanced deep TPP models. While these
models excel at processing complex and nonlinear temporal data, they encounter
limitations in modeling intensity functions, grapple with computational
complexities in integral computations, and struggle to capture long-range
temporal dependencies effectively. In this study, we introduce the CuFun model,
representing a novel approach to TPPs that revolves around the Cumulative
Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic
neural network for CDF representation, utilizing past events as a scaling
factor. This innovation significantly bolsters the model's adaptability and
precision across a wide range of data scenarios. Our approach addresses several
critical issues inherent in traditional TPP modeling: it simplifies
log-likelihood calculations, extends applicability beyond predefined density
function forms, and adeptly captures long-range temporal patterns. Our
contributions encompass the introduction of a pioneering CDF-based TPP model,
the development of a methodology for incorporating past event information into
future event prediction, and empirical validation of CuFun's effectiveness
through extensive experimentation on synthetic and real-world datasets.",http://arxiv.org/pdf/2402.00388v1,
Are Synthetic Time-series Data Really not as Good as Real Data?,01/02/2024,"Fanzhe Fu, Junru Chen, Jing Zhang, Carl Yang, Lvbin Ma, Yang Yang","Time-series data presents limitations stemming from data quality issues, bias
and vulnerabilities, and generalization problem. Integrating universal data
synthesis methods holds promise in improving generalization. However, current
methods cannot guarantee that the generator's output covers all unseen real
data. In this paper, we introduce InfoBoost -- a highly versatile cross-domain
data synthesizing framework with time series representation learning
capability. We have developed a method based on synthetic data that enables
model training without the need for real data, surpassing the performance of
models trained with real data. Additionally, we have trained a universal
feature extractor based on our synthetic data that is applicable to all
time-series data. Our approach overcomes interference from multiple sources
rhythmic signal, noise interference, and long-period features that exceed
sampling window capabilities. Through experiments, our non-deep-learning
synthetic data enables models to achieve superior reconstruction performance
and universal explicit representation extraction without the need for real
data.",http://arxiv.org/pdf/2402.00607v1,
Response Theory via Generative Score Modeling,01/02/2024,"Ludovico Theo Giorgini, Katherine Deck, Tobias Bischoff, Andre Souza","We introduce an approach for analyzing the responses of dynamical systems to
external perturbations that combines score-based generative modeling with the
Generalized Fluctuation-Dissipation Theorem (GFDT). The methodology enables
accurate estimation of system responses, including those with non-Gaussian
statistics. We numerically validate our approach using time-series data from
three different stochastic partial differential equations of increasing
complexity: an Ornstein-Uhlenbeck process with spatially correlated noise, a
modified stochastic Allen-Cahn equation, and the 2D Navier-Stokes equations. We
demonstrate the improved accuracy of the methodology over conventional methods
and discuss its potential as a versatile tool for predicting the statistical
behavior of complex dynamical systems.",http://arxiv.org/pdf/2402.01029v3,
Conditioning non-linear and infinite-dimensional diffusion processes,02/02/2024,"Elizabeth Louise Baker, Gefan Yang, Michael L. Severinsen, Christy Anna Hipsley, Stefan Sommer","Generative diffusion models and many stochastic models in science and
engineering naturally live in infinite dimensions before discretisation. To
incorporate observed data for statistical and learning tasks, one needs to
condition on observations. While recent work has treated conditioning linear
processes in infinite dimensions, conditioning non-linear processes in infinite
dimensions has not been explored. This paper conditions function valued
stochastic processes without prior discretisation. To do so, we use an
infinite-dimensional version of Girsanov's theorem to condition a
function-valued stochastic process, leading to a stochastic differential
equation (SDE) for the conditioned process involving the score. We apply this
technique to do time series analysis for shapes of organisms in evolutionary
biology, where we discretise via the Fourier basis and then learn the
coefficients of the score function with score matching methods.",http://arxiv.org/pdf/2402.01434v2,
GenFormer: A Deep-Learning-Based Approach for Generating Multivariate Stochastic Processes,03/02/2024,"Haoran Zhao, Wayne Isaac Tan Uy","Stochastic generators are essential to produce synthetic realizations that
preserve target statistical properties. We propose GenFormer, a stochastic
generator for spatio-temporal multivariate stochastic processes. It is
constructed using a Transformer-based deep learning model that learns a mapping
between a Markov state sequence and time series values. The synthetic data
generated by the GenFormer model preserves the target marginal distributions
and approximately captures other desired statistical properties even in
challenging applications involving a large number of spatial locations and a
long simulation horizon. The GenFormer model is applied to simulate synthetic
wind speed data at various stations in Florida to calculate exceedance
probabilities for risk management.",http://arxiv.org/pdf/2402.02010v1,
Risk-Sensitive Diffusion: Robustly Optimizing Diffusion Models with Noisy Samples,03/02/2024,"Yangming Li, Max Ruiz Luyten, Mihaela van der Schaar","Diffusion models are mainly studied on image data. However, non-image data
(e.g., tabular data) are also prevalent in real applications and tend to be
noisy due to some inevitable factors in the stage of data collection, degrading
the generation quality of diffusion models. In this paper, we consider a novel
problem setting where every collected sample is paired with a vector indicating
the data quality: risk vector. This setting applies to many scenarios involving
noisy data and we propose risk-sensitive SDE, a type of stochastic differential
equation (SDE) parameterized by the risk vector, to address it. With some
proper coefficients, risk-sensitive SDE can minimize the negative effect of
noisy samples on the optimization of diffusion models. We conduct systematic
studies for both Gaussian and non-Gaussian noise distributions, providing
analytical forms of risk-sensitive SDE. To verify the effectiveness of our
method, we have conducted extensive experiments on multiple tabular and
time-series datasets, showing that risk-sensitive SDE permits a robust
optimization of diffusion models with noisy samples and significantly
outperforms previous baselines.",http://arxiv.org/pdf/2402.02081v3,
SudokuSens: Enhancing Deep Learning Robustness for IoT Sensing Applications using a Generative Approach,03/02/2024,"Tianshi Wang, Jinyang Li, Ruijie Wang, Denizhan Kara, Shengzhong Liu, Davis Wertheimer, Antoni Viros-i-Martin, Raghu Ganti, Mudhakar Srivatsa, Tarek Abdelzaher","This paper introduces SudokuSens, a generative framework for automated
generation of training data in machine-learning-based Internet-of-Things (IoT)
applications, such that the generated synthetic data mimic experimental
configurations not encountered during actual sensor data collection. The
framework improves the robustness of resulting deep learning models, and is
intended for IoT applications where data collection is expensive. The work is
motivated by the fact that IoT time-series data entangle the signatures of
observed objects with the confounding intrinsic properties of the surrounding
environment and the dynamic environmental disturbances experienced. To
incorporate sufficient diversity into the IoT training data, one therefore
needs to consider a combinatorial explosion of training cases that are
multiplicative in the number of objects considered and the possible
environmental conditions in which such objects may be encountered. Our
framework substantially reduces these multiplicative training needs. To
decouple object signatures from environmental conditions, we employ a
Conditional Variational Autoencoder (CVAE) that allows us to reduce data
collection needs from multiplicative to (nearly) linear, while synthetically
generating (data for) the missing conditions. To obtain robustness with respect
to dynamic disturbances, a session-aware temporal contrastive learning approach
is taken. Integrating the aforementioned two approaches, SudokuSens
significantly improves the robustness of deep learning for IoT applications. We
explore the degree to which SudokuSens benefits downstream inference tasks in
different data sets and discuss conditions under which the approach is
particularly effective.",http://arxiv.org/pdf/2402.02275v2,10.1145/3625687.3625785
Timer: Generative Pre-trained Transformers Are Large Time Series Models,04/02/2024,"Yong Liu, Haoran Zhang, Chenyu Li, Xiangdong Huang, Jianmin Wang, Mingsheng Long","Deep learning has contributed remarkably to the advancement of time series
analysis. Still, deep models can encounter performance bottlenecks in
real-world data-scarce scenarios, which can be concealed due to the performance
saturation with small models on current benchmarks. Meanwhile, large models
have demonstrated great powers in these scenarios through large-scale
pre-training. Continuous progress has been achieved with the emergence of large
language models, exhibiting unprecedented abilities such as few-shot
generalization, scalability, and task generality, which are however absent in
small deep models. To change the status quo of training scenario-specific small
models from scratch, this paper aims at the early development of large time
series models (LTSM). During pre-training, we curate large-scale datasets with
up to 1 billion time points, unify heterogeneous time series into single-series
sequence (S3) format, and develop the GPT-style architecture toward LTSMs. To
meet diverse application needs, we convert forecasting, imputation, and anomaly
detection of time series into a unified generative task. The outcome of this
study is a Time Series Transformer (Timer), which is generative pre-trained by
next token prediction and adapted to various downstream tasks with promising
capabilities as an LTSM. Code and datasets are available at:
https://github.com/thuml/Large-Time-Series-Model.",http://arxiv.org/pdf/2402.02368v3,
Correlational Lagrangian Schrödinger Bridge: Learning Dynamics with Population-Level Regularization,04/02/2024,"Yuning You, Ruida Zhou, Yang Shen","Accurate modeling of system dynamics holds intriguing potential in broad
scientific fields including cytodynamics and fluid mechanics. This task often
presents significant challenges when (i) observations are limited to
cross-sectional samples (where individual trajectories are inaccessible for
learning), and moreover, (ii) the behaviors of individual particles are
heterogeneous (especially in biological systems due to biodiversity). To
address them, we introduce a novel framework dubbed correlational Lagrangian
Schr\""odinger bridge (CLSB), aiming to seek for the evolution ""bridging"" among
cross-sectional observations, while regularized for the minimal population
""cost"". In contrast to prior methods relying on \textit{individual}-level
regularizers for all particles \textit{homogeneously} (e.g. restraining
individual motions), CLSB operates at the population level admitting the
heterogeneity nature, resulting in a more generalizable modeling in practice.
To this end, our contributions include (1) a new class of population
regularizers capturing the temporal variations in multivariate relations, with
the tractable formulation derived, (2) three domain-informed instantiations
based on genetic co-expression stability, and (3) an integration of population
regularizers into data-driven generative models as constrained optimization,
and a numerical solution, with further extension to conditional generative
models. Empirically, we demonstrate the superiority of CLSB in single-cell
sequencing data analyses such as simulating cell development over time and
predicting cellular responses to drugs of varied doses.",http://arxiv.org/pdf/2402.10227v1,
MobilityGPT: Enhanced Human Mobility Modeling with a GPT model,05/02/2024,"Ammar Haydari, Dongjie Chen, Zhengfeng Lai, Michael Zhang, Chen-Nee Chuah","Generative models have shown promising results in capturing human mobility
characteristics and generating synthetic trajectories. However, it remains
challenging to ensure that the generated geospatial mobility data is
semantically realistic, including consistent location sequences, and reflects
real-world characteristics, such as constraining on geospatial limits. We
reformat human mobility modeling as an autoregressive generation task to
address these issues, leveraging the Generative Pre-trained Transformer (GPT)
architecture. To ensure its controllable generation to alleviate the above
challenges, we propose a geospatially-aware generative model, MobilityGPT. We
propose a gravity-based sampling method to train a transformer for semantic
sequence similarity. Then, we constrained the training process via a road
connectivity matrix that provides the connectivity of sequences in trajectory
generation, thereby keeping generated trajectories in geospatial limits.
Lastly, we proposed to construct a preference dataset for fine-tuning
MobilityGPT via Reinforcement Learning from Trajectory Feedback (RLTF)
mechanism, which minimizes the travel distance between training and the
synthetically generated trajectories. Experiments on real-world datasets
demonstrate MobilityGPT's superior performance over state-of-the-art methods in
generating high-quality mobility trajectories that are closest to real data in
terms of origin-destination similarity, trip length, travel radius, link, and
gravity distributions.",http://arxiv.org/pdf/2402.03264v2,
MOMENT: A Family of Open Time-series Foundation Models,06/02/2024,"Mononito Goswami, Konrad Szafer, Arjun Choudhry, Yifu Cai, Shuo Li, Artur Dubrawski","We introduce MOMENT, a family of open-source foundation models for
general-purpose time series analysis. Pre-training large models on time series
data is challenging due to (1) the absence of a large and cohesive public time
series repository, and (2) diverse time series characteristics which make
multi-dataset training onerous. Additionally, (3) experimental benchmarks to
evaluate these models, especially in scenarios with limited resources, time,
and supervision, are still in their nascent stages. To address these
challenges, we compile a large and diverse collection of public time series,
called the Time series Pile, and systematically tackle time series-specific
challenges to unlock large-scale multi-dataset pre-training. Finally, we build
on recent work to design a benchmark to evaluate time series foundation models
on diverse tasks and datasets in limited supervision settings. Experiments on
this benchmark demonstrate the effectiveness of our pre-trained models with
minimal data and task-specific fine-tuning. Finally, we present several
interesting empirical observations about large pre-trained time series models.
Pre-trained models (AutonLab/MOMENT-1-large) and Time Series Pile
(AutonLab/Timeseries-PILE) are available on Huggingface.",http://arxiv.org/pdf/2402.03885v3,
CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines,06/02/2024,"Chao Pang, Xinzhuo Jiang, Nishanth Parameshwar Pavinkurve, Krishna S. Kalluri, Elise L. Minto, Jason Patterson, Linying Zhang, George Hripcsak, Gamze Gürsoy, Noémie Elhadad, Karthik Natarajan","Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in
advancing healthcare applications and machine learning models, particularly for
researchers without direct access to healthcare data. Although existing
methods, like rule-based approaches and generative adversarial networks (GANs),
generate synthetic data that resembles real-world EHR data, these methods often
use a tabular format, disregarding temporal dependencies in patient histories
and limiting data replication. Recently, there has been a growing interest in
leveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables
applications like disease progression analysis, population estimation,
counterfactual reasoning, and synthetic data generation. In this work, we focus
on synthetic data generation and demonstrate the capability of training a GPT
model using a particular patient representation derived from CEHR-BERT,
enabling us to generate patient sequences that can be seamlessly converted to
the Observational Medical Outcomes Partnership (OMOP) data format.",http://arxiv.org/pdf/2402.04400v2,
Text2Data: Low-Resource Data Generation with Textual Control,08/02/2024,"Shiyu Wang, Yihao Feng, Tian Lan, Ning Yu, Yu Bai, Ran Xu, Huan Wang, Caiming Xiong, Silvio Savarese","Natural language serves as a common and straightforward control signal for
humans to interact seamlessly with machines. Recognizing the importance of this
interface, the machine learning community is investing considerable effort in
generating data that is semantically coherent with textual instructions. While
strides have been made in text-to-data generation spanning image editing, audio
synthesis, video creation, and beyond, low-resource areas characterized by
expensive annotations or complex data structures, such as molecules, motion
dynamics, and time series, often lack textual labels. This deficiency impedes
supervised learning, thereby constraining the application of advanced
generative models for text-to-data tasks. In response to these challenges in
the low-resource scenario, we propose Text2Data, a novel approach that utilizes
unlabeled data to understand the underlying data distribution through an
unsupervised diffusion model. Subsequently, it undergoes controllable
finetuning via a novel constraint optimization-based learning objective that
ensures controllability and effectively counteracts catastrophic forgetting.
Comprehensive experiments demonstrate that Text2Data is able to achieve
enhanced performance regarding controllability across various modalities,
including molecules, motions and time series, when compared to existing
baselines.",http://arxiv.org/pdf/2402.10941v1,
Social Physics Informed Diffusion Model for Crowd Simulation,08/02/2024,"Hongyi Chen, Jingtao Ding, Yong Li, Yue Wang, Xiao-Ping Zhang","Crowd simulation holds crucial applications in various domains, such as urban
planning, architectural design, and traffic arrangement. In recent years,
physics-informed machine learning methods have achieved state-of-the-art
performance in crowd simulation but fail to model the heterogeneity and
multi-modality of human movement comprehensively. In this paper, we propose a
social physics-informed diffusion model named SPDiff to mitigate the above gap.
SPDiff takes both the interactive and historical information of crowds in the
current timeframe to reverse the diffusion process, thereby generating the
distribution of pedestrian movement in the subsequent timeframe. Inspired by
the well-known social physics model, i.e., Social Force, regarding crowd
dynamics, we design a crowd interaction module to guide the denoising process
and further enhance this module with the equivariant properties of crowd
interactions. To mitigate error accumulation in long-term simulations, we
propose a multi-frame rollout training algorithm for diffusion modeling.
Experiments conducted on two real-world datasets demonstrate the superior
performance of SPDiff in terms of macroscopic and microscopic evaluation
metrics. Code and appendix are available at
https://github.com/tsinghua-fib-lab/SPDiff.",http://arxiv.org/pdf/2402.06680v1,
Latent variable model for high-dimensional point process with structured missingness,08/02/2024,"Maksim Sinelnikov, Manuel Haussmann, Harri Lähdesmäki","Longitudinal data are important in numerous fields, such as healthcare,
sociology and seismology, but real-world datasets present notable challenges
for practitioners because they can be high-dimensional, contain structured
missingness patterns, and measurement time points can be governed by an unknown
stochastic process. While various solutions have been suggested, the majority
of them have been designed to account for only one of these challenges. In this
work, we propose a flexible and efficient latent-variable model that is capable
of addressing all these limitations. Our approach utilizes Gaussian processes
to capture temporal correlations between samples and their associated
missingness masks as well as to model the underlying point process. We
construct our model as a variational autoencoder together with deep neural
network parameterised encoder and decoder models, and develop a scalable
amortised variational inference approach for efficient model training. We
demonstrate competitive performance using both simulated and real datasets.",http://arxiv.org/pdf/2402.05758v2,
Dirichlet Flow Matching with Applications to DNA Sequence Design,08/02/2024,"Hannes Stark, Bowen Jing, Chenyu Wang, Gabriele Corso, Bonnie Berger, Regina Barzilay, Tommi Jaakkola","Discrete diffusion or flow models could enable faster and more controllable
sequence generation than autoregressive models. We show that na\""ive linear
flow matching on the simplex is insufficient toward this goal since it suffers
from discontinuities in the training target and further pathologies. To
overcome this, we develop Dirichlet flow matching on the simplex based on
mixtures of Dirichlet distributions as probability paths. In this framework, we
derive a connection between the mixtures' scores and the flow's vector field
that allows for classifier and classifier-free guidance. Further, we provide
distilled Dirichlet flow matching, which enables one-step sequence generation
with minimal performance hits, resulting in $O(L)$ speedups compared to
autoregressive models. On complex DNA sequence generation tasks, we demonstrate
superior performance compared to all baselines in distributional metrics and in
achieving desired design targets for generated sequences. Finally, we show that
our classifier-free guidance approach improves unconditional generation and is
effective for generating DNA that satisfies design targets. Code is available
at https://github.com/HannesStark/dirichlet-flow-matching.",http://arxiv.org/pdf/2402.05841v2,
Time Series Diffusion in the Frequency Domain,08/02/2024,"Jonathan Crabbé, Nicolas Huynh, Jan Stanczuk, Mihaela van der Schaar","Fourier analysis has been an instrumental tool in the development of signal
processing. This leads us to wonder whether this framework could similarly
benefit generative modelling. In this paper, we explore this question through
the scope of time series diffusion models. More specifically, we analyze
whether representing time series in the frequency domain is a useful inductive
bias for score-based diffusion models. By starting from the canonical SDE
formulation of diffusion in the time domain, we show that a dual diffusion
process occurs in the frequency domain with an important nuance: Brownian
motions are replaced by what we call mirrored Brownian motions, characterized
by mirror symmetries among their components. Building on this insight, we show
how to adapt the denoising score matching approach to implement diffusion
models in the frequency domain. This results in frequency diffusion models,
which we compare to canonical time diffusion models. Our empirical evaluation
on real-world datasets, covering various domains like healthcare and finance,
shows that frequency diffusion models better capture the training distribution
than time diffusion models. We explain this observation by showing that time
series from these datasets tend to be more localized in the frequency domain
than in the time domain, which makes them easier to model in the former case.
All our observations point towards impactful synergies between Fourier analysis
and diffusion models.",http://arxiv.org/pdf/2402.05933v1,
DiscDiff: Latent Diffusion Model for DNA Sequence Generation,08/02/2024,"Zehui Li, Yuhao Ni, William A V Beardall, Guoxuan Xia, Akashaditya Das, Guy-Bart Stan, Yiren Zhao","This paper introduces a novel framework for DNA sequence generation,
comprising two key components: DiscDiff, a Latent Diffusion Model (LDM)
tailored for generating discrete DNA sequences, and Absorb-Escape, a
post-training algorithm designed to refine these sequences. Absorb-Escape
enhances the realism of the generated sequences by correcting `round errors'
inherent in the conversion process between latent and input spaces. Our
approach not only sets new standards in DNA sequence generation but also
demonstrates superior performance over existing diffusion models, in generating
both short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the
first comprehensive, multi-species dataset for DNA generation, encompassing
160,000 unique sequences from 15 species. We hope this study will advance the
generative modelling of DNA, with potential implications for gene therapy and
protein production.",http://arxiv.org/pdf/2402.06079v2,
Safe Active Learning for Time-Series Modeling with Gaussian Processes,09/02/2024,"Christoph Zimmer, Mona Meister, Duy Nguyen-Tuong","Learning time-series models is useful for many applications, such as
simulation and forecasting. In this study, we consider the problem of actively
learning time-series models while taking given safety constraints into account.
For time-series modeling we employ a Gaussian process with a nonlinear
exogenous input structure. The proposed approach generates data appropriate for
time series model learning, i.e. input and output trajectories, by dynamically
exploring the input space. The approach parametrizes the input trajectory as
consecutive trajectory sections, which are determined stepwise given safety
requirements and past observations. We analyze the proposed algorithm and
evaluate it empirically on a technical application. The results show the
effectiveness of our approach in a realistic technical use case.",http://arxiv.org/pdf/2402.06276v1,
TimEHR: Image-based Time Series Generation for Electronic Health Records,09/02/2024,"Hojjat Karami, Mary-Anne Hartley, David Atienza, Anisoara Ionescu","Time series in Electronic Health Records (EHRs) present unique challenges for
generative models, such as irregular sampling, missing values, and high
dimensionality. In this paper, we propose a novel generative adversarial
network (GAN) model, TimEHR, to generate time series data from EHRs. In
particular, TimEHR treats time series as images and is based on two conditional
GANs. The first GAN generates missingness patterns, and the second GAN
generates time series values based on the missingness pattern. Experimental
results on three real-world EHR datasets show that TimEHR outperforms
state-of-the-art methods in terms of fidelity, utility, and privacy metrics.",http://arxiv.org/pdf/2402.06318v1,
Generative Nowcasting of Marine Fog Visibility in the Grand Banks area and Sable Island in Canada,09/02/2024,"Eren Gultepe, Sen Wang, Byron Blomquist, Harindra J. S. Fernando, O. Patrick Kreidl, David J. Delene, Ismail Gultepe","This study presents the application of generative deep learning techniques to
evaluate marine fog visibility nowcasting using the FATIMA (Fog and turbulence
interactions in the marine atmosphere) campaign observations collected during
July 2022 in the North Atlantic in the Grand Banks area and vicinity of Sable
Island (SI), northeast of Canada. The measurements were collected using the
Vaisala Forward Scatter Sensor model FD70 and Weather Transmitter model WXT50,
and Gill R3A ultrasonic anemometer mounted on the Research Vessel Atlantic
Condor. To perform nowcasting, the time series of fog visibility (Vis), wind
speed, dew point depression, and relative humidity with respect to water were
preprocessed to have lagged time step features. Generative nowcasting of Vis
time series for lead times of 30 and 60 minutes were performed using
conditional generative adversarial networks (cGAN) regression at visibility
thresholds of Vis < 1 km and < 10 km. Extreme gradient boosting (XGBoost) was
used as a baseline method for comparison against cGAN. At the 30 min lead time,
Vis was best predicted with cGAN at Vis < 1 km (RMSE = 0.151 km) and with
XGBoost at Vis < 10 km (RMSE = 2.821 km). At the 60 min lead time, Vis was best
predicted with XGBoost at Vis < 1 km (RMSE = 0.167 km) and Vis < 10 km (RMSE =
3.508 km), but the cGAN RMSE was similar to XGBoost. Despite nowcasting Vis at
30 min being quite difficult, the ability of the cGAN model to track the
variation in Vis at 1 km suggests that there is potential for generative
analysis of marine fog visibility using observational meteorological
parameters.",http://arxiv.org/pdf/2402.06800v1,
SportsNGEN: Sustained Generation of Realistic Multi-player Sports Gameplay,10/02/2024,"Lachlan Thorpe, Lewis Bawden, Karanjot Vendal, John Bronskill, Richard E. Turner","We present a transformer decoder based sports simulation engine, SportsNGEN,
trained on sports player and ball tracking sequences, that is capable of
generating sustained gameplay and accurately mimicking the decision making of
real players. By training on a large database of professional tennis tracking
data, we demonstrate that simulations produced by SportsNGEN can be used to
predict the outcomes of rallies, determine the best shot choices at any point,
and evaluate counterfactual or what if scenarios to inform coaching decisions
and elevate broadcast coverage. By combining the generated simulations with a
shot classifier and logic to start and end rallies, the system is capable of
simulating an entire tennis match. We evaluate SportsNGEN by comparing
statistics of the simulations with those of real matches between the same
players. We show that the model output sampling parameters are crucial to
simulation realism and that SportsNGEN is probabilistically well-calibrated to
real data. In addition, a generic version of SportsNGEN can be customized to a
specific player by fine-tuning on the subset of match data that includes that
player. Finally, we show qualitative results indicating the same approach works
for football.",http://arxiv.org/pdf/2403.12977v3,10.5220/0012892000003828
UVTM: Universal Vehicle Trajectory Modeling with ST Feature Domain Generation,11/02/2024,"Yan Lin, Jilin Hu, Shengnan Guo, Bin Yang, Christian S. Jensen, Youfang Lin, Huaiyu Wan","Vehicle movement is frequently captured in the form of trajectories, i.e.,
sequences of timestamped locations. Numerous methods exist that target
different tasks involving trajectories such as travel-time estimation,
trajectory recovery, and trajectory prediction. However, most methods target
only one specific task and cannot be applied universally. Existing efforts to
create a universal trajectory model often involve adding prediction modules for
adapting to different tasks, while also struggle with incomplete or sparse
trajectories.
  To address these shortcomings, we propose the Universal Vehicle Trajectory
Model (UVTM) designed to support different tasks based on incomplete or sparse
trajectories without the need for retraining or extra prediction modules. To
addresses task adaptability on incomplete trajectories, UVTM divide the
spatio-temporal features of trajectories into three distinct domains. Each
domain can be masked and generated independently to suit the input and output
needs of specific tasks. To handle sparse trajectories effectively, UVTM is
pre-trained by reconstructing densely sampled trajectories from sparsely
sampled ones, allowing it to extract detailed spatio-temporal information from
sparse trajectories. Experiments involving three representative
trajectory-related tasks on two real-world vehicle trajectory datasets provide
insight into the intended properties performance of UVTM and offer evidence
that UVTM is capable of meeting its objectives.",http://arxiv.org/pdf/2402.07232v3,
Foundational Inference Models for Dynamical Systems,12/02/2024,"Patrick Seifner, Kostadin Cvejoski, Antonia Körner, Ramsés J. Sánchez","Dynamical systems governed by ordinary differential equations (ODEs) serve as
models for a vast number of natural and social phenomena. In this work, we
offer a fresh perspective on the classical problem of imputing missing time
series data, whose underlying dynamics are assumed to be determined by ODEs.
Specifically, we revisit ideas from amortized inference and neural operators,
and propose a novel supervised learning framework for zero-shot time series
imputation, through parametric functions satisfying some (hidden) ODEs. Our
proposal consists of two components. First, a broad probability distribution
over the space of ODE solutions, observation times and noise mechanisms, with
which we generate a large, synthetic dataset of (hidden) ODE solutions, along
with their noisy and sparse observations. Second, a neural recognition model
that is trained offline, to map the generated time series onto the spaces of
initial conditions and time derivatives of the (hidden) ODE solutions, which we
then integrate to impute the missing data. We empirically demonstrate that one
and the same (pretrained) recognition model can perform zero-shot imputation
across 63 distinct time series with missing values, each sampled from widely
different dynamical systems. Likewise, we demonstrate that it can perform
zero-shot imputation of missing high-dimensional data in 10 vastly different
settings, spanning human motion, air quality, traffic and electricity studies,
as well as Navier-Stokes simulations -- without requiring any fine-tuning. What
is more, our proposal often outperforms state-of-the-art methods, which are
trained on the target datasets.
  Our pretrained model will be available online soon.",http://arxiv.org/pdf/2402.07594v2,
Space-Time Diffusion Bridge,13/02/2024,"Hamidreza Behjoo, Michael Chertkov","In this study, we introduce a novel method for generating new synthetic
samples that are independent and identically distributed (i.i.d.) from
high-dimensional real-valued probability distributions, as defined implicitly
by a set of Ground Truth (GT) samples. Central to our method is the integration
of space-time mixing strategies that extend across temporal and spatial
dimensions. Our methodology is underpinned by three interrelated stochastic
processes designed to enable optimal transport from an easily tractable initial
probability distribution to the target distribution represented by the GT
samples: (a) linear processes incorporating space-time mixing that yield
Gaussian conditional probability densities, (b) their diffusion bridge analogs
that are conditioned to the initial and final state vectors, and (c) nonlinear
stochastic processes refined through score-matching techniques. The crux of our
training regime involves fine-tuning the nonlinear model, and potentially the
linear models -- to align closely with the GT data. We validate the efficacy of
our space-time diffusion approach with numerical experiments, laying the
groundwork for more extensive future theory and experiments to fully
authenticate the method, particularly providing a more efficient (possibly
simulation-free) inference.",http://arxiv.org/pdf/2402.08847v2,
Evaluating DTW Measures via a Synthesis Framework for Time-Series Data,14/02/2024,"Kishansingh Rajput, Duong Binh Nguyen, Guoning Chen","Time-series data originate from various applications that describe specific
observations or quantities of interest over time. Their analysis often involves
the comparison across different time-series data sequences, which in turn
requires the alignment of these sequences. Dynamic Time Warping (DTW) is the
standard approach to achieve an optimal alignment between two temporal signals.
Different variations of DTW have been proposed to address various needs for
signal alignment or classifications. However, a comprehensive evaluation of
their performance in these time-series data processing tasks is lacking. Most
DTW measures perform well on certain types of time-series data without a clear
explanation of the reason. To address that, we propose a synthesis framework to
model the variation between two time-series data sequences for comparison. Our
synthesis framework can produce a realistic initial signal and deform it with
controllable variations that mimic real-world scenarios. With this synthesis
framework, we produce a large number of time-series sequence pairs with
different but known variations, which are used to assess the performance of a
number of well-known DTW measures for the tasks of alignment and
classification. We report their performance on different variations and suggest
the proper DTW measure to use based on the type of variations between two
time-series sequences. This is the first time such a guideline is presented for
selecting a proper DTW measure. To validate our conclusion, we apply our
findings to real-world applications, i.e., the detection of the formation top
for the oil and gas industry and the pattern search in streamlines for flow
visualization.",http://arxiv.org/pdf/2402.08943v1,
Bidirectional Generative Pre-training for Improving Healthcare Time-series Representation Learning,14/02/2024,"Ziyang Song, Qincheng Lu, He Zhu, David Buckeridge, Yue Li","Learning time-series representations for discriminative tasks, such as
classification and regression, has been a long-standing challenge in the
healthcare domain. Current pre-training methods are limited in either
unidirectional next-token prediction or randomly masked token prediction. We
propose a novel architecture called Bidirectional Timely Generative Pre-trained
Transformer (BiTimelyGPT), which pre-trains on biosignals and longitudinal
clinical records by both next-token and previous-token prediction in
alternating transformer layers. This pre-training task preserves original
distribution and data shapes of the time-series. Additionally, the full-rank
forward and backward attention matrices exhibit more expressive representation
capabilities. Using biosignals and longitudinal clinical records, BiTimelyGPT
demonstrates superior performance in predicting neurological functionality,
disease diagnosis, and physiological signs. By visualizing the attention
heatmap, we observe that the pre-trained BiTimelyGPT can identify
discriminative segments from biosignal time-series sequences, even more so
after fine-tuning on the task.",http://arxiv.org/pdf/2402.09558v3,
ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling,16/02/2024,"Yuqi Chen, Kan Ren, Yansen Wang, Yuchen Fang, Weiwei Sun, Dongsheng Li","Modeling continuous-time dynamics on irregular time series is critical to
account for data evolution and correlations that occur continuously.
Traditional methods including recurrent neural networks or Transformer models
leverage inductive bias via powerful neural architectures to capture complex
patterns. However, due to their discrete characteristic, they have limitations
in generalizing to continuous-time data paradigms. Though neural ordinary
differential equations (Neural ODEs) and their variants have shown promising
results in dealing with irregular time series, they often fail to capture the
intricate correlations within these sequences. It is challenging yet demanding
to concurrently model the relationship between input data points and capture
the dynamic changes of the continuous-time system. To tackle this problem, we
propose ContiFormer that extends the relation modeling of vanilla Transformer
to the continuous-time domain, which explicitly incorporates the modeling
abilities of continuous dynamics of Neural ODEs with the attention mechanism of
Transformers. We mathematically characterize the expressive power of
ContiFormer and illustrate that, by curated designs of function hypothesis,
many Transformer variants specialized in irregular time series modeling can be
covered as a special case of ContiFormer. A wide range of experiments on both
synthetic and real-world datasets have illustrated the superior modeling
capacities and prediction performance of ContiFormer on irregular time series
data. The project link is https://seqml.github.io/contiformer/.",http://arxiv.org/pdf/2402.10635v1,
RAGIC: Risk-Aware Generative Adversarial Model for Stock Interval Construction,16/02/2024,"Jingyi Gu, Wenlu Du, Guiling Wang","Efforts to predict stock market outcomes have yielded limited success due to
the inherently stochastic nature of the market, influenced by numerous
unpredictable factors. Many existing prediction approaches focus on
single-point predictions, lacking the depth needed for effective
decision-making and often overlooking market risk. To bridge this gap, we
propose a novel model, RAGIC, which introduces sequence generation for stock
interval prediction to quantify uncertainty more effectively. Our approach
leverages a Generative Adversarial Network (GAN) to produce future price
sequences infused with randomness inherent in financial markets. RAGIC's
generator includes a risk module, capturing the risk perception of informed
investors, and a temporal module, accounting for historical price trends and
seasonality. This multi-faceted generator informs the creation of
risk-sensitive intervals through statistical inference, incorporating
horizon-wise insights. The interval's width is carefully adjusted to reflect
market volatility. Importantly, our approach relies solely on publicly
available data and incurs only low computational overhead. RAGIC's evaluation
across globally recognized broad-based indices demonstrates its balanced
performance, offering both accuracy and informativeness. Achieving a consistent
95% coverage, RAGIC maintains a narrow interval width. This promising outcome
suggests that our approach effectively addresses the challenges of stock market
prediction while incorporating vital risk considerations.",http://arxiv.org/pdf/2402.10760v1,
Synthetic location trajectory generation using categorical diffusion models,19/02/2024,"Simon Dirmeier, Ye Hong, Fernando Perez-Cruz","Diffusion probabilistic models (DPMs) have rapidly evolved to be one of the
predominant generative models for the simulation of synthetic data, for
instance, for computer vision, audio, natural language processing, or
biomolecule generation. Here, we propose using DPMs for the generation of
synthetic individual location trajectories (ILTs) which are sequences of
variables representing physical locations visited by individuals. ILTs are of
major importance in mobility research to understand the mobility behavior of
populations and to ultimately inform political decision-making. We represent
ILTs as multi-dimensional categorical random variables and propose to model
their joint distribution using a continuous DPM by first applying the diffusion
process in a continuous unconstrained space and then mapping the continuous
variables into a discrete space. We demonstrate that our model can synthesize
realistic ILPs by comparing conditionally and unconditionally generated
sequences to real-world ILPs from a GNSS tracking data set which suggests the
potential use of our model for synthetic data generation, for example, for
benchmarking models used in mobility research.",http://arxiv.org/pdf/2402.12242v1,
Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records,21/02/2024,"Navid Ashrafi, Vera Schmitt, Robert P. Spang, Sebastian Möller, Jan-Niklas Voigt-Antons","Preservation of private user data is of paramount importance for high Quality
of Experience (QoE) and acceptability, particularly with services treating
sensitive data, such as IT-based health services. Whereas anonymization
techniques were shown to be prone to data re-identification, synthetic data
generation has gradually replaced anonymization since it is relatively less
time and resource-consuming and more robust to data leakage. Generative
Adversarial Networks (GANs) have been used for generating synthetic datasets,
especially GAN frameworks adhering to the differential privacy phenomena. This
research compares state-of-the-art GAN-based models for synthetic data
generation to generate time-series synthetic medical records of dementia
patients which can be distributed without privacy concerns. Predictive
modeling, autocorrelation, and distribution analysis are used to assess the
Quality of Generating (QoG) of the generated data. The privacy preservation of
the respective models is assessed by applying membership inference attacks to
determine potential data leakage risks. Our experiments indicate the
superiority of the privacy-preserving GAN (PPGAN) model over other models
regarding privacy preservation while maintaining an acceptable level of QoG.
The presented results can support better data protection for medical use cases
in the future.",http://arxiv.org/pdf/2402.14042v2,
Generative Adversarial Network with Soft-Dynamic Time Warping and Parallel Reconstruction for Energy Time Series Anomaly Detection,22/02/2024,"Hardik Prabhu, Jayaraman Valadi, Pandarasamy Arjunan","In this paper, we employ a 1D deep convolutional generative adversarial
network (DCGAN) for sequential anomaly detection in energy time series data.
Anomaly detection involves gradient descent to reconstruct energy
sub-sequences, identifying the noise vector that closely generates them through
the generator network. Soft-DTW is used as a differentiable alternative for the
reconstruction loss and is found to be superior to Euclidean distance.
Combining reconstruction loss and the latent space's prior probability
distribution serves as the anomaly score. Our novel method accelerates
detection by parallel computation of reconstruction of multiple points and
shows promise in identifying anomalous energy consumption in buildings, as
evidenced by performing experiments on hourly energy time series from 15
buildings.",http://arxiv.org/pdf/2402.14384v1,
Text me the data: Generating Ground Pressure Sequence from Textual Descriptions for HAR,22/02/2024,"Lala Shakti Swarup Ray, Bo Zhou, Sungho Suh, Lars Krupp, Vitor Fortes Rey, Paul Lukowicz","In human activity recognition (HAR), the availability of substantial ground
truth is necessary for training efficient models. However, acquiring ground
pressure data through physical sensors itself can be cost-prohibitive,
time-consuming. To address this critical need, we introduce Text-to-Pressure
(T2P), a framework designed to generate extensive ground pressure sequences
from textual descriptions of human activities using deep learning techniques.
We show that the combination of vector quantization of sensor data along with
simple text conditioned auto regressive strategy allows us to obtain
high-quality generated pressure sequences from textual descriptions with the
help of discrete latent correlation between text and pressure maps. We achieved
comparable performance on the consistency between text and generated motion
with an R squared value of 0.722, Masked R squared value of 0.892, and FID
score of 1.83. Additionally, we trained a HAR model with the the synthesized
data and evaluated it on pressure dynamics collected by a real pressure sensor
which is on par with a model trained on only real data. Combining both real and
synthesized training data increases the overall macro F1 score by 5.9 percent.",http://arxiv.org/pdf/2402.14427v1,
SynthBrainGrow: Synthetic Diffusion Brain Aging for Longitudinal MRI Data Generation in Young People,22/02/2024,"Anna Zapaishchykova, Benjamin H. Kann, Divyanshu Tak, Zezhong Ye, Daphne A. Haas-Kogan, Hugo J. W. L. Aerts","Synthetic longitudinal brain MRI simulates brain aging and would enable more
efficient research on neurodevelopmental and neurodegenerative conditions.
Synthetically generated, age-adjusted brain images could serve as valuable
alternatives to costly longitudinal imaging acquisitions, serve as internal
controls for studies looking at the effects of environmental or therapeutic
modifiers on brain development, and allow data augmentation for diverse
populations. In this paper, we present a diffusion-based approach called
SynthBrainGrow for synthetic brain aging with a two-year step. To validate the
feasibility of using synthetically-generated data on downstream tasks, we
compared structural volumetrics of two-year-aged brains against
synthetically-aged brain MRI. Results show that SynthBrainGrow can accurately
capture substructure volumetrics and simulate structural changes such as
ventricle enlargement and cortical thinning. Our approach provides a novel way
to generate longitudinal brain datasets from cross-sectional data to enable
augmented training and benchmarking of computational tools for analyzing
lifespan trajectories. This work signifies an important advance in generative
modeling to synthesize realistic longitudinal data with limited lifelong MRI
scans. The code is available at XXX.",http://arxiv.org/pdf/2405.00682v1,
A VAE-based Framework for Learning Multi-Level Neural Granger-Causal Connectivity,25/02/2024,"Jiahe Lin, Huitian Lei, George Michailidis","Granger causality has been widely used in various application domains to
capture lead-lag relationships amongst the components of complex dynamical
systems, and the focus in extant literature has been on a single dynamical
system. In certain applications in macroeconomics and neuroscience, one has
access to data from a collection of related such systems, wherein the modeling
task of interest is to extract the shared common structure that is embedded
across them, as well as to identify the idiosyncrasies within individual ones.
This paper introduces a Variational Autoencoder (VAE) based framework that
jointly learns Granger-causal relationships amongst components in a collection
of related-yet-heterogeneous dynamical systems, and handles the aforementioned
task in a principled way. The performance of the proposed framework is
evaluated on several synthetic data settings and benchmarked against existing
approaches designed for individual system learning. The method is further
illustrated on a real dataset involving time series data from a
neurophysiological experiment and produces interpretable results.",http://arxiv.org/pdf/2402.16131v1,
Training Implicit Generative Models via an Invariant Statistical Loss,26/02/2024,"José Manuel de Frutos, Pablo M. Olmos, Manuel A. Vázquez, Joaquín Míguez","Implicit generative models have the capability to learn arbitrary complex
data distributions. On the downside, training requires telling apart real data
from artificially-generated ones using adversarial discriminators, leading to
unstable training and mode-dropping issues. As reported by Zahee et al. (2017),
even in the one-dimensional (1D) case, training a generative adversarial
network (GAN) is challenging and often suboptimal. In this work, we develop a
discriminator-free method for training one-dimensional (1D) generative implicit
models and subsequently expand this method to accommodate multivariate cases.
Our loss function is a discrepancy measure between a suitably chosen
transformation of the model samples and a uniform distribution; hence, it is
invariant with respect to the true distribution of the data. We first formulate
our method for 1D random variables, providing an effective solution for
approximate reparameterization of arbitrary complex distributions. Then, we
consider the temporal setting (both univariate and multivariate), in which we
model the conditional distribution of each sample given the history of the
process. We demonstrate through numerical simulations that this new method
yields promising results, successfully learning true distributions in a variety
of scenarios and mitigating some of the well-known problems that
state-of-the-art implicit methods present.",http://arxiv.org/pdf/2402.16435v1,
Time series generation for option pricing on quantum computers using tensor network,27/02/2024,"Nozomu Kobayashi, Yoshiyuki Suimon, Koichi Miyamoto","Finance, especially option pricing, is a promising industrial field that
might benefit from quantum computing. While quantum algorithms for option
pricing have been proposed, it is desired to devise more efficient
implementations of costly operations in the algorithms, one of which is
preparing a quantum state that encodes a probability distribution of the
underlying asset price. In particular, in pricing a path-dependent option, we
need to generate a state encoding a joint distribution of the underlying asset
price at multiple time points, which is more demanding. To address these
issues, we propose a novel approach using Matrix Product State (MPS) as a
generative model for time series generation. To validate our approach, taking
the Heston model as a target, we conduct numerical experiments to generate time
series in the model. Our findings demonstrate the capability of the MPS model
to generate paths in the Heston model, highlighting its potential for
path-dependent option pricing on quantum computers.",http://arxiv.org/pdf/2402.17148v1,
TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation,27/02/2024,"Lin Zongying, Li Hao, Lv Liuzhenghao, Lin Bin, Zhang Junwu, Chen Calvin Yu-Chian, Yuan Li, Tian Yonghong","Designing protein sequences with specific biological functions and structural
stability is crucial in biology and chemistry. Generative models already
demonstrated their capabilities for reliable protein design. However, previous
models are limited to the unconditional generation of protein sequences and
lack the controllable generation ability that is vital to biological tasks. In
this work, we propose TaxDiff, a taxonomic-guided diffusion model for
controllable protein sequence generation that combines biological species
information with the generative capabilities of diffusion models to generate
structurally stable proteins within the sequence space. Specifically, taxonomic
control information is inserted into each layer of the transformer block to
achieve fine-grained control. The combination of global and local attention
ensures the sequence consistency and structural foldability of
taxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can
consistently achieve better performance on multiple protein sequence generation
benchmarks in both taxonomic-guided controllable generation and unconditional
generation. Remarkably, the sequences generated by TaxDiff even surpass those
produced by direct-structure-generation models in terms of confidence based on
predicted structures and require only a quarter of the time of models based on
the diffusion model. The code for generating proteins and training new versions
of TaxDiff is available at:https://github.com/Linzy19/TaxDiff.",http://arxiv.org/pdf/2402.17156v1,
Markovletics: Methods and A Novel Application for Learning Continuous-Time Markov Chain Mixtures,27/02/2024,"Fabian Spaeh, Charalampos E. Tsourakakis","Sequential data naturally arises from user engagement on digital platforms
like social media, music streaming services, and web navigation, encapsulating
evolving user preferences and behaviors through continuous information streams.
A notable unresolved query in stochastic processes is learning mixtures of
continuous-time Markov chains (CTMCs). While there is progress in learning
mixtures of discrete-time Markov chains with recovery guarantees
[GKV16,ST23,KTT2023], the continuous scenario uncovers unique unexplored
challenges. The intrigue in CTMC mixtures stems from their potential to model
intricate continuous-time stochastic processes prevalent in various fields
including social media, finance, and biology.
  In this study, we introduce a novel framework for exploring CTMCs,
emphasizing the influence of observed trails' length and mixture parameters on
problem regimes, which demands specific algorithms. Through thorough
experimentation, we examine the impact of discretizing continuous-time trails
on the learnability of the continuous-time mixture, given that these processes
are often observed via discrete, resource-demanding observations. Our
comparative analysis with leading methods explores sample complexity and the
trade-off between the number of trails and their lengths, offering crucial
insights for method selection in different problem instances. We apply our
algorithms on an extensive collection of Lastfm's user-generated trails
spanning three years, demonstrating the capability of our algorithms to
differentiate diverse user preferences. We pioneer the use of CTMC mixtures on
a basketball passing dataset to unveil intricate offensive tactics of NBA
teams. This underscores the pragmatic utility and versatility of our proposed
framework. All results presented in this study are replicable, and we provide
the implementations to facilitate reproducibility.",http://arxiv.org/pdf/2402.17730v1,
"StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds",29/02/2024,"Prasad Cheema, Mahito Sugiyama","Data augmentation is an area of research which has seen active development in
many machine learning fields, such as in image-based learning models,
reinforcement learning for self driving vehicles, and general noise injection
for point cloud data. However, convincing methods for general time series data
augmentation still leaves much to be desired, especially since the methods
developed for these models do not readily cross-over. Three common approaches
for time series data augmentation include: (i) Constructing a physics-based
model and then imbuing uncertainty over the coefficient space (for example),
(ii) Adding noise to the observed data set(s), and, (iii) Having access to
ample amounts of time series data sets from which a robust generative neural
network model can be trained. However, for many practical problems that work
with time series data in the industry: (i) One usually does not have access to
a robust physical model, (ii) The addition of noise can in of itself require
large or difficult assumptions (for example, what probability distribution
should be used? Or, how large should the noise variance be?), and, (iii) In
practice, it can be difficult to source a large representative time series data
base with which to train the neural network model for the underlying problem.
In this paper, we propose a methodology which attempts to simultaneously tackle
all three of these previous limitations to a large extent. The method relies
upon the well-studied matrix differential geometry of the Stiefel manifold, as
it proposes a simple way in which time series signals can placed on, and then
smoothly perturbed over the manifold. We attempt to clarify how this method
works by showcasing several potential use cases which in particular work to
take advantage of the unique properties of this underlying manifold.",http://arxiv.org/pdf/2402.19287v1,
Humanoid Locomotion as Next Token Prediction,29/02/2024,"Ilija Radosavovic, Bike Zhang, Baifeng Shi, Jathushan Rajasegaran, Sarthak Kamat, Trevor Darrell, Koushil Sreenath, Jitendra Malik","We cast real-world humanoid control as a next token prediction problem, akin
to predicting the next word in language. Our model is a causal transformer
trained via autoregressive prediction of sensorimotor trajectories. To account
for the multi-modal nature of the data, we perform prediction in a
modality-aligned way, and for each input token predict the next token from the
same modality. This general formulation enables us to leverage data with
missing modalities, like video trajectories without actions. We train our model
on a collection of simulated trajectories coming from prior neural network
policies, model-based controllers, motion capture data, and YouTube videos of
humans. We show that our model enables a full-sized humanoid to walk in San
Francisco zero-shot. Our model can transfer to the real world even when trained
on only 27 hours of walking data, and can generalize to commands not seen
during training like walking backward. These findings suggest a promising path
toward learning challenging real-world control tasks by generative modeling of
sensorimotor trajectories.",http://arxiv.org/pdf/2402.19469v1,
Soft-constrained Schrodinger Bridge: a Stochastic Control Approach,04/03/2024,"Jhanvi Garg, Xianyang Zhang, Quan Zhou","Schr\""{o}dinger bridge can be viewed as a continuous-time stochastic control
problem where the goal is to find an optimally controlled diffusion process
whose terminal distribution coincides with a pre-specified target distribution.
We propose to generalize this problem by allowing the terminal distribution to
differ from the target but penalizing the Kullback-Leibler divergence between
the two distributions. We call this new control problem soft-constrained
Schr\""{o}dinger bridge (SSB). The main contribution of this work is a
theoretical derivation of the solution to SSB, which shows that the terminal
distribution of the optimally controlled process is a geometric mixture of the
target and some other distribution. This result is further extended to a time
series setting. One application is the development of robust generative
diffusion models. We propose a score matching-based algorithm for sampling from
geometric mixtures and showcase its use via a numerical example for the MNIST
data set.",http://arxiv.org/pdf/2403.01717v2,
Diffusion-TS: Interpretable Diffusion for General Time Series Generation,04/03/2024,"Xinyu Yuan, Yan Qiao","Denoising diffusion probabilistic models (DDPMs) are becoming the leading
paradigm for generative models. It has recently shown breakthroughs in audio
synthesis, time series imputation and forecasting. In this paper, we propose
Diffusion-TS, a novel diffusion-based framework that generates multivariate
time series samples of high quality by using an encoder-decoder transformer
with disentangled temporal representations, in which the decomposition
technique guides Diffusion-TS to capture the semantic meaning of time series
while transformers mine detailed sequential information from the noisy model
input. Different from existing diffusion-based approaches, we train the model
to directly reconstruct the sample instead of the noise in each diffusion step,
combining a Fourier-based loss term. Diffusion-TS is expected to generate time
series satisfying both interpretablity and realness. In addition, it is shown
that the proposed Diffusion-TS can be easily extended to conditional generation
tasks, such as forecasting and imputation, without any model changes. This also
motivates us to further explore the performance of Diffusion-TS under irregular
settings. Finally, through qualitative and quantitative experiments, results
show that Diffusion-TS achieves the state-of-the-art results on various
realistic analyses of time series.",http://arxiv.org/pdf/2403.01742v3,
Towards Foundation Time Series Model: To Synthesize Or Not To Synthesize?,04/03/2024,"Kseniia Kuvshinova, Olga Tsymboi, Alina Kostromina, Dmitry Simakov, Elizaveta Kovtun","The industry is rich in cases when we are required to make forecasting for
large amounts of time series at once. However, we might be in a situation where
we can not afford to train a separate model for each of them. Such issue in
time series modeling remains without due attention. The remedy for this setting
is the establishment of a foundation model. Such a model is expected to work in
zero-shot and few-shot regimes. However, what should we take as a training
dataset for such kind of model?
  Witnessing the benefits from the enrichment of NLP datasets with
artificially-generated data, we might want to adopt their experience for time
series. In contrast to natural language, the process of generation of synthetic
time series data is even more favorable because it provides full control of
series patterns, time horizons, and number of samples. In this work, we
consider the essential question if it is advantageous to train a foundation
model on synthetic data or it is better to utilize only a limited number of
real-life examples. Our experiments are conducted only for regular time series
and speak in favor of leveraging solely the real time series. Moreover, the
choice of the proper source dataset strongly influences the performance during
inference. When provided access even to a limited quantity of short time series
data, employing it within a supervised framework yields more favorable results
than training on a larger volume of synthetic data. The code for our
experiments is publicly available on Github
\url{https://github.com/sb-ai-lab/synthesize_or_not}.",http://arxiv.org/pdf/2403.02534v1,
Time Weaver: A Conditional Time Series Generation Model,05/03/2024,"Sai Shankar Narasimhan, Shubhankar Agarwal, Oguzhan Akcin, Sujay Sanghavi, Sandeep Chinchali","Imagine generating a city's electricity demand pattern based on weather, the
presence of an electric vehicle, and location, which could be used for capacity
planning during a winter freeze. Such real-world time series are often enriched
with paired heterogeneous contextual metadata (weather, location, etc.).
Current approaches to time series generation often ignore this paired metadata,
and its heterogeneity poses several practical challenges in adapting existing
conditional generation approaches from the image, audio, and video domains to
the time series domain. To address this gap, we introduce Time Weaver, a novel
diffusion-based model that leverages the heterogeneous metadata in the form of
categorical, continuous, and even time-variant variables to significantly
improve time series generation. Additionally, we show that naive extensions of
standard evaluation metrics from the image to the time series domain are
insufficient. These metrics do not penalize conditional generation approaches
for their poor specificity in reproducing the metadata-specific features in the
generated time series. Thus, we innovate a novel evaluation metric that
accurately captures the specificity of conditional generation and the realism
of the generated time series. We show that Time Weaver outperforms
state-of-the-art benchmarks, such as Generative Adversarial Networks (GANs), by
up to 27% in downstream classification tasks on real-world energy, medical, air
quality, and traffic data sets.",http://arxiv.org/pdf/2403.02682v1,
Towards Controllable Time Series Generation,06/03/2024,"Yifan Bao, Yihao Ang, Qiang Huang, Anthony K. H. Tung, Zhiyong Huang","Time Series Generation (TSG) has emerged as a pivotal technique in
synthesizing data that accurately mirrors real-world time series, becoming
indispensable in numerous applications. Despite significant advancements in
TSG, its efficacy frequently hinges on having large training datasets. This
dependency presents a substantial challenge in data-scarce scenarios,
especially when dealing with rare or unique conditions. To confront these
challenges, we explore a new problem of Controllable Time Series Generation
(CTSG), aiming to produce synthetic time series that can adapt to various
external conditions, thereby tackling the data scarcity issue.
  In this paper, we propose \textbf{C}ontrollable \textbf{T}ime \textbf{S}eries
(\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key
feature of \textsf{CTS} is that it decouples the mapping process from standard
VAE training, enabling precise learning of a complex interplay between latent
features and external conditions. Moreover, we develop a comprehensive
evaluation scheme for CTSG. Extensive experiments across three real-world time
series datasets showcase \textsf{CTS}'s exceptional capabilities in generating
high-quality, controllable outputs. This underscores its adeptness in
seamlessly integrating latent features with external conditions. Extending
\textsf{CTS} to the image domain highlights its remarkable potential for
explainability and further reinforces its versatility across different
modalities.",http://arxiv.org/pdf/2403.03698v1,
Diffusion on language model embeddings for protein sequence generation,06/03/2024,"Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov, Fedor Nikolaev, Nikita Ivanisenko, Olga Kardymon, Dmitry Vetrov","Protein design requires a deep understanding of the inherent complexities of
the protein universe. While many efforts lean towards conditional generation or
focus on specific families of proteins, the foundational task of unconditional
generation remains underexplored and undervalued. Here, we explore this pivotal
domain, introducing DiMA, a model that leverages continuous diffusion on
embeddings derived from the protein language model, ESM-2, to generate amino
acid sequences. DiMA surpasses leading solutions, including autoregressive
transformer-based and discrete diffusion models, and we quantitatively
illustrate the impact of the design choices that lead to its superior
performance. We extensively evaluate the quality, diversity, distribution
similarity, and biological relevance of the generated sequences using multiple
metrics across various modalities. Our approach consistently produces novel,
diverse protein sequences that accurately reflect the inherent structural and
functional diversity of the protein space. This work advances the field of
protein design and sets the stage for conditional models by providing a robust
framework for scalable and high-quality protein sequence generation.",http://arxiv.org/pdf/2403.03726v1,
Synthetic data generation for system identification: leveraging knowledge transfer from similar systems,08/03/2024,"Dario Piga, Matteo Rufolo, Gabriele Maroni, Manas Mejari, Marco Forgione","This paper addresses the challenge of overfitting in the learning of
dynamical systems by introducing a novel approach for the generation of
synthetic data, aimed at enhancing model generalization and robustness in
scenarios characterized by data scarcity. Central to the proposed methodology
is the concept of knowledge transfer from systems within the same class.
Specifically, synthetic data is generated through a pre-trained meta-model that
describes a broad class of systems to which the system of interest is assumed
to belong. Training data serves a dual purpose: firstly, as input to the
pre-trained meta model to discern the system's dynamics, enabling the
prediction of its behavior and thereby generating synthetic output sequences
for new input sequences; secondly, in conjunction with synthetic data, to
define the loss function used for model estimation. A validation dataset is
used to tune a scalar hyper-parameter balancing the relative importance of
training and synthetic data in the definition of the loss function. The same
validation set can be also used for other purposes, such as early stopping
during the training, fundamental to avoid overfitting in case of small-size
training datasets. The efficacy of the approach is shown through a numerical
example that highlights the advantages of integrating synthetic data into the
system identification process.",http://arxiv.org/pdf/2403.05164v1,
FFAD: A Novel Metric for Assessing Generated Time Series Data Utilizing Fourier Transform and Auto-encoder,11/03/2024,"Yang Chen, Dustin J. Kempton, Rafal A. Angryk","The success of deep learning-based generative models in producing realistic
images, videos, and audios has led to a crucial consideration: how to
effectively assess the quality of synthetic samples. While the Fr\'{e}chet
Inception Distance (FID) serves as the standard metric for evaluating
generative models in image synthesis, a comparable metric for time series data
is notably absent. This gap in assessment capabilities stems from the absence
of a widely accepted feature vector extractor pre-trained on benchmark time
series datasets. In addressing these challenges related to assessing the
quality of time series, particularly in the context of Fr\'echet Distance, this
work proposes a novel solution leveraging the Fourier transform and
Auto-encoder, termed the Fr\'{e}chet Fourier-transform Auto-encoder Distance
(FFAD). Through our experimental results, we showcase the potential of FFAD for
effectively distinguishing samples from different classes. This novel metric
emerges as a fundamental tool for the evaluation of generative time series
data, contributing to the ongoing efforts of enhancing assessment methodologies
in the realm of deep learning-based generative models.",http://arxiv.org/pdf/2403.06576v1,
Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI,11/03/2024,"Lang Tong, Xinyi Wang, Qing Zhao","Purpose This article presents a case for a next-generation grid monitoring
and control system, leveraging recent advances in generative artificial
intelligence (AI), machine learning, and statistical inference. Advancing
beyond earlier generations of wide-area monitoring systems built upon
supervisory control and data acquisition (SCADA) and synchrophasor
technologies, we argue for a monitoring and control framework based on the
streaming of continuous point-on-wave (CPOW) measurements with AI-powered data
compression and fault detection.
  Methods and Results: The architecture of the proposed design originates from
the Wiener-Kallianpur innovation representation of a random process that
transforms causally a stationary random process into an innovation sequence
with independent and identically distributed random variables. This work
presents a generative AI approach that (i) learns an innovation autoencoder
that extracts innovation sequence from CPOW time series, (ii) compresses the
CPOW streaming data with innovation autoencoder and subband coding, and (iii)
detects unknown faults and novel trends via nonparametric sequential hypothesis
testing.
  Conclusion: This work argues that conventional monitoring using SCADA and
phasor measurement unit (PMU) technologies is ill-suited for a future grid with
deep penetration of inverter-based renewable generations and distributed energy
resources. A monitoring system based on CPOW data streaming and AI data
analytics should be the basic building blocks for situational awareness of a
highly dynamic future grid.",http://arxiv.org/pdf/2403.06942v1,
Data-Efficient Sleep Staging with Synthetic Time Series Pretraining,13/03/2024,"Niklas Grieger, Siamak Mehrkanoon, Stephan Bialonski","Analyzing electroencephalographic (EEG) time series can be challenging,
especially with deep neural networks, due to the large variability among human
subjects and often small datasets. To address these challenges, various
strategies, such as self-supervised learning, have been suggested, but they
typically rely on extensive empirical datasets. Inspired by recent advances in
computer vision, we propose a pretraining task termed ""frequency pretraining""
to pretrain a neural network for sleep staging by predicting the frequency
content of randomly generated synthetic time series. Our experiments
demonstrate that our method surpasses fully supervised learning in scenarios
with limited data and few subjects, and matches its performance in regimes with
many subjects. Furthermore, our results underline the relevance of frequency
information for sleep stage scoring, while also demonstrating that deep neural
networks utilize information beyond frequencies to enhance sleep staging
performance, which is consistent with previous research. We anticipate that our
approach will be advantageous across a broad spectrum of applications where EEG
data is limited or derived from a small number of subjects, including the
domain of brain-computer interfaces.",http://arxiv.org/pdf/2403.08592v1,
Self-Supervised Learning for Time Series: Contrastive or Generative?,14/03/2024,"Ziyu Liu, Azadeh Alavi, Minyi Li, Xiang Zhang","Self-supervised learning (SSL) has recently emerged as a powerful approach to
learning representations from large-scale unlabeled data, showing promising
results in time series analysis. The self-supervised representation learning
can be categorized into two mainstream: contrastive and generative. In this
paper, we will present a comprehensive comparative study between contrastive
and generative methods in time series. We first introduce the basic frameworks
for contrastive and generative SSL, respectively, and discuss how to obtain the
supervision signal that guides the model optimization. We then implement
classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative
analysis in fair settings. Our results provide insights into the strengths and
weaknesses of each approach and offer practical recommendations for choosing
suitable SSL methods. We also discuss the implications of our findings for the
broader field of representation learning and propose future research
directions. All the code and data are released at
\url{https://github.com/DL4mHealth/SSL_Comparison}.",http://arxiv.org/pdf/2403.09809v1,
Generative Modelling of Stochastic Rotating Shallow Water Noise,15/03/2024,"Dan Crisan, Oana Lang, Alexander Lobbe","In recent work, the authors have developed a generic methodology for
calibrating the noise in fluid dynamics stochastic partial differential
equations where the stochasticity was introduced to parametrize subgrid-scale
processes. The stochastic parameterization of sub-grid scale processes is
required in the estimation of uncertainty in weather and climate predictions,
to represent systematic model errors arising from subgrid-scale fluctuations.
The previous methodology used a principal component analysis (PCA) technique
based on the ansatz that the increments of the stochastic parametrization are
normally distributed.
  In this paper, the PCA technique is replaced by a generative model technique.
This enables us to avoid imposing additional constraints on the increments. The
methodology is tested on a stochastic rotating shallow water model with the
elevation variable of the model used as input data. The numerical simulations
show that the noise is indeed non-Gaussian. The generative modelling technology
gives good RMSE, CRPS score and forecast rank histogram results.",http://arxiv.org/pdf/2403.10578v1,
Rough Transformers for Continuous and Efficient Time-Series Modelling,15/03/2024,"Fernando Moreno-Pino, Álvaro Arroyo, Harrison Waldon, Xiaowen Dong, Álvaro Cartea","Time-series data in real-world medical settings typically exhibit long-range
dependencies and are observed at non-uniform intervals. In such contexts,
traditional sequence-based recurrent models struggle. To overcome this,
researchers replace recurrent architectures with Neural ODE-based models to
model irregularly sampled data and use Transformer-based architectures to
account for long-range dependencies. Despite the success of these two
approaches, both incur very high computational costs for input sequences of
moderate lengths and greater. To mitigate this, we introduce the Rough
Transformer, a variation of the Transformer model which operates on
continuous-time representations of input sequences and incurs significantly
reduced computational costs, critical for addressing long-range dependencies
common in medical contexts. In particular, we propose multi-view signature
attention, which uses path signatures to augment vanilla attention and to
capture both local and global dependencies in input data, while remaining
robust to changes in the sequence length and sampling frequency. We find that
Rough Transformers consistently outperform their vanilla attention counterparts
while obtaining the benefits of Neural ODE-based models using a fraction of the
computational time and memory resources on synthetic and real-world time-series
tasks.",http://arxiv.org/pdf/2403.10288v1,
Variational Sampling of Temporal Trajectories,18/03/2024,"Jurijs Nazarovs, Zhichun Huang, Xingjian Zhen, Sourav Pal, Rudrasis Chakraborty, Vikas Singh","A deterministic temporal process can be determined by its trajectory, an
element in the product space of (a) initial condition $z_0 \in \mathcal{Z}$ and
(b) transition function $f: (\mathcal{Z}, \mathcal{T}) \to \mathcal{Z}$ often
influenced by the control of the underlying dynamical system. Existing methods
often model the transition function as a differential equation or as a
recurrent neural network. Despite their effectiveness in predicting future
measurements, few results have successfully established a method for sampling
and statistical inference of trajectories using neural networks, partially due
to constraints in the parameterization. In this work, we introduce a mechanism
to learn the distribution of trajectories by parameterizing the transition
function $f$ explicitly as an element in a function space. Our framework allows
efficient synthesis of novel trajectories, while also directly providing a
convenient tool for inference, i.e., uncertainty estimation, likelihood
evaluations and out of distribution detection for abnormal trajectories. These
capabilities can have implications for various downstream tasks, e.g.,
simulation and evaluation for reinforcement learning.",http://arxiv.org/pdf/2403.11418v1,
PITA: Physics-Informed Trajectory Autoencoder,18/03/2024,"Johannes Fischer, Kevin Rösch, Martin Lauer, Christoph Stiller","Validating robotic systems in safety-critical appli-cations requires testing
in many scenarios including rare edgecases that are unlikely to occur,
requiring to complement real-world testing with testing in simulation.
Generative models canbe used to augment real-world datasets with generated data
toproduce edge case scenarios by sampling in a learned latentspace.
Autoencoders can learn said latent representation for aspecific domain by
learning to reconstruct the input data froma lower-dimensional intermediate
representation. However, theresulting trajectories are not necessarily
physically plausible, butinstead typically contain noise that is not present in
the inputtrajectory. To resolve this issue, we propose the novel
Physics-Informed Trajectory Autoencoder (PITA) architecture, whichincorporates
a physical dynamics model into the loss functionof the autoencoder. This
results in smooth trajectories that notonly reconstruct the input trajectory
but also adhere to thephysical model. We evaluate PITA on a real-world dataset
ofvehicle trajectories and compare its performance to a normalautoencoder and a
state-of-the-art action-space autoencoder.",http://arxiv.org/pdf/2403.11728v1,
Notochord: a Flexible Probabilistic Model for Real-Time MIDI Performance,18/03/2024,"Victor Shepardson, Jack Armitage, Thor Magnusson","Deep learning-based probabilistic models of musical data are producing
increasingly realistic results and promise to enter creative workflows of many
kinds. Yet they have been little-studied in a performance setting, where the
results of user actions typically ought to feel instantaneous. To enable such
study, we designed Notochord, a deep probabilistic model for sequences of
structured events, and trained an instance of it on the Lakh MIDI dataset. Our
probabilistic formulation allows interpretable interventions at a sub-event
level, which enables one model to act as a backbone for diverse interactive
musical functions including steerable generation, harmonization, machine
improvisation, and likelihood-based interfaces. Notochord can generate
polyphonic and multi-track MIDI, and respond to inputs with latency below ten
milliseconds. Training code, model checkpoints and interactive examples are
provided as open source software.",http://arxiv.org/pdf/2403.12000v1,10.5281/zenodo.7088404
A conditional latent autoregressive recurrent model for generation and forecasting of beam dynamics in particle accelerators,19/03/2024,"Mahindra Rautela, Alan Williams, Alexander Scheinker","Particle accelerators are complex systems that focus, guide, and accelerate
intense charged particle beams to high energy. Beam diagnostics present a
challenging problem due to limited non-destructive measurements,
computationally demanding simulations, and inherent uncertainties in the
system. We propose a two-step unsupervised deep learning framework named as
Conditional Latent Autoregressive Recurrent Model (CLARM) for learning the
spatiotemporal dynamics of charged particles in accelerators. CLARM consists of
a Conditional Variational Autoencoder (CVAE) transforming six-dimensional phase
space into a lower-dimensional latent distribution and a Long Short-Term Memory
(LSTM) network capturing temporal dynamics in an autoregressive manner. The
CLARM can generate projections at various accelerator modules by sampling and
decoding the latent space representation. The model also forecasts future
states (downstream locations) of charged particles from past states (upstream
locations). The results demonstrate that the generative and forecasting ability
of the proposed approach is promising when tested against a variety of
evaluation metrics.",http://arxiv.org/pdf/2403.13858v1,
SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series,22/03/2024,"Badri N. Patro, Vijay S. Agneeswaran","Transformers have widely adopted attention networks for sequence mixing and
MLPs for channel mixing, playing a pivotal role in achieving breakthroughs
across domains. However, recent literature highlights issues with attention
networks, including low inductive bias and quadratic complexity concerning
input sequence length. State Space Models (SSMs) like S4 and others (Hippo,
Global Convolutions, liquid S4, LRU, Mega, and Mamba), have emerged to address
the above issues to help handle longer sequence lengths. Mamba, while being the
state-of-the-art SSM, has a stability issue when scaled to large networks for
computer vision datasets. We propose SiMBA, a new architecture that introduces
Einstein FFT (EinFFT) for channel modeling by specific eigenvalue computations
and uses the Mamba block for sequence modeling. Extensive performance studies
across image and time-series benchmarks demonstrate that SiMBA outperforms
existing SSMs, bridging the performance gap with state-of-the-art transformers.
Notably, SiMBA establishes itself as the new state-of-the-art SSM on ImageNet
and transfer learning benchmarks such as Stanford Car and Flower as well as
task learning benchmarks as well as seven time series benchmark datasets. The
project page is available on this website
~\url{https://github.com/badripatro/Simba}.",http://arxiv.org/pdf/2403.15360v2,
Generative weather for improved crop model simulations,31/03/2024,Yuji Saikai,"Accurate and precise crop yield prediction is invaluable for decision making
at both farm levels and regional levels. To make yield prediction, crop models
are widely used for their capability to simulate hypothetical scenarios. While
accuracy and precision of yield prediction critically depend on weather inputs
to simulations, surprisingly little attention has been paid to preparing
weather inputs. We propose a new method to construct generative models for
long-term weather forecasts and ultimately improve crop yield prediction. We
demonstrate use of the method in two representative scenarios -- single-year
production of wheat, barley and canola and three-year production using
rotations of these crops. Results show significant improvement from the
conventional method, measured in terms of mean and standard deviation of
prediction errors. Our method outperformed the conventional method in every one
of 18 metrics for the first scenario and in 29 out of 36 metrics for the second
scenario. For individual crop modellers to start applying the method to their
problems, technical details are carefully explained, and all the code, trained
PyTorch models, APSIM simulation files and result data are made available.",http://arxiv.org/pdf/2404.00528v1,
CAAP: Class-Dependent Automatic Data Augmentation Based On Adaptive Policies For Time Series,01/04/2024,"Tien-Yu Chang, Hao Dai, Vincent S. Tseng","Data Augmentation is a common technique used to enhance the performance of
deep learning models by expanding the training dataset. Automatic Data
Augmentation (ADA) methods are getting popular because of their capacity to
generate policies for various datasets. However, existing ADA methods primarily
focused on overall performance improvement, neglecting the problem of
class-dependent bias that leads to performance reduction in specific classes.
This bias poses significant challenges when deploying models in real-world
applications. Furthermore, ADA for time series remains an underexplored domain,
highlighting the need for advancements in this field. In particular, applying
ADA techniques to vital signals like an electrocardiogram (ECG) is a compelling
example due to its potential in medical domains such as heart disease
diagnostics.
  We propose a novel deep learning-based approach called Class-dependent
Automatic Adaptive Policies (CAAP) framework to overcome the notable
class-dependent bias problem while maintaining the overall improvement in
time-series data augmentation. Specifically, we utilize the policy network to
generate effective sample-wise policies with balanced difficulty through class
and feature information extraction. Second, we design the augmentation
probability regulation method to minimize class-dependent bias. Third, we
introduce the information region concepts into the ADA framework to preserve
essential regions in the sample. Through a series of experiments on real-world
ECG datasets, we demonstrate that CAAP outperforms representative methods in
achieving lower class-dependent bias combined with superior overall
performance. These results highlight the reliability of CAAP as a promising ADA
method for time series modeling that fits for the demands of real-world
applications.",http://arxiv.org/pdf/2404.00898v1,
A Generative Deep Learning Approach for Crash Severity Modeling with Imbalanced Data,02/04/2024,"Junlan Chen, Ziyuan Pu, Nan Zheng, Xiao Wen, Hongliang Ding, Xiucheng Guo","Crash data is often greatly imbalanced, with the majority of crashes being
non-fatal crashes, and only a small number being fatal crashes due to their
rarity. Such data imbalance issue poses a challenge for crash severity modeling
since it struggles to fit and interpret fatal crash outcomes with very limited
samples. Usually, such data imbalance issues are addressed by data resampling
methods, such as under-sampling and over-sampling techniques. However, most
traditional and deep learning-based data resampling methods, such as synthetic
minority oversampling technique (SMOTE) and generative Adversarial Networks
(GAN) are designed dedicated to processing continuous variables. Though some
resampling methods have improved to handle both continuous and discrete
variables, they may have difficulties in dealing with the collapse issue
associated with sparse discrete risk factors. Moreover, there is a lack of
comprehensive studies that compare the performance of various resampling
methods in crash severity modeling. To address the aforementioned issues, the
current study proposes a crash data generation method based on the Conditional
Tabular GAN. After data balancing, a crash severity model is employed to
estimate the performance of classification and interpretation. A comparative
study is conducted to assess classification accuracy and distribution
consistency of the proposed generation method using a 4-year imbalanced crash
dataset collected in Washington State, U.S. Additionally, Monte Carlo
simulation is employed to estimate the performance of parameter and probability
estimation in both two- and three-class imbalance scenarios. The results
indicate that using synthetic data generated by CTGAN-RU for crash severity
modeling outperforms using original data or synthetic data generated by other
resampling methods.",http://arxiv.org/pdf/2404.02187v1,
A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music,06/04/2024,"Roopa Mayya, Vivekanand Venkataraman, Anwesh P R, Narayana Darapaneni","Introduction: Music generation is a complex task that has received
significant attention in recent years, and deep learning techniques have shown
promising results in this field. Objectives: While extensive work has been
carried out on generating Piano and other Western music, there is limited
research on generating classical Indian music due to the scarcity of Indian
music in machine-encoded formats. In this technical paper, methods for
generating classical Indian music, specifically tabla music, is proposed.
Initially, this paper explores piano music generation using deep learning
architectures. Then the fundamentals are extended to generating tabla music.
Methods: Tabla music in waveform (.wav) files are pre-processed using the
librosa library in Python. A novel Bi-LSTM with an Attention approach and a
transformer model are trained on the extracted features and labels. Results:
The models are then used to predict the next sequences of tabla music. A loss
of 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the
transformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla
music generation. Conclusion: The resulting music embodies a harmonious fusion
of novelty and familiarity, pushing the limits of music composition to new
horizons.",http://arxiv.org/pdf/2404.05765v1,
scRDiT: Generating single-cell RNA-seq data by diffusion transformers and accelerating sampling,09/04/2024,"Shengze Dong, Zhuorui Cui, Ding Liu, Jinzhi Lei","Motivation: Single-cell RNA sequencing (scRNA-seq) is a groundbreaking
technology extensively utilized in biological research, facilitating the
examination of gene expression at the individual cell level within a given
tissue sample. While numerous tools have been developed for scRNA-seq data
analysis, the challenge persists in capturing the distinct features of such
data and replicating virtual datasets that share analogous statistical
properties. Results: Our study introduces a generative approach termed
scRNA-seq Diffusion Transformer (scRDiT). This method generates virtual
scRNA-seq data by leveraging a real dataset. The method is a neural network
constructed based on Denoising Diffusion Probabilistic Models (DDPMs) and
Diffusion Transformers (DiTs). This involves subjecting Gaussian noises to the
real dataset through iterative noise-adding steps and ultimately restoring the
noises to form scRNA-seq samples. This scheme allows us to learn data features
from actual scRNA-seq samples during model training. Our experiments, conducted
on two distinct scRNA-seq datasets, demonstrate superior performance.
Additionally, the model sampling process is expedited by incorporating
Denoising Diffusion Implicit Models (DDIM). scRDiT presents a unified
methodology empowering users to train neural network models with their unique
scRNA-seq datasets, enabling the generation of numerous high-quality scRNA-seq
samples. Availability and implementation: https://github.com/DongShengze/scRDiT",http://arxiv.org/pdf/2404.06153v1,
State-Space Systems as Dynamic Generative Models,12/04/2024,"Juan-Pablo Ortega, Florian Rossmannek","A probabilistic framework to study the dependence structure induced by
deterministic discrete-time state-space systems between input and output
processes is introduced. General sufficient conditions are formulated under
which output processes exist and are unique once an input process has been
fixed, a property that in the deterministic state-space literature is known as
the echo state property. When those conditions are satisfied, the given
state-space system becomes a generative model for probabilistic dependences
between two sequence spaces. Moreover, those conditions guarantee that the
output depends continuously on the input when using the Wasserstein metric. The
output processes whose existence is proved are shown to be causal in a specific
sense and to generalize those studied in purely deterministic situations. The
results in this paper constitute a significant stochastic generalization of
sufficient conditions for the deterministic echo state property to hold, in the
sense that the stochastic echo state property can be satisfied under
contractivity conditions that are strictly weaker than those in deterministic
situations. This means that state-space systems can induce a purely
probabilistic dependence structure between input and output sequence spaces
even when there is no functional relation between those two spaces.",http://arxiv.org/pdf/2404.08717v2,
Generating Synthetic Time Series Data for Cyber-Physical Systems,12/04/2024,"Alexander Sommers, Somayeh Bakhtiari Ramezani, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure","Data augmentation is an important facilitator of deep learning applications
in the time series domain. A gap is identified in the literature, demonstrating
sparse exploration of the transformer, the dominant sequence model, for data
augmentation in time series. A architecture hybridizing several successful
priors is put forth and tested using a powerful time domain similarity metric.
Results suggest the challenge of this domain, and several valuable directions
for future work.",http://arxiv.org/pdf/2404.08601v1,
RF-Diffusion: Radio Signal Generation via Time-Frequency Diffusion,14/04/2024,"Guoxuan Chi, Zheng Yang, Chenshu Wu, Jingao Xu, Yuchong Gao, Yunhao Liu, Tony Xiao Han","Along with AIGC shines in CV and NLP, its potential in the wireless domain
has also emerged in recent years. Yet, existing RF-oriented generative
solutions are ill-suited for generating high-quality, time-series RF data due
to limited representation capabilities. In this work, inspired by the stellar
achievements of the diffusion model in CV and NLP, we adapt it to the RF domain
and propose RF-Diffusion. To accommodate the unique characteristics of RF
signals, we first introduce a novel Time-Frequency Diffusion theory to enhance
the original diffusion model, enabling it to tap into the information within
the time, frequency, and complex-valued domains of RF signals. On this basis,
we propose a Hierarchical Diffusion Transformer to translate the theory into a
practical generative DNN through elaborated design spanning network
architecture, functional block, and complex-valued operator, making
RF-Diffusion a versatile solution to generate diverse, high-quality, and
time-series RF data. Performance comparison with three prevalent generative
models demonstrates the RF-Diffusion's superior performance in synthesizing
Wi-Fi and FMCW signals. We also showcase the versatility of RF-Diffusion in
boosting Wi-Fi sensing systems and performing channel estimation in 5G
networks.",http://arxiv.org/pdf/2404.09140v1,
Fault Detection in Mobile Networks Using Diffusion Models,14/04/2024,"Mohamad Nabeel, Doumitrou Daniil Nimara, Tahar Zanouda","In today's hyper-connected world, ensuring the reliability of telecom
networks becomes increasingly crucial. Telecom networks encompass numerous
underlying and intertwined software and hardware components, each providing
different functionalities. To ensure the stability of telecom networks, telecom
software, and hardware vendors developed several methods to detect any aberrant
behavior in telecom networks and enable instant feedback and alerts. These
approaches, although powerful, struggle to generalize due to the unsteady
nature of the software-intensive embedded system and the complexity and
diversity of multi-standard mobile networks. In this paper, we present a system
to detect anomalies in telecom networks using a generative AI model. We
evaluate several strategies using diffusion models to train the model for
anomaly detection using multivariate time-series data. The contributions of
this paper are threefold: (i) A proposal of a framework for utilizing diffusion
models for time-series anomaly detection in telecom networks, (ii) A proposal
of a particular Diffusion model architecture that outperforms other
state-of-the-art techniques, (iii) Experiments on a real-world dataset to
demonstrate that our model effectively provides explainable results, exposing
some of its limitations and suggesting future research avenues to enhance its
capabilities further.",http://arxiv.org/pdf/2404.09240v1,
Test Code Generation for Telecom Software Systems using Two-Stage Generative Model,14/04/2024,"Mohamad Nabeel, Doumitrou Daniil Nimara, Tahar Zanouda","In recent years, the evolution of Telecom towards achieving intelligent,
autonomous, and open networks has led to an increasingly complex Telecom
Software system, supporting various heterogeneous deployment scenarios, with
multi-standard and multi-vendor support. As a result, it becomes a challenge
for large-scale Telecom software companies to develop and test software for all
deployment scenarios. To address these challenges, we propose a framework for
Automated Test Generation for large-scale Telecom Software systems. We begin by
generating Test Case Input data for test scenarios observed using a time-series
Generative model trained on historical Telecom Network data during field
trials. Additionally, the time-series Generative model helps in preserving the
privacy of Telecom data. The generated time-series software performance data
are then utilized with test descriptions written in natural language to
generate Test Script using the Generative Large Language Model. Our
comprehensive experiments on public datasets and Telecom datasets obtained from
operational Telecom Networks demonstrate that the framework can effectively
generate comprehensive test case data input and useful test code.",http://arxiv.org/pdf/2404.09249v1,
σ-GPTs: A New Approach to Autoregressive Models,15/04/2024,"Arnaud Pannatier, Evann Courdier, François Fleuret","Autoregressive models, such as the GPT family, use a fixed order, usually
left-to-right, to generate sequences. However, this is not a necessity. In this
paper, we challenge this assumption and show that by simply adding a positional
encoding for the output, this order can be modulated on-the-fly per-sample
which offers key advantageous properties. It allows for the sampling of and
conditioning on arbitrary subsets of tokens, and it also allows sampling in one
shot multiple tokens dynamically according to a rejection strategy, leading to
a sub-linear number of model evaluations. We evaluate our method across various
domains, including language modeling, path-solving, and aircraft vertical rate
prediction, decreasing the number of steps required for generation by an order
of magnitude.",http://arxiv.org/pdf/2404.09562v2,
Personalized Heart Disease Detection via ECG Digital Twin Generation,17/04/2024,"Yaojun Hu, Jintai Chen, Lianting Hu, Dantong Li, Jiahuan Yan, Haochao Ying, Huiying Liang, Jian Wu","Heart diseases rank among the leading causes of global mortality,
demonstrating a crucial need for early diagnosis and intervention. Most
traditional electrocardiogram (ECG) based automated diagnosis methods are
trained at population level, neglecting the customization of personalized ECGs
to enhance individual healthcare management. A potential solution to address
this limitation is to employ digital twins to simulate symptoms of diseases in
real patients. In this paper, we present an innovative prospective learning
approach for personalized heart disease detection, which generates digital
twins of healthy individuals' anomalous ECGs and enhances the model sensitivity
to the personalized symptoms. In our approach, a vector quantized feature
separator is proposed to locate and isolate the disease symptom and normal
segments in ECG signals with ECG report guidance. Thus, the ECG digital twins
can simulate specific heart diseases used to train a personalized heart disease
detection model. Experiments demonstrate that our approach not only excels in
generating high-fidelity ECG signals but also improves personalized heart
disease detection. Moreover, our approach ensures robust privacy protection,
safeguarding patient data in model development.",http://arxiv.org/pdf/2404.11171v2,
Tensor-Networks-based Learning of Probabilistic Cellular Automata Dynamics,17/04/2024,"Heitor P. Casagrande, Bo Xing, William J. Munro, Chu Guo, Dario Poletti","Algorithms developed to solve many-body quantum problems, like tensor
networks, can turn into powerful quantum-inspired tools to tackle problems in
the classical domain. In this work, we focus on matrix product operators, a
prominent numerical technique to study many-body quantum systems, especially in
one dimension. It has been previously shown that such a tool can be used for
classification, learning of deterministic sequence-to-sequence processes and of
generic quantum processes. We further develop a matrix product operator
algorithm to learn probabilistic sequence-to-sequence processes and apply this
algorithm to probabilistic cellular automata. This new approach can accurately
learn probabilistic cellular automata processes in different conditions, even
when the process is a probabilistic mixture of different chaotic rules. In
addition, we find that the ability to learn these dynamics is a function of the
bit-wise difference between the rules and whether one is much more likely than
the other.",http://arxiv.org/pdf/2404.11768v1,10.1103/PhysRevResearch.6.043202
Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling,19/04/2024,"Grigory Bartosh, Dmitry Vetrov, Christian A. Naesseth","Conventional diffusion models typically relies on a fixed forward process,
which implicitly defines complex marginal distributions over latent variables.
This can often complicate the reverse process' task in learning generative
trajectories, and results in costly inference for diffusion models. To address
these limitations, we introduce Neural Flow Diffusion Models (NFDM), a novel
framework that enhances diffusion models by supporting a broader range of
forward processes beyond the standard Gaussian. We also propose a novel
parameterization technique for learning the forward process. Our framework
provides an end-to-end, simulation-free optimization objective, effectively
minimizing a variational upper bound on the negative log-likelihood.
Experimental results demonstrate NFDM's strong performance, evidenced by
state-of-the-art likelihood estimation. Furthermore, we investigate NFDM's
capacity for learning generative dynamics with specific characteristics, such
as deterministic straight lines trajectories, and demonstrate how the framework
may be adopted for learning bridges between two distributions. The results
underscores NFDM's versatility and its potential for a wide range of
applications.",http://arxiv.org/pdf/2404.12940v2,
Cumulative Hazard Function Based Efficient Multivariate Temporal Point Process Learning,21/04/2024,Bingqing Liu,"Most existing temporal point process models are characterized by conditional
intensity function. These models often require numerical approximation methods
for likelihood evaluation, which potentially hurts their performance. By
directly modelling the integral of the intensity function, i.e., the cumulative
hazard function (CHF), the likelihood can be evaluated accurately, making it a
promising approach. However, existing CHF-based methods are not well-defined,
i.e., the mathematical constraints of CHF are not completely satisfied, leading
to untrustworthy results. For multivariate temporal point process, most
existing methods model intensity (or density, etc.) functions for each variate,
limiting the scalability. In this paper, we explore using neural networks to
model a flexible but well-defined CHF and learning the multivariate temporal
point process with low parameter complexity. Experimental results on six
datasets show that the proposed model achieves the state-of-the-art performance
on data fitting and event prediction tasks while having significantly fewer
parameters and memory usage than the strong competitors. The source code and
data can be obtained from https://github.com/lbq8942/NPP.",http://arxiv.org/pdf/2404.13663v2,
Tensor-Valued Time and Inference Path Optimization in Differential Equation-Based Generative Modeling,22/04/2024,"Dohoon Lee, Kyogu Lee","In the field of generative modeling based on differential equations,
conventional methods utilize scalar-valued time during both the training and
inference phases. This work introduces, for the first time, a tensor-valued
time that expands the conventional scalar-valued time into multiple dimensions.
Additionally, we propose a novel path optimization problem designed to
adaptively determine multidimensional inference trajectories using a
predetermined differential equation solver and a fixed number of function
evaluations. Our approach leverages the stochastic interpolant framework,
simulation dynamics, and adversarial training to optimize the inference
pathway. Notably, incorporating tensor-valued time during training improves
some models' inference performance, even without path optimization. When the
adaptive, multidimensional path derived from our optimization process is
employed, further performance gains are achieved despite the fixed solver
configurations. The introduction of tensor-valued time not only enhances the
efficiency of models but also opens new avenues for exploration in training and
inference methodologies, highlighting the potential of adaptive
multidimensional paths.",http://arxiv.org/pdf/2404.14161v2,
Estimating the Distribution of Parameters in Differential Equations with Repeated Cross-Sectional Data,23/04/2024,"Hyeontae Jo, Sung Woong Cho, Hyung Ju Hwang","Differential equations are pivotal in modeling and understanding the dynamics
of various systems, offering insights into their future states through
parameter estimation fitted to time series data. In fields such as economy,
politics, and biology, the observation data points in the time series are often
independently obtained (i.e., Repeated Cross-Sectional (RCS) data). With RCS
data, we found that traditional methods for parameter estimation in
differential equations, such as using mean values of time trajectories or
Gaussian Process-based trajectory generation, have limitations in estimating
the shape of parameter distributions, often leading to a significant loss of
data information. To address this issue, we introduce a novel method,
Estimation of Parameter Distribution (EPD), providing accurate distribution of
parameters without loss of data information. EPD operates in three main steps:
generating synthetic time trajectories by randomly selecting observed values at
each time point, estimating parameters of a differential equation that minimize
the discrepancy between these trajectories and the true solution of the
equation, and selecting the parameters depending on the scale of discrepancy.
We then evaluated the performance of EPD across several models, including
exponential growth, logistic population models, and target cell-limited models
with delayed virus production, demonstrating its superiority in capturing the
shape of parameter distributions. Furthermore, we applied EPD to real-world
datasets, capturing various shapes of parameter distributions rather than a
normal distribution. These results effectively address the heterogeneity within
systems, marking a substantial progression in accurately modeling systems using
RCS data.",http://arxiv.org/pdf/2404.14873v1,
"Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges",24/04/2024,"Badri Narayana Patro, Vijay Srinivas Agneeswaran","Sequence modeling is a crucial area across various domains, including Natural
Language Processing (NLP), speech recognition, time series forecasting, music
generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short
Term Memory Networks (LSTMs) have historically dominated sequence modeling
tasks like Machine Translation, Named Entity Recognition (NER), etc. However,
the advancement of transformers has led to a shift in this paradigm, given
their superior performance. Yet, transformers suffer from $O(N^2)$ attention
complexity and challenges in handling inductive bias. Several variations have
been proposed to address these issues which use spectral networks or
convolutions and have performed well on a range of tasks. However, they still
have difficulty in dealing with long sequences. State Space Models(SSMs) have
emerged as promising alternatives for sequence modeling paradigms in this
context, especially with the advent of S4 and its variants, such as S4nd,
Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear
Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the
foundational SSMs based on three paradigms namely, Gating architectures,
Structural architectures, and Recurrent architectures. This survey also
highlights diverse applications of SSMs across domains such as vision, video,
audio, speech, language (especially long sequence modeling), medical (including
genomics), chemical (like drug design), recommendation systems, and time series
analysis, including tabular data. Moreover, we consolidate the performance of
SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,
ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,
COIN, LVU, and various time series datasets. The project page for Mamba-360
work is available on this webpage.\url{https://github.com/badripatro/mamba360}.",http://arxiv.org/pdf/2404.16112v1,
Time Series Data Augmentation as an Imbalanced Learning Problem,29/04/2024,"Vitor Cerqueira, Nuno Moniz, Ricardo Inácio, Carlos Soares","Recent state-of-the-art forecasting methods are trained on collections of
time series. These methods, often referred to as global models, can capture
common patterns in different time series to improve their generalization
performance. However, they require large amounts of data that might not be
readily available. Besides this, global models sometimes fail to capture
relevant patterns unique to a particular time series. In these cases, data
augmentation can be useful to increase the sample size of time series datasets.
The main contribution of this work is a novel method for generating univariate
time series synthetic samples. Our approach stems from the insight that the
observations concerning a particular time series of interest represent only a
small fraction of all observations. In this context, we frame the problem of
training a forecasting model as an imbalanced learning task. Oversampling
strategies are popular approaches used to deal with the imbalance problem in
machine learning. We use these techniques to create synthetic time series
observations and improve the accuracy of forecasting models. We carried out
experiments using 7 different databases that contain a total of 5502 univariate
time series. We found that the proposed solution outperforms both a global and
a local model, thus providing a better trade-off between these two approaches.",http://arxiv.org/pdf/2404.18537v1,
A Survey on Diffusion Models for Time Series and Spatio-Temporal Data,29/04/2024,"Yiyuan Yang, Ming Jin, Haomin Wen, Chaoli Zhang, Yuxuan Liang, Lintao Ma, Yi Wang, Chenghao Liu, Bin Yang, Zenglin Xu, Jiang Bian, Shirui Pan, Qingsong Wen","The study of time series is crucial for understanding trends and anomalies
over time, enabling predictive insights across various sectors. Spatio-temporal
data, on the other hand, is vital for analyzing phenomena in both space and
time, providing a dynamic perspective on complex system interactions. Recently,
diffusion models have seen widespread application in time series and
spatio-temporal data mining. Not only do they enhance the generative and
inferential capabilities for sequential and temporal data, but they also extend
to other downstream tasks. In this survey, we comprehensively and thoroughly
review the use of diffusion models in time series and spatio-temporal data,
categorizing them by model category, task type, data modality, and practical
application domain. In detail, we categorize diffusion models into
unconditioned and conditioned types and discuss time series and spatio-temporal
data separately. Unconditioned models, which operate unsupervised, are
subdivided into probability-based and score-based models, serving predictive
and generative tasks such as forecasting, anomaly detection, classification,
and imputation. Conditioned models, on the other hand, utilize extra
information to enhance performance and are similarly divided for both
predictive and generative tasks. Our survey extensively covers their
application in various fields, including healthcare, recommendation, climate,
energy, audio, and transportation, providing a foundational understanding of
how these models analyze and generate data. Through this structured overview,
we aim to provide researchers and practitioners with a comprehensive
understanding of diffusion models for time series and spatio-temporal data
analysis, aiming to direct future innovations and applications by addressing
traditional challenges and exploring innovative solutions within the diffusion
model framework.",http://arxiv.org/pdf/2404.18886v3,
BrainODE: Dynamic Brain Signal Analysis via Graph-Aided Neural Ordinary Differential Equations,30/04/2024,"Kaiqiao Han, Yi Yang, Zijie Huang, Xuan Kan, Yang Yang, Ying Guo, Lifang He, Liang Zhan, Yizhou Sun, Wei Wang, Carl Yang","Brain network analysis is vital for understanding the neural interactions
regarding brain structures and functions, and identifying potential biomarkers
for clinical phenotypes. However, widely used brain signals such as Blood
Oxygen Level Dependent (BOLD) time series generated from functional Magnetic
Resonance Imaging (fMRI) often manifest three challenges: (1) missing values,
(2) irregular samples, and (3) sampling misalignment, due to instrumental
limitations, impacting downstream brain network analysis and clinical outcome
predictions. In this work, we propose a novel model called BrainODE to achieve
continuous modeling of dynamic brain signals using Ordinary Differential
Equations (ODE). By learning latent initial values and neural ODE functions
from irregular time series, BrainODE effectively reconstructs brain signals at
any time point, mitigating the aforementioned three data challenges of brain
signals altogether. Comprehensive experimental results on real-world
neuroimaging datasets demonstrate the superior performance of BrainODE and its
capability of addressing the three data challenges.",http://arxiv.org/pdf/2405.00077v1,
Digital Twin Generators for Disease Modeling,02/05/2024,"Nameyeh Alam, Jake Basilico, Daniele Bertolini, Satish Casie Chetty, Heather D'Angelo, Ryan Douglas, Charles K. Fisher, Franklin Fuller, Melissa Gomes, Rishabh Gupta, Alex Lang, Anton Loukianov, Rachel Mak-McCully, Cary Murray, Hanalei Pham, Susanna Qiao, Elena Ryapolova-Webb, Aaron Smith, Dimitri Theoharatos, Anil Tolwani, Eric W. Tramel, Anna Vidovszky, Judy Viduya, Jonathan R. Walsh","A patient's digital twin is a computational model that describes the
evolution of their health over time. Digital twins have the potential to
revolutionize medicine by enabling individual-level computer simulations of
human health, which can be used to conduct more efficient clinical trials or to
recommend personalized treatment options. Due to the overwhelming complexity of
human biology, machine learning approaches that leverage large datasets of
historical patients' longitudinal health records to generate patients' digital
twins are more tractable than potential mechanistic models. In this manuscript,
we describe a neural network architecture that can learn conditional generative
models of clinical trajectories, which we call Digital Twin Generators (DTGs),
that can create digital twins of individual patients. We show that the same
neural network architecture can be trained to generate accurate digital twins
for patients across 13 different indications simply by changing the training
set and tuning hyperparameters. By introducing a general purpose architecture,
we aim to unlock the ability to scale machine learning approaches to larger
datasets and across more indications so that a digital twin could be created
for any patient in the world.",http://arxiv.org/pdf/2405.01488v1,
A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Model,03/05/2024,"Jiexia Ye, Weiqi Zhang, Ke Yi, Yongzi Yu, Ziyue Li, Jia Li, Fugee Tsung","Time series data are ubiquitous across various domains, making time series
analysis critically important. Traditional time series models are
task-specific, featuring singular functionality and limited generalization
capacity. Recently, large language foundation models have unveiled their
remarkable capabilities for cross-task transferability, zero-shot/few-shot
learning, and decision-making explainability. This success has sparked interest
in the exploration of foundation models to solve multiple time series
challenges simultaneously. There are two main research lines, namely
pre-training foundation models from scratch for time series and adapting large
language foundation models for time series. They both contribute to the
development of a unified model that is highly generalizable, versatile, and
comprehensible for time series analysis. This survey offers a 3E analytical
framework for comprehensive examination of related research. Specifically, we
examine existing works from three dimensions, namely Effectiveness, Efficiency
and Explainability. In each dimension, we focus on discussing how related works
devise tailored solution by considering unique challenges in the realm of time
series. Furthermore, we provide a domain taxonomy to help followers keep up
with the domain-specific advancements. In addition, we introduce extensive
resources to facilitate the field's development, including datasets,
open-source, time series libraries. A GitHub repository is also maintained for
resource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).",http://arxiv.org/pdf/2405.02358v2,
sc-OTGM: Single-Cell Perturbation Modeling by Solving Optimal Mass Transport on the Manifold of Gaussian Mixtures,06/05/2024,"Andac Demir, Elizaveta Solovyeva, James Boylan, Mei Xiao, Fabrizio Serluca, Sebastian Hoersch, Jeremy Jenkins, Murthy Devarakonda, Bulent Kiziltan","Influenced by breakthroughs in LLMs, single-cell foundation models are
emerging. While these models show successful performance in cell type
clustering, phenotype classification, and gene perturbation response
prediction, it remains to be seen if a simpler model could achieve comparable
or better results, especially with limited data. This is important, as the
quantity and quality of single-cell data typically fall short of the standards
in textual data used for training LLMs. Single-cell sequencing often suffers
from technical artifacts, dropout events, and batch effects. These challenges
are compounded in a weakly supervised setting, where the labels of cell states
can be noisy, further complicating the analysis. To tackle these challenges, we
present sc-OTGM, streamlined with less than 500K parameters, making it
approximately 100x more compact than the foundation models, offering an
efficient alternative. sc-OTGM is an unsupervised model grounded in the
inductive bias that the scRNAseq data can be generated from a combination of
the finite multivariate Gaussian distributions. The core function of sc-OTGM is
to create a probabilistic latent space utilizing a GMM as its prior
distribution and distinguish between distinct cell populations by learning
their respective marginal PDFs. It uses a Hit-and-Run Markov chain sampler to
determine the OT plan across these PDFs within the GMM framework. We evaluated
our model against a CRISPR-mediated perturbation dataset, called CROP-seq,
consisting of 57 one-gene perturbations. Our results demonstrate that sc-OTGM
is effective in cell state classification, aids in the analysis of differential
gene expression, and ranks genes for target identification through a
recommender system. It also predicts the effects of single-gene perturbations
on downstream gene regulation and generates synthetic scRNA-seq data
conditioned on specific cell states.",http://arxiv.org/pdf/2405.03726v1,
Variational Schrödinger Diffusion Models,08/05/2024,"Wei Deng, Weijian Luo, Yixin Tan, Marin Biloš, Yu Chen, Yuriy Nevmyvaka, Ricky T. Q. Chen","Schr\""odinger bridge (SB) has emerged as the go-to method for optimizing
transportation plans in diffusion models. However, SB requires estimating the
intractable forward score functions, inevitably resulting in the costly
implicit training loss based on simulated trajectories. To improve the
scalability while preserving efficient transportation plans, we leverage
variational inference to linearize the forward score functions (variational
scores) of SB and restore simulation-free properties in training backward
scores. We propose the variational Schr\""odinger diffusion model (VSDM), where
the forward process is a multivariate diffusion and the variational scores are
adaptively optimized for efficient transport. Theoretically, we use stochastic
approximation to prove the convergence of the variational scores and show the
convergence of the adaptively generated samples based on the optimal
variational scores. Empirically, we test the algorithm in simulated examples
and observe that VSDM is efficient in generations of anisotropic shapes and
yields straighter sample trajectories compared to the single-variate diffusion.
We also verify the scalability of the algorithm in real-world data and achieve
competitive unconditional generation performance in CIFAR10 and conditional
generation in time series modeling. Notably, VSDM no longer depends on warm-up
initializations and has become tuning-friendly in training large-scale
experiments.",http://arxiv.org/pdf/2405.04795v4,
Towards a Path Dependent Account of Category Fluency,09/05/2024,"David Heineman, Reba Koenen, Sashank Varma","Category fluency is a widely studied cognitive phenomenon, yet two
conflicting accounts have been proposed as the underlying retrieval mechanism
-- an optimal foraging process deliberately searching through memory (Hills et
al., 2012) and a random walk sampling from a semantic network (Abbott et al.,
2015). Evidence for both accounts has centered around predicting human patch
switches, where both existing models of category fluency produce paradoxically
identical results. We begin by peeling back the assumptions made by existing
models, namely that each named example only depends on the previous example, by
(i) adding an additional bias to model the category transition probability
directly and (ii) relying on a large language model to predict based on the
entire existing sequence. Then, we present evidence towards resolving the
disagreement between each account of foraging by reformulating models as
sequence generators. To evaluate, we compare generated category fluency runs to
a bank of human-written sequences by proposing a metric based on n-gram
overlap. We find category switch predictors do not necessarily produce
human-like sequences, in fact the additional biases used by the Hills et al.
(2012) model are required to improve generation quality, which are later
improved by our category modification. Even generating exclusively with an LLM
requires an additional global cue to trigger the patch switching behavior
during production. Further tests on only the search process on top of the
semantic network highlight the importance of deterministic search to replicate
human behavior.",http://arxiv.org/pdf/2405.06714v2,
Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask,09/05/2024,"Zineb Senane, Lele Cao, Valentin Leonhard Buchner, Yusuke Tashiro, Lei You, Pawel Herman, Mats Nordahl, Ruibo Tu, Vilhelm von Ehrenheim","Time Series Representation Learning (TSRL) focuses on generating informative
representations for various Time Series (TS) modeling tasks. Traditional
Self-Supervised Learning (SSL) methods in TSRL fall into four main categories:
reconstructive, adversarial, contrastive, and predictive, each with a common
challenge of sensitivity to noise and intricate data nuances. Recently,
diffusion-based methods have shown advanced generative capabilities. However,
they primarily target specific application scenarios like imputation and
forecasting, leaving a gap in leveraging diffusion models for generic TSRL. Our
work, Time Series Diffusion Embedding (TSDE), bridges this gap as the first
diffusion-based SSL TSRL approach. TSDE segments TS data into observed and
masked parts using an Imputation-Interpolation-Forecasting (IIF) mask. It
applies a trainable embedding function, featuring dual-orthogonal Transformer
encoders with a crossover mechanism, to the observed part. We train a reverse
diffusion process conditioned on the embeddings, designed to predict noise
added to the masked part. Extensive experiments demonstrate TSDE's superiority
in imputation, interpolation, forecasting, anomaly detection, classification,
and clustering. We also conduct an ablation study, present embedding
visualizations, and compare inference speed, further substantiating TSDE's
efficiency and validity in learning representations of TS data.",http://arxiv.org/pdf/2405.05959v2,10.1145/3637528.3671673
Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers,10/05/2024,"Andraž Jelinčič, James Foster, Patrick Kidger","Despite the success of adaptive time-stepping in ODE simulation, it has so
far seen few applications for Stochastic Differential Equations (SDEs). To
simulate SDEs adaptively, methods such as the Virtual Brownian Tree (VBT) have
been developed, which can generate Brownian motion (BM) non-chronologically.
However, in most applications, knowing only the values of Brownian motion is
not enough to achieve a high order of convergence; for that, we must compute
time-integrals of BM such as $\int_s^t W_r \, dr$. With the aim of using high
order SDE solvers adaptively, we extend the VBT to generate these integrals of
BM in addition to the Brownian increments. A JAX-based implementation of our
construction is included in the popular Diffrax library
(https://github.com/patrick-kidger/diffrax).
  Since the entire Brownian path produced by VBT is uniquely determined by a
single PRNG seed, previously generated samples need not be stored, which
results in a constant memory footprint and enables experiment repeatability and
strong error estimation. Based on binary search, the VBT's time complexity is
logarithmic in the tolerance parameter $\varepsilon$. Unlike the original VBT
algorithm, which was only precise at some dyadic times, we prove that our
construction exactly matches the joint distribution of the Brownian motion and
its time integrals at any query times, provided they are at least $\varepsilon$
apart.
  We present two applications of adaptive high order solvers enabled by our new
VBT. Using adaptive solvers to simulate a high-volatility CIR model, we achieve
more than twice the convergence order of constant stepping. We apply an
adaptive third order underdamped or kinetic Langevin solver to an MCMC problem,
where our approach outperforms the No U-Turn Sampler, while using only a tenth
of its function evaluations.",http://arxiv.org/pdf/2405.06464v3,
RoTHP: Rotary Position Embedding-based Transformer Hawkes Process,11/05/2024,"Anningzhe Gao, Shan Dai","Temporal Point Processes (TPPs), especially Hawkes Process are commonly used
for modeling asynchronous event sequences data such as financial transactions
and user behaviors in social networks. Due to the strong fitting ability of
neural networks, various neural Temporal Point Processes are proposed, among
which the Neural Hawkes Processes based on self-attention such as Transformer
Hawkes Process (THP) achieve distinct performance improvement. Although the THP
has gained increasing studies, it still suffers from the {sequence prediction
issue}, i.e., training on history sequences and inferencing about the future,
which is a prevalent paradigm in realistic sequence analysis tasks. What's
more, conventional THP and its variants simply adopt initial sinusoid embedding
in transformers, which shows performance sensitivity to temporal change or
noise in sequence data analysis by our empirical study. To deal with the
problems, we propose a new Rotary Position Embedding-based THP (RoTHP)
architecture in this paper. Notably, we show the translation invariance
property and {sequence prediction flexibility} of our RoTHP induced by the
{relative time embeddings} when coupled with Hawkes process theoretically.
Furthermore, we demonstrate empirically that our RoTHP can be better
generalized in sequence data scenarios with timestamp translations and in
sequence prediction tasks.",http://arxiv.org/pdf/2405.06985v1,
A Survey of Generative Techniques for Spatial-Temporal Data Mining,15/05/2024,"Qianru Zhang, Haixin Wang, Cheng Long, Liangcai Su, Xingwei He, Jianlong Chang, Tailin Wu, Hongzhi Yin, Siu-Ming Yiu, Qi Tian, Christian S. Jensen","This paper focuses on the integration of generative techniques into
spatial-temporal data mining, considering the significant growth and diverse
nature of spatial-temporal data. With the advancements in RNNs, CNNs, and other
non-generative techniques, researchers have explored their application in
capturing temporal and spatial dependencies within spatial-temporal data.
However, the emergence of generative techniques such as LLMs, SSL, Seq2Seq and
diffusion models has opened up new possibilities for enhancing spatial-temporal
data mining further. The paper provides a comprehensive analysis of generative
technique-based spatial-temporal methods and introduces a standardized
framework specifically designed for the spatial-temporal data mining pipeline.
By offering a detailed review and a novel taxonomy of spatial-temporal
methodology utilizing generative techniques, the paper enables a deeper
understanding of the various techniques employed in this field. Furthermore,
the paper highlights promising future research directions, urging researchers
to delve deeper into spatial-temporal data mining. It emphasizes the need to
explore untapped opportunities and push the boundaries of knowledge to unlock
new insights and improve the effectiveness and efficiency of spatial-temporal
data mining. By integrating generative techniques and providing a standardized
framework, the paper contributes to advancing the field and encourages
researchers to explore the vast potential of generative techniques in
spatial-temporal data mining.",http://arxiv.org/pdf/2405.09592v1,
UniCL: A Universal Contrastive Learning Framework for Large Time Series Models,17/05/2024,"Jiawei Li, Jingshu Peng, Haoyang Li, Lei Chen","Time-series analysis plays a pivotal role across a range of critical
applications, from finance to healthcare, which involves various tasks, such as
forecasting and classification. To handle the inherent complexities of
time-series data, such as high dimensionality and noise, traditional supervised
learning methods first annotate extensive labels for time-series data in each
task, which is very costly and impractical in real-world applications. In
contrast, pre-trained foundation models offer a promising alternative by
leveraging unlabeled data to capture general time series patterns, which can
then be fine-tuned for specific tasks. However, existing approaches to
pre-training such models typically suffer from high-bias and low-generality
issues due to the use of predefined and rigid augmentation operations and
domain-specific data training. To overcome these limitations, this paper
introduces UniCL, a universal and scalable contrastive learning framework
designed for pretraining time-series foundation models across cross-domain
datasets. Specifically, we propose a unified and trainable time-series
augmentation operation to generate pattern-preserved, diverse, and low-bias
time-series data by leveraging spectral information. Besides, we introduce a
scalable augmentation algorithm capable of handling datasets with varying
lengths, facilitating cross-domain pretraining. Extensive experiments on two
benchmark datasets across eleven domains validate the effectiveness of UniCL,
demonstrating its high generalization on time-series analysis across various
fields.",http://arxiv.org/pdf/2405.10597v1,
Switched Flow Matching: Eliminating Singularities via Switching ODEs,19/05/2024,"Qunxi Zhu, Wei Lin","Continuous-time generative models, such as Flow Matching (FM), construct
probability paths to transport between one distribution and another through the
simulation-free learning of the neural ordinary differential equations (ODEs).
During inference, however, the learned model often requires multiple neural
network evaluations to accurately integrate the flow, resulting in a slow
sampling speed. We attribute the reason to the inherent (joint) heterogeneity
of source and/or target distributions, namely the singularity problem, which
poses challenges for training the neural ODEs effectively. To address this
issue, we propose a more general framework, termed Switched FM (SFM), that
eliminates singularities via switching ODEs, as opposed to using a uniform ODE
in FM. Importantly, we theoretically show that FM cannot transport between two
simple distributions due to the existence and uniqueness of initial value
problems of ODEs, while these limitations can be well tackled by SFM. From an
orthogonal perspective, our framework can seamlessly integrate with the
existing advanced techniques, such as minibatch optimal transport, to further
enhance the straightness of the flow, yielding a more efficient sampling
process with reduced costs. We demonstrate the effectiveness of the newly
proposed SFM through several numerical examples.",http://arxiv.org/pdf/2405.11605v2,
Application of time-series quantum generative model to financial data,20/05/2024,"Shun Okumura, Masayuki Ohzeki, Masaya Abe","Despite proposing a quantum generative model for time series that
successfully learns correlated series with multiple Brownian motions, the model
has not been adapted and evaluated for financial problems. In this study, a
time-series generative model was applied as a quantum generative model to
actual financial data. Future data for two correlated time series were
generated and compared with classical methods such as long short-term memory
and vector autoregression. Furthermore, numerical experiments were performed to
complete missing values. Based on the results, we evaluated the practical
applications of the time-series quantum generation model. It was observed that
fewer parameter values were required compared with the classical method. In
addition, the quantum time-series generation model was feasible for both
stationary and nonstationary data. These results suggest that several
parameters can be applied to various types of time-series data.",http://arxiv.org/pdf/2405.11795v1,
Alternators For Sequence Modeling,20/05/2024,"Mohammad Reza Rezaei, Adji Bousso Dieng","This paper introduces alternators, a novel family of non-Markovian dynamical
models for sequences. An alternator features two neural networks: the
observation trajectory network (OTN) and the feature trajectory network (FTN).
The OTN and the FTN work in conjunction, alternating between outputting samples
in the observation space and some feature space, respectively, over a cycle.
The parameters of the OTN and the FTN are not time-dependent and are learned
via a minimum cross-entropy criterion over the trajectories. Alternators are
versatile. They can be used as dynamical latent-variable generative models or
as sequence-to-sequence predictors. Alternators can uncover the latent dynamics
underlying complex sequential data, accurately forecast and impute missing
data, and sample new trajectories. We showcase the capabilities of alternators
in three applications. We first used alternators to model the Lorenz equations,
often used to describe chaotic behavior. We then applied alternators to
Neuroscience, to map brain activity to physical activity. Finally, we applied
alternators to Climate Science, focusing on sea-surface temperature
forecasting. In all our experiments, we found alternators are stable to train,
fast to sample from, yield high-quality generated samples and latent variables,
and often outperform strong baselines such as Mambas, neural ODEs, and
diffusion models in the domains we studied.",http://arxiv.org/pdf/2405.11848v2,
A Versatile Diffusion Transformer with Mixture of Noise Levels for Audiovisual Generation,22/05/2024,"Gwanghyun Kim, Alonso Martinez, Yu-Chuan Su, Brendan Jou, José Lezama, Agrim Gupta, Lijun Yu, Lu Jiang, Aren Jansen, Jacob Walker, Krishna Somandepalli","Training diffusion models for audiovisual sequences allows for a range of
generation tasks by learning conditional distributions of various input-output
combinations of the two modalities. Nevertheless, this strategy often requires
training a separate model for each task which is expensive. Here, we propose a
novel training approach to effectively learn arbitrary conditional
distributions in the audiovisual space.Our key contribution lies in how we
parameterize the diffusion timestep in the forward diffusion process. Instead
of the standard fixed diffusion timestep, we propose applying variable
diffusion timesteps across the temporal dimension and across modalities of the
inputs. This formulation offers flexibility to introduce variable noise levels
for various portions of the input, hence the term mixture of noise levels. We
propose a transformer-based audiovisual latent diffusion model and show that it
can be trained in a task-agnostic fashion using our approach to enable a
variety of audiovisual generation tasks at inference time. Experiments
demonstrate the versatility of our method in tackling cross-modal and
multimodal interpolation tasks in the audiovisual space. Notably, our proposed
approach surpasses baselines in generating temporally and perceptually
consistent samples conditioned on the input. Project page: avdit2024.github.io",http://arxiv.org/pdf/2405.13762v1,
A Study of Posterior Stability for Time-Series Latent Diffusion,22/05/2024,"Yangming Li, Yixin Cheng, Mihaela van der Schaar","Latent diffusion has demonstrated promising results in image generation and
permits efficient sampling. However, this framework might suffer from the
problem of posterior collapse when applied to time series. In this paper, we
first show that posterior collapse will reduce latent diffusion to a
variational autoencoder (VAE), making it less expressive. This highlights the
importance of addressing this issue. We then introduce a principled method:
dependency measure, that quantifies the sensitivity of a recurrent decoder to
input variables. Using this tool, we confirm that posterior collapse
significantly affects time-series latent diffusion on real datasets, and a
phenomenon termed dependency illusion is also discovered in the case of
shuffled time series. Finally, building on our theoretical and empirical
studies, we introduce a new framework that extends latent diffusion and has a
stable posterior. Extensive experiments on multiple real time-series datasets
show that our new framework is free from posterior collapse and significantly
outperforms previous baselines in time series synthesis.",http://arxiv.org/pdf/2405.14021v2,
High Rank Path Development: an approach of learning the filtration of stochastic processes,23/05/2024,"Jiajie Tao, Hao Ni, Chong Liu","Since the weak convergence for stochastic processes does not account for the
growth of information over time which is represented by the underlying
filtration, a slightly erroneous stochastic model in weak topology may cause
huge loss in multi-periods decision making problems. To address such
discontinuities Aldous introduced the extended weak convergence, which can
fully characterise all essential properties, including the filtration, of
stochastic processes; however was considered to be hard to find efficient
numerical implementations. In this paper, we introduce a novel metric called
High Rank PCF Distance (HRPCFD) for extended weak convergence based on the high
rank path development method from rough path theory, which also defines the
characteristic function for measure-valued processes. We then show that such
HRPCFD admits many favourable analytic properties which allows us to design an
efficient algorithm for training HRPCFD from data and construct the HRPCF-GAN
by using HRPCFD as the discriminator for conditional time series generation.
Our numerical experiments on both hypothesis testing and generative modelling
validate the out-performance of our approach compared with several
state-of-the-art methods, highlighting its potential in broad applications of
synthetic time series generation and in addressing classic financial and
economic challenges, such as optimal stopping or utility maximisation problems.",http://arxiv.org/pdf/2405.14913v1,
Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis,24/05/2024,"Xishun Liao, Qinhua Jiang, Brian Yueshuai He, Yifan Liu, Chenchen Kuai, Jiaqi Ma","Human mobility plays a crucial role in transportation, urban planning, and
public health. Advances in deep learning and the availability of diverse
mobility data have transformed mobility modeling. However, existing deep
learning models often focus on spatio-temporal patterns and struggle to capture
the semantic interdependencies among activities, while also being limited by
specific data sources. These challenges reduce their realism and adaptability.
Traditional activity-based models (ABMs) face issues as well, relying on rigid
assumptions and requiring extensive data, making them costly and difficult to
adapt to new regions, especially those with limited conventional travel data.
To address these limitations, we develop a novel generative deep learning
approach for human mobility modeling and synthesis that incorporates both
activity patterns and location trajectories using open-source data. The model
can be fine-tuned with local data, allowing it to adapt to and accurately
represent mobility patterns across diverse regions. The model is evaluated on a
nationwide dataset of the United States, where it demonstrates superior
performance in generating activity-location chains that closely follow ground
truth distributions. Further tests using state- or city-specific datasets from
California, Washington, and Mexico City confirm its transferability. This
innovative approach offers substantial potential to advance mobility modeling
research, particularly in generating synthetic human mobility data. This can
provide urban planners and policymakers with enhanced tools for simulating
mobility in diverse regions and better informing decisions related to
transportation, urban development, and public health.",http://arxiv.org/pdf/2405.17468v2,
From Orthogonality to Dependency: Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals,25/05/2024,"Ruichu Cai, Zhifang Jiang, Zijian Li, Weilin Chen, Xuexin Chen, Zhifeng Hao, Yifan Shen, Guangyi Chen, Kun Zhang","Existing methods for multi-modal time series representation learning aim to
disentangle the modality-shared and modality-specific latent variables.
Although achieving notable performances on downstream tasks, they usually
assume an orthogonal latent space. However, the modality-specific and
modality-shared latent variables might be dependent on real-world scenarios.
Therefore, we propose a general generation process, where the modality-shared
and modality-specific latent variables are dependent, and further develop a
\textbf{M}ulti-mod\textbf{A}l \textbf{TE}mporal Disentanglement (\textbf{MATE})
model. Specifically, our \textbf{MATE} model is built on a temporally
variational inference architecture with the modality-shared and
modality-specific prior networks for the disentanglement of latent variables.
Furthermore, we establish identifiability results to show that the extracted
representation is disentangled. More specifically, we first achieve the
subspace identifiability for modality-shared and modality-specific latent
variables by leveraging the pairing of multi-modal data. Then we establish the
component-wise identifiability of modality-specific latent variables by
employing sufficient changes of historical latent variables. Extensive
experimental studies on multi-modal sensors, human activity recognition, and
healthcare datasets show a general improvement in different downstream tasks,
highlighting the effectiveness of our method in real-world scenarios.",http://arxiv.org/pdf/2405.16083v1,
The Scaling Law in Stellar Light Curves,27/05/2024,"Jia-Shu Pan, Yuan-Sen Ting, Yang Huang, Jie Yu, Ji-Feng Liu","Analyzing time series of fluxes from stars, known as stellar light curves,
can reveal valuable information about stellar properties. However, most current
methods rely on extracting summary statistics, and studies using deep learning
have been limited to supervised approaches. In this research, we investigate
the scaling law properties that emerge when learning from astronomical time
series data using self-supervised techniques. By employing the GPT-2
architecture, we show the learned representation improves as the number of
parameters increases from $10^4$ to $10^9$, with no signs of performance
plateauing. We demonstrate that a self-supervised Transformer model achieves
3-10 times the sample efficiency compared to the state-of-the-art supervised
learning model when inferring the surface gravity of stars as a downstream
task. Our research lays the groundwork for analyzing stellar light curves by
examining them through large-scale auto-regressive generative models.",http://arxiv.org/pdf/2405.17156v2,
Pretrained Mobility Transformer: A Foundation Model for Human Mobility,29/05/2024,"Xinhua Wu, Haoyu He, Yanchao Wang, Qi Wang","Ubiquitous mobile devices are generating vast amounts of location-based
service data that reveal how individuals navigate and utilize urban spaces in
detail. In this study, we utilize these extensive, unlabeled sequences of user
trajectories to develop a foundation model for understanding urban space and
human mobility. We introduce the \textbf{P}retrained \textbf{M}obility
\textbf{T}ransformer (PMT), which leverages the transformer architecture to
process user trajectories in an autoregressive manner, converting geographical
areas into tokens and embedding spatial and temporal information within these
representations. Experiments conducted in three U.S. metropolitan areas over a
two-month period demonstrate PMT's ability to capture underlying geographic and
socio-demographic characteristics of regions. The proposed PMT excels across
various downstream tasks, including next-location prediction, trajectory
imputation, and trajectory generation. These results support PMT's capability
and effectiveness in decoding complex patterns of human mobility, offering new
insights into urban spatial functionality and individual mobility preferences.",http://arxiv.org/pdf/2406.02578v1,
Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation,29/05/2024,"Zhiqiang Cai, Yu Cao, Yuanfei Huang, Xiang Zhou","Sampling invariant distributions from an Ito diffusion process presents a
significant challenge in stochastic simulation. Traditional numerical solvers
for stochastic differential equations require both a fine step size and a
lengthy simulation period, resulting in both biased and correlated samples.
Current deep learning-based method solves the stationary Fokker--Planck
equation to determine the invariant probability density function in form of
deep neural networks, but they generally do not directly address the problem of
sampling from the computed density function. In this work, we introduce a
framework that employs a weak generative sampler (WGS) to directly generate
independent and identically distributed (iid) samples induced by a
transformation map derived from the stationary Fokker--Planck equation. Our
proposed loss function is based on the weak form of the Fokker--Planck
equation, integrating normalizing flows to characterize the invariant
distribution and facilitate sample generation from the base distribution. Our
randomized test function circumvents the need for mini-max optimization in the
traditional weak formulation. Distinct from conventional generative models, our
method neither necessitates the computationally intensive calculation of the
Jacobian determinant nor the invertibility of the transformation map. A crucial
component of our framework is the adaptively chosen family of test functions in
the form of Gaussian kernel functions with centres selected from the generated
data samples. Experimental results on several benchmark examples demonstrate
the effectiveness of our method, which offers both low computational costs and
excellent capability in exploring multiple metastable states.",http://arxiv.org/pdf/2405.19256v1,
System-2 Recommenders: Disentangling Utility and Engagement in Recommendation Systems via Temporal Point-Processes,29/05/2024,"Arpit Agarwal, Nicolas Usunier, Alessandro Lazaric, Maximilian Nickel","Recommender systems are an important part of the modern human experience
whose influence ranges from the food we eat to the news we read. Yet, there is
still debate as to what extent recommendation platforms are aligned with the
user goals. A core issue fueling this debate is the challenge of inferring a
user utility based on engagement signals such as likes, shares, watch time
etc., which are the primary metric used by platforms to optimize content. This
is because users utility-driven decision-processes (which we refer to as
System-2), e.g., reading news that are relevant for them, are often confounded
by their impulsive decision-processes (which we refer to as System-1), e.g.,
spend time on click-bait news. As a result, it is difficult to infer whether an
observed engagement is utility-driven or impulse-driven. In this paper we
explore a new approach to recommender systems where we infer user utility based
on their return probability to the platform rather than engagement signals. Our
intuition is that users tend to return to a platform in the long run if it
creates utility for them, while pure engagement-driven interactions that do not
add utility, may affect user return in the short term but will not have a
lasting effect. We propose a generative model in which past content
interactions impact the arrival rates of users based on a self-exciting Hawkes
process. These arrival rates to the platform are a combination of both System-1
and System-2 decision processes. The System-2 arrival intensity depends on the
utility and has a long lasting effect, while the System-1 intensity depends on
the instantaneous gratification and tends to vanish rapidly. We show
analytically that given samples it is possible to disentangle System-1 and
System-2 and allow content optimization based on user utility. We conduct
experiments on synthetic data to demonstrate the effectiveness of our approach.",http://arxiv.org/pdf/2406.01611v1,
OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving,30/05/2024,"Lening Wang, Wenzhao Zheng, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jiwen Lu","Understanding the evolution of 3D scenes is important for effective
autonomous driving. While conventional methods mode scene development with the
motion of individual instances, world models emerge as a generative framework
to describe the general scene dynamics. However, most existing methods adopt an
autoregressive framework to perform next-token prediction, which suffer from
inefficiency in modeling long-term temporal evolutions. To address this, we
propose a diffusion-based 4D occupancy generation model, OccSora, to simulate
the development of the 3D world for autonomous driving. We employ a 4D scene
tokenizer to obtain compact discrete spatial-temporal representations for 4D
occupancy input and achieve high-quality reconstruction for long-sequence
occupancy videos. We then learn a diffusion transformer on the spatial-temporal
representations and generate 4D occupancy conditioned on a trajectory prompt.
We conduct extensive experiments on the widely used nuScenes dataset with Occ3D
occupancy annotations. OccSora can generate 16s-videos with authentic 3D layout
and temporal consistency, demonstrating its ability to understand the spatial
and temporal distributions of driving scenes. With trajectory-aware 4D
generation, OccSora has the potential to serve as a world simulator for the
decision-making of autonomous driving. Code is available at:
https://github.com/wzzheng/OccSora.",http://arxiv.org/pdf/2405.20337v1,
Stochastic Optimal Control for Diffusion Bridges in Function Spaces,31/05/2024,"Byoungwoo Park, Jungwon Choi, Sungbin Lim, Juho Lee","Recent advancements in diffusion models and diffusion bridges primarily focus
on finite-dimensional spaces, yet many real-world problems necessitate
operations in infinite-dimensional function spaces for more natural and
interpretable formulations. In this paper, we present a theory of stochastic
optimal control (SOC) tailored to infinite-dimensional spaces, aiming to extend
diffusion-based algorithms to function spaces. Specifically, we demonstrate how
Doob's $h$-transform, the fundamental tool for constructing diffusion bridges,
can be derived from the SOC perspective and expanded to infinite dimensions.
This expansion presents a challenge, as infinite-dimensional spaces typically
lack closed-form densities. Leveraging our theory, we establish that solving
the optimal control problem with a specific objective function choice is
equivalent to learning diffusion-based generative models. We propose two
applications: (1) learning bridges between two infinite-dimensional
distributions and (2) generative models for sampling from an
infinite-dimensional distribution. Our approach proves effective for diverse
problems involving continuous function space representations, such as
resolution-free images, time-series data, and probability density functions.",http://arxiv.org/pdf/2405.20630v4,
Rough Transformers: Lightweight Continuous-Time Sequence Modelling with Path Signatures,31/05/2024,"Fernando Moreno-Pino, Álvaro Arroyo, Harrison Waldon, Xiaowen Dong, Álvaro Cartea","Time-series data in real-world settings typically exhibit long-range
dependencies and are observed at non-uniform intervals. In these settings,
traditional sequence-based recurrent models struggle. To overcome this,
researchers often replace recurrent architectures with Neural ODE-based models
to account for irregularly sampled data and use Transformer-based architectures
to account for long-range dependencies. Despite the success of these two
approaches, both incur very high computational costs for input sequences of
even moderate length. To address this challenge, we introduce the Rough
Transformer, a variation of the Transformer model that operates on
continuous-time representations of input sequences and incurs significantly
lower computational costs. In particular, we propose multi-view signature
attention, which uses path signatures to augment vanilla attention and to
capture both local and global (multi-scale) dependencies in the input data,
while remaining robust to changes in the sequence length and sampling frequency
and yielding improved spatial processing. We find that, on a variety of
time-series-related tasks, Rough Transformers consistently outperform their
vanilla attention counterparts while obtaining the representational benefits of
Neural ODE-based models, all at a fraction of the computational time and memory
resources.",http://arxiv.org/pdf/2405.20799v2,
Representation and De-interleaving of Mixtures of Hidden Markov Processes,01/06/2024,"Jiadi Bao, Mengtao Zhu, Yunjie Li, Shafei Wang","De-interleaving of the mixtures of Hidden Markov Processes (HMPs) generally
depends on its representation model. Existing representation models consider
Markov chain mixtures rather than hidden Markov, resulting in the lack of
robustness to non-ideal situations such as observation noise or missing
observations. Besides, de-interleaving methods utilize a search-based strategy,
which is time-consuming. To address these issues, this paper proposes a novel
representation model and corresponding de-interleaving methods for the mixtures
of HMPs. At first, a generative model for representing the mixtures of HMPs is
designed. Subsequently, the de-interleaving process is formulated as a
posterior inference for the generative model. Secondly, an exact inference
method is developed to maximize the likelihood of the complete data, and two
approximate inference methods are developed to maximize the evidence lower
bound by creating tractable structures. Then, a theoretical error probability
lower bound is derived using the likelihood ratio test, and the algorithms are
shown to get reasonably close to the bound. Finally, simulation results
demonstrate that the proposed methods are highly effective and robust for
non-ideal situations, outperforming baseline methods on simulated and real-life
data.",http://arxiv.org/pdf/2406.00416v1,
Learning to Approximate Particle Smoothing Trajectories via Diffusion Generative Models,01/06/2024,"Ella Tamir, Arno Solin","Learning dynamical systems from sparse observations is critical in numerous
fields, including biology, finance, and physics. Even if tackling such problems
is standard in general information fusion, it remains challenging for
contemporary machine learning models, such as diffusion models. We introduce a
method that integrates conditional particle filtering with ancestral sampling
and diffusion models, enabling the generation of realistic trajectories that
align with observed data. Our approach uses a smoother based on iterating a
conditional particle filter with ancestral sampling to first generate plausible
trajectories matching observed marginals, and learns the corresponding
diffusion model. This approach provides both a generative method for
high-quality, smoothed trajectories under complex constraints, and an efficient
approximation of the particle smoothing distribution for classical tracking
problems. We demonstrate the approach in time-series generation and
interpolation tasks, including vehicle tracking and single-cell RNA sequencing
data.",http://arxiv.org/pdf/2406.00561v1,
State Space Models on Temporal Graphs: A First-Principles Study,03/06/2024,"Jintang Li, Ruofan Wu, Xinzhou Jin, Boqun Ma, Liang Chen, Zibin Zheng","Over the past few years, research on deep graph learning has shifted from
static graphs to temporal graphs in response to real-world complex systems that
exhibit dynamic behaviors. In practice, temporal graphs are formalized as an
ordered sequence of static graph snapshots observed at discrete time points.
Sequence models such as RNNs or Transformers have long been the predominant
backbone networks for modeling such temporal graphs. Yet, despite the promising
results, RNNs struggle with long-range dependencies, while transformers are
burdened by quadratic computational complexity. Recently, state space models
(SSMs), which are framed as discretized representations of an underlying
continuous-time linear dynamical system, have garnered substantial attention
and achieved breakthrough advancements in independent sequence modeling. In
this work, we undertake a principled investigation that extends SSM theory to
temporal graphs by integrating structural information into the online
approximation objective via the adoption of a Laplacian regularization term.
The emergent continuous-time system introduces novel algorithmic challenges,
thereby necessitating our development of GraphSSM, a graph state space model
for modeling the dynamics of temporal graphs. Extensive experimental results
demonstrate the effectiveness of our GraphSSM framework across various temporal
graph benchmarks.",http://arxiv.org/pdf/2406.00943v2,
A Survey of Transformer Enabled Time Series Synthesis,04/06/2024,"Alexander Sommers, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure, Thomas Arnold","Generative AI has received much attention in the image and language domains,
with the transformer neural network continuing to dominate the state of the
art. Application of these models to time series generation is less explored,
however, and is of great utility to machine learning, privacy preservation, and
explainability research. The present survey identifies this gap at the
intersection of the transformer, generative AI, and time series data, and
reviews works in this sparsely populated subdomain. The reviewed works show
great variety in approach, and have not yet converged on a conclusive answer to
the problems the domain poses. GANs, diffusion models, state space models, and
autoencoders were all encountered alongside or surrounding the transformers
which originally motivated the survey. While too open a domain to offer
conclusive insights, the works surveyed are quite suggestive, and several
recommendations for best practice, and suggestions of valuable future work, are
provided.",http://arxiv.org/pdf/2406.02322v1,
"Dynamical mixture modeling with fast, automatic determination of Markov chains",07/06/2024,"Christopher E. Miles, Robert J. Webber","Markov state modeling has gained popularity in various scientific fields due
to its ability to reduce complex time series data into transitions between a
few states. Yet, current frameworks are limited by assuming a single Markov
chain describes the data, and they suffer an inability to discern
heterogeneities. As a solution, this paper proposes a variational
expectation-maximization algorithm that identifies a mixture of Markov chains
in a time-series data set. The method is agnostic to the definition of the
Markov states, whether data-driven (e.g. by spectral clustering) or based on
domain knowledge. Variational EM efficiently and organically identifies the
number of Markov chains and dynamics of each chain without expensive model
comparisons or posterior sampling. The approach is supported by a theoretical
analysis and numerical experiments, including simulated and observational data
sets based on ${\tt Last.fm}$ music listening, ultramarathon running, and gene
expression. The results show the new algorithm is competitive with contemporary
mixture modeling approaches and powerful in identifying meaningful
heterogeneities in time series data.",http://arxiv.org/pdf/2406.04653v1,
Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction,07/06/2024,"Christoph Jürgen Hemmer, Manuel Brenner, Florian Hess, Daniel Durstewitz","In dynamical systems reconstruction (DSR) we seek to infer from time series
measurements a generative model of the underlying dynamical process. This is a
prime objective in any scientific discipline, where we are particularly
interested in parsimonious models with a low parameter load. A common strategy
here is parameter pruning, removing all parameters with small weights. However,
here we find this strategy does not work for DSR, where even low magnitude
parameters can contribute considerably to the system dynamics. On the other
hand, it is well known that many natural systems which generate complex
dynamics, like the brain or ecological networks, have a sparse topology with
comparatively few links. Inspired by this, we show that geometric pruning,
where in contrast to magnitude-based pruning weights with a low contribution to
an attractor's geometrical structure are removed, indeed manages to reduce
parameter load substantially without significantly hampering DSR quality. We
further find that the networks resulting from geometric pruning have a specific
type of topology, and that this topology, and not the magnitude of weights, is
what is most crucial to performance. We provide an algorithm that automatically
generates such topologies which can be used as priors for generative modeling
of dynamical systems by RNNs, and compare it to other well studied topologies
like small-world or scale-free networks.",http://arxiv.org/pdf/2406.04934v1,
A Tensor Decomposition Perspective on Second-order RNNs,07/06/2024,"Maude Lizaire, Michael Rizvi-Martel, Marawan Gamal Abdel Hameed, Guillaume Rabusseau","Second-order Recurrent Neural Networks (2RNNs) extend RNNs by leveraging
second-order interactions for sequence modelling. These models are provably
more expressive than their first-order counterparts and have connections to
well-studied models from formal language theory. However, their large parameter
tensor makes computations intractable. To circumvent this issue, one approach
known as MIRNN consists in limiting the type of interactions used by the model.
Another is to leverage tensor decomposition to diminish the parameter count. In
this work, we study the model resulting from parameterizing 2RNNs using the CP
decomposition, which we call CPRNN. Intuitively, the rank of the decomposition
should reduce expressivity. We analyze how rank and hidden size affect model
capacity and show the relationships between RNNs, 2RNNs, MIRNNs, and CPRNNs
based on these parameters. We support these results empirically with
experiments on the Penn Treebank dataset which demonstrate that, with a fixed
parameter budget, CPRNNs outperforms RNNs, 2RNNs, and MIRNNs with the right
choice of rank and hidden size.",http://arxiv.org/pdf/2406.05045v1,
Novel Approach to Intrusion Detection: Introducing GAN-MSCNN-BILSTM with LIME Predictions,08/06/2024,"Asmaa Benchama, Khalid Zebbara","This paper introduces an innovative intrusion detection system that harnesses
Generative Adversarial Networks (GANs), Multi-Scale Convolutional Neural
Networks (MSCNNs), and Bidirectional Long Short-Term Memory (BiLSTM) networks,
supplemented by Local Interpretable Model-Agnostic Explanations (LIME) for
interpretability. Employing a GAN, the system generates realistic network
traffic data, encompassing both normal and attack patterns. This synthesized
data is then fed into an MSCNN-BiLSTM architecture for intrusion detection. The
MSCNN layer extracts features from the network traffic data at different
scales, while the BiLSTM layer captures temporal dependencies within the
traffic sequences. Integration of LIME allows for explaining the model's
decisions. Evaluation on the Hogzilla dataset, a standard benchmark, showcases
an impressive accuracy of 99.16\% for multi-class classification and 99.10\%
for binary classification, while ensuring interpretability through LIME. This
fusion of deep learning and interpretability presents a promising avenue for
enhancing intrusion detection systems by improving transparency and decision
support in network security.",http://arxiv.org/pdf/2406.05443v1,10.56294/dm2023202
Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations,10/06/2024,"Yujee Song, Donghyun Lee, Rui Meng, Won Hwa Kim","A Marked Temporal Point Process (MTPP) is a stochastic process whose
realization is a set of event-time data. MTPP is often used to understand
complex dynamics of asynchronous temporal events such as money transaction,
social media, healthcare, etc. Recent studies have utilized deep neural
networks to capture complex temporal dependencies of events and generate
embedding that aptly represent the observed events. While most previous studies
focus on the inter-event dependencies and their representations, how individual
events influence the overall dynamics over time has been under-explored. In
this regime, we propose a Decoupled MTPP framework that disentangles
characterization of a stochastic process into a set of evolving influences from
different events. Our approach employs Neural Ordinary Differential Equations
(Neural ODEs) to learn flexible continuous dynamics of these influences while
simultaneously addressing multiple inference problems, such as density
estimation and survival rate computation. We emphasize the significance of
disentangling the influences by comparing our framework with state-of-the-art
methods on real-life datasets, and provide analysis on the model behavior for
potential applications.",http://arxiv.org/pdf/2406.06149v1,
Universal randomised signatures for generative time series modelling,14/06/2024,"Francesca Biagini, Lukas Gonon, Niklas Walter","Randomised signature has been proposed as a flexible and easily implementable
alternative to the well-established path signature. In this article, we employ
randomised signature to introduce a generative model for financial time series
data in the spirit of reservoir computing. Specifically, we propose a novel
Wasserstein-type distance based on discrete-time randomised signatures. This
metric on the space of probability measures captures the distance between
(conditional) distributions. Its use is justified by our novel universal
approximation results for randomised signatures on the space of continuous
functions taking the underlying path as an input. We then use our metric as the
loss function in a non-adversarial generator model for synthetic time series
data based on a reservoir neural stochastic differential equation. We compare
the results of our model to benchmarks from the existing literature.",http://arxiv.org/pdf/2406.10214v2,
SigDiffusions: Score-Based Diffusion Models for Long Time Series via Log-Signature Embeddings,14/06/2024,"Barbora Barancikova, Zhuoyue Huang, Cristopher Salvi","Score-based diffusion models have recently emerged as state-of-the-art
generative models for a variety of data modalities. Nonetheless, it remains
unclear how to adapt these models to generate long multivariate time series.
Viewing a time series as the discretization of an underlying continuous
process, we introduce SigDiffusion, a novel diffusion model operating on
log-signature embeddings of the data. The forward and backward processes
gradually perturb and denoise log-signatures preserving their algebraic
structure. To recover a signal from its log-signature, we provide new
closed-form inversion formulae expressing the coefficients obtained by
expanding the signal in a given basis (e.g. Fourier or orthogonal polynomials)
as explicit polynomial functions of the log-signature. Finally, we show that
combining SigDiffusion with these inversion formulae results in highly
realistic time series generation, competitive with the current state-of-the-art
on various datasets of synthetic and real-world examples.",http://arxiv.org/pdf/2406.10354v1,
Unfolding Time: Generative Modeling for Turbulent Flows in 4D,17/06/2024,"Abdullah Saydemir, Marten Lienen, Stephan Günnemann","A recent study in turbulent flow simulation demonstrated the potential of
generative diffusion models for fast 3D surrogate modeling. This approach
eliminates the need for specifying initial states or performing lengthy
simulations, significantly accelerating the process. While adept at sampling
individual frames from the learned manifold of turbulent flow states, the
previous model lacks the capability to generate sequences, hindering analysis
of dynamic phenomena. This work addresses this limitation by introducing a 4D
generative diffusion model and a physics-informed guidance technique that
enables the generation of realistic sequences of flow states. Our findings
indicate that the proposed method can successfully sample entire subsequences
from the turbulent manifold, even though generalizing from individual frames to
sequences remains a challenging task. This advancement opens doors for the
application of generative modeling in analyzing the temporal evolution of
turbulent flows, providing valuable insights into their complex dynamics.",http://arxiv.org/pdf/2406.11390v2,
Delay Embedding Theory of Neural Sequence Models,17/06/2024,"Mitchell Ostrow, Adam Eisen, Ila Fiete","To generate coherent responses, language models infer unobserved meaning from
their input text sequence. One potential explanation for this capability arises
from theories of delay embeddings in dynamical systems, which prove that
unobserved variables can be recovered from the history of only a handful of
observed variables. To test whether language models are effectively
constructing delay embeddings, we measure the capacities of sequence models to
reconstruct unobserved dynamics. We trained 1-layer transformer decoders and
state-space sequence models on next-step prediction from noisy,
partially-observed time series data. We found that each sequence layer can
learn a viable embedding of the underlying system. However, state-space models
have a stronger inductive bias than transformers-in particular, they more
effectively reconstruct unobserved information at initialization, leading to
more parameter-efficient models and lower error on dynamics tasks. Our work
thus forges a novel connection between dynamical systems and deep learning
sequence models via delay embedding theory.",http://arxiv.org/pdf/2406.11993v1,
ChatEMG: Synthetic Data Generation to Control a Robotic Hand Orthosis for Stroke,17/06/2024,"Jingxi Xu, Runsheng Wang, Siqi Shang, Ava Chen, Lauren Winterbottom, To-Liang Hsu, Wenxi Chen, Khondoker Ahmed, Pedro Leandro La Rotta, Xinyue Zhu, Dawn M. Nilsen, Joel Stein, Matei Ciocarlie","Intent inferral on a hand orthosis for stroke patients is challenging due to
the difficulty of data collection. Additionally, EMG signals exhibit
significant variations across different conditions, sessions, and subjects,
making it hard for classifiers to generalize. Traditional approaches require a
large labeled dataset from the new condition, session, or subject to train
intent classifiers; however, this data collection process is burdensome and
time-consuming. In this paper, we propose ChatEMG, an autoregressive generative
model that can generate synthetic EMG signals conditioned on prompts (i.e., a
given sequence of EMG signals). ChatEMG enables us to collect only a small
dataset from the new condition, session, or subject and expand it with
synthetic samples conditioned on prompts from this new context. ChatEMG
leverages a vast repository of previous data via generative training while
still remaining context-specific via prompting. Our experiments show that these
synthetic samples are classifier-agnostic and can improve intent inferral
accuracy for different types of classifiers. We demonstrate that our complete
approach can be integrated into a single patient session, including the use of
the classifier for functional orthosis-assisted tasks. To the best of our
knowledge, this is the first time an intent classifier trained partially on
synthetic data has been deployed for functional control of an orthosis by a
stroke survivor. Videos, source code, and additional information can be found
at https://jxu.ai/chatemg.",http://arxiv.org/pdf/2406.12123v2,
Deep Temporal Deaggregation: Large-Scale Spatio-Temporal Generative Models,18/06/2024,"David Bergström, Mattias Tiger, Fredrik Heintz","Many of today's data is time-series data originating from various sources,
such as sensors, transaction systems, or production systems. Major challenges
with such data include privacy and business sensitivity. Generative time-series
models have the potential to overcome these problems, allowing representative
synthetic data, such as people's movement in cities, to be shared openly and be
used to the benefit of society at large. However, contemporary approaches are
limited to prohibitively short sequences and small scales. Aside from major
memory limitations, the models generate less accurate and less representative
samples the longer the sequences are. This issue is further exacerbated by the
lack of a comprehensive and accessible benchmark. Furthermore, a common need in
practical applications is what-if analysis and dynamic adaptation to data
distribution changes, for usage in decision making and to manage a changing
world: What if this road is temporarily blocked or another road is added? The
focus of this paper is on mobility data, such as people's movement in cities,
requiring all these issues to be addressed. To this end, we propose a
transformer-based diffusion model, TDDPM, for time-series which outperforms and
scales substantially better than state-of-the-art. This is evaluated in a new
comprehensive benchmark across several sequence lengths, standard datasets, and
evaluation measures. We also demonstrate how the model can be conditioned on a
prior over spatial occupancy frequency information, allowing the model to
generate mobility data for previously unseen environments and for hypothetical
scenarios where the underlying road network and its usage changes. This is
evaluated by training on mobility data from part of a city. Then, using only
aggregate spatial information as prior, we demonstrate out-of-distribution
generalization to the unobserved remainder of the city.",http://arxiv.org/pdf/2406.12423v1,
Generative Data Assimilation of Sparse Weather Station Observations at Kilometer Scales,19/06/2024,"Peter Manshausen, Yair Cohen, Jaideep Pathak, Mike Pritchard, Piyush Garg, Morteza Mardani, Karthik Kashinath, Simon Byrne, Noah Brenowitz","Data assimilation of observational data into full atmospheric states is
essential for weather forecast model initialization. Recently, methods for deep
generative data assimilation have been proposed which allow for using new input
data without retraining the model. They could also dramatically accelerate the
costly data assimilation process used in operational regional weather models.
Here, in a central US testbed, we demonstrate the viability of score-based data
assimilation in the context of realistically complex km-scale weather. We train
an unconditional diffusion model to generate snapshots of a state-of-the-art
km-scale analysis product, the High Resolution Rapid Refresh. Then, using
score-based data assimilation to incorporate sparse weather station data, the
model produces maps of precipitation and surface winds. The generated fields
display physically plausible structures, such as gust fronts, and sensitivity
tests confirm learnt physics through multivariate relationships. Preliminary
skill analysis shows the approach already outperforms a naive baseline of the
High-Resolution Rapid Refresh system itself. By incorporating observations from
40 weather stations, 10% lower RMSEs on left-out stations are attained. Despite
some lingering imperfections such as insufficiently disperse ensemble DA
estimates, we find the results overall an encouraging proof of concept, and the
first at km-scale. It is a ripe time to explore extensions that combine
increasingly ambitious regional state generators with an increasing set of in
situ, ground-based, and satellite remote sensing data streams.",http://arxiv.org/pdf/2406.16947v2,
Probabilistic Emulation of a Global Climate Model with Spherical DYffusion,21/06/2024,"Salva Rühling Cachay, Brian Henn, Oliver Watt-Meyer, Christopher S. Bretherton, Rose Yu","Data-driven deep learning models are transforming global weather forecasting.
It is an open question if this success can extend to climate modeling, where
the complexity of the data and long inference rollouts pose significant
challenges. Here, we present the first conditional generative model that
produces accurate and physically consistent global climate ensemble simulations
by emulating a coarse version of the United States' primary operational global
forecast model, FV3GFS. Our model integrates the dynamics-informed diffusion
framework (DYffusion) with the Spherical Fourier Neural Operator (SFNO)
architecture, enabling stable 100-year simulations at 6-hourly timesteps while
maintaining low computational overhead compared to single-step deterministic
baselines. The model achieves near gold-standard performance for climate model
emulation, outperforming existing approaches and demonstrating promising
ensemble skill. This work represents a significant advance towards efficient,
data-driven climate simulations that can enhance our understanding of the
climate system and inform adaptation strategies.",http://arxiv.org/pdf/2406.14798v2,
Continual Learning with Diffusion-based Generative Replay for Industrial Streaming Data,22/06/2024,"Jiayi He, Jiao Chen, Qianmiao Liu, Suyan Dai, Jianhua Tang, Dongpo Liu","The Industrial Internet of Things (IIoT) integrates interconnected sensors
and devices to support industrial applications, but its dynamic environments
pose challenges related to data drift. Considering the limited resources and
the need to effectively adapt models to new data distributions, this paper
introduces a Continual Learning (CL) approach, i.e., Distillation-based
Self-Guidance (DSG), to address challenges presented by industrial streaming
data via a novel generative replay mechanism. DSG utilizes knowledge
distillation to transfer knowledge from the previous diffusion-based generator
to the updated one, improving both the stability of the generator and the
quality of reproduced data, thereby enhancing the mitigation of catastrophic
forgetting. Experimental results on CWRU, DSA, and WISDM datasets demonstrate
the effectiveness of DSG. DSG outperforms the state-of-the-art baseline in
accuracy, demonstrating improvements ranging from 2.9% to 5.0% on key datasets,
showcasing its potential for practical industrial applications.",http://arxiv.org/pdf/2406.15766v1,
TimeAutoDiff: Combining Autoencoder and Diffusion model for time series tabular data synthesizing,23/06/2024,"Namjoon Suh, Yuning Yang, Din-Yin Hsieh, Qitong Luan, Shirong Xu, Shixiang Zhu, Guang Cheng","In this paper, we leverage the power of latent diffusion models to generate
synthetic time series tabular data. Along with the temporal and feature
correlations, the heterogeneous nature of the feature in the table has been one
of the main obstacles in time series tabular data modeling. We tackle this
problem by combining the ideas of the variational auto-encoder (VAE) and the
denoising diffusion probabilistic model (DDPM). Our model named as
\texttt{TimeAutoDiff} has several key advantages including (1) Generality: the
ability to handle the broad spectrum of time series tabular data from single to
multi-sequence datasets; (2) Good fidelity and utility guarantees: numerical
experiments on six publicly available datasets demonstrating significant
improvements over state-of-the-art models in generating time series tabular
data, across four metrics measuring fidelity and utility; (3) Fast sampling
speed: entire time series data generation as opposed to the sequential data
sampling schemes implemented in the existing diffusion-based models, eventually
leading to significant improvements in sampling speed, (4) Entity conditional
generation: the first implementation of conditional generation of
multi-sequence time series tabular data with heterogenous features in the
literature, enabling scenario exploration across multiple scientific and
engineering domains. Codes are in preparation for release to the public, but
available upon request.",http://arxiv.org/pdf/2406.16028v2,
Inferring stochastic low-rank recurrent neural networks from neural data,24/06/2024,"Matthijs Pals, A Erdem Sağtekin, Felix Pei, Manuel Gloeckler, Jakob H Macke","A central aim in computational neuroscience is to relate the activity of
large populations of neurons to an underlying dynamical system. Models of these
neural dynamics should ideally be both interpretable and fit the observed data
well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability
by having tractable dynamics. However, it is unclear how to best fit low-rank
RNNs to data consisting of noisy observations of an underlying stochastic
system. Here, we propose to fit stochastic low-rank RNNs with variational
sequential Monte Carlo methods. We validate our method on several datasets
consisting of both continuous and spiking neural data, where we obtain lower
dimensional latent dynamics than current state of the art methods.
Additionally, for low-rank models with piecewise linear nonlinearities, we show
how to efficiently identify all fixed points in polynomial rather than
exponential cost in the number of units, making analysis of the inferred
dynamics tractable for large RNNs. Our method both elucidates the dynamical
systems underlying experimental recordings and provides a generative model
whose trajectories match observed variability.",http://arxiv.org/pdf/2406.16749v3,
BrainMAE: A Region-aware Self-supervised Learning Framework for Brain Signals,24/06/2024,"Yifan Yang, Yutong Mao, Xufu Liu, Xiao Liu","The human brain is a complex, dynamic network, which is commonly studied
using functional magnetic resonance imaging (fMRI) and modeled as network of
Regions of interest (ROIs) for understanding various brain functions. Recent
studies utilize deep learning approaches to learn the brain network
representation based on functional connectivity (FC) profile, broadly falling
into two main categories. The Fixed-FC approaches, utilizing the FC profile
which represents the linear temporal relation within the brain network, are
limited by failing to capture informative brain temporal dynamics. On the other
hand, the Dynamic-FC approaches, modeling the evolving FC profile over time,
often exhibit less satisfactory performance due to challenges in handling the
inherent noisy nature of fMRI data.
  To address these challenges, we propose Brain Masked Auto-Encoder (BrainMAE)
for learning representations directly from fMRI time-series data. Our approach
incorporates two essential components: a region-aware graph attention mechanism
designed to capture the relationships between different brain ROIs, and a novel
self-supervised masked autoencoding framework for effective model pre-training.
These components enable the model to capture rich temporal dynamics of brain
activity while maintaining resilience to inherent noise in fMRI data. Our
experiments demonstrate that BrainMAE consistently outperforms established
baseline methods by significant margins in four distinct downstream tasks.
Finally, leveraging the model's inherent interpretability, our analysis of
model-generated representations reveals findings that resonate with ongoing
research in the field of neuroscience.",http://arxiv.org/pdf/2406.17086v1,
A Matrix Product State Model for Simultaneous Classification and Generation,25/06/2024,"Alex Mossi, Bojan Žunkovic, Kyriakos Flouris","Quantum machine learning (QML) is a rapidly expanding field that merges the
principles of quantum computing with the techniques of machine learning. One of
the powerful mathematical frameworks in this domain is tensor networks. These
networks are used to approximate high-order tensors by contracting tensors with
lower ranks. Originally developed for simulating quantum systems, tensor
networks have become integral to quantum computing and, by extension, to QML.
Their ability to efficiently represent and manipulate complex, high-dimensional
data makes them suitable for various machine learning tasks within the quantum
realm. Here, we present a matrix product state (MPS) model, where the MPS
functions as both a classifier and a generator. The dual functionality of this
novel MPS model permits a strategy that enhances the traditional training of
supervised MPS models. This framework is inspired by generative adversarial
networks and is geared towards generating more realistic samples by reducing
outliers. Additionally, our contributions offer insights into the mechanics of
tensor network methods for generation tasks. Specifically, we discuss
alternative embedding functions and a new sampling method from non-normalized
MPSs.",http://arxiv.org/pdf/2406.17441v1,
Sequential Disentanglement by Extracting Static Information From A Single Sequence Element,26/06/2024,"Nimrod Berman, Ilan Naiman, Idan Arbiv, Gal Fadlon, Omri Azencot","One of the fundamental representation learning tasks is unsupervised
sequential disentanglement, where latent codes of inputs are decomposed to a
single static factor and a sequence of dynamic factors. To extract this latent
information, existing methods condition the static and dynamic codes on the
entire input sequence. Unfortunately, these models often suffer from
information leakage, i.e., the dynamic vectors encode both static and dynamic
information, or vice versa, leading to a non-disentangled representation.
Attempts to alleviate this problem via reducing the dynamic dimension and
auxiliary loss terms gain only partial success. Instead, we propose a novel and
simple architecture that mitigates information leakage by offering a simple and
effective subtraction inductive bias while conditioning on a single sample.
Remarkably, the resulting variational framework is simpler in terms of required
loss terms, hyperparameters, and data augmentation. We evaluate our method on
multiple data-modality benchmarks including general time series, video, and
audio, and we show beyond state-of-the-art results on generation and prediction
tasks in comparison to several strong baselines.",http://arxiv.org/pdf/2406.18131v1,
Latent Diffusion for Neural Spiking Data,27/06/2024,"Jaivardhan Kapoor, Auguste Schulz, Julius Vetter, Felix Pei, Richard Gao, Jakob H. Macke","Modern datasets in neuroscience enable unprecedented inquiries into the
relationship between complex behaviors and the activity of many simultaneously
recorded neurons. While latent variable models can successfully extract
low-dimensional embeddings from such recordings, using them to generate
realistic spiking data, especially in a behavior-dependent manner, still poses
a challenge. Here, we present Latent Diffusion for Neural Spiking data (LDNS),
a diffusion-based generative model with a low-dimensional latent space: LDNS
employs an autoencoder with structured state-space (S4) layers to project
discrete high-dimensional spiking data into continuous time-aligned latents. On
these inferred latents, we train expressive (conditional) diffusion models,
enabling us to sample neural activity with realistic single-neuron and
population spiking statistics. We validate LDNS on synthetic data, accurately
recovering latent structure, firing rates, and spiking statistics. Next, we
demonstrate its flexibility by generating variable-length data that mimics
human cortical activity during attempted speech. We show how to equip LDNS with
an expressive observation model that accounts for single-neuron dynamics not
mediated by the latent state, further increasing the realism of generated
samples. Finally, conditional LDNS trained on motor cortical activity during
diverse reaching behaviors can generate realistic spiking data given reach
direction or unseen reach trajectories. In summary, LDNS simultaneously enables
inference of low-dimensional latents and realistic conditional generation of
neural spiking datasets, opening up further possibilities for simulating
experimentally testable hypotheses.",http://arxiv.org/pdf/2407.08751v2,
Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges,27/06/2024,"Mahmoud Ibrahim, Yasmina Al Khalil, Sina Amirrajab, Chang Sun, Marcel Breeuwer, Josien Pluim, Bart Elen, Gokhan Ertaylan, Michel Dumontier","This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.",http://arxiv.org/pdf/2407.00116v2,
Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion,01/07/2024,"Boyuan Chen, Diego Marti Monso, Yilun Du, Max Simchowitz, Russ Tedrake, Vincent Sitzmann","This paper presents Diffusion Forcing, a new training paradigm where a
diffusion model is trained to denoise a set of tokens with independent
per-token noise levels. We apply Diffusion Forcing to sequence generative
modeling by training a causal next-token prediction model to generate one or
several future tokens without fully diffusing past ones. Our approach is shown
to combine the strengths of next-token prediction models, such as
variable-length generation, with the strengths of full-sequence diffusion
models, such as the ability to guide sampling to desirable trajectories. Our
method offers a range of additional capabilities, such as (1) rolling-out
sequences of continuous tokens, such as video, with lengths past the training
horizon, where baselines diverge and (2) new sampling and guiding schemes that
uniquely profit from Diffusion Forcing's variable-horizon and causal
architecture, and which lead to marked performance gains in decision-making and
planning tasks. In addition to its empirical success, our method is proven to
optimize a variational lower bound on the likelihoods of all subsequences of
tokens drawn from the true joint distribution. Project website:
https://boyuan.space/diffusion-forcing",http://arxiv.org/pdf/2407.01392v4,
Latent Diffusion Model for Generating Ensembles of Climate Simulations,02/07/2024,"Johannes Meuer, Maximilian Witte, Tobias Sebastian Finn, Claudia Timmreck, Thomas Ludwig, Christopher Kadow","Obtaining accurate estimates of uncertainty in climate scenarios often
requires generating large ensembles of high-resolution climate simulations, a
computationally expensive and memory intensive process. To address this
challenge, we train a novel generative deep learning approach on extensive sets
of climate simulations. The model consists of two components: a variational
autoencoder for dimensionality reduction and a denoising diffusion
probabilistic model that generates multiple ensemble members. We validate our
model on the Max Planck Institute Grand Ensemble and show that it achieves good
agreement with the original ensemble in terms of variability. By leveraging the
latent space representation, our model can rapidly generate large ensembles
on-the-fly with minimal memory requirements, which can significantly improve
the efficiency of uncertainty quantification in climate simulations.",http://arxiv.org/pdf/2407.02070v2,
TimeLDM: Latent Diffusion Model for Unconditional Time Series Generation,05/07/2024,"Jian Qian, Bingyu Xie, Biao Wan, Minhao Li, Miao Sun, Patrick Yin Chiang","Time series generation is a crucial research topic in the area of
decision-making systems, which can be particularly important in domains like
autonomous driving, healthcare, and, notably, robotics. Recent approaches focus
on learning in the data space to model time series information. However, the
data space often contains limited observations and noisy features. In this
paper, we propose TimeLDM, a novel latent diffusion model for high-quality time
series generation. TimeLDM is composed of a variational autoencoder that
encodes time series into an informative and smoothed latent content and a
latent diffusion model operating in the latent space to generate latent
information. We evaluate the ability of our method to generate synthetic time
series with simulated and real-world datasets and benchmark the performance
against existing state-of-the-art methods. Qualitatively and quantitatively, we
find that the proposed TimeLDM persistently delivers high-quality generated
time series. For example, TimeLDM achieves new state-of-the-art results on the
simulated benchmarks and an average improvement of 55% in Discriminative score
with all benchmarks. Further studies demonstrate that our method yields more
robust outcomes across various lengths of time series data generation.
Especially, for the Context-FID score and Discriminative score, TimeLDM
realizes significant improvements of 80% and 50%, respectively. The code will
be released after publication.",http://arxiv.org/pdf/2407.04211v2,
High-Quality and Full Bandwidth Seismic Signal Synthesis using Operational GANs,06/07/2024,"Ozer Can Devecioglu, Serkan Kiranyaz, Zafer Yilmaz, Onur Avci, Moncef Gabbouj, Ertugrul Taciroglu","Vibration sensors are essential in acquiring seismic activity for an accurate
earthquake assessment. The state-of-the-art sensors can provide the best signal
quality and the highest bandwidth; however, their high cost usually hinders a
wide range of applicability and coverage, which is otherwise possible with
their basic and cheap counterparts. But, their poor quality and low bandwidth
can significantly degrade the signal fidelity and result in an imprecise
analysis. To address these drawbacks, in this study, we propose a novel,
high-quality, and full bandwidth seismic signal synthesis by transforming the
signal acquired from an inferior sensor. We employ 1D Operational Generative
Adversarial Networks (Op-GANs) with novel loss functions to achieve this.
Therefore, the study's key contributions include releasing a new dataset,
addressing operational constraints in seismic monitoring, and pioneering a
deep-learning transformation technique to create the first virtual seismic
sensor. The proposed method is extensively evaluated over the Simulated Ground
Motion (SimGM) benchmark dataset, and the results demonstrated that the
proposed approach significantly improves the quality and bandwidth of seismic
signals acquired from a variety of sensors, including a cheap seismic sensor,
the CSN-Phidgets, and the integrated accelerometers of an Android, and iOS
phone, to the same level as the state-of-the-art sensor (e.g.,
Kinemetrics-Episensor). The SimGM dataset, our results, and the optimized
PyTorch implementation of the proposed approach are publicly shared.",http://arxiv.org/pdf/2407.11040v1,
Synthetic Test Data Generation Using Recurrent Neural Networks: A Position Paper,07/07/2024,"Razieh Behjati, Erik Arisholm, Chao Tan, Margrethe M. Bedregal","Testing in production-like test environments is an essential part of quality
assurance processes in many industries. Provisioning of such test environments,
for information-intensive services, involves setting up databases that are
rich-enough to enable simulating a wide variety of user scenarios. While
production data is perhaps the gold-standard here, many organizations,
particularly within the public sectors, are not allowed to use production data
for testing purposes due to privacy concerns. The alternatives are to use
anonymized data, or synthetically generated data. In this paper, we elaborate
on these alternatives and compare them in an industrial context. Further we
focus on synthetic data generation and investigate the use of recurrent neural
networks for this purpose. In our preliminary experiments, we were able to
generate representative and highly accurate data using a recurrent neural
network. These results open new research questions that we discuss here, and
plan to investigate in our future research.",http://arxiv.org/pdf/2407.05410v1,10.1109/RAISE.2019.00012
Flow to Rare Events: An Application of Normalizing Flow in Temporal Importance Sampling for Automated Vehicle Validation,10/07/2024,"Yichun Ye, He Zhang, Ye Tian, Jian Sun, Karl Meinke","Automated Vehicle (AV) validation based on simulated testing requires
unbiased evaluation and high efficiency. One effective solution is to increase
the exposure to risky rare events while reweighting the probability measure.
However, characterizing the distribution of risky events is particularly
challenging due to the paucity of samples and the temporality of continuous
scenario variables. To solve it, we devise a method to represent, generate, and
reweight the distribution of risky rare events. We decompose the temporal
evolution of continuous variables into distribution components based on
conditional probability. By introducing the Risk Indicator Function, the
distribution of risky rare events is theoretically precipitated out of
naturalistic driving distribution. This targeted distribution is practically
generated via Normalizing Flow, which achieves exact and tractable probability
evaluation of intricate distribution. The rare event distribution is then
demonstrated as the advantageous Importance Sampling distribution. We also
promote the technique of temporal Importance Sampling. The combined method,
named as TrimFlow, is executed to estimate the collision rate of Car-following
scenarios as a tentative practice. The results showed that sampling background
vehicle maneuvers from rare event distribution could evolve testing scenarios
to hazardous states. TrimFlow reduced 86.1% of tests compared to generating
testing scenarios according to their exposure in the naturalistic driving
environment. In addition, the TrimFlow method is not limited to one specific
type of functional scenario.",http://arxiv.org/pdf/2407.07320v2,
Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder,11/07/2024,"Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier","The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.",http://arxiv.org/pdf/2407.08166v1,
Parallelizing Autoregressive Generation with Variational State Space Models,11/07/2024,"Gaspard Lambrechts, Yann Claes, Pierre Geurts, Damien Ernst","Attention-based models such as Transformers and recurrent models like state
space models (SSMs) have emerged as successful methods for autoregressive
sequence modeling. Although both enable parallel training, none enable parallel
generation due to their autoregressiveness. We propose the variational SSM
(VSSM), a variational autoencoder (VAE) where both the encoder and decoder are
SSMs. Since sampling the latent variables and decoding them with the SSM can be
parallelized, both training and generation can be conducted in parallel.
Moreover, the decoder recurrence allows generation to be resumed without
reprocessing the whole sequence. Finally, we propose the autoregressive VSSM
that can be conditioned on a partial realization of the sequence, as is common
in language generation tasks. Interestingly, the autoregressive VSSM still
enables parallel generation. We highlight on toy problems (MNIST, CIFAR) the
empirical gains in speed-up and show that it competes with traditional models
in terms of generation quality (Transformer, Mamba SSM).",http://arxiv.org/pdf/2407.08415v1,
Generating In-store Customer Journeys from Scratch with GPT Architectures,13/07/2024,"Taizo Horikomi, Takayuki Mizuno","We propose a method that can generate customer trajectories and purchasing
behaviors in retail stores simultaneously using Transformer-based deep learning
structure. Utilizing customer trajectory data, layout diagrams, and retail
scanner data obtained from a retail store, we trained a GPT-2 architecture from
scratch to generate indoor trajectories and purchase actions. Additionally, we
explored the effectiveness of fine-tuning the pre-trained model with data from
another store. Results demonstrate that our method reproduces in-store
trajectories and purchase behaviors more accurately than LSTM and SVM models,
with fine-tuning significantly reducing the required training data.",http://arxiv.org/pdf/2407.11081v1,
BandControlNet: Parallel Transformers-based Steerable Popular Music Generation with Fine-Grained Spatiotemporal Features,15/07/2024,"Jing Luo, Xinyu Yang, Dorien Herremans","Controllable music generation promotes the interaction between humans and
composition systems by projecting the users' intent on their desired music. The
challenge of introducing controllability is an increasingly important issue in
the symbolic music generation field. When building controllable generative
popular multi-instrument music systems, two main challenges typically present
themselves, namely weak controllability and poor music quality. To address
these issues, we first propose spatiotemporal features as powerful and
fine-grained controls to enhance the controllability of the generative model.
In addition, an efficient music representation called REMI_Track is designed to
convert multitrack music into multiple parallel music sequences and shorten the
sequence length of each track with Byte Pair Encoding (BPE) techniques.
Subsequently, we release BandControlNet, a conditional model based on parallel
Transformers, to tackle the multiple music sequences and generate high-quality
music samples that are conditioned to the given spatiotemporal control
features. More concretely, the two specially designed modules of
BandControlNet, namely structure-enhanced self-attention (SE-SA) and
Cross-Track Transformer (CTT), are utilized to strengthen the resulting musical
structure and inter-track harmony modeling respectively. Experimental results
tested on two popular music datasets of different lengths demonstrate that the
proposed BandControlNet outperforms other conditional music generation models
on most objective metrics in terms of fidelity and inference speed and shows
great robustness in generating long music samples. The subjective evaluations
show BandControlNet trained on short datasets can generate music with
comparable quality to state-of-the-art models, while outperforming them
significantly using longer datasets.",http://arxiv.org/pdf/2407.10462v1,
Spatio-temporal neural distance fields for conditional generative modeling of the heart,15/07/2024,"Kristine Sørensen, Paula Diez, Jan Margeta, Yasmin El Youssef, Michael Pham, Jonas Jalili Pedersen, Tobias Kühl, Ole de Backer, Klaus Kofoed, Oscar Camara, Rasmus Paulsen","The rhythmic pumping motion of the heart stands as a cornerstone in life, as
it circulates blood to the entire human body through a series of carefully
timed contractions of the individual chambers. Changes in the size, shape and
movement of the chambers can be important markers for cardiac disease and
modeling this in relation to clinical demography or disease is therefore of
interest. Existing methods for spatio-temporal modeling of the human heart
require shape correspondence over time or suffer from large memory
requirements, making it difficult to use for complex anatomies. We introduce a
novel conditional generative model, where the shape and movement is modeled
implicitly in the form of a spatio-temporal neural distance field and
conditioned on clinical demography. The model is based on an auto-decoder
architecture and aims to disentangle the individual variations from that
related to the clinical demography. It is tested on the left atrium (including
the left atrial appendage), where it outperforms current state-of-the-art
methods for anatomical sequence completion and generates synthetic sequences
that realistically mimics the shape and motion of the real left atrium. In
practice, this means we can infer functional measurements from a static image,
generate synthetic populations with specified demography or disease and
investigate how non-imaging clinical data effect the shape and motion of
cardiac anatomies.",http://arxiv.org/pdf/2407.10663v1,
Semi-Supervised Generative Models for Disease Trajectories: A Case Study on Systemic Sclerosis,16/07/2024,"Cécile Trottet, Manuel Schürch, Ahmed Allam, Imon Barua, Liubov Petelytska, David Launay, Paolo Airò, Radim Bečvář, Christopher Denton, Mislav Radic, Oliver Distler, Anna-Maria Hoffmann-Vold, Michael Krauthammer, the EUSTAR collaborators","We propose a deep generative approach using latent temporal processes for
modeling and holistically analyzing complex disease trajectories, with a
particular focus on Systemic Sclerosis (SSc). We aim to learn temporal latent
representations of the underlying generative process that explain the observed
patient disease trajectories in an interpretable and comprehensive way. To
enhance the interpretability of these latent temporal processes, we develop a
semi-supervised approach for disentangling the latent space using established
medical knowledge. By combining the generative approach with medical
definitions of different characteristics of SSc, we facilitate the discovery of
new aspects of the disease. We show that the learned temporal latent processes
can be utilized for further data analysis and clinical hypothesis testing,
including finding similar patients and clustering SSc patient trajectories into
novel sub-types. Moreover, our method enables personalized online monitoring
and prediction of multivariate time series with uncertainty quantification.",http://arxiv.org/pdf/2407.11427v2,
AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models,16/07/2024,"Lei Ren, Haiteng Wang, Yang Tang, Chunhua Yang","With the remarkable success of generative models like ChatGPT, Artificial
Intelligence Generated Content (AIGC) is undergoing explosive development. Not
limited to text and images, generative models can generate industrial time
series data, addressing challenges such as the difficulty of data collection
and data annotation. Due to their outstanding generation ability, they have
been widely used in Internet of Things, metaverse, and cyber-physical-social
systems to enhance the efficiency of industrial production. In this paper, we
present a comprehensive overview of generative models for industrial time
series from deep generative models (DGMs) to large generative models (LGMs).
First, a DGM-based AIGC framework is proposed for industrial time series
generation. Within this framework, we survey advanced industrial DGMs and
present a multi-perspective categorization. Furthermore, we systematically
analyze the critical technologies required to construct industrial LGMs from
four aspects: large-scale industrial dataset, LGMs architecture for complex
industrial characteristics, self-supervised training for industrial time
series, and fine-tuning of industrial downstream tasks. Finally, we conclude
the challenges and future directions to enable the development of generative
models in industry.",http://arxiv.org/pdf/2407.11480v1,
Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era,16/07/2024,"Lei Ren, Haiteng Wang, Yuanjun Laili","Industrial Multivariate Time Series (MTS) is a critical view of the
industrial field for people to understand the state of machines. However, due
to data collection difficulty and privacy concerns, available data for building
industrial intelligence and industrial large models is far from sufficient.
Therefore, industrial time series data generation is of great importance.
Existing research usually applies Generative Adversarial Networks (GANs) to
generate MTS. However, GANs suffer from unstable training process due to the
joint training of the generator and discriminator. This paper proposes a
temporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for
MTS generation. It aims to better handle the complex temporal dependencies and
dynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean
Discrepancy (Ada-MMD) method has been proposed for the controlled generation of
MTS, which does not require a classifier to control the generation. It improves
the condition consistency of the diffusion model. Moreover, a Temporal
Decomposition Reconstruction UNet (TDR-UNet) is established to capture complex
temporal patterns and further improve the quality of the synthetic time series.
Comprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that
the proposed Diff-MTS performs substantially better in terms of diversity,
fidelity, and utility compared with GAN-based methods. These results show that
Diff-MTS facilitates the generation of industrial data, contributing to
intelligent maintenance and the construction of industrial large models.",http://arxiv.org/pdf/2407.11501v1,10.1109/TCYB.2024.3462500
EnergyDiff: Universal Time-Series Energy Data Generation using Diffusion Models,18/07/2024,"Nan Lin, Peter Palensky, Pedro P. Vergara","High-resolution time series data are crucial for operation and planning in
energy systems such as electrical power systems and heating systems. However,
due to data collection costs and privacy concerns, such data is often
unavailable or insufficient for downstream tasks. Data synthesis is a potential
solution for this data scarcity. With the recent development of generative AI,
we propose EnergyDiff, a universal data generation framework for energy time
series data. EnergyDiff builds on state-of-the-art denoising diffusion
probabilistic models, utilizing a proposed denoising network dedicated to
high-resolution time series data and introducing a novel Marginal Calibration
technique. Our extensive experimental results demonstrate that EnergyDiff
achieves significant improvement in capturing temporal dependencies and
marginal distributions compared to baselines, particularly at the 1-minute
resolution. Additionally, EnergyDiff consistently generates high-quality time
series data across diverse energy domains, time resolutions, and at both
customer and transformer levels with reduced computational need.",http://arxiv.org/pdf/2407.13538v1,
Time Series Generative Learning with Application to Brain Imaging Analysis,19/07/2024,"Zhenghao Li, Sanyou Wu, Long Feng","This paper focuses on the analysis of sequential image data, particularly
brain imaging data such as MRI, fMRI, CT, with the motivation of understanding
the brain aging process and neurodegenerative diseases. To achieve this goal,
we investigate image generation in a time series context. Specifically, we
formulate a min-max problem derived from the $f$-divergence between neighboring
pairs to learn a time series generator in a nonparametric manner. The generator
enables us to generate future images by transforming prior lag-k observations
and a random vector from a reference distribution. With a deep neural network
learned generator, we prove that the joint distribution of the generated
sequence converges to the latent truth under a Markov and a conditional
invariance condition. Furthermore, we extend our generation mechanism to a
panel data scenario to accommodate multiple samples. The effectiveness of our
mechanism is evaluated by generating real brain MRI sequences from the
Alzheimer's Disease Neuroimaging Initiative. These generated image sequences
can be used as data augmentation to enhance the performance of further
downstream tasks, such as Alzheimer's disease detection.",http://arxiv.org/pdf/2407.14003v1,
Learning Physics for Unveiling Hidden Earthquake Ground Motions via Conditional Generative Modeling,21/07/2024,"Pu Ren, Rie Nakata, Maxime Lacour, Ilan Naiman, Nori Nakata, Jialin Song, Zhengfa Bi, Osman Asif Malik, Dmitriy Morozov, Omri Azencot, N. Benjamin Erichson, Michael W. Mahoney","Predicting high-fidelity ground motions for future earthquakes is crucial for
seismic hazard assessment and infrastructure resilience. Conventional empirical
simulations suffer from sparse sensor distribution and geographically localized
earthquake locations, while physics-based methods are computationally intensive
and require accurate representations of Earth structures and earthquake
sources. We propose a novel artificial intelligence (AI) simulator, Conditional
Generative Modeling for Ground Motion (CGM-GM), to synthesize high-frequency
and spatially continuous earthquake ground motion waveforms. CGM-GM leverages
earthquake magnitudes and geographic coordinates of earthquakes and sensors as
inputs, learning complex wave physics and Earth heterogeneities, without
explicit physics constraints. This is achieved through a probabilistic
autoencoder that captures latent distributions in the time-frequency domain and
variational sequential models for prior and posterior distributions. We
evaluate the performance of CGM-GM using small-magnitude earthquake records
from the San Francisco Bay Area, a region with high seismic risks. CGM-GM
demonstrates a strong potential for outperforming a state-of-the-art
non-ergodic empirical ground motion model and shows great promise in seismology
and beyond.",http://arxiv.org/pdf/2407.15089v1,
Synthetic Time Series for Anomaly Detection in Cloud Microservices,21/07/2024,"Mohamed Allam, Noureddine Boujnah, Noel E. O'Connor, Mingming Liu","This paper proposes a framework for time series generation built to
investigate anomaly detection in cloud microservices. In the field of cloud
computing, ensuring the reliability of microservices is of paramount concern
and yet a remarkably challenging task. Despite the large amount of research in
this area, validation of anomaly detection algorithms in realistic environments
is difficult to achieve. To address this challenge, we propose a framework to
mimic the complex time series patterns representative of both normal and
anomalous cloud microservices behaviors. We detail the pipeline implementation
that allows deployment and management of microservices as well as the
theoretical approach required to generate anomalies. Two datasets generated
using the proposed framework have been made publicly available through GitHub.",http://arxiv.org/pdf/2408.00006v1,
TADA: Temporal Adversarial Data Augmentation for Time Series Data,21/07/2024,"Byeong Tak Lee, Joon-myoung Kwon, Yong-Yeon Jo","Domain generalization aim to train models to effectively perform on samples
that are unseen and outside of the distribution. Adversarial data augmentation
(ADA) is a widely used technique in domain generalization. It enhances the
model robustness by including synthetic samples designed to simulate potential
unseen scenarios into the training datasets, which is then used to train the
model. However, in time series data, traditional ADA approaches often fail to
address distribution shifts related to temporal characteristics. To address
this limitation, we propose Temporal Adversarial Data Augmentation (TADA) for
time series data, which incorporate time warping into ADA. Although time
warping is inherently non-differentiable, ADA relies on generating samples
through backpropagation. We resolve this issue by leveraging the duality
between phase shifts in the frequency domain and time shifts in the time
domain, thereby making the process differentiable. Our evaluations across
various time series datasets demonstrate that TADA outperforms existing methods
for domain generalization. In addition, using distribution visualization, we
confirmed that the distribution shifts induced by TADA are clearly different
from those induced by ADA, and together, they effectively simulate real-world
distribution shifts.",http://arxiv.org/pdf/2407.15174v2,
Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data,23/07/2024,"Hengyu Fu, Zehao Dou, Jiawei Guo, Mengdi Wang, Minshuo Chen","Diffusion Transformer, the backbone of Sora for video generation,
successfully scales the capacity of diffusion models, pioneering new avenues
for high-fidelity sequential data generation. Unlike static data such as
images, sequential data consists of consecutive data frames indexed by time,
exhibiting rich spatial and temporal dependencies. These dependencies represent
the underlying dynamic model and are critical to validate the generated data.
In this paper, we make the first theoretical step towards bridging diffusion
transformers for capturing spatial-temporal dependencies. Specifically, we
establish score approximation and distribution estimation guarantees of
diffusion transformers for learning Gaussian process data with covariance
functions of various decay patterns. We highlight how the spatial-temporal
dependencies are captured and affect learning efficiency. Our study proposes a
novel transformer approximation theory, where the transformer acts to unroll an
algorithm. We support our theoretical results by numerical experiments,
providing strong evidence that spatial-temporal dependencies are captured
within attention layers, aligning with our approximation theory.",http://arxiv.org/pdf/2407.16134v1,
PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning,23/07/2024,"Huandong Wang, Changzheng Gao, Yuchen Wu, Depeng Jin, Lina Yao, Yong Li","Generating human mobility trajectories is of great importance to solve the
lack of large-scale trajectory data in numerous applications, which is caused
by privacy concerns. However, existing mobility trajectory generation methods
still require real-world human trajectories centrally collected as the training
data, where there exists an inescapable risk of privacy leakage. To overcome
this limitation, in this paper, we propose PateGail, a privacy-preserving
imitation learning model to generate mobility trajectories, which utilizes the
powerful generative adversary imitation learning model to simulate the
decision-making process of humans. Further, in order to protect user privacy,
we train this model collectively based on decentralized mobility data stored in
user devices, where personal discriminators are trained locally to distinguish
and reward the real and generated human trajectories. In the training process,
only the generated trajectories and their rewards obtained based on personal
discriminators are shared between the server and devices, whose privacy is
further preserved by our proposed perturbation mechanisms with theoretical
proof to satisfy differential privacy. Further, to better model the human
decision-making process, we propose a novel aggregation mechanism of the
rewards obtained from personal discriminators. We theoretically prove that
under the reward obtained based on the aggregation mechanism, our proposed
model maximizes the lower bound of the discounted total rewards of users.
Extensive experiments show that the trajectories generated by our model are
able to resemble real-world trajectories in terms of five key statistical
metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore,
we demonstrate that the synthetic trajectories are able to efficiently support
practical applications, including mobility prediction and location
recommendation.",http://arxiv.org/pdf/2407.16729v1,
Synthetic Trajectory Generation Through Convolutional Neural Networks,24/07/2024,"Jesse Merhi, Erik Buchholz, Salil S. Kanhere","Location trajectories provide valuable insights for applications from urban
planning to pandemic control. However, mobility data can also reveal sensitive
information about individuals, such as political opinions, religious beliefs,
or sexual orientations. Existing privacy-preserving approaches for publishing
this data face a significant utility-privacy trade-off. Releasing synthetic
trajectory data generated through deep learning offers a promising solution.
Due to the trajectories' sequential nature, most existing models are based on
recurrent neural networks (RNNs). However, research in generative adversarial
networks (GANs) largely employs convolutional neural networks (CNNs) for image
generation. This discrepancy raises the question of whether advances in
computer vision can be applied to trajectory generation. In this work, we
introduce a Reversible Trajectory-to-CNN Transformation (RTCT) that adapts
trajectories into a format suitable for CNN-based models. We integrated this
transformation with the well-known DCGAN in a proof-of-concept (PoC) and
evaluated its performance against an RNN-based trajectory GAN using four
metrics across two datasets. The PoC was superior in capturing spatial
distributions compared to the RNN model but had difficulty replicating
sequential and temporal properties. Although the PoC's utility is not
sufficient for practical applications, the results demonstrate the
transformation's potential to facilitate the use of CNNs for trajectory
generation, opening up avenues for future research. To support continued
research, all source code has been made available under an open-source license.",http://arxiv.org/pdf/2407.16938v1,
Transformers on Markov Data: Constant Depth Suffices,25/07/2024,"Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva","Attention-based transformers have been remarkably successful at modeling
generative processes across various domains and modalities. In this paper, we
study the behavior of transformers on data drawn from \kth Markov processes,
where the conditional distribution of the next symbol in a sequence depends on
the previous $k$ symbols observed. We observe a surprising phenomenon
empirically which contradicts previous findings: when trained for sufficiently
long, a transformer with a fixed depth and $1$ head per layer is able to
achieve low test loss on sequences drawn from \kth Markov sources, even as $k$
grows. Furthermore, this low test loss is achieved by the transformer's ability
to represent and learn the in-context conditional empirical distribution. On
the theoretical side, our main result is that a transformer with a single head
and three layers can represent the in-context conditional empirical
distribution for \kth Markov sources, concurring with our empirical
observations. Along the way, we prove that \textit{attention-only} transformers
with $O(\log_2(k))$ layers can represent the in-context conditional empirical
distribution by composing induction heads to track the previous $k$ symbols in
the sequence. These results provide more insight into our current understanding
of the mechanisms by which transformers learn to capture context, by
understanding their behavior on Markov sources.",http://arxiv.org/pdf/2407.17686v1,
Approximate learning of parsimonious Bayesian context trees,27/07/2024,"Daniyar Ghani, Nicholas A. Heard, Francesco Sanna Passino","Models for categorical sequences typically assume exchangeable or first-order
dependent sequence elements. These are common assumptions, for example, in
models of computer malware traces and protein sequences. Although such
simplifying assumptions lead to computational tractability, these models fail
to capture long-range, complex dependence structures that may be harnessed for
greater predictive power. To this end, a Bayesian modelling framework is
proposed to parsimoniously capture rich dependence structures in categorical
sequences, with memory efficiency suitable for real-time processing of data
streams. Parsimonious Bayesian context trees are introduced as a form of
variable-order Markov model with conjugate prior distributions. The novel
framework requires fewer parameters than fixed-order Markov models by dropping
redundant dependencies and clustering sequential contexts. Approximate
inference on the context tree structure is performed via a computationally
efficient model-based agglomerative clustering procedure. The proposed
framework is tested on synthetic and real-world data examples, and it
outperforms existing sequence models when fitted to real protein sequences and
honeypot computer terminal sessions.",http://arxiv.org/pdf/2407.19236v1,
Piecewise deterministic generative models,28/07/2024,"Andrea Bertazzi, Dario Shariatian, Umut Simsekli, Eric Moulines, Alain Durmus","We introduce a novel class of generative models based on piecewise
deterministic Markov processes (PDMPs), a family of non-diffusive stochastic
processes consisting of deterministic motion and random jumps at random times.
Similarly to diffusions, such Markov processes admit time reversals that turn
out to be PDMPs as well. We apply this observation to three PDMPs considered in
the literature: the Zig-Zag process, Bouncy Particle Sampler, and Randomised
Hamiltonian Monte Carlo. For these three particular instances, we show that the
jump rates and kernels of the corresponding time reversals admit explicit
expressions depending on some conditional densities of the PDMP under
consideration before and after a jump. Based on these results, we propose
efficient training procedures to learn these characteristics and consider
methods to approximately simulate the reverse process. Finally, we provide
bounds in the total variation distance between the data distribution and the
resulting distribution of our model in the case where the base distribution is
the standard $d$-dimensional Gaussian distribution. Promising numerical
simulations support further investigations into this class of models.",http://arxiv.org/pdf/2407.19448v2,
Generative model for financial time series trained with MMD using a signature kernel,29/07/2024,"Chung I Lu, Julian Sester","Generating synthetic financial time series data that accurately reflects
real-world market dynamics holds tremendous potential for various applications,
including portfolio optimization, risk management, and large scale machine
learning. We present an approach for training generative models for financial
time series using the maximum mean discrepancy (MMD) with a signature kernel.
Our method leverages the expressive power of the signature transform to capture
the complex dependencies and temporal structures inherent in financial data. We
employ a moving average model to model the variance of the noise input,
enhancing the model's ability to reproduce stylized facts such as volatility
clustering. Through empirical experiments on S&P 500 index data, we demonstrate
that our model effectively captures key characteristics of financial time
series and outperforms a comparable GAN-based approach. In addition, we explore
the application of the synthetic data generated to train a reinforcement
learning agent for portfolio management, achieving promising results. Finally,
we propose a method to add robustness to the generative model by tweaking the
noise input so that the generated sequences can be adjusted to different market
environments with minimal data.",http://arxiv.org/pdf/2407.19848v3,
Diffusion-Based Generation of Neural Activity from Disentangled Latent Codes,30/07/2024,"Jonathan D. McCart, Andrew R. Sedler, Christopher Versteeg, Domenick Mifsud, Mattia Rigotti-Thompson, Chethan Pandarinath","Recent advances in recording technology have allowed neuroscientists to
monitor activity from thousands of neurons simultaneously. Latent variable
models are increasingly valuable for distilling these recordings into compact
and interpretable representations. Here we propose a new approach to neural
data analysis that leverages advances in conditional generative modeling to
enable the unsupervised inference of disentangled behavioral variables from
recorded neural activity. Our approach builds on InfoDiffusion, which augments
diffusion models with a set of latent variables that capture important factors
of variation in the data. We apply our model, called Generating Neural
Observations Conditioned on Codes with High Information (GNOCCHI), to time
series neural data and test its application to synthetic and biological
recordings of neural activity during reaching. In comparison to a VAE-based
sequential autoencoder, GNOCCHI learns higher-quality latent spaces that are
more clearly structured and more disentangled with respect to key behavioral
variables. These properties enable accurate generation of novel samples (unseen
behavioral conditions) through simple linear traversal of the latent spaces
produced by GNOCCHI. Our work demonstrates the potential of unsupervised,
information-based models for the discovery of interpretable latent spaces from
neural data, enabling researchers to generate high-quality samples from unseen
conditions.",http://arxiv.org/pdf/2407.21195v1,
Generative Learning of the Solution of Parametric Partial Differential Equations Using Guided Diffusion Models and Virtual Observations,31/07/2024,"Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos","We introduce a generative learning framework to model high-dimensional
parametric systems using gradient guidance and virtual observations. We
consider systems described by Partial Differential Equations (PDEs) discretized
with structured or unstructured grids. The framework integrates multi-level
information to generate high fidelity time sequences of the system dynamics. We
demonstrate the effectiveness and versatility of our framework with two case
studies in incompressible, two dimensional, low Reynolds cylinder flow on an
unstructured mesh and incompressible turbulent channel flow on a structured
mesh, both parameterized by the Reynolds number. Our results illustrate the
framework's robustness and ability to generate accurate flow sequences across
various parameter settings, significantly reducing computational costs allowing
for efficient forecasting and reconstruction of flow dynamics.",http://arxiv.org/pdf/2408.00157v1,
Modeling stochastic eye tracking data: A comparison of quantum generative adversarial networks and Markov models,01/08/2024,"Shailendra Bhandari, Pedro Lincastre, Pedro Lind","We explore the use of quantum generative adversarial networks QGANs for
modeling eye movement velocity data. We assess whether the advanced
computational capabilities of QGANs can enhance the modeling of complex
stochastic distribution beyond the traditional mathematical models,
particularly the Markov model. The findings indicate that while QGANs
demonstrate potential in approximating complex distributions, the Markov model
consistently outperforms in accurately replicating the real data distribution.
This comparison underlines the challenges and avenues for refinement in time
series data generation using quantum computing techniques. It emphasizes the
need for further optimization of quantum models to better align with real-world
data characteristics.",http://arxiv.org/pdf/2408.00673v1,10.1145/3638530.3664134
TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation,02/08/2024,"Yicheng Lin, Dandan Zhang, Yun Liu","T-cell receptors (TCRs) play a crucial role in the immune system by
recognizing and binding to specific antigens presented by infected or cancerous
cells. Understanding the sequence patterns of TCRs is essential for developing
targeted immune therapies and designing effective vaccines. Language models,
such as auto-regressive transformers, offer a powerful solution to this problem
by learning the probability distributions of TCR repertoires, enabling the
generation of new TCR sequences that inherit the underlying patterns of the
repertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only
transformer architecture, designed to uncover and replicate sequence patterns
in TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring
sequence probability distributions measured by Pearson correlation coefficient.
Furthermore, by leveraging Reinforcement Learning(RL), we adapted the
distribution of TCR sequences to generate TCRs capable of recognizing specific
peptides, offering significant potential for advancing targeted immune
therapies and vaccine development. With the efficacy of RL, fine-tuned
pretrained TCR-GPT models demonstrated the ability to produce TCR repertoires
likely to bind specific peptides, illustrating RL's efficiency in enhancing the
model's adaptability to the probability distributions of biologically relevant
TCR sequences.",http://arxiv.org/pdf/2408.01156v1,
Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation,02/08/2024,"Jiwoo Ryu, Hao-Wen Dong, Jongmin Jung, Dasaem Jeong","Representing symbolic music with compound tokens, where each token consists
of several different sub-tokens representing a distinct musical feature or
attribute, offers the advantage of reducing sequence length. While previous
research has validated the efficacy of compound tokens in music sequence
modeling, predicting all sub-tokens simultaneously can lead to suboptimal
results as it may not fully capture the interdependencies between them. We
introduce the Nested Music Transformer (NMT), an architecture tailored for
decoding compound tokens autoregressively, similar to processing flattened
tokens, but with low memory usage. The NMT consists of two transformers: the
main decoder that models a sequence of compound tokens and the sub-decoder for
modeling sub-tokens of each compound token. The experiment results showed that
applying the NMT to compound tokens can enhance the performance in terms of
better perplexity in processing various symbolic music datasets and discrete
audio tokens from the MAESTRO dataset.",http://arxiv.org/pdf/2408.01180v1,
NeuralFactors: A Novel Factor Learning Approach to Generative Modeling of Equities,02/08/2024,Achintya Gopal,"The use of machine learning for statistical modeling (and thus, generative
modeling) has grown in popularity with the proliferation of time series models,
text-to-image models, and especially large language models. Fundamentally, the
goal of classical factor modeling is statistical modeling of stock returns, and
in this work, we explore using deep generative modeling to enhance classical
factor models. Prior work has explored the use of deep generative models in
order to model hundreds of stocks, leading to accurate risk forecasting and
alpha portfolio construction; however, that specific model does not allow for
easy factor modeling interpretation in that the factor exposures cannot be
deduced. In this work, we introduce NeuralFactors, a novel machine-learning
based approach to factor analysis where a neural network outputs factor
exposures and factor returns, trained using the same methodology as variational
autoencoders. We show that this model outperforms prior approaches both in
terms of log-likelihood performance and computational efficiency. Further, we
show that this method is competitive to prior work in generating realistic
synthetic data, covariance estimation, risk analysis (e.g., value at risk, or
VaR, of portfolios), and portfolio optimization. Finally, due to the connection
to classical factor analysis, we analyze how the factors our model learns
cluster together and show that the factor exposures could be used for embedding
stocks.",http://arxiv.org/pdf/2408.01499v1,
Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator,06/08/2024,"Xinghao Dong, Chuanqi Chen, Jin-Long Wu","Closure models are widely used in simulating complex multiscale dynamical
systems such as turbulence and the earth system, for which direct numerical
simulation that resolves all scales is often too expensive. For those systems
without a clear scale separation, deterministic and local closure models often
lack enough generalization capability, which limits their performance in many
real-world applications. In this work, we propose a data-driven modeling
framework for constructing stochastic and non-local closure models via
conditional diffusion model and neural operator. Specifically, the Fourier
neural operator is incorporated into a score-based diffusion model, which
serves as a data-driven stochastic closure model for complex dynamical systems
governed by partial differential equations (PDEs). We also demonstrate how
accelerated sampling methods can improve the efficiency of the data-driven
stochastic closure model. The results show that the proposed methodology
provides a systematic approach via generative machine learning techniques to
construct data-driven stochastic closure models for multiscale dynamical
systems with continuous spatiotemporal fields.",http://arxiv.org/pdf/2408.02965v1,
Exchangeable Sequence Models Quantify Uncertainty Over Latent Concepts,06/08/2024,"Naimeng Ye, Hongseok Namkoong","Intelligent agents must be able to articulate its own uncertainty. In this
work, we show that pre-trained sequence models are naturally capable of
probabilistic reasoning over exchangeable data points -- forming informed
beliefs and sharpening them as it gathers more information. A sequence model
learns the relationship between observations, which differs from typical
Bayesian models that quantify uncertainty over latent parameters through priors
and likelihoods (e.g., topic models). Despite the apparent difference, we
illustrate how exchangeable sequence modeling provides a valid Bayesian model
by going back to De Finetti's classical predictive view of probabilistic
reasoning: uncertainty comes from data that has not been observed yet, rather
than latent parameters. From this perspective, pre-training autoregressive
models is equivalent to formulating informed beliefs based on prior
observations (""empirical Bayes""), and forward generation is equivalent to
simulating instantiations of an environment (""posterior inference""). In
particular, exchangeable sequence models can explicitly perform statistical
inference; epistemic uncertainty over latent environments is captured by
variation in predicted future observations. Formally, we show the sequence
prediction loss controls the quality of uncertainty quantification, and propose
several approaches for encoding exchangeability in sequence model
architectures: data augmentation, regularization, and causal masking.",http://arxiv.org/pdf/2408.03307v3,
Consumer Transactions Simulation through Generative Adversarial Networks,07/08/2024,"Sergiy Tkachuk, Szymon Łukasik, Anna Wróblewska","In the rapidly evolving domain of large-scale retail data systems,
envisioning and simulating future consumer transactions has become a crucial
area of interest. It offers significant potential to fortify demand forecasting
and fine-tune inventory management. This paper presents an innovative
application of Generative Adversarial Networks (GANs) to generate synthetic
retail transaction data, specifically focusing on a novel system architecture
that combines consumer behavior modeling with stock-keeping unit (SKU)
availability constraints to address real-world assortment optimization
challenges. We diverge from conventional methodologies by integrating SKU data
into our GAN architecture and using more sophisticated embedding methods (e.g.,
hyper-graphs). This design choice enables our system to generate not only
simulated consumer purchase behaviors but also reflects the dynamic interplay
between consumer behavior and SKU availability -- an aspect often overlooked,
among others, because of data scarcity in legacy retail simulation models. Our
GAN model generates transactions under stock constraints, pioneering a
resourceful experimental system with practical implications for real-world
retail operation and strategy. Preliminary results demonstrate enhanced realism
in simulated transactions measured by comparing generated items with real ones
using methods employed earlier in related studies. This underscores the
potential for more accurate predictive modeling.",http://arxiv.org/pdf/2408.03655v1,
MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation,11/08/2024,"Jianping Zhou, Junhao Li, Guanjie Zheng, Xinbing Wang, Chenghu Zhou","Missing values are prevalent in multivariate time series, compromising the
integrity of analyses and degrading the performance of downstream tasks.
Consequently, research has focused on multivariate time series imputation,
aiming to accurately impute the missing values based on available observations.
A key research question is how to ensure imputation consistency, i.e.,
intra-consistency between observed and imputed values, and inter-consistency
between adjacent windows after imputation. However, previous methods rely
solely on the inductive bias of the imputation targets to guide the learning
process, ignoring imputation consistency and ultimately resulting in poor
performance. Diffusion models, known for their powerful generative abilities,
prefer to generate consistent results based on available observations.
Therefore, we propose a conditional diffusion model for Multivariate Time
Series Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive
complementary mask to generate dual views during the forward noising process.
Then, the intra contrastive loss is calculated to ensure intra-consistency
between the imputed and observed values. Meanwhile, MTSCI utilizes a mixup
mechanism to incorporate conditional information from adjacent windows during
the denoising process, facilitating the inter-consistency between imputed
samples. Extensive experiments on multiple real-world datasets demonstrate that
our method achieves the state-of-the-art performance on multivariate time
series imputation task under different missing scenarios. Code is available at
https://github.com/JeremyChou28/MTSCI.",http://arxiv.org/pdf/2408.05740v1,10.1145/3627673.3679532
Leveraging Priors via Diffusion Bridge for Time Series Generation,13/08/2024,"Jinseong Park, Seungyun Lee, Woojin Jeong, Yujin Choi, Jaewook Lee","Time series generation is widely used in real-world applications such as
simulation, data augmentation, and hypothesis test techniques. Recently,
diffusion models have emerged as the de facto approach for time series
generation, emphasizing diverse synthesis scenarios based on historical or
correlated time series data streams. Since time series have unique
characteristics, such as fixed time order and data scaling, standard Gaussian
prior might be ill-suited for general time series generation. In this paper, we
exploit the usage of diverse prior distributions for synthesis. Then, we
propose TimeBridge, a framework that enables flexible synthesis by leveraging
diffusion bridges to learn the transport between chosen prior and data
distributions. Our model covers a wide range of scenarios in time series
diffusion models, which leverages (i) data- and time-dependent priors for
unconditional synthesis, and (ii) data-scale preserving synthesis with a
constraint as a prior for conditional generation. Experimentally, our model
achieves state-of-the-art performance in both unconditional and conditional
time series generation tasks.",http://arxiv.org/pdf/2408.06672v1,
A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining,15/08/2024,"Audrey Der, Chin-Chia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Zhongfang Zhuang, Vivian Lai, Junpeng Wang, Liang Wang, Wei Zhang, Eamonn Keogh","Self-supervised Pretrained Models (PTMs) have demonstrated remarkable
performance in computer vision and natural language processing tasks. These
successes have prompted researchers to design PTMs for time series data. In our
experiments, most self-supervised time series PTMs were surpassed by simple
supervised models. We hypothesize this undesired phenomenon may be caused by
data scarcity. In response, we test six time series generation methods, use the
generated data in pretraining in lieu of the real data, and examine the effects
on classification performance. Our results indicate that replacing a real-data
pretraining set with a greater volume of only generated samples produces
noticeable improvement.",http://arxiv.org/pdf/2408.07869v1,
COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences,15/08/2024,"Ilya Kuleshov, Galina Boeva, Vladislav Zhuzhel, Evgenia Romanenkova, Evgeni Vorsin, Alexey Zaytsev","Observation of the underlying actors that generate event sequences reveals
that they often evolve continuously. Most modern methods, however, tend to
model such processes through at most piecewise-continuous trajectories. To
address this, we adopt a way of viewing events not as standalone phenomena but
instead as observations of a Gaussian Process, which in turn governs the
actor's dynamics. We propose integrating these obtained dynamics, resulting in
a continuous-trajectory modification of the widely successful Neural ODE model.
Through Gaussian Process theory, we were able to evaluate the uncertainty in an
actor's representation, which arises from not observing them between events.
This estimate led us to develop a novel, theoretically backed negative feedback
mechanism. Empirical studies indicate that our model with Gaussian process
interpolation and negative feedback achieves state-of-the-art performance, with
improvements up to 20% AUROC against similar architectures.",http://arxiv.org/pdf/2408.08055v1,
PITN: Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation,16/08/2024,"Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma","Monitoring blood pressure with non-invasive sensors has gained popularity for
providing comfortable user experiences, one of which is a significant function
of smart wearables. Although providing a comfortable user experience, such
methods are suffering from the demand for a significant amount of realistic
data to train an individual model for each subject, especially considering the
invasive or obtrusive BP ground-truth measurements. To tackle this challenge,
we introduce a novel physics-informed temporal network~(PITN) with adversarial
contrastive learning to enable precise BP estimation with very limited data.
Specifically, we first enhance the physics-informed neural network~(PINN) with
the temporal block for investigating BP dynamics' multi-periodicity for
personal cardiovascular cycle modeling and temporal variation. We then employ
adversarial training to generate extra physiological time series data,
improving PITN's robustness in the face of sparse subject-specific training
data. Furthermore, we utilize contrastive learning to capture the
discriminative variations of cardiovascular physiologic phenomena. This
approach aggregates physiological signals with similar blood pressure values in
latent space while separating clusters of samples with dissimilar blood
pressure values. Experiments on three widely-adopted datasets with different
modailties (\emph{i.e.,} bioimpedance, PPG, millimeter-wave) demonstrate the
superiority and effectiveness of the proposed methods over previous
state-of-the-art approaches. The code is available
at~\url{https://github.com/Zest86/ACL-PITN}.",http://arxiv.org/pdf/2408.08488v2,
DivDiff: A Conditional Diffusion Model for Diverse Human Motion Prediction,16/08/2024,"Hua Yu, Yaqing Hou, Wenbin Pei, Qiang Zhang","Diverse human motion prediction (HMP) aims to predict multiple plausible
future motions given an observed human motion sequence. It is a challenging
task due to the diversity of potential human motions while ensuring an accurate
description of future human motions. Current solutions are either low-diversity
or limited in expressiveness. Recent denoising diffusion models (DDPM) hold
potential generative capabilities in generative tasks. However, introducing
DDPM directly into diverse HMP incurs some issues. Although DDPM can increase
the diversity of the potential patterns of human motions, the predicted human
motions become implausible over time because of the significant noise
disturbances in the forward process of DDPM. This phenomenon leads to the
predicted human motions being hard to control, seriously impacting the quality
of predicted motions and restricting their practical applicability in
real-world scenarios. To alleviate this, we propose a novel conditional
diffusion-based generative model, called DivDiff, to predict more diverse and
realistic human motions. Specifically, the DivDiff employs DDPM as our backbone
and incorporates Discrete Cosine Transform (DCT) and transformer mechanisms to
encode the observed human motion sequence as a condition to instruct the
reverse process of DDPM. More importantly, we design a diversified
reinforcement sampling function (DRSF) to enforce human skeletal constraints on
the predicted human motions. DRSF utilizes the acquired information from human
skeletal as prior knowledge, thereby reducing significant disturbances
introduced during the forward process. Extensive results received in the
experiments on two widely-used datasets (Human3.6M and HumanEva-I) demonstrate
that our model obtains competitive performance on both diversity and accuracy.",http://arxiv.org/pdf/2409.00014v1,
From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis,20/08/2024,"Guy Lutsker, Gal Sapir, Anastasia Godneva, Smadar Shilo, Jerry R Greenfield, Dorit Samocha-Bonet, Shie Mannor, Eli Meirom, Gal Chechik, Hagai Rossman, Eran Segal","Recent advances in self-supervised learning enabled novel medical AI models,
known as foundation models (FMs) that offer great potential for characterizing
health from diverse biomedical data. Continuous glucose monitoring (CGM)
provides rich, temporal data on glycemic patterns, but its full potential for
predicting broader health outcomes remains underutilized. Here, we present
GluFormer, a generative foundation model on biomedical temporal data based on a
transformer architecture, and trained on over 10 million CGM measurements from
10,812 non-diabetic individuals. We tokenized the CGM training data and trained
GluFormer using next token prediction in a generative, autoregressive manner.
We demonstrate that GluFormer generalizes effectively to 15 different external
datasets, including 4936 individuals across 5 different geographical regions, 6
different CGM devices, and several metabolic disorders, including
normoglycemic, prediabetic, and diabetic populations, as well as those with
gestational diabetes and obesity. GluFormer produces embeddings which
outperform traditional CGM analysis tools, and achieves high Pearson
correlations in predicting clinical parameters such as HbA1c, liver-related
parameters, blood lipids, and sleep-related indices. Notably, GluFormer can
also predict onset of future health outcomes even 4 years in advance. We also
show that CGM embeddings from pre-intervention periods in Randomized Clinical
Trials (RCTs) outperform other methods in predicting primary and secondary
outcomes. When integrating dietary data into GluFormer, we show that the
enhanced model can accurately generate CGM data based only on dietary intake
data, simulate outcomes of dietary interventions, and predict individual
responses to specific foods. Overall, we show that GluFormer accurately
predicts health outcomes which generalize across different populations
metabolic conditions.",http://arxiv.org/pdf/2408.11876v1,
Kilometer-Scale Convection Allowing Model Emulation using Generative Diffusion Modeling,20/08/2024,"Jaideep Pathak, Yair Cohen, Piyush Garg, Peter Harrington, Noah Brenowitz, Dale Durran, Morteza Mardani, Arash Vahdat, Shaoming Xu, Karthik Kashinath, Michael Pritchard","Storm-scale convection-allowing models (CAMs) are an important tool for
predicting the evolution of thunderstorms and mesoscale convective systems that
result in damaging extreme weather. By explicitly resolving convective dynamics
within the atmosphere they afford meteorologists the nuance needed to provide
outlook on hazard. Deep learning models have thus far not proven skilful at
km-scale atmospheric simulation, despite being competitive at coarser
resolution with state-of-the-art global, medium-range weather forecasting. We
present a generative diffusion model called StormCast, which emulates the
high-resolution rapid refresh (HRRR) model-NOAA's state-of-the-art 3km
operational CAM. StormCast autoregressively predicts 99 state variables at km
scale using a 1-hour time step, with dense vertical resolution in the
atmospheric boundary layer, conditioned on 26 synoptic variables. We present
evidence of successfully learnt km-scale dynamics including competitive 1-6
hour forecast skill for composite radar reflectivity alongside physically
realistic convective cluster evolution, moist updrafts, and cold pool
morphology. StormCast predictions maintain realistic power spectra for multiple
predicted variables across multi-hour forecasts. Together, these results
establish the potential for autoregressive ML to emulate CAMs -- opening up new
km-scale frontiers for regional ML weather prediction and future climate hazard
dynamical downscaling.",http://arxiv.org/pdf/2408.10958v1,
Extraction of Typical Operating Scenarios of New Power System Based on Deep Time Series Aggregation,23/08/2024,"Zhaoyang Qu, Zhenming Zhang, Nan Qu, Yuguang Zhou, Yang Li, Tao Jiang, Min Li, Chao Long","Extracting typical operational scenarios is essential for making flexible
decisions in the dispatch of a new power system. This study proposed a novel
deep time series aggregation scheme (DTSAs) to generate typical operational
scenarios, considering the large amount of historical operational snapshot
data. Specifically, DTSAs analyze the intrinsic mechanisms of different
scheduling operational scenario switching to mathematically represent typical
operational scenarios. A gramian angular summation field (GASF) based
operational scenario image encoder was designed to convert operational scenario
sequences into high-dimensional spaces. This enables DTSAs to fully capture the
spatiotemporal characteristics of new power systems using deep feature
iterative aggregation models. The encoder also facilitates the generation of
typical operational scenarios that conform to historical data distributions
while ensuring the integrity of grid operational snapshots. Case studies
demonstrate that the proposed method extracted new fine-grained power system
dispatch schemes and outperformed the latest high-dimensional featurescreening
methods. In addition, experiments with different new energy access ratios were
conducted to verify the robustness of the proposed method. DTSAs enables
dispatchers to master the operation experience of the power system in advance,
and actively respond to the dynamic changes of the operation scenarios under
the high access rate of new energy.",http://arxiv.org/pdf/2408.14493v1,10.1049/cit2.12369
Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with Spatiotemporal Constraints,25/08/2024,"Siyu Li, Toan Tran, Haowen Lin, John Krumm, Cyrus Shahabi, Li Xiong","Simulating human mobility data is essential for various application domains,
including transportation, urban planning, and epidemic control, since real data
are often inaccessible to researchers due to expensive costs and privacy
issues. Several existing deep generative solutions propose learning from real
trajectories to generate synthetic ones. Despite the progress, most of them
suffer from training stability issues and scale poorly with growing data size.
More importantly, they generally lack control mechanisms to steer the generated
trajectories based on spatiotemporal constraints such as fixing specific
visits. To address such limitations, we formally define the controlled
trajectory generation problem with spatiotemporal constraints and propose
Geo-Llama. This novel LLM-inspired framework enforces explicit visit
constraints in a contextually coherent way. It fine-tunes pre-trained LLMs on
trajectories with a visit-wise permutation strategy where each visit
corresponds to a time and location. This enables the model to capture the
spatiotemporal patterns regardless of visit orders and allows flexible and
in-context constraint integration through prompts during generation. Extensive
experiments on real-world and synthetic datasets validate the effectiveness of
Geo-Llama, demonstrating its versatility and robustness in handling a broad
range of constraints to generate more realistic trajectories compared to
existing methods.",http://arxiv.org/pdf/2408.13918v3,
Force-Guided Bridge Matching for Full-Atom Time-Coarsened Dynamics of Peptides,27/08/2024,"Ziyang Yu, Wenbing Huang, Yang Liu","Molecular Dynamics (MD) is crucial in various fields such as materials
science, chemistry, and pharmacology to name a few. Conventional MD software
struggles with the balance between time cost and prediction accuracy, which
restricts its wider application. Recently, data-driven approaches based on deep
generative models have been devised for time-coarsened dynamics, which aim at
learning dynamics of diverse molecular systems over a long timestep, enjoying
both universality and efficiency. Nevertheless, most current methods are
designed solely to learn from the data distribution regardless of the
underlying Boltzmann distribution, and the physics priors such as energies and
forces are constantly overlooked. In this work, we propose a conditional
generative model called Force-guided Bridge Matching (FBM), which learns
full-atom time-coarsened dynamics and targets the Boltzmann-constrained
distribution. With the guidance of our delicately-designed intermediate force
field, FBM leverages favourable physics priors into the generation process,
giving rise to enhanced simulations. Experiments on two datasets consisting of
peptides verify our superiority in terms of comprehensive metrics and
demonstrate transferability to unseen systems.",http://arxiv.org/pdf/2408.15126v6,
How transformers learn structured data: insights from hierarchical filtering,27/08/2024,"Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti","Understanding the learning process and the embedded computation in
transformers is becoming a central goal for the development of interpretable
AI. In the present study, we introduce a hierarchical filtering procedure for
generative models of sequences on trees, allowing us to hand-tune the range of
positional correlations in the data. Leveraging this controlled setting, we
provide evidence that vanilla encoder-only transformers can approximate the
exact inference algorithm when trained on root classification and masked
language modeling tasks, and study how this computation is discovered and
implemented. We find that correlations at larger distances, corresponding to
increasing layers of the hierarchy, are sequentially included by the network
during training. Moreover, by comparing attention maps from models trained with
varying degrees of filtering and by probing the different encoder levels, we
find clear evidence of a reconstruction of correlations on successive length
scales corresponding to the various levels of the hierarchy, which we relate to
a plausible implementation of the exact inference algorithm within the same
architecture.",http://arxiv.org/pdf/2408.15138v2,
Toward Time-Continuous Data Inference in Sparse Urban CrowdSensing,27/08/2024,"Ziyu Sun, Haoyang Su, Hanqi Sun, En Wang, Wenbin Liu","Mobile Crowd Sensing (MCS) is a promising paradigm that leverages mobile
users and their smart portable devices to perform various real-world tasks.
However, due to budget constraints and the inaccessibility of certain areas,
Sparse MCS has emerged as a more practical alternative, collecting data from a
limited number of target subareas and utilizing inference algorithms to
complete the full sensing map. While existing approaches typically assume a
time-discrete setting with data remaining constant within each sensing cycle,
this simplification can introduce significant errors, especially when dealing
with long cycles, as real-world sensing data often changes continuously. In
this paper, we go from fine-grained completion, i.e., the subdivision of
sensing cycles into minimal time units, towards a more accurate,
time-continuous completion. We first introduce Deep Matrix Factorization (DMF)
as a neural network-enabled framework and enhance it with a Recurrent Neural
Network (RNN-DMF) to capture temporal correlations in these finer time slices.
To further deal with the continuous data, we propose TIME-DMF, which captures
temporal information across unequal intervals, enabling time-continuous
completion. Additionally, we present the Query-Generate (Q-G) strategy within
TIME-DMF to model the infinite states of continuous data. Extensive experiments
across five types of sensing tasks demonstrate the effectiveness of our models
and the advantages of time-continuous completion.",http://arxiv.org/pdf/2408.16027v1,
Simulating realistic short tandem repeat capillary electrophoretic signal using a generative adversarial network,28/08/2024,"Duncan Taylor, Melissa Humphries","DNA profiles are made up from multiple series of electrophoretic signal
measuring fluorescence over time. Typically, human DNA analysts 'read' DNA
profiles using their experience to distinguish instrument noise, artefactual
signal, and signal corresponding to DNA fragments of interest. Recent work has
developed an artificial neural network, ANN, to carry out the task of
classifying fluorescence types into categories in DNA profile electrophoretic
signal. But the creation of the necessarily large amount of labelled training
data for the ANN is time consuming and expensive, and a limiting factor in the
ability to robustly train the ANN. If realistic, prelabelled, training data
could be simulated then this would remove the barrier to training an ANN with
high efficacy. Here we develop a generative adversarial network, GAN, modified
from the pix2pix GAN to achieve this task. With 1078 DNA profiles we train the
GAN and achieve the ability to simulate DNA profile information, and then use
the generator from the GAN as a 'realism filter' that applies the noise and
artefact elements exhibited in typical electrophoretic signal.",http://arxiv.org/pdf/2408.16169v1,
Flexible framework for generating synthetic electrocardiograms and photoplethysmograms,29/08/2024,"Katri Karhinoja, Antti Vasankari, Jukka-Pekka Sirkiä, Antti Airola, David Wong, Matti Kaisti","By generating synthetic biosignals, the quantity and variety of health data
can be increased. This is especially useful when training machine learning
models by enabling data augmentation and introduction of more physiologically
plausible variation to the data. For these purposes, we have developed a
synthetic biosignal model for two signal modalities, electrocardiography (ECG)
and photoplethysmography (PPG). The model produces realistic signals that
account for physiological effects such as breathing modulation and changes in
heart rate due to physical stress. Arrhythmic signals can be generated with
beat intervals extracted from real measurements. The model also includes a
flexible approach to adding different kinds of noise and signal artifacts. The
noise is generated from power spectral densities extracted from both measured
noisy signals and modeled power spectra. Importantly, the model also
automatically produces labels for noise, segmentation (e.g. P and T waves, QRS
complex, for electrocardiograms), and artifacts. We assessed how this
comprehensive model can be used in practice to improve the performance of
models trained on ECG or PPG data. For example, we trained an LSTM to detect
ECG R-peaks using both real ECG signals from the MIT-BIH arrythmia set and our
new generator. The F1 score of the model was 0.83 using real data, in
comparison to 0.98 using our generator. In addition, the model can be used for
example in signal segmentation, quality detection and bench-marking detection
algorithms. The model code has been released in
\url{https://github.com/UTU-Health-Research/framework_for_synthetic_biosignals}",http://arxiv.org/pdf/2408.16291v1,
Blending Low and High-Level Semantics of Time Series for Better Masked Time Series Generation,29/08/2024,"Johan Vik Mathisen, Erlend Lokna, Daesoo Lee, Erlend Aune","State-of-the-art approaches in time series generation (TSG), such as
TimeVQVAE, utilize vector quantization-based tokenization to effectively model
complex distributions of time series. These approaches first learn to transform
time series into a sequence of discrete latent vectors, and then a prior model
is learned to model the sequence. The discrete latent vectors, however, only
capture low-level semantics (\textit{e.g.,} shapes). We hypothesize that
higher-fidelity time series can be generated by training a prior model on more
informative discrete latent vectors that contain both low and high-level
semantics (\textit{e.g.,} characteristic dynamics). In this paper, we introduce
a novel framework, termed NC-VQVAE, to integrate self-supervised learning into
those TSG methods to derive a discrete latent space where low and high-level
semantics are captured. Our experimental results demonstrate that NC-VQVAE
results in a considerable improvement in the quality of synthetic samples.",http://arxiv.org/pdf/2408.16613v1,
Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation,29/08/2024,Christian D. Blakely,"We construct a two-layered model for learning and generating sequential data
that is both computationally fast and competitive with vanilla Tsetlin
machines, adding numerous advantages. Through the use of hyperdimensional
vector computing (HVC) algebras and Tsetlin machine clause structures, we
demonstrate that the combination of both inherits the generality of data
encoding and decoding of HVC with the fast interpretable nature of Tsetlin
machines to yield a powerful machine learning model. We apply the approach in
two areas, namely in forecasting, generating new sequences, and classification.
For the latter, we derive results for the entire UCR Time Series Archive and
compare with the standard benchmarks to see how well the method competes in
time series classification.",http://arxiv.org/pdf/2408.16620v1,
Differentially Private Synthetic High-dimensional Tabular Stream,31/08/2024,"Girish Kumar, Thomas Strohmer, Roman Vershynin","While differentially private synthetic data generation has been explored
extensively in the literature, how to update this data in the future if the
underlying private data changes is much less understood. We propose an
algorithmic framework for streaming data that generates multiple synthetic
datasets over time, tracking changes in the underlying private data. Our
algorithm satisfies differential privacy for the entire input stream (continual
differential privacy) and can be used for high-dimensional tabular data.
Furthermore, we show the utility of our method via experiments on real-world
datasets. The proposed algorithm builds upon a popular select, measure, fit,
and iterate paradigm (used by offline synthetic data generation algorithms) and
private counters for streams.",http://arxiv.org/pdf/2409.00322v1,
TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model,03/09/2024,"Defu Cao, Wen Ye, Yizhou Zhang, Yan Liu","With recent advances in building foundation models for texts and video data,
there is a surge of interest in foundation models for time series. A family of
models have been developed, utilizing a temporal auto-regressive generative
Transformer architecture, whose effectiveness has been proven in Large Language
Models. While the empirical results are promising, almost all existing time
series foundation models have only been tested on well-curated ``benchmark''
datasets very similar to texts. However, real-world time series exhibit unique
challenges, such as variable channel sizes across domains, missing values, and
varying signal sampling intervals due to the multi-resolution nature of
real-world data. Additionally, the uni-directional nature of temporally
auto-regressive decoding limits the incorporation of domain knowledge, such as
physical laws expressed as partial differential equations (PDEs). To address
these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a
general foundation model for time series that employs a denoising diffusion
paradigm instead of temporal auto-regressive generation. TimeDiT leverages the
Transformer architecture to capture temporal dependencies and employs diffusion
processes to generate high-quality candidate samples without imposing stringent
assumptions on the target distribution via novel masking schemes and a channel
alignment strategy. Furthermore, we propose a finetuning-free model editing
strategy that allows the seamless integration of external knowledge during the
sampling process without updating any model parameters. Extensive experiments
conducted on a varity of tasks such as forecasting, imputation, and anomaly
detection, demonstrate the effectiveness of TimeDiT.",http://arxiv.org/pdf/2409.02322v1,
MarS: a Financial Market Simulation Engine Powered by Generative Foundation Model,04/09/2024,"Junjie Li, Yang Liu, Weiqing Liu, Shikai Fang, Lewen Wang, Chang Xu, Jiang Bian","Generative models aim to simulate realistic effects of various actions across
different contexts, from text generation to visual effects. Despite efforts to
build real-world simulators, leveraging generative models for virtual worlds,
like financial markets, remains underexplored. In financial markets, generative
models can simulate market effects of various behaviors, enabling interaction
with market scenes and players, and training strategies without financial risk.
This simulation relies on the finest structured data in financial market like
orders thus building the finest realistic simulation. We propose Large Market
Model (LMM), an order-level generative foundation model, for financial market
simulation, akin to language modeling in the digital world. Our financial
Market Simulation engine (MarS), powered by LMM, addresses the need for
realistic, interactive and controllable order generation. Key objectives of
this paper include evaluating LMM's scaling law in financial markets, assessing
MarS's realism, balancing controlled generation with market impact, and
demonstrating MarS's potential applications. We showcase MarS as a forecast
tool, detection system, analysis platform, and agent training environment. Our
contributions include pioneering a generative model for financial markets,
designing MarS to meet domain-specific needs, and demonstrating MarS-based
applications' industry potential.",http://arxiv.org/pdf/2409.07486v1,
VFLGAN-TS: Vertical Federated Learning-based Generative Adversarial Networks for Publication of Vertically Partitioned Time-Series Data,05/09/2024,"Xun Yuan, Zilong Zhao, Prosanta Gope, Biplab Sikdar","In the current artificial intelligence (AI) era, the scale and quality of the
dataset play a crucial role in training a high-quality AI model. However, often
original data cannot be shared due to privacy concerns and regulations. A
potential solution is to release a synthetic dataset with a similar
distribution to the private dataset. Nevertheless, in some scenarios, the
attributes required to train an AI model are distributed among different
parties, and the parties cannot share the local data for synthetic data
construction due to privacy regulations. In PETS 2024, we recently introduced
the first Vertical Federated Learning-based Generative Adversarial Network
(VFLGAN) for publishing vertically partitioned static data. However, VFLGAN
cannot effectively handle time-series data, presenting both temporal and
attribute dimensions. In this article, we proposed VFLGAN-TS, which combines
the ideas of attribute discriminator and vertical federated learning to
generate synthetic time-series data in the vertically partitioned scenario. The
performance of VFLGAN-TS is close to that of its counterpart, which is trained
in a centralized manner and represents the upper limit for VFLGAN-TS. To
further protect privacy, we apply a Gaussian mechanism to make VFLGAN-TS
satisfy an $(\epsilon,\delta)$-differential privacy. Besides, we develop an
enhanced privacy auditing scheme to evaluate the potential privacy breach
through the framework of VFLGAN-TS and synthetic datasets.",http://arxiv.org/pdf/2409.03612v1,
A method to benchmark high-dimensional process drift detection,05/09/2024,"Edgar Wolf, Tobias Windisch","Process curves are multivariate finite time series data coming from
manufacturing processes. This paper studies machine learning that detect drifts
in process curve datasets. A theoretic framework to synthetically generate
process curves in a controlled way is introduced in order to benchmark machine
learning algorithms for process drift detection. An evaluation score, called
the temporal area under the curve, is introduced, which allows to quantify how
well machine learning models unveil curves belonging to drift segments.
Finally, a benchmark study comparing popular machine learning approaches on
synthetic data generated with the introduced framework is presented that shows
that existing algorithms often struggle with datasets containing multiple drift
segments.",http://arxiv.org/pdf/2409.03669v2,
Latent Space Energy-based Neural ODEs,05/09/2024,"Sheng Cheng, Deqian Kong, Jianwen Xie, Kookjin Lee, Ying Nian Wu, Yezhou Yang","This paper introduces a novel family of deep dynamical models designed to
represent continuous-time sequence data. This family of models generates each
data point in the time series by a neural emission model, which is a non-linear
transformation of a latent state vector. The trajectory of the latent states is
implicitly described by a neural ordinary differential equation (ODE), with the
initial state following an informative prior distribution parameterized by an
energy-based model. Furthermore, we can extend this model to disentangle
dynamic states from underlying static factors of variation, represented as
time-invariant variables in the latent space. We train the model using maximum
likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end
manner, without requiring additional assisting components such as an inference
network. Our experiments on oscillating systems, videos and real-world state
sequences (MuJoCo) illustrate that ODEs with the learnable energy-based prior
outperform existing counterparts, and can generalize to new dynamic
parameterization, enabling long-horizon predictions.",http://arxiv.org/pdf/2409.03845v1,
Human Motion Synthesis_ A Diffusion Approach for Motion Stitching and In-Betweening,10/09/2024,"Michael Adewole, Oluwaseyi Giwa, Favour Nerrise, Martins Osifeko, Ajibola Oyedeji","Human motion generation is an important area of research in many fields. In
this work, we tackle the problem of motion stitching and in-betweening. Current
methods either require manual efforts, or are incapable of handling longer
sequences. To address these challenges, we propose a diffusion model with a
transformer-based denoiser to generate realistic human motion. Our method
demonstrated strong performance in generating in-betweening sequences,
transforming a variable number of input poses into smooth and realistic motion
sequences consisting of 75 frames at 15 fps, resulting in a total duration of 5
seconds. We present the performance evaluation of our method using quantitative
metrics such as Frechet Inception Distance (FID), Diversity, and Multimodality,
along with visual assessments of the generated outputs.",http://arxiv.org/pdf/2409.06791v1,
TrialSynth: Generation of Synthetic Sequential Clinical Trial Data,11/09/2024,"Chufan Gao, Mandis Beigi, Afrah Shafquat, Jacob Aptekar, Jimeng Sun","Analyzing data from past clinical trials is part of the ongoing effort to
optimize the design, implementation, and execution of new clinical trials and
more efficiently bring life-saving interventions to market. While there have
been recent advances in the generation of static context synthetic clinical
trial data, due to both limited patient availability and constraints imposed by
patient privacy needs, the generation of fine-grained synthetic time-sequential
clinical trial data has been challenging. Given that patient trajectories over
an entire clinical trial are of high importance for optimizing trial design and
efforts to prevent harmful adverse events, there is a significant need for the
generation of high-fidelity time-sequence clinical trial data. Here we
introduce TrialSynth, a Variational Autoencoder (VAE) designed to address the
specific challenges of generating synthetic time-sequence clinical trial data.
Distinct from related clinical data VAE methods, the core of our method
leverages Hawkes Processes (HP), which are particularly well-suited for
modeling event-type and time gap prediction needed to capture the structure of
sequential clinical trial data. Our experiments demonstrate that TrialSynth
surpasses the performance of other comparable methods that can generate
sequential clinical trial data at varying levels of fidelity / privacy
tradeoff, enabling the generation of highly accurate event sequences across
multiple real-world sequential event datasets with small patient source
populations. Notably, our empirical findings highlight that TrialSynth not only
outperforms existing clinical sequence-generating methods but also produces
data with superior utility while empirically preserving patient privacy.",http://arxiv.org/pdf/2409.07089v2,
Recent Trends in Modelling the Continuous Time Series using Deep Learning: A Survey,13/09/2024,"Mansura Habiba, Barak A. Pearlmutter, Mehrdad Maleki","Continuous-time series is essential for different modern application areas,
e.g. healthcare, automobile, energy, finance, Internet of things (IoT) and
other related areas. Different application needs to process as well as analyse
a massive amount of data in time series structure in order to determine the
data-driven result, for example, financial trend prediction, potential
probability of the occurrence of a particular event occurrence identification,
patient health record processing and so many more. However, modeling real-time
data using a continuous-time series is challenging since the dynamical systems
behind the data could be a differential equation. Several research works have
tried to solve the challenges of modelling the continuous-time series using
different neural network models and approaches for data processing and
learning. The existing deep learning models are not free from challenges and
limitations due to diversity among different attributes, behaviour, duration of
steps, energy, and data sampling rate. This paper has described the general
problem domain of time series and reviewed the challenges of modelling the
continuous time series. We have presented a comparative analysis of recent
developments in deep learning models and their contribution to solving
different difficulties of modelling the continuous time series. We have also
identified the limitations of the existing neural network model and open
issues. The main goal of this review is to understand the recent trend of
neural network models used in a different real-world application with
continuous-time data.",http://arxiv.org/pdf/2409.09106v1,
Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation,13/09/2024,"Guojun Liang, Najmeh Abiri, Atiye Sadat Hashemi, Jens Lundström, Stefan Byttner, Prayag Tiwari","Accurate imputation is essential for the reliability and success of
downstream tasks. Recently, diffusion models have attracted great attention in
this field. However, these models neglect the latent distribution in a
lower-dimensional space derived from the observed data, which limits the
generative capacity of the diffusion model. Additionally, dealing with the
original missing data without labels becomes particularly problematic. To
address these issues, we propose the Latent Space Score-Based Diffusion Model
(LSSDM) for probabilistic multivariate time series imputation. Observed values
are projected onto low-dimensional latent space and coarse values of the
missing data are reconstructed without knowing their ground truth values by
this unsupervised learning approach. Finally, the reconstructed values are fed
into a conditional diffusion model to obtain the precise imputed values of the
time series. In this way, LSSDM not only possesses the power to identify the
latent distribution but also seamlessly integrates the diffusion model to
obtain the high-fidelity imputed values and assess the uncertainty of the
dataset. Experimental results demonstrate that LSSDM achieves superior
imputation performance while also providing a better explanation and
uncertainty analysis of the imputation mechanism. The website of the code is
\textit{https://github.com/gorgen2020/LSSDM\_imputation}.",http://arxiv.org/pdf/2409.08917v1,
Latent Diffusion Models for Controllable RNA Sequence Generation,15/09/2024,"Kaixuan Huang, Yukang Yang, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang","This work presents RNAdiffusion, a latent diffusion model for generating and
optimizing discrete RNA sequences of variable lengths. RNA is a key
intermediary between DNA and protein, exhibiting high sequence diversity and
complex three-dimensional structures to support a wide range of functions. We
utilize pretrained BERT-type models to encode raw RNA sequences into
token-level, biologically meaningful representations. A Query Transformer is
employed to compress such representations into a set of fixed-length latent
vectors, with an autoregressive decoder trained to reconstruct RNA sequences
from these latent variables. We then develop a continuous diffusion model
within this latent space. To enable optimization, we integrate the gradients of
reward models--surrogates for RNA functional properties--into the backward
diffusion process, thereby generating RNAs with high reward scores. Empirical
results confirm that RNAdiffusion generates non-coding RNAs that align with
natural distributions across various biological metrics. Further, we fine-tune
the diffusion model on mRNA 5' untranslated regions (5'-UTRs) and optimize
sequences for high translation efficiencies. Our guided diffusion model
effectively generates diverse 5'-UTRs with high Mean Ribosome Loading (MRL) and
Translation Efficiency (TE), outperforming baselines in balancing rewards and
structural stability trade-off. Our findings hold potential for advancing RNA
sequence-function research and therapeutic RNA design.",http://arxiv.org/pdf/2409.09828v2,
Latent mixed-effect models for high-dimensional longitudinal data,17/09/2024,"Priscilla Ong, Manuel Haußmann, Otto Lönnroth, Harri Lähdesmäki","Modelling longitudinal data is an important yet challenging task. These
datasets can be high-dimensional, contain non-linear effects and time-varying
covariates. Gaussian process (GP) prior-based variational autoencoders (VAEs)
have emerged as a promising approach due to their ability to model time-series
data. However, they are costly to train and struggle to fully exploit the rich
covariates characteristic of longitudinal data, making them difficult for
practitioners to use effectively. In this work, we leverage linear mixed models
(LMMs) and amortized variational inference to provide conditional priors for
VAEs, and propose LMM-VAE, a scalable, interpretable and identifiable model. We
highlight theoretical connections between it and GP-based techniques, providing
a unified framework for this class of methods. Our proposal performs
competitively compared to existing approaches across simulated and real-world
datasets.",http://arxiv.org/pdf/2409.11008v1,
DiffESM: Conditional Emulation of Temperature and Precipitation in Earth System Models with 3D Diffusion Models,17/09/2024,"Seth Bassetti, Brian Hutchinson, Claudia Tebaldi, Ben Kravitz","Earth System Models (ESMs) are essential for understanding the interaction
between human activities and the Earth's climate. However, the computational
demands of ESMs often limit the number of simulations that can be run,
hindering the robust analysis of risks associated with extreme weather events.
While low-cost climate emulators have emerged as an alternative to emulate ESMs
and enable rapid analysis of future climate, many of these emulators only
provide output on at most a monthly frequency. This temporal resolution is
insufficient for analyzing events that require daily characterization, such as
heat waves or heavy precipitation. We propose using diffusion models, a class
of generative deep learning models, to effectively downscale ESM output from a
monthly to a daily frequency. Trained on a handful of ESM realizations,
reflecting a wide range of radiative forcings, our DiffESM model takes monthly
mean precipitation or temperature as input, and is capable of producing daily
values with statistical characteristics close to ESM output. Combined with a
low-cost emulator providing monthly means, this approach requires only a small
fraction of the computational resources needed to run a large ensemble. We
evaluate model behavior using a number of extreme metrics, showing that DiffESM
closely matches the spatio-temporal behavior of the ESM output it emulates in
terms of the frequency and spatial characteristics of phenomena such as heat
waves, dry spells, or rainfall intensity.",http://arxiv.org/pdf/2409.11601v1,
Topological Deep Learning with State-Space Models: A Mamba Approach for Simplicial Complexes,18/09/2024,"Marco Montagna, Simone Scardapane, Lev Telyatnikov","Graph Neural Networks based on the message-passing (MP) mechanism are a
dominant approach for handling graph-structured data. However, they are
inherently limited to modeling only pairwise interactions, making it difficult
to explicitly capture the complexity of systems with $n$-body relations. To
address this, topological deep learning has emerged as a promising field for
studying and modeling higher-order interactions using various topological
domains, such as simplicial and cellular complexes. While these new domains
provide powerful representations, they introduce new challenges, such as
effectively modeling the interactions among higher-order structures through
higher-order MP. Meanwhile, structured state-space sequence models have proven
to be effective for sequence modeling and have recently been adapted for graph
data by encoding the neighborhood of a node as a sequence, thereby avoiding the
MP mechanism. In this work, we propose a novel architecture designed to operate
with simplicial complexes, utilizing the Mamba state-space model as its
backbone. Our approach generates sequences for the nodes based on the
neighboring cells, enabling direct communication between all higher-order
structures, regardless of their rank. We extensively validate our model,
demonstrating that it achieves competitive performance compared to
state-of-the-art models developed for simplicial complexes.",http://arxiv.org/pdf/2409.12033v1,
Revisiting Synthetic Human Trajectories: Imitative Generation and Benchmarks Beyond Datasaurus,20/09/2024,"Bangchao Deng, Xin Jing, Tianyue Yang, Bingqing Qu, Philippe Cudre-Mauroux, Dingqi Yang","Human trajectory data, which plays a crucial role in various applications
such as crowd management and epidemic prevention, is challenging to obtain due
to practical constraints and privacy concerns. In this context, synthetic human
trajectory data is generated to simulate as close as possible to real-world
human trajectories, often under summary statistics and distributional
similarities. However, the complexity of human mobility patterns is
oversimplified by these similarities (a.k.a. ``Datasaurus''), resulting in
intrinsic biases in both generative model design and benchmarks of the
generated trajectories. Against this background, we propose MIRAGE, a
huMan-Imitative tRAjectory GenErative model designed as a neural Temporal Point
Process integrating an Exploration and Preferential Return model. It imitates
the human decision-making process in trajectory generation, rather than fitting
any specific statistical distributions as traditional methods do, thus avoiding
the Datasaurus issue. Moreover, we also propose a comprehensive task-based
evaluation protocol beyond Datasaurus to systematically benchmark trajectory
generative models on four typical downstream tasks, integrating multiple
techniques and evaluation metrics for each task, to comprehensively assess the
ultimate utility of the generated trajectories. We conduct a thorough
evaluation of MIRAGE on three real-world user trajectory datasets against a
sizeable collection of baselines. Results show that compared to the best
baselines, MIRAGE-generated trajectory data not only achieves the best
statistical and distributional similarities with 59.0-71.5% improvement, but
also yields the best performance in the task-based evaluation with 10.9-33.4%
improvement.",http://arxiv.org/pdf/2409.13790v1,
Towards Long-Context Time Series Foundation Models,20/09/2024,"Nina Żukowska, Mononito Goswami, Michał Wiliński, Willa Potosnak, Artur Dubrawski","Time series foundation models have shown impressive performance on a variety
of tasks, across a wide range of domains, even in zero-shot settings. However,
most of these models are designed to handle short univariate time series as an
input. This limits their practical use, especially in domains such as
healthcare with copious amounts of long and multivariate data with strong
temporal and intra-variate dependencies. Our study bridges this gap by
cataloging and systematically comparing various context expansion techniques
from both language and time series domains, and introducing a novel compressive
memory mechanism to allow encoder-only TSFMs to effectively model intra-variate
dependencies. We demonstrate the benefits of our approach by imbuing MOMENT, a
recent family of multi-task time series foundation models, with the
multivariate context.",http://arxiv.org/pdf/2409.13530v1,
A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics,20/09/2024,"Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai","Understanding the structure and motion of the heart is crucial for diagnosing
and managing cardiovascular diseases, the leading cause of global death. There
is wide variation in cardiac shape and motion patterns, that are influenced by
demographic, anthropometric and disease factors. Unravelling the normal
patterns of shape and motion, as well as understanding how each individual
deviates from the norm, would facilitate accurate diagnosis and personalised
treatment strategies. To this end, we developed a novel conditional generative
model, MeshHeart, to learn the distribution of cardiac shape and motion
patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences,
taking into account clinical factors such as age, sex, weight and height. To
model the high-dimensional and complex spatio-temporal mesh data, MeshHeart
employs a geometric encoder to represent cardiac meshes in a latent space,
followed by a temporal Transformer to model the motion dynamics of latent
representations. Based on MeshHeart, we investigate the latent space of 3D+t
cardiac mesh sequences and propose a novel distance metric termed latent delta,
which quantifies the deviation of a real heart from its personalised normative
pattern in the latent space. In experiments using a large dataset of 38,309
subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence
reconstruction and generation. Features defined in the latent space are highly
discriminative for cardiac disease classification, whereas the latent delta
exhibits strong correlation with clinical phenotypes in phenome-wide
association studies. The codes and models of this study will be released to
benefit further research on digital heart modelling.",http://arxiv.org/pdf/2409.13825v1,
High-Resolution Flood Probability Mapping Using Generative Machine Learning with Large-Scale Synthetic Precipitation and Inundation Data,20/09/2024,"Lipai Huang, Federico Antolini, Ali Mostafavi, Russell Blessing, Matthew Garcia, Samuel D. Brody","High-resolution flood probability maps are essential for addressing the
limitations of existing flood risk assessment approaches but are often limited
by the availability of historical event data. Also, producing simulated data
needed for creating probabilistic flood maps using physics-based models
involves significant computation and time effort inhibiting the feasibility. To
address this gap, this study introduces Flood-Precip GAN (Flood-Precipitation
Generative Adversarial Network), a novel methodology that leverages generative
machine learning to simulate large-scale synthetic inundation data to produce
probabilistic flood maps. With a focus on Harris County, Texas, Flood-Precip
GAN begins with training a cell-wise depth estimator using a limited number of
physics-based model-generated precipitation-flood events. This model, which
emphasizes precipitation-based features, outperforms universal models.
Subsequently, a Generative Adversarial Network (GAN) with constraints is
employed to conditionally generate synthetic precipitation records. Strategic
thresholds are established to filter these records, ensuring close alignment
with true precipitation patterns. For each cell, synthetic events are smoothed
using a K-nearest neighbors algorithm and processed through the depth estimator
to derive synthetic depth distributions. By iterating this procedure and after
generating 10,000 synthetic precipitation-flood events, we construct flood
probability maps in various formats, considering different inundation depths.
Validation through similarity and correlation metrics confirms the fidelity of
the synthetic depth distributions relative to true data. Flood-Precip GAN
provides a scalable solution for generating synthetic flood depth data needed
to create high-resolution flood probability maps, significantly enhancing flood
preparedness and mitigation efforts.",http://arxiv.org/pdf/2409.13936v1,
ChronoGAN: Supervised and Embedded Generative Adversarial Networks for Time Series Generation,21/09/2024,"MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi","Generating time series data using Generative Adversarial Networks (GANs)
presents several prevalent challenges, such as slow convergence, information
loss in embedding spaces, instability, and performance variability depending on
the series length. To tackle these obstacles, we introduce a robust framework
aimed at addressing and mitigating these issues effectively. This advanced
framework integrates the benefits of an Autoencoder-generated embedding space
with the adversarial training dynamics of GANs. This framework benefits from a
time series-based loss function and oversight from a supervisory network, both
of which capture the stepwise conditional distributions of the data
effectively. The generator functions within the latent space, while the
discriminator offers essential feedback based on the feature space. Moreover,
we introduce an early generation algorithm and an improved neural network
architecture to enhance stability and ensure effective generalization across
both short and long time series. Through joint training, our framework
consistently outperforms existing benchmarks, generating high-quality time
series data across a range of real and synthetic datasets with diverse
characteristics.",http://arxiv.org/pdf/2409.14013v1,
Implicit Dynamical Flow Fusion (IDFF) for Generative Modeling,22/09/2024,"Mohammad R. Rezaei, Rahul G. Krishnan, Milos R. Popovic, Milad Lankarany","Conditional Flow Matching (CFM) models can generate high-quality samples from
a non-informative prior, but they can be slow, often needing hundreds of
network evaluations (NFE). To address this, we propose Implicit Dynamical Flow
Fusion (IDFF); IDFF learns a new vector field with an additional momentum term
that enables taking longer steps during sample generation while maintaining the
fidelity of the generated distribution. Consequently, IDFFs reduce the NFEs by
a factor of ten (relative to CFMs) without sacrificing sample quality, enabling
rapid sampling and efficient handling of image and time-series data generation
tasks. We evaluate IDFF on standard benchmarks such as CIFAR-10 and CelebA for
image generation, where we achieve likelihood and quality performance
comparable to CFMs and diffusion-based models with fewer NFEs. IDFF also shows
superior performance on time-series datasets modeling, including molecular
simulation and sea surface temperature (SST) datasets, highlighting its
versatility and effectiveness across different
domains.\href{https://github.com/MrRezaeiUofT/IDFF}{Github Repository}",http://arxiv.org/pdf/2409.14599v3,
EMIT- Event-Based Masked Auto Encoding for Irregular Time Series,25/09/2024,"Hrishikesh Patel, Ruihong Qiu, Adam Irwin, Shazia Sadiq, Sen Wang","Irregular time series, where data points are recorded at uneven intervals,
are prevalent in healthcare settings, such as emergency wards where vital signs
and laboratory results are captured at varying times. This variability, which
reflects critical fluctuations in patient health, is essential for informed
clinical decision-making. Existing self-supervised learning research on
irregular time series often relies on generic pretext tasks like forecasting,
which may not fully utilise the signal provided by irregular time series. There
is a significant need for specialised pretext tasks designed for the
characteristics of irregular time series to enhance model performance and
robustness, especially in scenarios with limited data availability. This paper
proposes a novel pretraining framework, EMIT, an event-based masking for
irregular time series. EMIT focuses on masking-based reconstruction in the
latent space, selecting masking points based on the rate of change in the data.
This method preserves the natural variability and timing of measurements while
enhancing the model's ability to process irregular intervals without losing
essential information. Extensive experiments on the MIMIC-III and PhysioNet
Challenge datasets demonstrate the superior performance of our event-based
masking strategy. The code has been released at
https://github.com/hrishi-ds/EMIT.",http://arxiv.org/pdf/2409.16554v2,
Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification,25/09/2024,"Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni","In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.",http://arxiv.org/pdf/2409.17091v1,
Generative Modeling of Molecular Dynamics Trajectories,26/09/2024,"Bowen Jing, Hannes Stärk, Tommi Jaakkola, Bonnie Berger","Molecular dynamics (MD) is a powerful technique for studying microscopic
phenomena, but its computational cost has driven significant interest in the
development of deep learning-based surrogate models. We introduce generative
modeling of molecular trajectories as a paradigm for learning flexible
multi-task surrogate models of MD from data. By conditioning on appropriately
chosen frames of the trajectory, we show such generative models can be adapted
to diverse tasks such as forward simulation, transition path sampling, and
trajectory upsampling. By alternatively conditioning on part of the molecular
system and inpainting the rest, we also demonstrate the first steps towards
dynamics-conditioned molecular design. We validate the full set of these
capabilities on tetrapeptide simulations and show that our model can produce
reasonable ensembles of protein monomers. Altogether, our work illustrates how
generative modeling can unlock value from MD data towards diverse downstream
tasks that are not straightforward to address with existing methods or even MD
itself. Code is available at https://github.com/bjing2016/mdgen.",http://arxiv.org/pdf/2409.17808v1,
Ordinary Differential Equations for Enhanced 12-Lead ECG Generation,26/09/2024,"Yakir Yehuda, Kira Radinsky","In the realm of artificial intelligence, the generation of realistic training
data for supervised learning tasks presents a significant challenge. This is
particularly true in the synthesis of electrocardiograms (ECGs), where the
objective is to develop a synthetic 12-lead ECG model. The primary complexity
of this task stems from accurately modeling the intricate biological and
physiological interactions among different ECG leads. Although mathematical
process simulators have shed light on these dynamics, effectively incorporating
this understanding into generative models is not straightforward. In this work,
we introduce an innovative method that employs ordinary differential equations
(ODEs) to enhance the fidelity of generating 12-lead ECG data. This approach
integrates a system of ODEs that represent cardiac dynamics directly into the
generative model's optimization process, allowing for the production of
biologically plausible ECG training data that authentically reflects real-world
variability and inter-lead dependencies. We conducted an empirical analysis of
thousands of ECGs and found that incorporating cardiac simulation insights into
the data generation process significantly improves the accuracy of heart
abnormality classifiers trained on this synthetic 12-lead ECG data.",http://arxiv.org/pdf/2409.17833v1,
Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks,27/09/2024,"Richard Osuala, Smriti Joshi, Apostolia Tsirikoglou, Lidia Garrucho, Walter H. L. Pinaya, Daniel M. Lang, Julia A. Schnabel, Oliver Diaz, Karim Lekadir","This paper presents a method for virtual contrast enhancement in breast MRI,
offering a promising non-invasive alternative to traditional contrast
agent-based DCE-MRI acquisition. Using a conditional generative adversarial
network, we predict DCE-MRI images, including jointly-generated sequences of
multiple corresponding DCE-MRI timepoints, from non-contrast-enhanced MRIs,
enabling tumor localization and characterization without the associated health
risks. Furthermore, we qualitatively and quantitatively evaluate the synthetic
DCE-MRI images, proposing a multi-metric Scaled Aggregate Measure (SAMe),
assessing their utility in a tumor segmentation downstream task, and conclude
with an analysis of the temporal patterns in multi-sequence DCE-MRI generation.
Our approach demonstrates promising results in generating realistic and useful
DCE-MRI sequences, highlighting the potential of virtual contrast enhancement
for improving breast cancer diagnosis and treatment, particularly for patients
where contrast agent administration is contraindicated.",http://arxiv.org/pdf/2409.18872v1,
Stream-level flow matching from a Bayesian decision theoretic perspective,30/09/2024,"Ganchao Wei, Li Ma","Flow matching (FM) is a family of training algorithms for fitting continuous
normalizing flows (CNFs). A standard approach to FM, called conditional flow
matching (CFM), exploits the fact that the marginal vector field of a CNF can
be learned by fitting least-square regression to the so-called conditional
vector field specified given one or both ends of the flow path. We show that
viewing CFM training from a Bayesian decision theoretic perspective on
parameter estimation opens the door to generalizations of CFM algorithms. We
propose one such extension by introducing a CFM algorithm based on defining
conditional probability paths given what we refer to as ``streams'', instances
of latent stochastic paths that connect pairs of noise and observed data.
Further, we advocate the modeling of these latent streams using Gaussian
processes (GPs). The unique distributional properties of GPs, and in particular
the fact that the velocity of a GP is still a GP, allows drawing samples from
the resulting stream-augmented conditional probability path without simulating
the actual streams, and hence the ``simulation-free"" nature of CFM training is
preserved. We show that this generalization of the CFM can substantially reduce
the variance in the estimated marginal vector field at a moderate computational
cost, thereby improving the quality of the generated samples under common
metrics. Additionally, we show that adopting the GP on the streams allows for
flexibly linking multiple related training data points (e.g., time series) and
incorporating additional prior information. We empirically validate our claim
through both simulations and applications to two hand-written image datasets.",http://arxiv.org/pdf/2409.20423v4,
Restoring Super-High Resolution GPS Mobility Data,01/10/2024,"Haruki Yonekura, Ren Ozeki, Hamada Rizk, Hirozumi Yamaguchi","This paper presents a novel system for reconstructing high-resolution GPS
trajectory data from truncated or synthetic low-resolution inputs, addressing
the critical challenge of balancing data utility with privacy preservation in
mobility applications. The system integrates transformer-based encoder-decoder
models with graph convolutional networks (GCNs) to effectively capture both the
temporal dependencies of trajectory data and the spatial relationships in road
networks. By combining these techniques, the system is able to recover
fine-grained trajectory details that are lost through data truncation or
rounding, a common practice to protect user privacy. We evaluate the system on
the Beijing trajectory dataset, demonstrating its superior performance over
traditional map-matching algorithms and LSTM-based synthetic data generation
methods. The proposed model achieves an average Fr\'echet distance of 0.198 km,
significantly outperforming map-matching algorithms (0.632 km) and synthetic
trajectory models (0.498 km). The results show that the system is not only
capable of accurately reconstructing real-world trajectories but also
generalizes effectively to synthetic data. These findings suggest that the
system can be deployed in urban mobility applications, providing both high
accuracy and robust privacy protection.",http://arxiv.org/pdf/2410.12818v1,
GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset,02/10/2024,"Hossein Amiri, Richard Yang, Andreas Zufle","Analyzing individual human trajectory data helps our understanding of human
mobility and finds many commercial and academic applications. There are two
main approaches to accessing trajectory data for research: one involves using
real-world datasets like GeoLife, while the other employs simulations to
synthesize data. Real-world data provides insights from real human activities,
but such data is generally sparse due to voluntary participation. Conversely,
simulated data can be more comprehensive but may capture unrealistic human
behavior. In this Data and Resource paper, we combine the benefit of both by
leveraging the statistical features of real-world data and the
comprehensiveness of simulated data. Specifically, we extract features from the
real-world GeoLife dataset such as the average number of individual daily
trips, average radius of gyration, and maximum and minimum trip distances. We
calibrate the Pattern of Life Simulation, a realistic simulation of human
mobility, to reproduce these features. Therefore, we use a genetic algorithm to
calibrate the parameters of the simulation to mimic the GeoLife features. For
this calibration, we simulated numerous random simulation settings, measured
the similarity of generated trajectories to GeoLife, and iteratively (over many
generations) combined parameter settings of trajectory datasets most similar to
GeoLife. Using the calibrated simulation, we simulate large trajectory datasets
that we call GeoLife+, where + denotes the Kleene Plus, indicating unlimited
replication with at least one occurrence. We provide simulated GeoLife+ data
with 182, 1k, and 5k over 5 years, 10k, and 50k over a year and 100k users over
6 months of simulation lifetime.",http://arxiv.org/pdf/2410.11853v1,
FutureFill: Fast Generation from Convolutional Sequence Models,02/10/2024,"Naman Agarwal, Xinyi Chen, Evan Dogariu, Vlad Feinberg, Daniel Suo, Peter Bartlett, Elad Hazan","We address the challenge of efficient auto-regressive generation in sequence
prediction models by introducing FutureFill - a method for fast generation that
applies to any sequence prediction algorithm based on convolutional operators.
Our approach reduces the generation time requirement from quadratic to
quasilinear relative to the context length. Additionally, FutureFill requires a
prefill cache sized only by the number of tokens generated, which is smaller
than the cache requirements for standard convolutional and attention-based
models. We validate our theoretical findings with experimental evidence
demonstrating correctness and efficiency gains in a synthetic generation task.",http://arxiv.org/pdf/2410.03766v2,
PerTok: Expressive Encoding and Modeling of Symbolic Musical Ideas and Variations,02/10/2024,"Julian Lenz, Anirudh Mani","We introduce Cadenza, a new multi-stage generative framework for predicting
expressive variations of symbolic musical ideas as well as unconditional
generations. To accomplish this we propose a novel MIDI encoding method, PerTok
(Performance Tokenizer) that captures minute expressive details whilst reducing
sequence length up to 59% and vocabulary size up to 95% for polyphonic,
monophonic and rhythmic tasks. The proposed framework comprises of two
sequential stages: 1) Composer and 2) Performer. The Composer model is a
transformer-based Variational Autoencoder (VAE), with Rotary Positional
Embeddings (RoPE)ROPE and an autoregressive decoder modified to more
effectively integrate the latent codes of the input musical idea. The Performer
model is a bidirectional transformer encoder that is separately trained to
predict velocities and microtimings on MIDI sequences. Objective and human
evaluations demonstrate Cadenza's versatile capability in 1) matching other
unconditional state-of-the-art symbolic models in musical quality whilst
sounding more expressive, and 2) composing new, expressive ideas that are both
stylistically related to the input whilst providing novel ideas to the user.
Our framework is designed, researched and implemented with the objective of
ethically providing inspiration for musicians.",http://arxiv.org/pdf/2410.02060v1,
TPP-LLM: Modeling Temporal Point Processes by Efficiently Fine-Tuning Large Language Models,02/10/2024,"Zefang Liu, Yinzhu Quan","Temporal point processes (TPPs) are widely used to model the timing and
occurrence of events in domains such as social networks, transportation
systems, and e-commerce. In this paper, we introduce TPP-LLM, a novel framework
that integrates large language models (LLMs) with TPPs to capture both the
semantic and temporal aspects of event sequences. Unlike traditional methods
that rely on categorical event type representations, TPP-LLM directly utilizes
the textual descriptions of event types, enabling the model to capture rich
semantic information embedded in the text. While LLMs excel at understanding
event semantics, they are less adept at capturing temporal patterns. To address
this, TPP-LLM incorporates temporal embeddings and employs parameter-efficient
fine-tuning (PEFT) methods to effectively learn temporal dynamics without
extensive retraining. This approach improves both predictive accuracy and
computational efficiency. Experimental results across diverse real-world
datasets demonstrate that TPP-LLM outperforms state-of-the-art baselines in
sequence modeling and event prediction, highlighting the benefits of combining
LLMs with TPPs.",http://arxiv.org/pdf/2410.02062v1,
CaLMFlow: Volterra Flow Matching using Causal Language Models,03/10/2024,"Sizhuang He, Daniel Levine, Ivan Vrkic, Marco Francesco Bressana, David Zhang, Syed Asad Rizvi, Yangtian Zhang, Emanuele Zappala, David van Dijk","We introduce CaLMFlow (Causal Language Models for Flow Matching), a novel
framework that casts flow matching as a Volterra integral equation (VIE),
leveraging the power of large language models (LLMs) for continuous data
generation. CaLMFlow enables the direct application of LLMs to learn complex
flows by formulating flow matching as a sequence modeling task, bridging
discrete language modeling and continuous generative modeling. Our method
implements tokenization across space and time, thereby solving a VIE over these
domains. This approach enables efficient handling of high-dimensional data and
outperforms ODE solver-dependent methods like conditional flow matching (CFM).
We demonstrate CaLMFlow's effectiveness on synthetic and real-world data,
including single-cell perturbation response prediction, showcasing its ability
to incorporate textual context and generalize to unseen conditions. Our results
highlight LLM-driven flow matching as a promising paradigm in generative
modeling, offering improved scalability, flexibility, and context-awareness.",http://arxiv.org/pdf/2410.05292v1,
Diffusion Meets Options: Hierarchical Generative Skill Composition for Temporally-Extended Tasks,03/10/2024,"Zeyu Feng, Hao Luan, Kevin Yuchen Ma, Harold Soh","Safe and successful deployment of robots requires not only the ability to
generate complex plans but also the capacity to frequently replan and correct
execution errors. This paper addresses the challenge of long-horizon trajectory
planning under temporally extended objectives in a receding horizon manner. To
this end, we propose DOPPLER, a data-driven hierarchical framework that
generates and updates plans based on instruction specified by linear temporal
logic (LTL). Our method decomposes temporal tasks into chain of options with
hierarchical reinforcement learning from offline non-expert datasets. It
leverages diffusion models to generate options with low-level actions. We
devise a determinantal-guided posterior sampling technique during batch
generation, which improves the speed and diversity of diffusion generated
options, leading to more efficient querying. Experiments on robot navigation
and manipulation tasks demonstrate that DOPPLER can generate sequences of
trajectories that progressively satisfy the specified formulae for obstacle
avoidance and sequential visitation. Demonstration videos are available online
at: https://philiptheother.github.io/doppler/.",http://arxiv.org/pdf/2410.02389v1,
Predictive Attractor Models,03/10/2024,"Ramy Mounir, Sudeep Sarkar","Sequential memory, the ability to form and accurately recall a sequence of
events or stimuli in the correct order, is a fundamental prerequisite for
biological and artificial intelligence as it underpins numerous cognitive
functions (e.g., language comprehension, planning, episodic memory formation,
etc.) However, existing methods of sequential memory suffer from catastrophic
forgetting, limited capacity, slow iterative learning procedures, low-order
Markov memory, and, most importantly, the inability to represent and generate
multiple valid future possibilities stemming from the same context. Inspired by
biologically plausible neuroscience theories of cognition, we propose
\textit{Predictive Attractor Models (PAM)}, a novel sequence memory
architecture with desirable generative properties. PAM is a streaming model
that learns a sequence in an online, continuous manner by observing each input
\textit{only once}. Additionally, we find that PAM avoids catastrophic
forgetting by uniquely representing past context through lateral inhibition in
cortical minicolumns, which prevents new memories from overwriting previously
learned knowledge. PAM generates future predictions by sampling from a union
set of predicted possibilities; this generative ability is realized through an
attractor model trained alongside the predictor. We show that PAM is trained
with local computations through Hebbian plasticity rules in a biologically
plausible framework. Other desirable traits (e.g., noise tolerance, CPU-based
learning, capacity scaling) are discussed throughout the paper. Our findings
suggest that PAM represents a significant step forward in the pursuit of
biologically plausible and computationally efficient sequential memory models,
with broad implications for cognitive science and artificial intelligence
research.",http://arxiv.org/pdf/2410.02430v1,
Local Flow Matching Generative Models,03/10/2024,"Chen Xu, Xiuyuan Cheng, Yao Xie","Flow Matching (FM) is a simulation-free method for learning a continuous and
invertible flow to interpolate between two distributions, and in particular to
generate data from noise in generative modeling. In this paper, we introduce
Local Flow Matching (LFM), which learns a sequence of FM sub-models and each
matches a diffusion process up to the time of the step size in the
data-to-noise direction. In each step, the two distributions to be interpolated
by the sub-model are closer to each other than data vs. noise, and this enables
the use of smaller models with faster training. The stepwise structure of LFM
is natural to be distilled and different distillation techniques can be adopted
to speed up generation. Theoretically, we prove a generation guarantee of the
proposed flow model in terms of the $\chi^2$-divergence between the generated
and true data distributions. In experiments, we demonstrate the improved
training efficiency and competitive generative performance of LFM compared to
FM on the unconditional generation of tabular data and image datasets, and also
on the conditional generation of robotic manipulation policies.",http://arxiv.org/pdf/2410.02548v1,
Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting,03/10/2024,"Marcel Kollovieh, Marten Lienen, David Lüdke, Leo Schwinn, Stephan Günnemann","Recent advancements in generative modeling, particularly diffusion models,
have opened new directions for time series modeling, achieving state-of-the-art
performance in forecasting and synthesis. However, the reliance of
diffusion-based models on a simple, fixed prior complicates the generative
process since the data and prior distributions differ significantly. We
introduce TSFlow, a conditional flow matching (CFM) model for time series that
simplifies the generative problem by combining Gaussian processes, optimal
transport paths, and data-dependent prior distributions. By incorporating
(conditional) Gaussian processes, TSFlow aligns the prior distribution more
closely with the temporal structure of the data, enhancing both unconditional
and conditional generation. Furthermore, we propose conditional prior sampling
to enable probabilistic forecasting with an unconditionally trained model. In
our experimental evaluation on eight real-world datasets, we demonstrate the
generative capabilities of TSFlow, producing high-quality unconditional
samples. Finally, we show that both conditionally and unconditionally trained
models achieve competitive results in forecasting benchmarks, surpassing other
methods on 6 out of 8 datasets.",http://arxiv.org/pdf/2410.03024v1,
S7: Selective and Simplified State Space Layers for Sequence Modeling,04/10/2024,"Taylan Soydan, Nikola Zubić, Nico Messikommer, Siddhartha Mishra, Davide Scaramuzza","A central challenge in sequence modeling is efficiently handling tasks with
extended contexts. While recent state-space models (SSMs) have made significant
progress in this area, they often lack input-dependent filtering or require
substantial increases in model complexity to handle input variability. We
address this gap by introducing S7, a simplified yet powerful SSM that can
handle input dependence while incorporating stable reparameterization and
specific design choices to dynamically adjust state transitions based on input
content, maintaining efficiency and performance. We prove that this
reparameterization ensures stability in long-sequence modeling by keeping state
transitions well-behaved over time. Additionally, it controls the gradient
norm, enabling efficient training and preventing issues like exploding or
vanishing gradients. S7 significantly outperforms baselines across various
sequence modeling tasks, including neuromorphic event-based datasets, Long
Range Arena benchmarks, and various physical and biological time series.
Overall, S7 offers a more straightforward approach to sequence modeling without
relying on complex, domain-specific inductive biases, achieving significant
improvements across key benchmarks.",http://arxiv.org/pdf/2410.03464v1,
Compositional Diffusion Models for Powered Descent Trajectory Generation with Flexible Constraints,05/10/2024,"Julia Briden, Yilun Du, Enrico M. Zucchelli, Richard Linares","This work introduces TrajDiffuser, a compositional diffusion-based flexible
and concurrent trajectory generator for 6 degrees of freedom powered descent
guidance. TrajDiffuser is a statistical model that learns the multi-modal
distributions of a dataset of simulated optimal trajectories, each subject to
only one or few constraints that may vary for different trajectories. During
inference, the trajectory is generated simultaneously over time, providing
stable long-horizon planning, and constraints can be composed together,
increasing the model's generalizability and decreasing the training data
required. The generated trajectory is then used to initialize an optimizer,
increasing its robustness and speed.",http://arxiv.org/pdf/2410.04261v1,
Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data,07/10/2024,"Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz","In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.",http://arxiv.org/pdf/2410.04814v1,
"SPikE-SSM: A Sparse, Precise, and Efficient Spiking State Space Model for Long Sequences Learning",07/10/2024,"Yan Zhong, Ruoyu Zhao, Chao Wang, Qinghai Guo, Jianguo Zhang, Zhichao Lu, Luziwei Leng","Spiking neural networks (SNNs) provide an energy-efficient solution by
utilizing the spike-based and sparse nature of biological systems. Since the
advent of Transformers, SNNs have struggled to compete with artificial networks
on long sequential tasks, until the recent emergence of state space models
(SSMs), which offer superior computational efficiency and modeling capability.
However, applying the highly capable SSMs to SNNs for long sequences learning
poses three major challenges: (1) The membrane potential is determined by the
past spiking history of the neuron, leading to reduced efficiency for sequence
modeling in parallel computing scenarios. (2) Complex dynamics of biological
spiking neurons are crucial for functionality but challenging to simulate and
exploit effectively in large networks. (3) It is arduous to maintain high
sparsity while achieving high accuracy for spiking neurons without resorting to
dense computing, as utilized in artificial neuron-based SSMs. To address them,
we propose a sparse, precise and efficient spiking SSM framework, termed
SPikE-SSM. For (1), we propose a boundary compression strategy (PMBC) to
accelerate the inference of the spiking neuron model, enabling parallel
processing for long sequence learning. For (2), we propose a novel and concise
neuron model incorporating reset-refractory mechanism to leverage the inherent
temporal dimension for dynamic computing with biological interpretability. For
(3), we hierarchically integrate the proposed neuron model to the original SSM
block, and enhance the dynamics of SPikE-SSM by incorporating trainable
thresholds and refractory magnitudes to balance accuracy and sparsity.
Extensive experiments verify the effectiveness and robustness of SPikE-SSM on
the long range arena benchmarks and large language dataset WikiText-103,
showing the potential of dynamic spiking neurons in efficient long sequence
learning.",http://arxiv.org/pdf/2410.17268v1,
Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series,08/10/2024,"Byoungwoo Park, Hyungi Lee, Juho Lee","Many real-world datasets, such as healthcare, climate, and economics, are
often collected as irregular time series, which poses challenges for accurate
modeling. In this paper, we propose the Amortized Control of continuous State
Space Model (ACSSM) for continuous dynamical modeling of time series for
irregular and discrete observations. We first present a multi-marginal Doob's
$h$-transform to construct a continuous dynamical system conditioned on these
irregular observations. Following this, we introduce a variational inference
algorithm with a tight evidence lower bound (ELBO), leveraging stochastic
optimal control (SOC) theory to approximate the intractable Doob's
$h$-transform and simulate the conditioned dynamics. To improve efficiency and
scalability during both training and inference, ACSSM employs amortized
inference to decouple representation learning from the latent dynamics.
Additionally, it incorporates a simulation-free latent dynamics framework and a
transformer-based data assimilation scheme, facilitating parallel inference of
the latent states and ELBO computation. Through empirical evaluations across a
variety of real-world datasets, ACSSM demonstrates superior performance in
tasks such as classification, regression, interpolation, and extrapolation,
while maintaining computational efficiency.",http://arxiv.org/pdf/2410.05602v1,
Federated Neural Nonparametric Point Processes,08/10/2024,"Hui Chen, Hengyu Liu, Yaqiong Li, Xuhui Fan, Zhilin Zhao, Feng Zhou, Christopher John Quinn, Longbing Cao","Temporal point processes (TPPs) are effective for modeling event occurrences
over time, but they struggle with sparse and uncertain events in federated
systems, where privacy is a major concern. To address this, we propose
\textit{FedPP}, a Federated neural nonparametric Point Process model. FedPP
integrates neural embeddings into Sigmoidal Gaussian Cox Processes (SGCPs) on
the client side, which is a flexible and expressive class of TPPs, allowing it
to generate highly flexible intensity functions that capture client-specific
event dynamics and uncertainties while efficiently summarizing historical
records. For global aggregation, FedPP introduces a divergence-based mechanism
that communicates the distributions of SGCPs' kernel hyperparameters between
the server and clients, while keeping client-specific parameters local to
ensure privacy and personalization. FedPP effectively captures event
uncertainty and sparsity, and extensive experiments demonstrate its superior
performance in federated settings, particularly with KL divergence and
Wasserstein distance-based global aggregation.",http://arxiv.org/pdf/2410.05637v1,
EventFlow: Forecasting Continuous-Time Event Data with Flow Matching,09/10/2024,"Gavin Kerrigan, Kai Nelson, Padhraic Smyth","Continuous-time event sequences, in which events occur at irregular
intervals, are ubiquitous across a wide range of industrial and scientific
domains. The contemporary modeling paradigm is to treat such data as
realizations of a temporal point process, and in machine learning it is common
to model temporal point processes in an autoregressive fashion using a neural
network. While autoregressive models are successful in predicting the time of a
single subsequent event, their performance can be unsatisfactory in forecasting
longer horizons due to cascading errors. We propose EventFlow, a
non-autoregressive generative model for temporal point processes. Our model
builds on the flow matching framework in order to directly learn joint
distributions over event times, side-stepping the autoregressive process.
EventFlow is likelihood-free, easy to implement and sample from, and either
matches or surpasses the performance of state-of-the-art models in both
unconditional and conditional generation tasks on a set of standard benchmarks",http://arxiv.org/pdf/2410.07430v1,
Masked Generative Priors Improve World Models Sequence Modelling Capabilities,10/10/2024,"Cristian Meo, Mircea Lica, Zarif Ikram, Akihiro Nakano, Vedant Shah, Aniket Rajiv Didolkar, Dianbo Liu, Anirudh Goyal, Justin Dauwels","Deep Reinforcement Learning (RL) has become the leading approach for creating
artificial agents in complex environments. Model-based approaches, which are RL
methods with world models that predict environment dynamics, are among the most
promising directions for improving data efficiency, forming a critical step
toward bridging the gap between research and real-world deployment. In
particular, world models enhance sample efficiency by learning in imagination,
which involves training a generative sequence model of the environment in a
self-supervised manner. Recently, Masked Generative Modelling has emerged as a
more efficient and superior inductive bias for modelling and generating token
sequences. Building on the Efficient Stochastic Transformer-based World Models
(STORM) architecture, we replace the traditional MLP prior with a Masked
Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM. We evaluate our
model on two downstream tasks: reinforcement learning and video prediction.
GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari
100k benchmark. Moreover, we apply Transformer-based World Models to continuous
action environments for the first time, addressing a significant gap in prior
research. To achieve this, we employ a state mixer function that integrates
latent state representations with actions, enabling our model to handle
continuous control tasks. We validate this approach through qualitative and
quantitative analyses on the DeepMind Control Suite, showcasing the
effectiveness of Transformer-based World Models in this new domain. Our results
highlight the versatility and efficacy of the MaskGIT dynamics prior, paving
the way for more accurate world models and effective RL policies.",http://arxiv.org/pdf/2410.07836v4,
Variance-Hawkes Process and its Application to Energy Markets,10/10/2024,"Joshua McGillivray, Anatoliy Swishchuk","We define a new model using a Hawkes process as a subordinator in a standard
Brownian motion. We demonstrate that this Hawkes subordinated Brownian motion
or more succinctly, variance-Hawkes process can be fit to 2018 and 2019 natural
gas and crude oil front-month futures log returns. This variance-Hawkes process
allows financial models to easily have clustering effects encoded into their
behaviour in a simple and tractable way. We also compare the simulations of a
square of a variance Hawkes process with its Ito formula. We simulate both
processes and compare their distributions, trajectories, and percent errors
across multiple runs. We derive the generator relating to this Hawkes
subordinated Brownian motion, calculate several moments, and conjecture its
distribution. We also provide explicit solutions to the second moments of the
Hawkes process and its intensity as well as the cross moment between the Hawkes
process and its intensity in the case of an exponential kernel.",http://arxiv.org/pdf/2410.08420v1,
Generalizable autoregressive modeling of time series through functional narratives,10/10/2024,"Ran Liu, Wenrui Ma, Ellen Zippi, Hadi Pouransari, Jingyun Xiao, Chris Sandino, Behrooz Mahasseni, Juri Minxha, Erdrin Azemi, Eva L. Dyer, Ali Moin","Time series data are inherently functions of time, yet current transformers
often learn time series by modeling them as mere concatenations of time
periods, overlooking their functional properties. In this work, we propose a
novel objective for transformers that learn time series by re-interpreting them
as temporal functions. We build an alternative sequence of time series by
constructing degradation operators of different intensity in the functional
space, creating augmented variants of the original sample that are abstracted
or simplified to different degrees. Based on the new set of generated sequence,
we train an autoregressive transformer that progressively recovers the original
sample from the most simplified variant. Analogous to the next word prediction
task in languages that learns narratives by connecting different words, our
autoregressive transformer aims to learn the Narratives of Time Series (NoTS)
by connecting different functions in time. Theoretically, we justify the
construction of the alternative sequence through its advantages in
approximating functions. When learning time series data with transformers,
constructing sequences of temporal functions allows for a broader class of
approximable functions (e.g., differentiation) compared to sequences of time
periods, leading to a 26\% performance improvement in synthetic feature
regression experiments. Experimentally, we validate NoTS in 3 different tasks
across 22 real-world datasets, where we show that NoTS significantly
outperforms other pre-training methods by up to 6\%. Additionally, combining
NoTS on top of existing transformer architectures can consistently boost the
performance. Our results demonstrate the potential of NoTS as a general-purpose
dynamic learner, offering a viable alternative for developing foundation models
for time series analysis.",http://arxiv.org/pdf/2410.08421v1,
EquiJump: Protein Dynamics Simulation via SO(3)-Equivariant Stochastic Interpolants,12/10/2024,"Allan dos Santos Costa, Ilan Mitnikov, Franco Pellegrini, Ameya Daigavane, Mario Geiger, Zhonglin Cao, Karsten Kreis, Tess Smidt, Emine Kucukbenli, Joseph Jacobson","Mapping the conformational dynamics of proteins is crucial for elucidating
their functional mechanisms. While Molecular Dynamics (MD) simulation enables
detailed time evolution of protein motion, its computational toll hinders its
use in practice. To address this challenge, multiple deep learning models for
reproducing and accelerating MD have been proposed drawing on transport-based
generative methods. However, existing work focuses on generation through
transport of samples from prior distributions, that can often be distant from
the data manifold. The recently proposed framework of stochastic interpolants,
instead, enables transport between arbitrary distribution endpoints. Building
upon this work, we introduce EquiJump, a transferable SO(3)-equivariant model
that bridges all-atom protein dynamics simulation time steps directly. Our
approach unifies diverse sampling methods and is benchmarked against existing
models on trajectory data of fast folding proteins. EquiJump achieves
state-of-the-art results on dynamics simulation with a transferable model on
all of the fast folding proteins.",http://arxiv.org/pdf/2410.09667v2,
Can GANs Learn the Stylized Facts of Financial Time Series?,13/10/2024,"Sohyeon Kwon, Yongjae Lee","In the financial sector, a sophisticated financial time series simulator is
essential for evaluating financial products and investment strategies.
Traditional back-testing methods have mainly relied on historical data-driven
approaches or mathematical model-driven approaches, such as various stochastic
processes. However, in the current era of AI, data-driven approaches, where
models learn the intrinsic characteristics of data directly, have emerged as
promising techniques. Generative Adversarial Networks (GANs) have surfaced as
promising generative models, capturing data distributions through adversarial
learning. Financial time series, characterized 'stylized facts' such as random
walks, mean-reverting patterns, unexpected jumps, and time-varying volatility,
present significant challenges for deep neural networks to learn their
intrinsic characteristics. This study examines the ability of GANs to learn
diverse and complex temporal patterns (i.e., stylized facts) of both univariate
and multivariate financial time series. Our extensive experiments revealed that
GANs can capture various stylized facts of financial time series, but their
performance varies significantly depending on the choice of generator
architecture. This suggests that naively applying GANs might not effectively
capture the intricate characteristics inherent in financial time series,
highlighting the importance of carefully considering and validating the
modeling choices.",http://arxiv.org/pdf/2410.09850v1,
Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approximations,14/10/2024,"Julius Aka, Johannes Brunnemann, Jörg Eiden, Arne Speerforck, Lars Mikelsons","Variational Autoencoders (VAEs) are a powerful framework for learning compact
latent representations, while NeuralODEs excel in learning transient system
dynamics. This work combines the strengths of both to create fast surrogate
models with adjustable complexity. By leveraging the VAE's dimensionality
reduction using a non-hierarchical prior, our method adaptively assigns
stochastic noise, naturally complementing known NeuralODE training enhancements
and enabling probabilistic time series modeling. We show that standard Latent
ODEs struggle with dimensionality reduction in systems with time-varying
inputs. Our approach mitigates this by continuously propagating variational
parameters through time, establishing fixed information channels in latent
space. This results in a flexible and robust method that can learn different
system complexities, e.g. deep neural networks or linear matrices. Hereby, it
enables efficient approximation of the Koopman operator without the need for
predefining its dimensionality. As our method balances dimensionality reduction
and reconstruction accuracy, we call it Balanced Neural ODE (B-NODE). We
demonstrate the effectiveness of this method on academic test cases and apply
it to a real-world example of a thermal power plant.",http://arxiv.org/pdf/2410.10174v2,
HELM: Hierarchical Encoding for mRNA Language Modeling,16/10/2024,"Mehdi Yazdani-Jahromi, Mangal Prakash, Tommaso Mansi, Artem Moskalev, Rui Liao","Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its
codon structure directly impacting biological properties. While Language Models
(LMs) have shown promise in analyzing biological sequences, existing approaches
fail to account for the hierarchical nature of mRNA's codon structure. We
introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel
pre-training strategy that incorporates codon-level hierarchical structure into
language model training. HELM modulates the loss function based on codon
synonymity, aligning the model's learning process with the biological reality
of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks,
demonstrating that HELM outperforms standard language model pre-training as
well as existing foundation model baselines on six diverse downstream property
prediction tasks and an antibody region annotation tasks on average by around
8\%. Additionally, HELM enhances the generative capabilities of language model,
producing diverse mRNA sequences that better align with the underlying true
data distribution compared to non-hierarchical baselines.",http://arxiv.org/pdf/2410.12459v1,
Constrained Posterior Sampling: Time Series Generation with Hard Constraints,16/10/2024,"Sai Shankar Narasimhan, Shubhankar Agarwal, Litu Rout, Sanjay Shakkottai, Sandeep P. Chinchali","Generating realistic time series samples is crucial for stress-testing models
and protecting user privacy by using synthetic data. In engineering and
safety-critical applications, these samples must meet certain hard constraints
that are domain-specific or naturally imposed by physics or nature. Consider,
for example, generating electricity demand patterns with constraints on peak
demand times. This can be used to stress-test the functioning of power grids
during adverse weather conditions. Existing approaches for generating
constrained time series are either not scalable or degrade sample quality. To
address these challenges, we introduce Constrained Posterior Sampling (CPS), a
diffusion-based sampling algorithm that aims to project the posterior mean
estimate into the constraint set after each denoising update. Notably, CPS
scales to a large number of constraints (~100) without requiring additional
training. We provide theoretical justifications highlighting the impact of our
projection step on sampling. Empirically, CPS outperforms state-of-the-art
methods in sample quality and similarity to real time series by around 10% and
42%, respectively, on real-world stocks, traffic, and air quality datasets.",http://arxiv.org/pdf/2410.12652v1,
Geometric Trajectory Diffusion Models,16/10/2024,"Jiaqi Han, Minkai Xu, Aaron Lou, Haotian Ye, Stefano Ermon","Generative models have shown great promise in generating 3D geometric
systems, which is a fundamental problem in many natural science domains such as
molecule and protein design. However, existing approaches only operate on
static structures, neglecting the fact that physical systems are always dynamic
in nature. In this work, we propose geometric trajectory diffusion models
(GeoTDM), the first diffusion model for modeling the temporal distribution of
3D geometric trajectories. Modeling such distribution is challenging as it
requires capturing both the complex spatial interactions with physical
symmetries and temporal correspondence encapsulated in the dynamics. We
theoretically justify that diffusion models with equivariant temporal kernels
can lead to density with desired symmetry, and develop a novel transition
kernel leveraging SE(3)-equivariant spatial convolution and temporal attention.
Furthermore, to induce an expressive trajectory distribution for conditional
generation, we introduce a generalized learnable geometric prior into the
forward diffusion process to enhance temporal conditioning. We conduct
extensive experiments on both unconditional and conditional generation in
various scenarios, including physical simulation, molecular dynamics, and
pedestrian motion. Empirical results on a wide suite of metrics demonstrate
that GeoTDM can generate realistic geometric trajectories with significantly
higher quality.",http://arxiv.org/pdf/2410.13027v1,
DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone,17/10/2024,"Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang","Probabilistic time series imputation has been widely applied in real-world
scenarios due to its ability to estimate uncertainty of imputation results.
Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great
success in probabilistic time series imputation tasks with its power to model
complex distributions. However, current DDPM-based probabilistic time series
imputation methodologies are confronted with two types of challenges:
1)~\textit{~The backbone modules of the denoising parts are not capable of
achieving sequence modeling with low time complexity.} 2)~\textit{The
architecture of denoising modules can not handle the inter-variable and
bidirectional dependencies in the time series imputation problem effectively.}
To address the first challenge, we integrate the computational efficient state
space model, namely Mamba, as the backbone denosing module for DDPMs. To tackle
the second challenge, we carefully devise several SSM-based blocks for
bidirectional modeling and inter-variable relation understanding. Experimental
results demonstrate that our approach can achieve state-of-the-art time series
imputation results on multiple datasets, different missing scenarios and
missing ratios.",http://arxiv.org/pdf/2410.13338v1,
Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design,17/10/2024,"Chenyu Wang, Masatoshi Uehara, Yichun He, Amy Wang, Tommaso Biancalani, Avantika Lal, Tommi Jaakkola, Sergey Levine, Hanchen Wang, Aviv Regev","Recent studies have demonstrated the strong empirical performance of
diffusion models on discrete sequences across domains from natural language to
biological sequence generation. For example, in the protein inverse folding
task, conditional diffusion models have achieved impressive results in
generating natural-like sequences that fold back into the original structure.
However, practical design tasks often require not only modeling a conditional
distribution but also optimizing specific task objectives. For instance, we may
prefer protein sequences with high stability. To address this, we consider the
scenario where we have pre-trained discrete diffusion models that can generate
natural-like sequences, as well as reward models that map sequences to task
objectives. We then formulate the reward maximization problem within discrete
diffusion models, analogous to reinforcement learning (RL), while minimizing
the KL divergence against pretrained diffusion models to preserve naturalness.
To solve this RL problem, we propose a novel algorithm, DRAKES, that enables
direct backpropagation of rewards through entire trajectories generated by
diffusion models, by making the originally non-differentiable trajectories
differentiable using the Gumbel-Softmax trick. Our theoretical analysis
indicates that our approach can generate sequences that are both natural-like
and yield high rewards. While similar tasks have been recently explored in
diffusion models for continuous domains, our work addresses unique algorithmic
and theoretical challenges specific to discrete diffusion models, which arise
from their foundation in continuous-time Markov chains rather than Brownian
motion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA
and protein sequences that optimize enhancer activity and protein stability,
respectively, important tasks for gene therapies and protein-based
therapeutics.",http://arxiv.org/pdf/2410.13643v1,
Recurrent Neural Goodness-of-Fit Test for Time Series,17/10/2024,"Aoran Zhang, Wenbin Zhou, Liyan Xie, Shixiang Zhu","Time series data are crucial across diverse domains such as finance and
healthcare, where accurate forecasting and decision-making rely on advanced
modeling techniques. While generative models have shown great promise in
capturing the intricate dynamics inherent in time series, evaluating their
performance remains a major challenge. Traditional evaluation metrics fall
short due to the temporal dependencies and potential high dimensionality of the
features. In this paper, we propose the REcurrent NeurAL (RENAL)
Goodness-of-Fit test, a novel and statistically rigorous framework for
evaluating generative time series models. By leveraging recurrent neural
networks, we transform the time series into conditionally independent data
pairs, enabling the application of a chi-square-based goodness-of-fit test to
the temporal dependencies within the data. This approach offers a robust,
theoretically grounded solution for assessing the quality of generative models,
particularly in settings with limited time sequences. We demonstrate the
efficacy of our method across both synthetic and real-world datasets,
outperforming existing methods in terms of reliability and accuracy. Our method
fills a critical gap in the evaluation of time series generative models,
offering a tool that is both practical and adaptable to high-stakes
applications.",http://arxiv.org/pdf/2410.13986v3,
"Ensemble-based, large-eddy reconstruction of wind turbine inflow in a near-stationary atmospheric boundary layer through generative artificial intelligence",17/10/2024,"Alex Rybchuk, Luis A. Martínez-Tossas, Stefano Letizia, Nicholas Hamilton, Andy Scholbrock, Emina Maric, Daniel R. Houck, Thomas G. Herges, Nathaniel B. de Velder, Paula Doubrawa","To validate the second-by-second dynamics of turbines in field experiments,
it is necessary to accurately reconstruct the winds going into the turbine.
Current time-resolved inflow reconstruction techniques estimate wind behavior
in unobserved regions using relatively simple spectral-based models of the
atmosphere. Here, we develop a technique for time-resolved inflow
reconstruction that is rooted in a large-eddy simulation model of the
atmosphere. Our ""large-eddy reconstruction"" technique blends observations and
atmospheric model information through a diffusion model machine learning
algorithm, allowing us to generate probabilistic ensembles of reconstructions
for a single 10-min observational period. Our generated inflows can be used
directly by aeroelastic codes or as inflow boundary conditions in a large-eddy
simulation. We verify the second-by-second reconstruction capability of our
technique in three synthetic field campaigns, finding positive Pearson
correlation coefficient values (0.20>r>0.85) between ground-truth and
reconstructed streamwise velocity, as well as smaller positive correlation
coefficient values for unobserved fields (spanwise velocity, vertical velocity,
and temperature). We validate our technique in three real-world case studies by
driving large-eddy simulations with reconstructed inflows and comparing to
independent inflow measurements. The reconstructions are visually similar to
measurements, follow desired power spectra properties, and track
second-by-second behavior (0.25 > r > 0.75).",http://arxiv.org/pdf/2410.14024v1,
UniMTS: Unified Pre-training for Motion Time Series,18/10/2024,"Xiyuan Zhang, Diyan Teng, Ranak Roy Chowdhury, Shuheng Li, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang","Motion time series collected from mobile and wearable devices such as
smartphones and smartwatches offer significant insights into human behavioral
patterns, with wide applications in healthcare, automation, IoT, and AR/XR due
to their low-power, always-on nature. However, given security and privacy
concerns, building large-scale motion time series datasets remains difficult,
preventing the development of pre-trained models for human activity analysis.
Typically, existing models are trained and tested on the same dataset, leading
to poor generalizability across variations in device location, device mounting
orientation and human activity type. In this paper, we introduce UniMTS, the
first unified pre-training procedure for motion time series that generalizes
across diverse device latent factors and activities. Specifically, we employ a
contrastive learning framework that aligns motion time series with text
descriptions enriched by large language models. This helps the model learn the
semantics of time series to generalize across activities. Given the absence of
large-scale motion time series data, we derive and synthesize time series from
existing motion skeleton data with all-joint coverage. Spatio-temporal graph
networks are utilized to capture the relationships across joints for
generalization across different device locations. We further design
rotation-invariant augmentation to make the model agnostic to changes in device
mounting orientations. Our model shows exceptional generalizability across 18
motion time series classification benchmark datasets, outperforming the best
baselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and
9.2% in the full-shot setting.",http://arxiv.org/pdf/2410.19818v1,
ANT: Adaptive Noise Schedule for Time Series Diffusion Models,18/10/2024,"Seunghan Lee, Kibok Lee, Taeyoung Park","Advances in diffusion models for generative artificial intelligence have
recently propagated to the time series (TS) domain, demonstrating
state-of-the-art performance on various tasks. However, prior works on TS
diffusion models often borrow the framework of existing works proposed in other
domains without considering the characteristics of TS data, leading to
suboptimal performance. In this work, we propose Adaptive Noise schedule for
Time series diffusion models (ANT), which automatically predetermines proper
noise schedules for given TS datasets based on their statistics representing
non-stationarity. Our intuition is that an optimal noise schedule should
satisfy the following desiderata: 1) It linearly reduces the non-stationarity
of TS data so that all diffusion steps are equally meaningful, 2) the data is
corrupted to the random noise at the final step, and 3) the number of steps is
sufficiently large. The proposed method is practical for use in that it
eliminates the necessity of finding the optimal noise schedule with a small
additional cost to compute the statistics for given datasets, which can be done
offline before training. We validate the effectiveness of our method across
various tasks, including TS forecasting, refinement, and generation, on
datasets from diverse domains. Code is available at this repository:
https://github.com/seunghan96/ANT.",http://arxiv.org/pdf/2410.14488v1,
Data Augmentation of Multivariate Sensor Time Series using Autoregressive Models and Application to Failure Prognostics,21/10/2024,"Douglas Baptista de Souza, Bruno Paes Leao","This work presents a novel data augmentation solution for non-stationary
multivariate time series and its application to failure prognostics. The method
extends previous work from the authors which is based on time-varying
autoregressive processes. It can be employed to extract key information from a
limited number of samples and generate new synthetic samples in a way that
potentially improves the performance of PHM solutions. This is especially
valuable in situations of data scarcity which are very usual in PHM, especially
for failure prognostics. The proposed approach is tested based on the CMAPSS
dataset, commonly employed for prognostics experiments and benchmarks. An
AutoML approach from PHM literature is employed for automating the design of
the prognostics solution. The empirical evaluation provides evidence that the
proposed method can substantially improve the performance of PHM solutions.",http://arxiv.org/pdf/2410.16419v2,
Unsupervised Time Series Anomaly Prediction with Importance-based Generative Contrastive Learning,22/10/2024,"Kai Zhao, Zhihao Zhuang, Chenjuan Guo, Hao Miao, Yunyao Cheng, Bin Yang","Time series anomaly prediction plays an essential role in many real-world
scenarios, such as environmental prevention and prompt maintenance of
cyber-physical systems. However, existing time series anomaly prediction
methods mainly require supervised training with plenty of manually labeled
data, which are difficult to obtain in practice. Besides, unseen anomalies can
occur during inference, which could differ from the labeled training data and
make these models fail to predict such new anomalies. In this paper, we study a
novel problem of unsupervised time series anomaly prediction. We provide a
theoretical analysis and propose Importance-based Generative Contrastive
Learning (IGCL) to address the aforementioned problems. IGCL distinguishes
between normal and anomaly precursors, which are generated by our anomaly
precursor pattern generation module. To address the efficiency issues caused by
the potential complex anomaly precursor combinations, we propose a memory bank
with importance-based scores to adaptively store representative anomaly
precursors and generate more complicated anomaly precursors. Extensive
experiments on seven benchmark datasets show our method outperforms
state-of-the-art baselines on unsupervised time series anomaly prediction
problems.",http://arxiv.org/pdf/2410.16888v1,
Fast and interpretable electricity consumption scenario generation for individual consumers,23/10/2024,"J. Soenen, A. Yurtman, T. Becker, K. Vanthournout, H. Blockeel","To enable the transition from fossil fuels towards renewable energy, the
low-voltage grid needs to be reinforced at a faster pace and on a larger scale
than was historically the case. To efficiently plan reinforcements, one needs
to estimate the currents and voltages throughout the grid, which are unknown
but can be calculated from the grid layout and the electricity consumption time
series of each consumer. However, for many consumers, these time series are
unknown and have to be estimated from the available consumer information. We
refer to this task as scenario generation. The state-of-the-art approach that
generates electricity consumption scenarios is complex, resulting in a
computationally expensive procedure with only limited interpretability. To
alleviate these drawbacks, we propose a fast and interpretable scenario
generation technique based on predictive clustering trees (PCTs) that does not
compromise accuracy. In our experiments on three datasets from different
locations, we found that our proposed approach generates time series that are
at least as accurate as the state-of-the-art while being at least 7 times
faster in training and prediction. Moreover, the interpretability of the PCT
allows domain experts to gain insight into their data while simultaneously
building trust in the predictions of the model.",http://arxiv.org/pdf/2411.05014v1,
Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation,23/10/2024,"Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin","Integrating multi-modal clinical data, such as electronic health records
(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical
prediction tasks. However, in a temporal setting, multi-modal data are often
inherently asynchronous. EHR can be continuously collected but CXR is generally
taken with a much longer interval due to its high cost and radiation dose. When
clinical prediction is needed, the last available CXR image might have been
outdated, leading to suboptimal predictions. To address this challenge, we
propose DDL-CXR, a method that dynamically generates an up-to-date latent
representation of the individualized CXR images. Our approach leverages latent
diffusion models for patient-specific generation strategically conditioned on a
previous CXR image and EHR time series, providing information regarding
anatomical structures and disease progressions, respectively. In this way, the
interaction across modalities could be better captured by the latent CXR
generation process, ultimately improving the prediction performance.
Experiments using MIMIC datasets show that the proposed model could effectively
address asynchronicity in multimodal fusion and consistently outperform
existing methods.",http://arxiv.org/pdf/2410.17918v1,
Generation of synthetic financial time series by diffusion models,24/10/2024,"Tomonori Takahashi, Takayuki Mizuno","Despite its practical significance, generating realistic synthetic financial
time series is challenging due to statistical properties known as stylized
facts, such as fat tails, volatility clustering, and seasonality patterns.
Various generative models, including generative adversarial networks (GANs) and
variational autoencoders (VAEs), have been employed to address this challenge,
although no model yet satisfies all the stylized facts. We alternatively
propose utilizing diffusion models, specifically denoising diffusion
probabilistic models (DDPMs), to generate synthetic financial time series. This
approach employs wavelet transformation to convert multiple time series (into
images), such as stock prices, trading volumes, and spreads. Given these
converted images, the model gains the ability to generate images that can be
transformed back into realistic time series by inverse wavelet transformation.
We demonstrate that our proposed approach satisfies stylized facts.",http://arxiv.org/pdf/2410.18897v1,
High Resolution Seismic Waveform Generation using Denoising Diffusion,25/10/2024,"Andreas Bergmeister, Kadek Hendrawan Palgunadi, Andrea Bosisio, Laura Ermert, Maria Koroni, Nathanaël Perraudin, Simon Dirmeier, Men-Andrin Meier","Accurate prediction and synthesis of seismic waveforms are crucial for
seismic hazard assessment and earthquake-resistant infrastructure design.
Existing prediction methods, such as Ground Motion Models and physics-based
simulations, often fail to capture the full complexity of seismic wavefields,
particularly at higher frequencies. This study introduces a novel, efficient,
and scalable generative model for high-frequency seismic waveform generation.
Our approach leverages a spectrogram representation of seismic waveform data,
which is reduced to a lower-dimensional submanifold via an autoencoder. A
state-of-the-art diffusion model is trained to generate this latent
representation, conditioned on key input parameters: earthquake magnitude,
recording distance, site conditions, and faulting type. The model generates
waveforms with frequency content up to 50 Hz. Any scalar ground motion
statistic, such as peak ground motion amplitudes and spectral accelerations,
can be readily derived from the synthesized waveforms. We validate our model
using commonly used seismological metrics, and performance metrics from image
generation studies. Our results demonstrate that our openly available model can
generate distributions of realistic high-frequency seismic waveforms across a
wide range of input parameters, even in data-sparse regions. For the scalar
ground motion statistics commonly used in seismic hazard and earthquake
engineering studies, we show that the model accurately reproduces both the
median trends of the real data and its variability. To evaluate and compare the
growing number of this and similar 'Generative Waveform Models' (GWM), we argue
that they should generally be openly available and that they should be included
in community efforts for ground motion model evaluations.",http://arxiv.org/pdf/2410.19343v1,
Marked Temporal Bayesian Flow Point Processes,25/10/2024,"Hui Chen, Xuhui Fan, Hengyu Liu, Longbing Cao","Marked event data captures events by recording their continuous-valued
occurrence timestamps along with their corresponding discrete-valued types.
They have appeared in various real-world scenarios such as social media,
financial transactions, and healthcare records, and have been effectively
modeled through Marked Temporal Point Process (MTPP) models. Recently,
developing generative models for these MTPP models have seen rapid development
due to their powerful generative capability and less restrictive functional
forms. However, existing generative MTPP models are usually challenged in
jointly modeling events' timestamps and types since: (1) mainstream methods
design the generative mechanisms for timestamps only and do not include event
types; (2) the complex interdependence between the timestamps and event types
are overlooked. In this paper, we propose a novel generative MTPP model called
BMTPP. Unlike existing generative MTPP models, BMTPP flexibly models marked
temporal joint distributions using a parameter-based approach. Additionally, by
adding joint noise to the marked temporal data space, BMTPP effectively
captures and explicitly reveals the interdependence between timestamps and
event types. Extensive experiments validate the superiority of our approach
over other state-of-the-art models and its ability to effectively capture
marked-temporal interdependence.",http://arxiv.org/pdf/2410.19512v1,
Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series,25/10/2024,"Ilan Naiman, Nimrod Berman, Itai Pemper, Idan Arbiv, Gal Fadlon, Omri Azencot","Lately, there has been a surge in interest surrounding generative modeling of
time series data. Most existing approaches are designed either to process short
sequences or to handle long-range sequences. This dichotomy can be attributed
to gradient issues with recurrent networks, computational costs associated with
transformers, and limited expressiveness of state space models. Towards a
unified generative model for varying-length time series, we propose in this
work to transform sequences into images. By employing invertible transforms
such as the delay embedding and the short-time Fourier transform, we unlock
three main advantages: i) We can exploit advanced diffusion vision models; ii)
We can remarkably process short- and long-range inputs within the same
framework; and iii) We can harness recent and established tools proposed in the
time series to image literature. We validate the effectiveness of our method
through a comprehensive evaluation across multiple tasks, including
unconditional generation, interpolation, and extrapolation. We show that our
approach achieves consistently state-of-the-art results against strong
baselines. In the unconditional generation tasks, we show remarkable mean
improvements of 58.17% over previous diffusion models in the short
discriminative score and 132.61% in the (ultra-)long classification scores.
Code is at https://github.com/azencot-group/ImagenTime.",http://arxiv.org/pdf/2410.19538v1,
Absorb & Escape: Overcoming Single Model Limitations in Generating Genomic Sequences,28/10/2024,"Zehui Li, Yuhao Ni, Guoxuan Xia, William Beardall, Akashaditya Das, Guy-Bart Stan, Yiren Zhao","Abstract Recent advances in immunology and synthetic biology have accelerated
the development of deep generative methods for DNA sequence design. Two
dominant approaches in this field are AutoRegressive (AR) models and Diffusion
Models (DMs). However, genomic sequences are functionally heterogeneous,
consisting of multiple connected regions (e.g., Promoter Regions, Exons, and
Introns) where elements within each region come from the same probability
distribution, but the overall sequence is non-homogeneous. This heterogeneous
nature presents challenges for a single model to accurately generate genomic
sequences. In this paper, we analyze the properties of AR models and DMs in
heterogeneous genomic sequence generation, pointing out crucial limitations in
both methods: (i) AR models capture the underlying distribution of data by
factorizing and learning the transition probability but fail to capture the
global property of DNA sequences. (ii) DMs learn to recover the global
distribution but tend to produce errors at the base pair level. To overcome the
limitations of both approaches, we propose a post-training sampling method,
termed Absorb & Escape (A&E) to perform compositional generation from AR models
and DMs. This approach starts with samples generated by DMs and refines the
sample quality using an AR model through the alternation of the Absorb and
Escape steps. To assess the quality of generated sequences, we conduct
extensive experiments on 15 species for conditional and unconditional DNA
generation. The experiment results from motif distribution, diversity checks,
and genome integration tests unequivocally show that A&E outperforms
state-of-the-art AR models and DMs in genomic sequence generation.",http://arxiv.org/pdf/2410.21345v1,
Federated Time Series Generation on Feature and Temporally Misaligned Data,28/10/2024,"Chenrui Fan, Zhi Wen Soi, Aditya Shankar, Abele Mălan, Lydia Y. Chen","Distributed time series data presents a challenge for federated learning, as
clients often possess different feature sets and have misaligned time steps.
Existing federated time series models are limited by the assumption of perfect
temporal or feature alignment across clients. In this paper, we propose FedTDD,
a novel federated time series diffusion model that jointly learns a synthesizer
across clients. At the core of FedTDD is a novel data distillation and
aggregation framework that reconciles the differences between clients by
imputing the misaligned timesteps and features. In contrast to traditional
federated learning, FedTDD learns the correlation across clients' time series
through the exchange of local synthetic outputs instead of model parameters. A
coordinator iteratively improves a global distiller network by leveraging
shared knowledge from clients through the exchange of synthetic data. As the
distiller becomes more refined over time, it subsequently enhances the quality
of the clients' local feature estimates, allowing each client to then improve
its local imputations for missing data using the latest, more accurate
distiller. Experimental results on five datasets demonstrate FedTDD's
effectiveness compared to centralized training, and the effectiveness of
sharing synthetic outputs to transfer knowledge of local time series. Notably,
FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID
and Correlational scores.",http://arxiv.org/pdf/2410.21072v1,
Trajectory Flow Matching with Applications to Clinical Time Series Modeling,28/10/2024,"Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong","Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.",http://arxiv.org/pdf/2410.21154v1,
SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning,28/10/2024,"MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi","Current Generative Adversarial Network (GAN)-based approaches for time series
generation face challenges such as suboptimal convergence, information loss in
embedding spaces, and instability. To overcome these challenges, we introduce
an advanced framework that integrates the advantages of an
autoencoder-generated embedding space with the adversarial training dynamics of
GANs. This method employs two discriminators: one to specifically guide the
generator and another to refine both the autoencoder's and generator's output.
Additionally, our framework incorporates a novel autoencoder-based loss
function and supervision from a teacher-forcing supervisor network, which
captures the stepwise conditional distributions of the data. The generator
operates within the latent space, while the two discriminators work on latent
and feature spaces separately, providing crucial feedback to both the generator
and the autoencoder. By leveraging this dual-discriminator approach, we
minimize information loss in the embedding space. Through joint training, our
framework excels at generating high-fidelity time series data, consistently
outperforming existing state-of-the-art benchmarks both qualitatively and
quantitatively across a range of real and synthetic multivariate time series
datasets.",http://arxiv.org/pdf/2410.21203v1,
A Generative Model Based Honeypot for Industrial OPC UA Communication,28/10/2024,"Olaf Sassnick, Georg Schäfer, Thomas Rosenstatter, Stefan Huber","Industrial Operational Technology (OT) systems are increasingly targeted by
cyber-attacks due to their integration with Information Technology (IT) systems
in the Industry 4.0 era. Besides intrusion detection systems, honeypots can
effectively detect these attacks. However, creating realistic honeypots for
brownfield systems is particularly challenging. This paper introduces a
generative model-based honeypot designed to mimic industrial OPC UA
communication. Utilizing a Long ShortTerm Memory (LSTM) network, the honeypot
learns the characteristics of a highly dynamic mechatronic system from recorded
state space trajectories. Our contributions are twofold: first, we present a
proof-of concept for a honeypot based on generative machine-learning models,
and second, we publish a dataset for a cyclic industrial process. The results
demonstrate that a generative model-based honeypot can feasibly replicate a
cyclic industrial process via OPC UA communication. In the short-term, the
generative model indicates a stable and plausible trajectory generation, while
deviations occur over extended periods. The proposed honeypot implementation
operates efficiently on constrained hardware, requiring low computational
resources. Future work will focus on improving model accuracy, interaction
capabilities, and extending the dataset for broader applications.",http://arxiv.org/pdf/2410.21574v1,
Unlocking Point Processes through Point Set Diffusion,29/10/2024,"David Lüdke, Enric Rabasseda Raventós, Marcel Kollovieh, Stephan Günnemann","Point processes model the distribution of random point sets in mathematical
spaces, such as spatial and temporal domains, with applications in fields like
seismology, neuroscience, and economics. Existing statistical and machine
learning models for point processes are predominantly constrained by their
reliance on the characteristic intensity function, introducing an inherent
trade-off between efficiency and flexibility. In this paper, we introduce Point
Set Diffusion, a diffusion-based latent variable model that can represent
arbitrary point processes on general metric spaces without relying on the
intensity function. By directly learning to stochastically interpolate between
noise and data point sets, our approach enables efficient, parallel sampling
and flexible generation for complex conditional tasks defined on the metric
space. Experiments on synthetic and real-world datasets demonstrate that Point
Set Diffusion achieves state-of-the-art performance in unconditional and
conditional generation of spatial and spatiotemporal point processes while
providing up to orders of magnitude faster sampling than autoregressive
baselines.",http://arxiv.org/pdf/2410.22493v1,
DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis,31/10/2024,"Hamidreza Eivazi, André Hebenbrock, Raphael Ginster, Steffen Blömeke, Stefan Wittek, Christoph Herrmann, Thomas S. Spengler, Thomas Turek, Andreas Rausch","Battery degradation remains a critical challenge in the pursuit of green
technologies and sustainable energy solutions. Despite significant research
efforts, predicting battery capacity loss accurately remains a formidable task
due to its complex nature, influenced by both aging and cycling behaviors. To
address this challenge, we introduce a novel general-purpose model for battery
degradation prediction and synthesis, DiffBatt. Leveraging an innovative
combination of conditional and unconditional diffusion models with
classifier-free guidance and transformer architecture, DiffBatt achieves high
expressivity and scalability. DiffBatt operates as a probabilistic model to
capture uncertainty in aging behaviors and a generative model to simulate
battery degradation. The performance of the model excels in prediction tasks
while also enabling the generation of synthetic degradation curves,
facilitating enhanced model training by data augmentation. In the remaining
useful life prediction task, DiffBatt provides accurate results with a mean
RMSE of 196 cycles across all datasets, outperforming all other models and
demonstrating superior generalizability. This work represents an important step
towards developing foundational models for battery degradation.",http://arxiv.org/pdf/2410.23893v3,
Variational Neural Stochastic Differential Equations with Change Points,01/11/2024,"Yousef El-Laham, Zhongchang Sun, Haibei Zhu, Tucker Balch, Svitlana Vyetrenko","In this work, we explore modeling change points in time-series data using
neural stochastic differential equations (neural SDEs). We propose a novel
model formulation and training procedure based on the variational autoencoder
(VAE) framework for modeling time-series as a neural SDE. Unlike existing
algorithms training neural SDEs as VAEs, our proposed algorithm only
necessitates a Gaussian prior of the initial state of the latent stochastic
process, rather than a Wiener process prior on the entire latent stochastic
process. We develop two methodologies for modeling and estimating change points
in time-series data with distribution shifts. Our iterative algorithm
alternates between updating neural SDE parameters and updating the change
points based on either a maximum likelihood-based approach or a change point
detection algorithm using the sequential likelihood ratio test. We provide a
theoretical analysis of this proposed change point detection scheme. Finally,
we present an empirical evaluation that demonstrates the expressive power of
our proposed model, showing that it can effectively model both classical
parametric SDEs and some real datasets with distribution shifts.",http://arxiv.org/pdf/2411.00635v1,
Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis,04/11/2024,"Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman","Artificial Intelligence (AI) research often aims to develop models that can
generalize reliably across complex datasets, yet this remains challenging in
fields where data is scarce, intricate, or inaccessible. This paper introduces
a novel approach that leverages three generative models of varying complexity
to synthesize one of the most demanding structured datasets: Malicious Network
Traffic. Our approach uniquely transforms numerical data into text, re-framing
data generation as a language modeling task, which not only enhances data
regularization but also significantly improves generalization and the quality
of the synthetic data. Extensive statistical analyses demonstrate that our
method surpasses state-of-the-art generative models in producing high-fidelity
synthetic data. Additionally, we conduct a comprehensive study on synthetic
data applications, effectiveness, and evaluation strategies, offering valuable
insights into its role across various domains. Our code and pre-trained models
are openly accessible at Github, enabling further exploration and application
of our methodology. Index Terms: Data synthesis, machine learning, traffic
generation, privacy preserving data, generative models.",http://arxiv.org/pdf/2411.01929v2,10.33140/JDAEDM
Generating the Traces You Need: A Conditional Generative Model for Process Mining Data,04/11/2024,"Riccardo Graziosi, Massimiliano Ronzani, Andrei Buliga, Chiara Di Francescomarino, Francesco Folino, Chiara Ghidini, Francesca Meneghello, Luigi Pontieri","In recent years, trace generation has emerged as a significant challenge
within the Process Mining community. Deep Learning (DL) models have
demonstrated accuracy in reproducing the features of the selected processes.
However, current DL generative models are limited in their ability to adapt the
learned distributions to generate data samples based on specific conditions or
attributes. This limitation is particularly significant because the ability to
control the type of generated data can be beneficial in various contexts,
enabling a focus on specific behaviours, exploration of infrequent patterns, or
simulation of alternative 'what-if' scenarios. In this work, we address this
challenge by introducing a conditional model for process data generation based
on a conditional variational autoencoder (CVAE). Conditional models offer
control over the generation process by tuning input conditional variables,
enabling more targeted and controlled data generation. Unlike other domains,
CVAE for process mining faces specific challenges due to the multiperspective
nature of the data and the need to adhere to control-flow rules while ensuring
data variability. Specifically, we focus on generating process executions
conditioned on control flow and temporal features of the trace, allowing us to
produce traces for specific, identified sub-processes. The generated traces are
then evaluated using common metrics for generative model assessment, along with
additional metrics to evaluate the quality of the conditional generation",http://arxiv.org/pdf/2411.02131v1,
Recursive Learning of Asymptotic Variational Objectives,04/11/2024,"Alessandro Mastrototaro, Mathias Müller, Jimmy Olsson","General state-space models (SSMs) are widely used in statistical machine
learning and are among the most classical generative models for sequential
time-series data. SSMs, comprising latent Markovian states, can be subjected to
variational inference (VI), but standard VI methods like the
importance-weighted autoencoder (IWAE) lack functionality for streaming data.
To enable online VI in SSMs when the observations are received in real time, we
propose maximising an IWAE-type variational lower bound on the asymptotic
contrast function, rather than the standard IWAE ELBO, using stochastic
approximation. Unlike the recursive maximum likelihood method, which directly
maximises the asymptotic contrast, our approach, called online sequential IWAE
(OSIWAE), allows for online learning of both model parameters and a Markovian
recognition model for inferring latent states. By approximating filter state
posteriors and their derivatives using sequential Monte Carlo (SMC) methods, we
create a particle-based framework for online VI in SSMs. This approach is more
theoretically well-founded than recently proposed online variational SMC
methods. We provide rigorous theoretical results on the learning objective and
a numerical study demonstrating the method's efficiency in learning model
parameters and particle proposal kernels.",http://arxiv.org/pdf/2411.02217v1,
Point processes with event time uncertainty,05/11/2024,"Xiuyuan Cheng, Tingnan Gong, Yao Xie","Point processes are widely used statistical models for uncovering the
temporal patterns in dependent event data. In many applications, the event time
cannot be observed exactly, calling for the incorporation of time uncertainty
into the modeling of point process data. In this work, we introduce a framework
to model time-uncertain point processes possibly on a network. We start by
deriving the formulation in the continuous-time setting under a few assumptions
motivated by application scenarios. After imposing a time grid, we obtain a
discrete-time model that facilitates inference and can be computed by
first-order optimization methods such as Gradient Descent or Variation
inequality (VI) using batch-based Stochastic Gradient Descent (SGD). The
parameter recovery guarantee is proved for VI inference at an $O(1/k)$
convergence rate using $k$ SGD steps. Our framework handles non-stationary
processes by modeling the inference kernel as a matrix (or tensor on a network)
and it covers the stationary process, such as the classical Hawkes process, as
a special case. We experimentally show that the proposed approach outperforms
previous General Linear model (GLM) baselines on simulated and real data and
reveals meaningful causal relations on a Sepsis-associated Derangements
dataset.",http://arxiv.org/pdf/2411.02694v1,
Time-Causal VAE: Robust Financial Time Series Generator,05/11/2024,"Beatrice Acciaio, Stephan Eckstein, Songyan Hou","We build a time-causal variational autoencoder (TC-VAE) for robust generation
of financial time series data. Our approach imposes a causality constraint on
the encoder and decoder networks, ensuring a causal transport from the real
market time series to the fake generated time series. Specifically, we prove
that the TC-VAE loss provides an upper bound on the causal Wasserstein distance
between market distributions and generated distributions. Consequently, the
TC-VAE loss controls the discrepancy between optimal values of various dynamic
stochastic optimization problems under real and generated distributions. To
further enhance the model's ability to approximate the latent representation of
the real market distribution, we integrate a RealNVP prior into the TC-VAE
framework. Finally, extensive numerical experiments show that TC-VAE achieves
promising results on both synthetic and real market data. This is done by
comparing real and generated distributions according to various statistical
distances, demonstrating the effectiveness of the generated data for downstream
financial optimization tasks, as well as showcasing that the generated data
reproduces stylized facts of real financial market data.",http://arxiv.org/pdf/2411.02947v1,
A scalable generative model for dynamical system reconstruction from neuroimaging data,05/11/2024,"Eric Volkmann, Alena Brändle, Daniel Durstewitz, Georgia Koppe","Data-driven inference of the generative dynamics underlying a set of observed
time series is of growing interest in machine learning and the natural
sciences. In neuroscience, such methods promise to alleviate the need to
handcraft models based on biophysical principles and allow to automatize the
inference of inter-individual differences in brain dynamics. Recent
breakthroughs in training techniques for state space models (SSMs) specifically
geared toward dynamical systems (DS) reconstruction (DSR) enable to recover the
underlying system including its geometrical (attractor) and long-term
statistical invariants from even short time series. These techniques are based
on control-theoretic ideas, like modern variants of teacher forcing (TF), to
ensure stable loss gradient propagation while training. However, as it
currently stands, these techniques are not directly applicable to data
modalities where current observations depend on an entire history of previous
states due to a signal's filtering properties, as common in neuroscience (and
physiology more generally). Prominent examples are the blood oxygenation level
dependent (BOLD) signal in functional magnetic resonance imaging (fMRI) or
Ca$^{2+}$ imaging data. Such types of signals render the SSM's decoder model
non-invertible, a requirement for previous TF-based methods. Here, exploiting
the recent success of control techniques for training SSMs, we propose a novel
algorithm that solves this problem and scales exceptionally well with model
dimensionality and filter length. We demonstrate its efficiency in
reconstructing dynamical systems, including their state space geometry and
long-term temporal properties, from just short BOLD time series.",http://arxiv.org/pdf/2411.02949v1,
IMUDiffusion: A Diffusion Model for Multivariate Time Series Synthetisation for Inertial Motion Capturing Systems,05/11/2024,"Heiko Oppel, Michael Munz","Kinematic sensors are often used to analyze movement behaviors in sports and
daily activities due to their ease of use and lack of spatial restrictions,
unlike video-based motion capturing systems. Still, the generation, and
especially the labeling of motion data for specific activities can be
time-consuming and costly. Additionally, many models struggle with limited
data, which limits their performance in recognizing complex movement patterns.
To address those issues, generating synthetic data can help expand the
diversity and variability. In this work, we propose IMUDiffusion, a
probabilistic diffusion model specifically designed for multivariate time
series generation. Our approach enables the generation of high-quality time
series sequences which accurately capture the dynamics of human activities.
Moreover, by joining our dataset with synthetic data, we achieve a significant
improvement in the performance of our baseline human activity classifier. In
some cases, we are able to improve the macro F1-score by almost 30%.
IMUDiffusion provides a valuable tool for generating realistic human activity
movements and enhance the robustness of models in scenarios with limited
training data.",http://arxiv.org/pdf/2411.02954v1,
"Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences",06/11/2024,"Niklas Schmidinger, Lisa Schneckenreiter, Philipp Seidl, Johannes Schimunek, Pieter-Jan Hoedt, Johannes Brandstetter, Andreas Mayr, Sohvi Luukkonen, Sepp Hochreiter, Günter Klambauer","Language models for biological and chemical sequences enable crucial
applications such as drug discovery, protein engineering, and precision
medicine. Currently, these language models are predominantly based on
Transformer architectures. While Transformers have yielded impressive results,
their quadratic runtime dependency on the sequence length complicates their use
for long genomic sequences and in-context learning on proteins and chemical
sequences. Recently, the recurrent xLSTM architecture has been shown to perform
favorably compared to Transformers and modern state-space model (SSM)
architectures in the natural language domain. Similar to SSMs, xLSTMs have a
linear runtime dependency on the sequence length and allow for constant-memory
decoding at inference time, which makes them prime candidates for modeling
long-range dependencies in biological and chemical sequences. In this work, we
tailor xLSTM towards these domains and propose a suite of architectural
variants called Bio-xLSTM. Extensive experiments in three large domains,
genomics, proteins, and chemistry, were performed to assess xLSTM's ability to
model biological and chemical sequences. The results show that models based on
Bio-xLSTM a) can serve as proficient generative models for DNA, protein, and
chemical sequences, b) learn rich representations for those modalities, and c)
can perform in-context learning for proteins and small molecules.",http://arxiv.org/pdf/2411.04165v1,
TrajGPT: Controlled Synthetic Trajectory Generation Using a Multitask Transformer-Based Spatiotemporal Model,07/11/2024,"Shang-Ling Hsu, Emmanuel Tung, John Krumm, Cyrus Shahabi, Khurram Shafique","Human mobility modeling from GPS-trajectories and synthetic trajectory
generation are crucial for various applications, such as urban planning,
disaster management and epidemiology. Both of these tasks often require filling
gaps in a partially specified sequence of visits - a new problem that we call
""controlled"" synthetic trajectory generation. Existing methods for
next-location prediction or synthetic trajectory generation cannot solve this
problem as they lack the mechanisms needed to constrain the generated sequences
of visits. Moreover, existing approaches (1) frequently treat space and time as
independent factors, an assumption that fails to hold true in real-world
scenarios, and (2) suffer from challenges in accuracy of temporal prediction as
they fail to deal with mixed distributions and the inter-relationships of
different modes with latent variables (e.g., day-of-the-week). These
limitations become even more pronounced when the task involves filling gaps
within sequences instead of solely predicting the next visit.
  We introduce TrajGPT, a transformer-based, multi-task, joint spatiotemporal
generative model to address these issues. Taking inspiration from large
language models, TrajGPT poses the problem of controlled trajectory generation
as that of text infilling in natural language. TrajGPT integrates the spatial
and temporal models in a transformer architecture through a Bayesian
probability model that ensures that the gaps in a visit sequence are filled in
a spatiotemporally consistent manner. Our experiments on public and private
datasets demonstrate that TrajGPT not only excels in controlled synthetic visit
generation but also outperforms competing models in next-location prediction
tasks - Relatively, TrajGPT achieves a 26-fold improvement in temporal accuracy
while retaining more than 98% of spatial accuracy on average.",http://arxiv.org/pdf/2411.04381v1,10.1145/3678717.3691303
A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior,07/11/2024,"Yiwei Dong, Shaoxin Ye, Yuwen Cao, Qiyu Han, Hongteng Xu, Hanfang Yang","Asynchronous event sequence clustering aims to group similar event sequences
in an unsupervised manner. Mixture models of temporal point processes have been
proposed to solve this problem, but they often suffer from overfitting, leading
to excessive cluster generation with a lack of diversity. To overcome these
limitations, we propose a Bayesian mixture model of Temporal Point Processes
with Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an
efficient posterior inference algorithm based on conditional Gibbs sampling.
Our work provides a flexible learning framework for event sequence clustering,
enabling automatic identification of the potential number of clusters and
accurate grouping of sequences with similar features. It is applicable to a
wide range of parametric temporal point processes, including neural
network-based models. Experimental results on both synthetic and real-world
data suggest that our framework could produce moderately fewer yet more diverse
mixture components, and achieve outstanding results across multiple evaluation
metrics.",http://arxiv.org/pdf/2411.04397v1,
Discovering Latent Structural Causal Models from Spatio-Temporal Data,08/11/2024,"Kun Wang, Sumanth Varambally, Duncan Watson-Parris, Yi-An Ma, Rose Yu","Many important phenomena in scientific fields such as climate, neuroscience,
and epidemiology are naturally represented as spatiotemporal gridded data with
complex interactions. For example, in climate science, researchers aim to
uncover how large-scale events, such as the North Atlantic Oscillation (NAO)
and the Antarctic Oscillation (AAO), influence other global processes.
Inferring causal relationships from these data is a challenging problem
compounded by the high dimensionality of such data and the correlations between
spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY),
a novel framework based on variational inference, designed to explicitly model
latent time-series and their causal relationships from spatially confined modes
in the data. Our method uses an end-to-end training process that maximizes an
evidence-lower bound (ELBO) for the data likelihood. Theoretically, we show
that, under some conditions, the latent variables are identifiable up to
transformation by an invertible matrix. Empirically, we show that SPACY
outperforms state-of-the-art baselines on synthetic data, remains scalable for
large grids, and identifies key known phenomena from real-world climate data.",http://arxiv.org/pdf/2411.05331v1,
White-Box Diffusion Transformer for single-cell RNA-seq generation,11/11/2024,"Zhuorui Cui, Shengze Dong, Ding Liu","As a powerful tool for characterizing cellular subpopulations and cellular
heterogeneity, single cell RNA sequencing (scRNA-seq) technology offers
advantages of high throughput and multidimensional analysis. However, the
process of data acquisition is often constrained by high cost and limited
sample availability. To overcome these limitations, we propose a hybrid model
based on Diffusion model and White-Box transformer that aims to generate
synthetic and biologically plausible scRNA-seq data. Diffusion model
progressively introduce noise into the data and then recover the original data
through a denoising process, a forward and reverse process that is particularly
suitable for generating complex data distributions. White-Box transformer is a
deep learning architecture that emphasizes mathematical interpretability. By
minimizing the encoding rate of the data and maximizing the sparsity of the
representation, it not only reduces the computational burden, but also provides
clear insight into underlying structure. Our White-Box Diffusion Transformer
combines the generative capabilities of Diffusion model with the mathematical
interpretability of White-Box transformer. Through experiments using six
different single-cell RNA-Seq datasets, we visualize both generated and real
data using t-SNE dimensionality reduction technique, as well as quantify
similarity between generated and real data using various metrics to demonstrate
comparable performance of White-Box Diffusion Transformer and Diffusion
Transformer in generating scRNA-seq data alongside significant improvements in
training efficiency and resource utilization. Our code is available at
https://github.com/lingximamo/White-Box-Diffusion-Transformer",http://arxiv.org/pdf/2411.06785v2,
Reconstruction of neuromorphic dynamics from a single scalar time series using variational autoencoder and neural network map,11/11/2024,"Pavel V. Kuptsov, Nataliya V. Stankevich","This paper examines the reconstruction of a family of dynamical systems with
neuromorphic behavior using a single scalar time series. A model of a
physiological neuron based on the Hodgkin-Huxley formalism is considered.
Single time series of one of its variables is shown to be enough to train a
neural network that can operate as a discrete time dynamical system with one
control parameter. The neural network system is created in two steps. First,
the delay-coordinate embedding vectors are constructed form the original time
series and their dimension is reduced with by means of a variational
autoencoder to obtain the recovered state-space vectors. It is shown that an
appropriate reduced dimension can be determined by analyzing the autoencoder
training process. Second, pairs of the recovered state-space vectors at
consecutive time steps supplied with a constant value playing the role of a
control parameter are used to train another neural network to make it operate
as a recurrent map. The regimes of thus created neural network system observed
when its control parameter is varied are in very good accordance with those of
the original system, though they were not explicitly presented during training.",http://arxiv.org/pdf/2411.07055v1,
FM-TS: Flow Matching for Time Series Generation,12/11/2024,"Yang Hu, Xiao Wang, Lirong Wu, Huatian Zhang, Stan Z. Li, Sheng Wang, Tianlong Chen","Time series generation has emerged as an essential tool for analyzing
temporal data across numerous fields. While diffusion models have recently
gained significant attention in generating high-quality time series, they tend
to be computationally demanding and reliant on complex stochastic processes. To
address these limitations, we introduce FM-TS, a rectified Flow Matching-based
framework for Time Series generation, which simplifies the time series
generation process by directly optimizing continuous trajectories. This
approach avoids the need for iterative sampling or complex noise schedules
typically required in diffusion-based models. FM-TS is more efficient in terms
of training and inference. Moreover, FM-TS is highly adaptive, supporting both
conditional and unconditional time series generation. Notably, through our
novel inference design, the model trained in an unconditional setting can
seamlessly generalize to conditional tasks without the need for retraining.
Extensive benchmarking across both settings demonstrates that FM-TS
consistently delivers superior performance compared to existing approaches
while being more efficient in terms of training and inference. For instance, in
terms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,
0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI
unconditional time series datasets, respectively, significantly outperforming
the second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and
0.167 on the same datasets. We have achieved superior performance in solar
forecasting and MuJoCo imputation tasks, significantly enhanced by our
innovative $t$ power sampling method. The code is available at
https://github.com/UNITES-Lab/FMTS.",http://arxiv.org/pdf/2411.07506v1,
Approximate Probabilistic Inference for Time-Series Data A Robust Latent Gaussian Model With Temporal Awareness,14/11/2024,"Anton Johansson, Arunselvan Ramaswamy","The development of robust generative models for highly varied non-stationary
time series data is a complex yet important problem. Traditional models for
time series data prediction, such as Long Short-Term Memory (LSTM), are
inefficient and generalize poorly as they cannot capture complex temporal
relationships. In this paper, we present a probabilistic generative model that
can be trained to capture temporal information, and that is robust to data
errors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel
architecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is
trained to minimize a loss function based on the negative log loss. One
contributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is
our regularizer, which accounts for data trends. Experiments conducted show
that tDLGM is able to reconstruct and generate complex time series data, and
that it is robust against to noise and faulty data.",http://arxiv.org/pdf/2411.09312v2,
Local deployment of large-scale music AI models on commodity hardware,14/11/2024,"Xun Zhou, Charlie Ruan, Zihe Zhao, Tianqi Chen, Chris Donahue","We present the MIDInfinite, a web application capable of generating symbolic
music using a large-scale generative AI model locally on commodity hardware.
Creating this demo involved porting the Anticipatory Music Transformer, a large
language model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine
Learning Compilation (MLC) framework. Once the model is ported, MLC facilitates
inference on a variety of runtimes including C++, mobile, and the browser. We
envision that MLC has the potential to bridge the gap between the landscape of
increasingly capable music AI models and technology more familiar to music
software developers. As a proof of concept, we build a web application that
allows users to generate endless streams of multi-instrumental MIDI in the
browser, either from scratch or conditioned on a prompt. On commodity hardware
(an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster
than real-time playback for 72.9% of generations, and increases to 86.3% with 2
seconds of upfront buffering.",http://arxiv.org/pdf/2411.09625v1,
Enhancing Decision Transformer with Diffusion-Based Trajectory Branch Generation,18/11/2024,"Zhihong Liu, Long Qian, Zeyang Liu, Lipeng Wan, Xingyu Chen, Xuguang Lan","Decision Transformer (DT) can learn effective policy from offline datasets by
converting the offline reinforcement learning (RL) into a supervised sequence
modeling task, where the trajectory elements are generated auto-regressively
conditioned on the return-to-go (RTG).However, the sequence modeling learning
approach tends to learn policies that converge on the sub-optimal trajectories
within the dataset, for lack of bridging data to move to better trajectories,
even if the condition is set to the highest RTG.To address this issue, we
introduce Diffusion-Based Trajectory Branch Generation (BG), which expands the
trajectories of the dataset with branches generated by a diffusion model.The
trajectory branch is generated based on the segment of the trajectory within
the dataset, and leads to trajectories with higher returns.We concatenate the
generated branch with the trajectory segment as an expansion of the
trajectory.After expanding, DT has more opportunities to learn policies to move
to better trajectories, preventing it from converging to the sub-optimal
trajectories.Empirically, after processing with BG, DT outperforms
state-of-the-art sequence modeling methods on D4RL benchmark, demonstrating the
effectiveness of adding branches to the dataset without further modifications.",http://arxiv.org/pdf/2411.11327v1,
"A Review on Generative AI Models for Synthetic Medical Text, Time Series, and Longitudinal Data",19/11/2024,"Mohammad Loni, Fatemeh Poursalim, Mehdi Asadi, Arash Gharehbaghi","This paper presents the results of a novel scoping review on the practical
models for generating three different types of synthetic health records (SHRs):
medical text, time series, and longitudinal data. The innovative aspects of the
review, which incorporate study objectives, data modality, and research
methodology of the reviewed studies, uncover the importance and the scope of
the topic for the digital medicine context. In total, 52 publications met the
eligibility criteria for generating medical time series (22), longitudinal data
(17), and medical text (13). Privacy preservation was found to be the main
research objective of the studied papers, along with class imbalance, data
scarcity, and data imputation as the other objectives. The adversarial
network-based, probabilistic, and large language models exhibited superiority
for generating synthetic longitudinal data, time series, and medical texts,
respectively. Finding a reliable performance measure to quantify SHR
re-identification risk is the major research gap of the topic.",http://arxiv.org/pdf/2411.12274v1,
PyAWD: A Library for Generating Large Synthetic Datasets of Acoustic Wave Propagation with Devito,19/11/2024,"Pascal Tribel, Gianluca Bontempi","Seismic data is often sparse and unevenly distributed due to the high costs
and logistical challenges associated with deploying physical seismometers,
limiting the application of Machine Learning (ML) in earthquake analysis. To
address this gap, we introduce PyAWD, a Python library designed to generate
high-resolution synthetic datasets simulating spatio-temporal acoustic wave
propagation in both two-dimensional and three-dimensional heterogeneous media.
By allowing fine control over parameters such as wave speed, external forces,
spatial and temporal discretization, and media composition, PyAWD enables the
creation of ML-scale datasets that capture the complexity of seismic wave
behavior. We illustrate the library's potential with an epicenter retrieval
task, showcasing its suitability for designing complex, accurate seismic
problems that support advanced ML approaches in the absence or lack of dense
real-world data.",http://arxiv.org/pdf/2411.12636v1,
Quantum Kernel-Based Long Short-term Memory,20/11/2024,"Yu-Chao Hsu, Tai-Yu Li, Kuan-Cheng Chen","The integration of quantum computing into classical machine learning
architectures has emerged as a promising approach to enhance model efficiency
and computational capacity. In this work, we introduce the Quantum Kernel-Based
Long Short-Term Memory (QK-LSTM) network, which utilizes quantum kernel
functions within the classical LSTM framework to capture complex, non-linear
patterns in sequential data. By embedding input data into a high-dimensional
quantum feature space, the QK-LSTM model reduces the reliance on large
parameter sets, achieving effective compression while maintaining accuracy in
sequence modeling tasks. This quantum-enhanced architecture demonstrates
efficient convergence, robust loss minimization, and model compactness, making
it suitable for deployment in edge computing environments and resource-limited
quantum devices (especially in the NISQ era). Benchmark comparisons reveal that
QK-LSTM achieves performance on par with classical LSTM models, yet with fewer
parameters, underscoring its potential to advance quantum machine learning
applications in natural language processing and other domains requiring
efficient temporal data processing.",http://arxiv.org/pdf/2411.13225v1,
SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers,20/11/2024,"Hojjat Karami, David Atienza, Anisoara Ionescu","Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.",http://arxiv.org/pdf/2411.13428v1,
Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics,21/11/2024,"Andrew Lesniewski, Giulio Trigila","We propose a highly efficient and accurate methodology for generating
synthetic financial market data using a diffusion model approach. The synthetic
data produced by our methodology align closely with observed market data in
several key aspects: (i) they pass the two-sample Cramer - von Mises test for
portfolios of assets, and (ii) Q - Q plots demonstrate consistency across
quantiles, including in the tails, between observed and generated market data.
Moreover, the covariance matrices derived from a large set of synthetic market
data exhibit significantly lower condition numbers compared to the estimated
covariance matrices of the observed data. This property makes them suitable for
use as regularized versions of the latter. For model training, we develop an
efficient and fast algorithm based on numerical integration rather than Monte
Carlo simulations. The methodology is tested on a large set of equity data.",http://arxiv.org/pdf/2412.00036v2,
CoNFiLD-inlet: Synthetic Turbulence Inflow Using Generative Latent Diffusion Models with Neural Fields,21/11/2024,"Xin-Yang Liu, Meet Hemant Parikh, Xiantao Fan, Pan Du, Qing Wang, Yi-Fan Chen, Jian-Xun Wang","Eddy-resolving turbulence simulations require stochastic inflow conditions
that accurately replicate the complex, multi-scale structures of turbulence.
Traditional recycling-based methods rely on computationally expensive precursor
simulations, while existing synthetic inflow generators often fail to reproduce
realistic coherent structures of turbulence. Recent advances in deep learning
(DL) have opened new possibilities for inflow turbulence generation, yet many
DL-based methods rely on deterministic, autoregressive frameworks prone to
error accumulation, resulting in poor robustness for long-term predictions. In
this work, we present CoNFiLD-inlet, a novel DL-based inflow turbulence
generator that integrates diffusion models with a conditional neural field
(CNF)-encoded latent space to produce realistic, stochastic inflow turbulence.
By parameterizing inflow conditions using Reynolds numbers, CoNFiLD-inlet
generalizes effectively across a wide range of Reynolds numbers ($Re_\tau$
between $10^3$ and $10^4$) without requiring retraining or parameter tuning.
Comprehensive validation through a priori and a posteriori tests in Direct
Numerical Simulation (DNS) and Wall-Modeled Large Eddy Simulation (WMLES)
demonstrates its high fidelity, robustness, and scalability, positioning it as
an efficient and versatile solution for inflow turbulence synthesis.",http://arxiv.org/pdf/2411.14378v1,
VQalAttent: a Transparent Speech Generation Pipeline based on Transformer-learned VQ-VAE Latent Space,22/11/2024,"Armani Rodriguez, Silvija Kokalj-Filipovic","Generating high-quality speech efficiently remains a key challenge for
generative models in speech synthesis. This paper introduces VQalAttent, a
lightweight model designed to generate fake speech with tunable performance and
interpretability. Leveraging the AudioMNIST dataset, consisting of human
utterances of decimal digits (0-9), our method employs a two-step architecture:
first, a scalable vector quantized autoencoder (VQ-VAE) that compresses audio
spectrograms into discrete latent representations, and second, a decoder-only
transformer that learns the probability model of these latents. Trained
transformer generates similar latent sequences, convertible to audio
spectrograms by the VQ-VAE decoder, from which we generate fake utterances.
Interpreting statistical and perceptual quality of the fakes, depending on the
dimension and the extrinsic information of the latent space, enables guided
improvements in larger, commercial generative models. As a valuable tool for
understanding and refining audio synthesis, our results demonstrate
VQalAttent's capacity to generate intelligible speech samples with limited
computational resources, while the modularity and transparency of the training
pipeline helps easily correlate the analytics with modular modifications, hence
providing insights for the more complex models.",http://arxiv.org/pdf/2411.14642v1,
Risk Management with Feature-Enriched Generative Adversarial Networks (FE-GAN),23/11/2024,Ling Chen,"This paper investigates the application of Feature-Enriched Generative
Adversarial Networks (FE-GAN) in financial risk management, with a focus on
improving the estimation of Value at Risk (VaR) and Expected Shortfall (ES).
FE-GAN enhances existing GANs architectures by incorporating an additional
input sequence derived from preceding data to improve model performance. Two
specialized GANs models, the Wasserstein Generative Adversarial Network (WGAN)
and the Tail Generative Adversarial Network (Tail-GAN), were evaluated under
the FE-GAN framework. The results demonstrate that FE-GAN significantly
outperforms traditional architectures in both VaR and ES estimation. Tail-GAN,
leveraging its task-specific loss function, consistently outperforms WGAN in ES
estimation, while both models exhibit similar performance in VaR estimation.
Despite these promising results, the study acknowledges limitations, including
reliance on highly correlated temporal data and restricted applicability to
other domains. Future research directions include exploring alternative input
generation methods, dynamic forecasting models, and advanced neural network
architectures to further enhance GANs-based financial risk estimation.",http://arxiv.org/pdf/2411.15519v1,
Towards Foundation Models for Critical Care Time Series,25/11/2024,"Manuel Burger, Fedor Sergeev, Malte Londschien, Daphné Chopard, Hugo Yèche, Eike Gerdes, Polina Leshetkina, Alexander Morgenroth, Zeynep Babür, Jasmina Bogojeska, Martin Faltys, Rita Kuznetsova, Gunnar Rätsch","Notable progress has been made in generalist medical large language models
across various healthcare areas. However, large-scale modeling of in-hospital
time series data - such as vital signs, lab results, and treatments in critical
care - remains underexplored. Existing datasets are relatively small, but
combining them can enhance patient diversity and improve model robustness. To
effectively utilize these combined datasets for large-scale modeling, it is
essential to address the distribution shifts caused by varying treatment
policies, necessitating the harmonization of treatment variables across the
different datasets. This work aims to establish a foundation for training
large-scale multi-variate time series models on critical care data and to
provide a benchmark for machine learning models in transfer learning across
hospitals to study and address distribution shift challenges. We introduce a
harmonized dataset for sequence modeling and transfer learning research,
representing the first large-scale collection to include core treatment
variables. Future plans involve expanding this dataset to support further
advancements in transfer learning and the development of scalable,
generalizable models for critical healthcare applications.",http://arxiv.org/pdf/2411.16346v1,
Multi-Resolution Generative Modeling of Human Motion from Limited Data,25/11/2024,"David Eduardo Moreno-Villamarín, Anna Hilsmann, Peter Eisert","We present a generative model that learns to synthesize human motion from
limited training sequences. Our framework provides conditional generation and
blending across multiple temporal resolutions. The model adeptly captures human
motion patterns by integrating skeletal convolution layers and a multi-scale
architecture. Our model contains a set of generative and adversarial networks,
along with embedding modules, each tailored for generating motions at specific
frame rates while exerting control over their content and details. Notably, our
approach also extends to the synthesis of co-speech gestures, demonstrating its
ability to generate synchronized gestures from speech inputs, even with limited
paired data. Through direct synthesis of SMPL pose parameters, our approach
avoids test-time adjustments to fit human body meshes. Experimental results
showcase our model's ability to achieve extensive coverage of training
examples, while generating diverse motions, as indicated by local and global
diversity metrics.",http://arxiv.org/pdf/2411.16498v1,10.1145/3697294.3697309
Evolving Markov Chains: Unsupervised Mode Discovery and Recognition from Data Streams,26/11/2024,"Kutalmış Coşkun, Borahan Tümer, Bjarne C. Hiller, Martin Becker","Markov chains are simple yet powerful mathematical structures to model
temporally dependent processes. They generally assume stationary data, i.e.,
fixed transition probabilities between observations/states. However, live,
real-world processes, like in the context of activity tracking, biological time
series, or industrial monitoring, often switch behavior over time. Such
behavior switches can be modeled as transitions between higher-level
\emph{modes} (e.g., running, walking, etc.). Yet all modes are usually not
previously known, often exhibit vastly differing transition probabilities, and
can switch unpredictably. Thus, to track behavior changes of live, real-world
processes, this study proposes an online and efficient method to construct
Evolving Markov chains (EMCs). EMCs adaptively track transition probabilities,
automatically discover modes, and detect mode switches in an online manner. In
contrast to previous work, EMCs are of arbitrary order, the proposed update
scheme does not rely on tracking windows, only updates the relevant region of
the probability tensor, and enjoys geometric convergence of the expected
estimates. Our evaluation of synthetic data and real-world applications on
human activity recognition, electric motor condition monitoring, and eye-state
recognition from electroencephalography (EEG) measurements illustrates the
versatility of the approach and points to the potential of EMCs to efficiently
track, model, and understand live, real-world processes.",http://arxiv.org/pdf/2411.17528v1,
Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation,27/11/2024,"Marco Pasini, Javier Nistal, Stefan Lattner, George Fazekas","Autoregressive models are typically applied to sequences of discrete tokens,
but recent research indicates that generating sequences of continuous
embeddings in an autoregressive manner is also feasible. However, such
Continuous Autoregressive Models (CAMs) can suffer from a decline in generation
quality over extended sequences due to error accumulation during inference. We
introduce a novel method to address this issue by injecting random noise into
the input embeddings during training. This procedure makes the model robust
against varying error levels at inference. We further reduce error accumulation
through an inference procedure that introduces low-level noise. Experiments on
musical audio generation show that CAM substantially outperforms existing
autoregressive and non-autoregressive approaches while preserving audio quality
over extended sequences. This work paves the way for generating continuous
embeddings in a purely autoregressive setting, opening new possibilities for
real-time and interactive generative applications.",http://arxiv.org/pdf/2411.18447v1,
Well log data generation and imputation using sequence-based generative adversarial networks,01/12/2024,"Abdulrahman Al-Fakih, A. Koeshidayatullah, Tapan Mukerji, Sadam Al-Azani, SanLinn I. Kaka","Well log analysis is crucial for hydrocarbon exploration, providing detailed
insights into subsurface geological formations. However, gaps and inaccuracies
in well log data, often due to equipment limitations, operational challenges,
and harsh subsurface conditions, can introduce significant uncertainties in
reservoir evaluation. Addressing these challenges requires effective methods
for both synthetic data generation and precise imputation of missing data,
ensuring data completeness and reliability. This study introduces a novel
framework utilizing sequence-based generative adversarial networks (GANs)
specifically designed for well log data generation and imputation. The
framework integrates two distinct sequence-based GAN models: Time Series GAN
(TSGAN) for generating synthetic well log data and Sequence GAN (SeqGAN) for
imputing missing data. Both models were tested on a dataset from the North Sea,
Netherlands region, focusing on different sections of 5, 10, and 50 data
points. Experimental results demonstrate that this approach achieves superior
accuracy in filling data gaps compared to other deep learning models for
spatial series analysis. The method yielded R^2 values of 0.921, 0.899, and
0.594, with corresponding mean absolute percentage error (MAPE) values of
8.320, 0.005, and 151.154, and mean absolute error (MAE) values of 0.012,
0.005, and 0.032, respectively. These results set a new benchmark for data
integrity and utility in geosciences, particularly in well log data analysis.",http://arxiv.org/pdf/2412.00718v1,
UTSD: Unified Time Series Diffusion Model,04/12/2024,"Xiangkai Ma, Xiaobin Hong, Wenzhong Li, Sanglu Lu","Transformer-based architectures have achieved unprecedented success in time
series analysis. However, facing the challenge of across-domain modeling,
existing studies utilize statistical prior as prompt engineering fails under
the huge distribution shift among various domains. In this paper, a Unified
Time Series Diffusion (UTSD) model is established for the first time to model
the multi-domain probability distribution, utilizing the powerful probability
distribution modeling ability of Diffusion. Unlike the autoregressive models
that capture the conditional probabilities of the prediction horizon to the
historical sequence, we use a diffusion denoising process to model the mixture
distribution of the cross-domain data and generate the prediction sequence for
the target domain directly utilizing conditional sampling. The proposed UTSD
contains three pivotal designs: (1) The condition network captures the
multi-scale fluctuation patterns from the observation sequence, which are
utilized as context representations to guide the denoising network to generate
the prediction sequence; (2) Adapter-based fine-tuning strategy, the
multi-domain universal representation learned in the pretraining stage is
utilized for downstream tasks in target domains; (3) The diffusion and
denoising process on the actual sequence space, combined with the improved
classifier free guidance as the conditional generation strategy, greatly
improves the stability and accuracy of the downstream task. We conduct
extensive experiments on mainstream benchmarks, and the pre-trained UTSD
outperforms existing foundation models on all data domains, exhibiting superior
zero-shot generalization ability. After training from scratch, UTSD achieves
comparable performance against domain-specific proprietary models. The
empirical results validate the potential of UTSD as a time series foundational
model.",http://arxiv.org/pdf/2412.03068v1,
ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning,04/12/2024,"Zhe Xie, Zeyan Li, Xiao He, Longlong Xu, Xidao Wen, Tieying Zhang, Jianjun Chen, Rui Shi, Dan Pei","Understanding time series is crucial for its application in real-world
scenarios. Recently, large language models (LLMs) have been increasingly
applied to time series tasks, leveraging their strong language capabilities to
enhance various applications. However, research on multimodal LLMs (MLLMs) for
time series understanding and reasoning remains limited, primarily due to the
scarcity of high-quality datasets that align time series with textual
information. This paper introduces ChatTS, a novel MLLM designed for time
series analysis. ChatTS treats time series as a modality, similar to how vision
MLLMs process images, enabling it to perform both understanding and reasoning
with time series. To address the scarcity of training data, we propose an
attribute-based method for generating synthetic time series with detailed
attribute descriptions. We further introduce Time Series Evol-Instruct, a novel
approach that generates diverse time series Q&As, enhancing the model's
reasoning capabilities. To the best of our knowledge, ChatTS is the first MLLM
that takes multivariate time series as input, which is fine-tuned exclusively
on synthetic datasets. We evaluate its performance using benchmark datasets
with real-world data, including six alignment tasks and four reasoning tasks.
Our results show that ChatTS significantly outperforms existing vision-based
MLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0% improvement
in alignment tasks and a 25.8% improvement in reasoning tasks.",http://arxiv.org/pdf/2412.03104v1,
Modeling Eye Gaze Velocity Trajectories using GANs with Spectral Loss for Enhanced Fidelity,05/12/2024,"Shailendra Bhandari, Pedro Lencastre, Rujeena Mathema, Alexander Szorkovszky, Anis Yazidi, Pedro Lind","Accurate modeling of eye gaze dynamics is essential for advancement in
human-computer interaction, neurological diagnostics, and cognitive research.
Traditional generative models like Markov models often fail to capture the
complex temporal dependencies and distributional nuance inherent in eye gaze
trajectories data. This study introduces a GAN framework employing LSTM and CNN
generators and discriminators to generate high-fidelity synthetic eye gaze
velocity trajectories. We conducted a comprehensive evaluation of four GAN
architectures: CNN-CNN, LSTM-CNN, CNN-LSTM, and LSTM-LSTM trained under two
conditions: using only adversarial loss and using a weighted combination of
adversarial and spectral losses. Our findings reveal that the LSTM-CNN
architecture trained with this new loss function exhibits the closest alignment
to the real data distribution, effectively capturing both the distribution
tails and the intricate temporal dependencies. The inclusion of spectral
regularization significantly enhances the GANs ability to replicate the
spectral characteristics of eye gaze movements, leading to a more stable
learning process and improved data fidelity. Comparative analysis with an HMM
optimized to four hidden states further highlights the advantages of the
LSTM-CNN GAN. Statistical metrics show that the HMM-generated data
significantly diverges from the real data in terms of mean, standard deviation,
skewness, and kurtosis. In contrast, the LSTM-CNN model closely matches the
real data across these statistics, affirming its capacity to model the
complexity of eye gaze dynamics effectively. These results position the
spectrally regularized LSTM-CNN GAN as a robust tool for generating synthetic
eye gaze velocity data with high fidelity.",http://arxiv.org/pdf/2412.04184v1,
Zephyr quantum-assisted hierarchical Calo4pQVAE for particle-calorimeter interactions,06/12/2024,"Ian Lu, Hao Jia, Sebastian Gonzalez, Deniz Sogutlu, J. Quetzalcoatl Toledo-Marin, Sehmimul Hoque, Abhishek Abhishek, Colin Gay, Roger Melko, Eric Paquet, Geoffrey Fox, Maximilian Swiatlowski, Wojciech Fedorko","With the approach of the High Luminosity Large Hadron Collider (HL-LHC) era
set to begin particle collisions by the end of this decade, it is evident that
the computational demands of traditional collision simulation methods are
becoming increasingly unsustainable. Existing approaches, which rely heavily on
first-principles Monte Carlo simulations for modeling event showers in
calorimeters, are projected to require millions of CPU-years annually -- far
exceeding current computational capacities. This bottleneck presents an
exciting opportunity for advancements in computational physics by integrating
deep generative models with quantum simulations. We propose a quantum-assisted
hierarchical deep generative surrogate founded on a variational autoencoder
(VAE) in combination with an energy conditioned restricted Boltzmann machine
(RBM) embedded in the model's latent space as a prior. By mapping the topology
of D-Wave's Zephyr quantum annealer (QA) into the nodes and couplings of a
4-partite RBM, we leverage quantum simulation to accelerate our shower
generation times significantly. To evaluate our framework, we use Dataset 2 of
the CaloChallenge 2022. Through the integration of classical computation and
quantum simulation, this hybrid framework paves way for utilizing large-scale
quantum simulations as priors in deep generative models.",http://arxiv.org/pdf/2412.04677v1,
Exploring the Impact of Synthetic Data on Human Gesture Recognition Tasks Using GANs,09/12/2024,"George Kontogiannis, Pantelis Tzamalis, Sotiris Nikoletseas","In the evolving domain of Human Activity Recognition (HAR) using Internet of
Things (IoT) devices, there is an emerging interest in employing Deep
Generative Models (DGMs) to address data scarcity, enhance data quality, and
improve classification metrics scores. Among these types of models, Generative
Adversarial Networks (GANs) have arisen as a powerful tool for generating
synthetic data that mimic real-world scenarios with high fidelity. However,
Human Gesture Recognition (HGR), a subset of HAR, particularly in healthcare
applications, using time series data such as allergic gestures, remains highly
unexplored.
  In this paper, we examine and evaluate the performance of two GANs in the
generation of synthetic gesture motion data that compose a part of an
open-source benchmark dataset. The data is related to the disease
identification domain and healthcare, specifically to allergic rhinitis. We
also focus on these AI models' performance in terms of fidelity, diversity, and
privacy. Furthermore, we examine the scenario if the synthetic data can
substitute real data, in training scenarios and how well models trained on
synthetic data can be generalized for the allergic rhinitis gestures. In our
work, these gestures are related to 6-axes accelerometer and gyroscope data,
serving as multi-variate time series instances, and retrieved from smart
wearable devices. To the best of our knowledge, this study is the first to
explore the feasibility of synthesizing motion gestures for allergic rhinitis
from wearable IoT device data using Generative Adversarial Networks (GANs) and
testing their impact on the generalization of gesture recognition systems. It
is worth noting that, even if our method has been applied to a specific
category of gestures, it is designed to be generalized and can be deployed also
to other motion data in the HGR domain.",http://arxiv.org/pdf/2412.06389v1,10.1109/DCOSS-IoT61029.2024.00064
Systematic comparison of deep generative models applied to multivariate financial time series,09/12/2024,"Howard Caulfield, James P. Gleeson","Financial time series (FTS) generation models are a core pillar to
applications in finance. Risk management and portfolio optimization rely on
realistic multivariate price generation models. Accordingly, there is a strong
modelling literature dating back to Bachelier's Theory of Speculation in 1901.
Generating FTS using deep generative models (DGMs) is still in its infancy. In
this work, we systematically compare DGMs against state-of-the-art parametric
alternatives for multivariate FTS generation. We initially compare both DGMs
and parametric models over increasingly complex synthetic datasets. The models
are evaluated through distance measures for varying distribution moments of
both the full and rolling FTS. We then apply the best performing DGM models to
empirical data, demonstrating the benefit of DGMs through a implied volatility
trading task.",http://arxiv.org/pdf/2412.06417v1,
Diffusion-based Method for Satellite Pattern-of-Life Identification,14/12/2024,"Yongchao Ye, Xinting Zhu, Xuejin Shen, Xiaoyu Chen, Lishuai Li, S. Joe Qin","Satellite pattern-of-life (PoL) identification is crucial for space safety
and satellite monitoring, involving the analysis of typical satellite behaviors
such as station-keeping, drift, etc. However, existing PoL identification
methods remain underdeveloped due to the complexity of aerospace systems,
variability in satellite behaviors, and fluctuating observation sampling rates.
In a first attempt, we developed a domain expertise-informed machine learning
method (Expert-ML) to combine satellite orbital movement knowledge and machine
learning models. The Expert-ML method achieved high accuracy results in
simulation data and real-world data with normal sampling rate. However, this
approach lacks of generality as it requires domain expertise and its
performance degraded significantly when data sampling rate varied. To achieve
generality, we propose a novel diffusion-based PoL identification method.
Distinct from prior approaches, the proposed method leverages a diffusion model
to achieve end-to-end identification without manual refinement or
domain-specific knowledge. Specifically, we employ a multivariate time-series
encoder to capture hidden representations of satellite positional data. The
encoded features are subsequently incorporated as conditional information in
the denoising process to generate PoL labels. Through experimentation across
real-world satellite settings, our proposed diffusion-based method demonstrates
its high identification quality and provides a robust solution even with
reduced data sampling rates, indicating its great potential in practical
satellite behavior pattern identification, tracking and related mission
deployment.",http://arxiv.org/pdf/2412.10814v1,
Deep Learning-based Approaches for State Space Models: A Selective Review,15/12/2024,"Jiahe Lin, George Michailidis","State-space models (SSMs) offer a powerful framework for dynamical system
analysis, wherein the temporal dynamics of the system are assumed to be
captured through the evolution of the latent states, which govern the values of
the observations. This paper provides a selective review of recent advancements
in deep neural network-based approaches for SSMs, and presents a unified
perspective for discrete time deep state space models and continuous time ones
such as latent neural Ordinary Differential and Stochastic Differential
Equations. It starts with an overview of the classical maximum likelihood based
approach for learning SSMs, reviews variational autoencoder as a general
learning pipeline for neural network-based approaches in the presence of latent
variables, and discusses in detail representative deep learning models that
fall under the SSM framework. Very recent developments, where SSMs are used as
standalone architectural modules for improving efficiency in sequence modeling,
are also examined. Finally, examples involving mixed frequency and
irregularly-spaced time series data are presented to demonstrate the advantage
of SSMs in these settings.",http://arxiv.org/pdf/2412.11211v1,
Grassmannian Geometry Meets Dynamic Mode Decomposition in DMD-GEN: A New Metric for Mode Collapse in Time Series Generative Models,15/12/2024,"Amime Mohamed Aboussalah, Yassine Abbahaddou","Generative models like Generative Adversarial Networks (GANs) and Variational
Autoencoders (VAEs) often fail to capture the full diversity of their training
data, leading to mode collapse. While this issue is well-explored in image
generation, it remains underinvestigated for time series data. We introduce a
new definition of mode collapse specific to time series and propose a novel
metric, DMD-GEN, to quantify its severity. Our metric utilizes Dynamic Mode
Decomposition (DMD), a data-driven technique for identifying coherent
spatiotemporal patterns, and employs Optimal Transport between DMD eigenvectors
to assess discrepancies between the underlying dynamics of the original and
generated data. This approach not only quantifies the preservation of essential
dynamic characteristics but also provides interpretability by pinpointing which
modes have collapsed. We validate DMD-GEN on both synthetic and real-world
datasets using various generative models, including TimeGAN, TimeVAE, and
DiffusionTS. The results demonstrate that DMD-GEN correlates well with
traditional evaluation metrics for static data while offering the advantage of
applicability to dynamic data. This work offers for the first time a definition
of mode collapse for time series, improving understanding, and forming the
basis of our tool for assessing and improving generative models in the time
series domain.",http://arxiv.org/pdf/2412.11292v1,
Quantization of Climate Change Impacts on Renewable Energy Generation Capacity: A Super-Resolution Recurrent Diffusion Model,16/12/2024,"Xiaochong Dong, Jun Dan, Yingyun Sun, Yang Liu, Xuemin Zhang, Shengwei Mei","Driven by global climate change and the ongoing energy transition, the
coupling between power supply capabilities and meteorological factors has
become increasingly significant. Over the long term, accurately quantifying the
power generation capacity of renewable energy under the influence of climate
change is essential for the development of sustainable power systems. However,
due to interdisciplinary differences in data requirements, climate data often
lacks the necessary hourly resolution to capture the short-term variability and
uncertainties of renewable energy resources. To address this limitation, a
super-resolution recurrent diffusion model (SRDM) has been developed to enhance
the temporal resolution of climate data and model the short-term uncertainty.
The SRDM incorporates a pre-trained decoder and a denoising network, that
generates long-term, high-resolution climate data through a recurrent coupling
mechanism. The high-resolution climate data is then converted into power value
using the mechanism model, enabling the simulation of wind and photovoltaic
(PV) power generation capacity on future long-term scales. Case studies were
conducted in the Ejina region of Inner Mongolia, China, using fifth-generation
reanalysis (ERA5) and coupled model intercomparison project (CMIP6) data under
two climate pathways: SSP126 and SSP585. The results demonstrate that the SRDM
outperforms existing generative models in generating super-resolution climate
data. For the Ejina region, under a high-emission pathway, the annual
utilization hours of wind power are projected to decrease by 2.82 hours/year,
while those for PV power are projected to decrease by 0.26 hours/year.
Furthermore, the research highlights the estimation biases introduced when
low-resolution climate data is used for power conversion.",http://arxiv.org/pdf/2412.11399v1,
Deep Learning for Hydroelectric Optimization: Generating Long-Term River Discharge Scenarios with Ensemble Forecasts from Global Circulation Models,16/12/2024,Julio Alberto Silva Dias,"Hydroelectric power generation is a critical component of the global energy
matrix, particularly in countries like Brazil, where it represents the majority
of the energy supply. However, its strong dependence on river discharges, which
are inherently uncertain due to climate variability, poses significant
challenges. River discharges are linked to precipitation patterns, making the
development of accurate probabilistic forecasting models crucial for improving
operational planning in systems heavily reliant on this resource.
Traditionally, statistical models have been used to represent river discharges
in energy optimization. Yet, these models are increasingly unable to produce
realistic scenarios due to structural shifts in climate behavior. Changes in
precipitation patterns have altered discharge dynamics, which traditional
approaches struggle to capture. Machine learning methods, while effective as
universal predictors for time series, often focus solely on historical data,
ignoring key external factors such as meteorological and climatic conditions.
Furthermore, these methods typically lack a probabilistic framework, which is
vital for representing the inherent variability of hydrological processes. The
limited availability of historical discharge data further complicates the
application of large-scale deep learning models to this domain. To address
these challenges, we propose a framework based on a modified recurrent neural
network architecture. This model generates parameterized probability
distributions conditioned on projections from global circulation models,
effectively accounting for the stochastic nature of river discharges.
Additionally, the architecture incorporates enhancements to improve its
generalization capabilities. We validate this framework within the Brazilian
Interconnected System, using projections from the SEAS5-ECMWF system as
conditional variables.",http://arxiv.org/pdf/2412.12234v1,
Generating Unseen Nonlinear Evolution in Sea Surface Temperature Using a Deep Learning-Based Latent Space Data Assimilation Framework,18/12/2024,"Qingyu Zheng, Guijun Han, Wei Li, Lige Cao, Gongfu Zhou, Haowen Wu, Qi Shao, Ru Wang, Xiaobo Wu, Xudong Cui, Hong Li, Xuan Wang","Advances in data assimilation (DA) methods have greatly improved the accuracy
of Earth system predictions. To fuse multi-source data and reconstruct the
nonlinear evolution missing from observations, geoscientists are developing
future-oriented DA methods. In this paper, we redesign a purely data-driven
latent space DA framework (DeepDA) that employs a generative artificial
intelligence model to capture the nonlinear evolution in sea surface
temperature. Under variational constraints, DeepDA embedded with nonlinear
features can effectively fuse heterogeneous data. The results show that DeepDA
remains highly stable in capturing and generating nonlinear evolutions even
when a large amount of observational information is missing. It can be found
that when only 10% of the observation information is available, the error
increase of DeepDA does not exceed 40%. Furthermore, DeepDA has been shown to
be robust in the fusion of real observations and ensemble simulations. In
particular, this paper provides a mechanism analysis of the nonlinear evolution
generated by DeepDA from the perspective of physical patterns, which reveals
the inherent explainability of our DL model in capturing multi-scale ocean
signals.",http://arxiv.org/pdf/2412.13477v1,
TAUDiff: Improving statistical downscaling for extreme weather events using generative diffusion models,18/12/2024,"Rahul Sundar, Nishant Parashar, Antoine Blanchard, Boyko Dodov","Deterministic regression-based downscaling models for climate variables often
suffer from spectral bias, which can be mitigated by generative models like
diffusion models. To enable efficient and reliable simulation of extreme
weather events, it is crucial to achieve rapid turnaround, dynamical
consistency, and accurate spatio-temporal spectral recovery. We propose an
efficient correction diffusion model, TAUDiff, that combines a deterministic
spatio-temporal model for mean field downscaling with a smaller generative
diffusion model for recovering the fine-scale stochastic features. We
demonstrate the efficacy of this approach on downscaling atmospheric wind
velocity fields obtained from coarse GCM simulations. Our approach can not only
ensure quicker simulation of extreme events but also reduce overall carbon
footprint due to low inference times.",http://arxiv.org/pdf/2412.13627v1,
Continuous latent representations for modeling precipitation with deep learning,19/12/2024,"Gokul Radhakrishnan, Rahul Sundar, Nishant Parashar, Antoine Blanchard, Daiwei Wang, Boyko Dodov","The sparse and spatio-temporally discontinuous nature of precipitation data
presents significant challenges for simulation and statistical processing for
bias correction and downscaling. These include incorrect representation of
intermittency and extreme values (critical for hydrology applications), Gibbs
phenomenon upon regridding, and lack of fine scales details. To address these
challenges, a common approach is to transform the precipitation variable
nonlinearly into one that is more malleable. In this work, we explore how deep
learning can be used to generate a smooth, spatio-temporally continuous
variable as a proxy for simulation of precipitation data. We develop a normally
distributed field called pseudo-precipitation (PP) as an alternative for
simulating precipitation. The practical applicability of this variable is
investigated by applying it for downscaling precipitation from \(1\degree\)
(\(\sim\) 100 km) to \(0.25\degree\) (\(\sim\) 25 km).",http://arxiv.org/pdf/2412.14620v1,
Spatiotemporally Coherent Probabilistic Generation of Weather from Climate,19/12/2024,"Jonathan Schmidt, Luca Schmidt, Felix Strnad, Nicole Ludwig, Philipp Hennig","Local climate information is crucial for impact assessment and
decision-making, yet coarse global climate simulations cannot capture
small-scale phenomena. Current statistical downscaling methods infer these
phenomena as temporally decoupled spatial patches. However, to preserve
physical properties, estimating spatio-temporally coherent high-resolution
weather dynamics for multiple variables across long time horizons is crucial.
We present a novel generative approach that uses a score-based diffusion model
trained on high-resolution reanalysis data to capture the statistical
properties of local weather dynamics. After training, we condition on coarse
climate model data to generate weather patterns consistent with the aggregate
information. As this inference task is inherently uncertain, we leverage the
probabilistic nature of diffusion models and sample multiple trajectories. We
evaluate our approach with high-resolution reanalysis information before
applying it to the climate model downscaling task. We then demonstrate that the
model generates spatially and temporally coherent weather dynamics that align
with global climate output.",http://arxiv.org/pdf/2412.15361v1,
Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis,20/12/2024,"Haowen Xu, Ali Boyaci, Jianming Lian, Aaron Wilson","Detecting and analyzing complex patterns in multivariate time-series data is
crucial for decision-making in urban and environmental system operations.
However, challenges arise from the high dimensionality, intricate complexity,
and interconnected nature of complex patterns, which hinder the understanding
of their underlying physical processes. Existing AI methods often face
limitations in interpretability, computational efficiency, and scalability,
reducing their applicability in real-world scenarios. This paper proposes a
novel visual analytics framework that integrates two generative AI models, Time
Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complex
patterns into lower-dimensional latent spaces and visualize them in 2D using
dimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN.
These visualizations, presented through coordinated and interactive views and
tailored glyphs, enable intuitive exploration of complex multivariate temporal
patterns, identifying patterns' similarities and uncover their potential
correlations for a better interpretability of the AI outputs. The framework is
demonstrated through a case study on power grid signal data, where it
identifies multi-label grid event signatures, including faults and anomalies
with diverse root causes. Additionally, novel metrics and visualizations are
introduced to validate the models and evaluate the performance, efficiency, and
consistency of latent maps generated by TFT and VAE under different
configurations. These analyses provide actionable insights for model parameter
tuning and reliability improvements. Comparative results highlight that TFT
achieves shorter run times and superior scalability to diverse time-series data
shapes compared to VAE. This work advances fault diagnosis in multivariate time
series, fostering explainable AI to support critical system operations.",http://arxiv.org/pdf/2412.16098v1,
