Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Harnessing Causality in Reinforcement Learning With Bagged Decision Times,18/10/2024,"Daiqi Gao, Hsin-Yu Lai, Predrag Klasnja, Susan A. Murphy","We consider reinforcement learning (RL) for a class of problems with bagged
decision times. A bag contains a finite sequence of consecutive decision times.
The transition dynamics are non-Markovian and non-stationary within a bag.
Further, all actions within a bag jointly impact a single reward, observed at
the end of the bag. Our goal is to construct an online RL algorithm to maximize
the discounted sum of the bag-specific rewards. To handle non-Markovian
transitions within a bag, we utilize an expert-provided causal directed acyclic
graph (DAG). Based on the DAG, we construct the states as a dynamical Bayesian
sufficient statistic of the observed history, which results in Markovian state
transitions within and across bags. We then frame this problem as a periodic
Markov decision process (MDP) that allows non-stationarity within a period. An
online RL algorithm based on Bellman-equations for stationary MDPs is
generalized to handle periodic MDPs. To justify the proposed RL algorithm, we
show that our constructed state achieves the maximal optimal value function
among all state constructions for a periodic MDP. Further we prove the Bellman
optimality equations for periodic MDPs. We evaluate the proposed method on
testbed variants, constructed with real data from a mobile health clinical
trial.",http://arxiv.org/pdf/2410.14659v1,,False
Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens,18/10/2024,"Zhepeng Cen, Yao Liu, Siliang Zeng, Pratik Chaudhar, Huzefa Rangwala, George Karypis, Rasool Fakoor","Language models are often trained to maximize the likelihood of the next
token given past tokens in the training dataset. However, during inference
time, they are utilized differently, generating text sequentially and
auto-regressively by using previously generated tokens as input to predict the
next one. Marginal differences in predictions at each step can cascade over
successive steps, resulting in different distributions from what the models
were trained for and potentially leading to unpredictable behavior. This paper
proposes two simple approaches based on model own generation to address this
discrepancy between the training and inference time. Our first approach is
Batch-Scheduled Sampling, where, during training, we stochastically choose
between the ground-truth token from the dataset and the model's own generated
token as input to predict the next token. This is done in an offline manner,
modifying the context window by interleaving ground-truth tokens with those
generated by the model. Our second approach is Reference-Answer-based
Correction, where we explicitly incorporate a self-correction capability into
the model during training. This enables the model to effectively self-correct
the gaps between the generated sequences and the ground truth data without
relying on an external oracle model. By incorporating our proposed strategies
during training, we have observed an overall improvement in performance
compared to baseline methods, as demonstrated by our extensive experiments
using summarization, general question-answering, and math question-answering
tasks.",http://arxiv.org/pdf/2410.14655v1,,False
Neuro-Symbolic Traders: Assessing the Wisdom of AI Crowds in Markets,18/10/2024,"Namid R. Stillman, Rory Baggott","Deep generative models are becoming increasingly used as tools for financial
analysis. However, it is unclear how these models will influence financial
markets, especially when they infer financial value in a semi-autonomous way.
In this work, we explore the interplay between deep generative models and
market dynamics. We develop a form of virtual traders that use deep generative
models to make buy/sell decisions, which we term neuro-symbolic traders, and
expose them to a virtual market. Under our framework, neuro-symbolic traders
are agents that use vision-language models to discover a model of the
fundamental value of an asset. Agents develop this model as a stochastic
differential equation, calibrated to market data using gradient descent. We
test our neuro-symbolic traders on both synthetic data and real financial time
series, including an equity stock, commodity, and a foreign exchange pair. We
then expose several groups of neuro-symbolic traders to a virtual market
environment. This market environment allows for feedback between the traders
belief of the underlying value to the observed price dynamics. We find that
this leads to price suppression compared to the historical data, highlighting a
future risk to market stability. Our work is a first step towards quantifying
the effect of deep generative agents on markets dynamics and sets out some of
the potential risks and benefits of this approach in the future.",http://arxiv.org/pdf/2410.14587v1,,False
ANT: Adaptive Noise Schedule for Time Series Diffusion Models,18/10/2024,"Seunghan Lee, Kibok Lee, Taeyoung Park","Advances in diffusion models for generative artificial intelligence have
recently propagated to the time series (TS) domain, demonstrating
state-of-the-art performance on various tasks. However, prior works on TS
diffusion models often borrow the framework of existing works proposed in other
domains without considering the characteristics of TS data, leading to
suboptimal performance. In this work, we propose Adaptive Noise schedule for
Time series diffusion models (ANT), which automatically predetermines proper
noise schedules for given TS datasets based on their statistics representing
non-stationarity. Our intuition is that an optimal noise schedule should
satisfy the following desiderata: 1) It linearly reduces the non-stationarity
of TS data so that all diffusion steps are equally meaningful, 2) the data is
corrupted to the random noise at the final step, and 3) the number of steps is
sufficiently large. The proposed method is practical for use in that it
eliminates the necessity of finding the optimal noise schedule with a small
additional cost to compute the statistics for given datasets, which can be done
offline before training. We validate the effectiveness of our method across
various tasks, including TS forecasting, refinement, and generation, on
datasets from diverse domains. Code is available at this repository:
https://github.com/seunghan96/ANT.",http://arxiv.org/pdf/2410.14488v1,,False
Transfer Reinforcement Learning in Heterogeneous Action Spaces using Subgoal Mapping,18/10/2024,"Kavinayan P. Sivakumar, Yan Zhang, Zachary Bell, Scott Nivison, Michael M. Zavlanos","In this paper, we consider a transfer reinforcement learning problem
involving agents with different action spaces. Specifically, for any new unseen
task, the goal is to use a successful demonstration of this task by an expert
agent in its action space to enable a learner agent learn an optimal policy in
its own different action space with fewer samples than those required if the
learner was learning on its own. Existing transfer learning methods across
different action spaces either require handcrafted mappings between those
action spaces provided by human experts, which can induce bias in the learning
procedure, or require the expert agent to share its policy parameters with the
learner agent, which does not generalize well to unseen tasks. In this work, we
propose a method that learns a subgoal mapping between the expert agent policy
and the learner agent policy. Since the expert agent and the learner agent have
different action spaces, their optimal policies can have different subgoal
trajectories. We learn this subgoal mapping by training a Long Short Term
Memory (LSTM) network for a distribution of tasks and then use this mapping to
predict the learner subgoal sequence for unseen tasks, thereby improving the
speed of learning by biasing the agent's policy towards the predicted learner
subgoal sequence. Through numerical experiments, we demonstrate that the
proposed learning scheme can effectively find the subgoal mapping underlying
the given distribution of tasks. Moreover, letting the learner agent imitate
the expert agent's policy with the learnt subgoal mapping can significantly
improve the sample efficiency and training time of the learner agent in unseen
new tasks.",http://arxiv.org/pdf/2410.14484v1,,False
DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation,18/10/2024,"Junjie Wu, Xuming Fang, Dusit Niyato, Jiacheng Wang, Jingyu Wang","With the rapid advancements in wireless communication fields, including
low-altitude economies, 6G, and Wi-Fi, the scale of wireless networks continues
to expand, accompanied by increasing service quality demands. Traditional deep
reinforcement learning (DRL)-based optimization models can improve network
performance by solving non-convex optimization problems intelligently. However,
they heavily rely on online deployment and often require extensive initial
training. Online DRL optimization models typically make accurate decisions
based on current channel state distributions. When these distributions change,
their generalization capability diminishes, which hinders the responsiveness
essential for real-time and high-reliability wireless communication networks.
Furthermore, different users have varying quality of service (QoS) requirements
across diverse scenarios, and conventional online DRL methods struggle to
accommodate this variability. Consequently, exploring flexible and customized
AI strategies is critical. We propose a wireless network intent (WNI)-guided
trajectory generation model based on a generative diffusion model (GDM). This
model can be generated and fine-tuned in real time to achieve the objective and
meet the constraints of target intent networks, significantly reducing state
information exposure during wireless communication. Moreover, The WNI-guided
optimization trajectory generation can be customized to address differentiated
QoS requirements, enhancing the overall quality of communication in future
intelligent networks. Extensive simulation results demonstrate that our
approach achieves greater stability in spectral efficiency variations and
outperforms traditional DRL optimization models in dynamic communication
systems.",http://arxiv.org/pdf/2410.14481v1,,False
FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models,18/10/2024,"Rui Hu, Qian He, Gaofeng He, Jiedong Zhuang, Huang Chen, Huafeng Liu, Huamin Wang","Modeling and producing lifelike clothed human images has attracted
researchers' attention from different areas for decades, with the complexity
from highly articulated and structured content. Rendering algorithms decompose
and simulate the imaging process of a camera, while are limited by the accuracy
of modeled variables and the efficiency of computation. Generative models can
produce impressively vivid human images, however still lacking in
controllability and editability. This paper studies photorealism enhancement of
rendered images, leveraging generative power from diffusion models on the
controlled basis of rendering. We introduce a novel framework to translate
rendered images into their realistic counterparts, which consists of two
stages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).
In DKI, we adopt positive (real) domain finetuning and negative (rendered)
domain embedding to inject knowledge into a pretrained Text-to-image (T2I)
diffusion model. In RIG, we generate the realistic image corresponding to the
input rendered image, with a Texture-preserving Attention Control (TAC) to
preserve fine-grained clothing textures, exploiting the decoupled features
encoded in the UNet structure. Additionally, we introduce SynFashion dataset,
featuring high-quality digital clothing images with diverse textures. Extensive
experimental results demonstrate the superiority and effectiveness of our
method in rendered-to-real image translation.",http://arxiv.org/pdf/2410.14429v1,,False
Predicting time-varying flux and balance in metabolic systems using structured neural-ODE processes,18/10/2024,"Santanu Rathod, Pietro Lio, Xiao Zhang","We develop a novel data-driven framework as an alternative to dynamic flux
balance analysis, bypassing the demand for deep domain knowledge and manual
efforts to formulate the optimization problem. The proposed framework is
end-to-end, which trains a structured neural ODE process (SNODEP) model to
estimate flux and balance samples using gene-expression time-series data.
SNODEP is designed to circumvent the limitations of the standard neural ODE
process model, including restricting the latent and decoder sampling
distributions to be normal and lacking structure between context points for
calculating the latent, thus more suitable for modeling the underlying dynamics
of a metabolic system. Through comprehensive experiments ($156$ in total), we
demonstrate that SNODEP not only predicts the unseen time points of real-world
gene-expression data and the flux and balance estimates well but can even
generalize to more challenging unseen knockout configurations and irregular
data sampling scenarios, all essential for metabolic pathway analysis. We hope
our work can serve as a catalyst for building more scalable and powerful models
for genome-scale metabolic analysis. Our code is available at:
\url{https://github.com/TrustMLRG/SNODEP}.",http://arxiv.org/pdf/2410.14426v1,,False
Unscrambling disease progression at scale: fast inference of event permutations with optimal transport,18/10/2024,"Peter A. Wijeratne, Daniel C. Alexander","Disease progression models infer group-level temporal trajectories of change
in patients' features as a chronic degenerative condition plays out. They
provide unique insight into disease biology and staging systems with
individual-level clinical utility. Discrete models consider disease progression
as a latent permutation of events, where each event corresponds to a feature
becoming measurably abnormal. However, permutation inference using traditional
maximum likelihood approaches becomes prohibitive due to combinatoric
explosion, severely limiting model dimensionality and utility. Here we leverage
ideas from optimal transport to model disease progression as a latent
permutation matrix of events belonging to the Birkhoff polytope, facilitating
fast inference via optimisation of the variational lower bound. This enables a
factor of 1000 times faster inference than the current state of the art and,
correspondingly, supports models with several orders of magnitude more features
than the current state of the art can consider. Experiments demonstrate the
increase in speed, accuracy and robustness to noise in simulation. Further
experiments with real-world imaging data from two separate datasets, one from
Alzheimer's disease patients, the other age-related macular degeneration,
showcase, for the first time, pixel-level disease progression events in the
brain and eye, respectively. Our method is low compute, interpretable and
applicable to any progressive condition and data modality, giving it broad
potential clinical utility.",http://arxiv.org/pdf/2410.14388v1,,False
Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and the inductive Gauss-Bregman centers,18/10/2024,Frank Nielsen,"The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of
a set of mutually absolutely continuous probability distributions on a measure
space provides a notion of centrality which has proven useful in many tasks
including information retrieval, information fusion, and clustering in image,
video and sound processing. However, the Jeffreys centroid is not available in
closed-form for sets of categorical or normal distributions, two widely used
statistical models, and thus need to be approximated numerically in practice.
In this paper, we first propose the new Jeffreys-Fisher-Rao center defined as
the Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in
replacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a
generic formula for uni-parameter exponential family distributions, and
closed-form formula for categorical and normal distributions, matches exactly
the Jeffreys centroid for same-mean normal distributions, and is experimentally
observed in practice to be close to the Jeffreys centroid. Second, we define a
new type of inductive centers generalizing the principle of Gauss
arithmetic-geometric double sequence mean for pairs of densities of any given
exponential family. This center is shown experimentally to approximate very
well the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao
center is not available in closed form. Moreover, this Gauss-Bregman inductive
center always converges and matches the Jeffreys centroid for sets of same-mean
normal distributions. We report on our experiments demonstrating the use of the
Jeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.
Finally, we conclude this work by reinterpreting these fast proxy centers of
Jeffreys centroids under the lens of dually flat spaces in information
geometry.",http://arxiv.org/pdf/2410.14326v1,,False
Game Theory with Simulation in the Presence of Unpredictable Randomisation,18/10/2024,"Vojtech Kovarik, Nathaniel Sauerberg, Lewis Hammond, Vincent Conitzer","AI agents will be predictable in certain ways that traditional agents are
not. Where and how can we leverage this predictability in order to improve
social welfare? We study this question in a game-theoretic setting where one
agent can pay a fixed cost to simulate the other in order to learn its mixed
strategy. As a negative result, we prove that, in contrast to prior work on
pure-strategy simulation, enabling mixed-strategy simulation may no longer lead
to improved outcomes for both players in all so-called ""generalised trust
games"". In fact, mixed-strategy simulation does not help in any game where the
simulatee's action can depend on that of the simulator. We also show that, in
general, deciding whether simulation introduces Pareto-improving Nash
equilibria in a given game is NP-hard. As positive results, we establish that
mixed-strategy simulation can improve social welfare if the simulator has the
option to scale their level of trust, if the players face challenges with both
trust and coordination, or if maintaining some level of privacy is essential
for enabling cooperation.",http://arxiv.org/pdf/2410.14311v1,,False
On time series clustering with k-means,18/10/2024,"Christopher Holder, Anthony Bagnall, Jason Lines","There is a long history of research into time series clustering using
distance-based partitional clustering. Many of the most popular algorithms
adapt k-means (also known as Lloyd's algorithm) to exploit time dependencies in
the data by specifying a time series distance function. However, these
algorithms are often presented with k-means configured in various ways,
altering key parameters such as the initialisation strategy. This variability
makes it difficult to compare studies because k-means is known to be highly
sensitive to its configuration. To address this, we propose a standard
Lloyd's-based model for TSCL that adopts an end-to-end approach, incorporating
a specialised distance function not only in the assignment step but also in the
initialisation and stopping criteria. By doing so, we create a unified
structure for comparing seven popular Lloyd's-based TSCL algorithms. This
common framework enables us to more easily attribute differences in clustering
performance to the distance function itself, rather than variations in the
k-means configuration.",http://arxiv.org/pdf/2410.14269v1,,False
Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation,18/10/2024,"Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Xiaowen Dong, Yanfeng Wang, Siheng Chen","Post-training is essential for enabling large language models (LLMs) to
follow human instructions. Inspired by the recent success of using LLMs to
simulate human society, we leverage multi-agent simulation to automatically
generate diverse text-based scenarios, capturing a wide range of real-world
human needs. We propose MATRIX, a multi-agent simulator that creates realistic
and scalable scenarios. Leveraging these outputs, we introduce a novel
scenario-driven instruction generator MATRIX-Gen for controllable and highly
realistic data synthesis. Extensive experiments demonstrate that our framework
effectively generates both general and domain-specific data. Notably, on
AlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on
datasets synthesized by MATRIX-Gen with just 20K instruction-response pairs,
outperforms Meta's Llama-3-8B-Instruct model, which was trained on over 10M
pairs; see our project at https://github.com/ShuoTang123/MATRIX-Gen.",http://arxiv.org/pdf/2410.14251v1,,False
Auto Detecting Cognitive Events Using Machine Learning on Pupillary Data,18/10/2024,"Quang Dang, Murat Kucukosmanoglu, Michael Anoruo, Golshan Kargosha, Sarah Conklin, Justin Brooks","Assessing cognitive workload is crucial for human performance as it affects
information processing, decision making, and task execution. Pupil size is a
valuable indicator of cognitive workload, reflecting changes in attention and
arousal governed by the autonomic nervous system. Cognitive events are closely
linked to cognitive workload as they activate mental processes and trigger
cognitive responses. This study explores the potential of using machine
learning to automatically detect cognitive events experienced using
individuals. We framed the problem as a binary classification task, focusing on
detecting stimulus onset across four cognitive tasks using CNN models and
1-second pupillary data. The results, measured by Matthew's correlation
coefficient, ranged from 0.47 to 0.80, depending on the cognitive task. This
paper discusses the trade-offs between generalization and specialization, model
behavior when encountering unseen stimulus onset times, structural variances
among cognitive tasks, factors influencing model predictions, and real-time
simulation. These findings highlight the potential of machine learning
techniques in detecting cognitive events based on pupil and eye movement
responses, contributing to advancements in personalized learning and optimizing
neurocognitive workload management.",http://arxiv.org/pdf/2410.14174v1,,False
Estimating the Causal Effects of T Cell Receptors,18/10/2024,"Eli N. Weinstein, Elizabeth B. Wood, David M. Blei","A central question in human immunology is how a patient's repertoire of T
cells impacts disease. Here, we introduce a method to infer the causal effects
of T cell receptor (TCR) sequences on patient outcomes using observational TCR
repertoire sequencing data and clinical outcomes data. Our approach corrects
for unobserved confounders, such as a patient's environment and life history,
by using the patient's immature, pre-selection TCR repertoire. The
pre-selection repertoire can be estimated from nonproductive TCR data, which is
widely available. It is generated by a randomized mutational process, V(D)J
recombination, which provides a natural experiment. We show formally how to use
the pre-selection repertoire to draw causal inferences, and develop a scalable
neural-network estimator for our identification formula. Our method produces an
estimate of the effect of interventions that add a specific TCR sequence to
patient repertoires. As a demonstration, we use it to analyze the effects of
TCRs on COVID-19 severity, uncovering potentially therapeutic TCRs that are (1)
observed in patients, (2) bind SARS-CoV-2 antigens in vitro and (3) have strong
positive effects on clinical outcomes.",http://arxiv.org/pdf/2410.14127v1,,False
Transfer Learning on Transformers for Building Energy Consumption Forecasting -- A Comparative Study,18/10/2024,"Robert Spencer, Surangika Ranathunga, Mikael Boulic, Andries, van Heerden, Teo Susnjak","This study investigates the application of Transfer Learning (TL) on
Transformer architectures to enhance building energy consumption forecasting.
Transformers are a relatively new deep learning architecture, which has served
as the foundation for groundbreaking technologies such as ChatGPT. While TL has
been studied in the past, these studies considered either one TL strategy or
used older deep learning models such as Recurrent Neural Networks or
Convolutional Neural Networks. Here, we carry out an extensive empirical study
on six different TL strategies and analyse their performance under varying
feature spaces. In addition to the vanilla Transformer architecture, we also
experiment with Informer and PatchTST, specifically designed for time series
forecasting. We use 16 datasets from the Building Data Genome Project 2 to
create building energy consumption forecasting models. Experiment results
reveal that while TL is generally beneficial, especially when the target domain
has no data, careful selection of the exact TL strategy should be made to gain
the maximum benefit. This decision largely depends on the feature space
properties such as the recorded weather features. We also note that PatchTST
outperforms the other two Transformer variants (vanilla Transformer and
Informer). We believe our findings would assist researchers in making informed
decision in using TL and transformer architectures for building energy
consumption forecasting.",http://arxiv.org/pdf/2410.14107v1,,False
