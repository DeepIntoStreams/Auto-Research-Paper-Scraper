Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Approaching Deep Learning through the Spectral Dynamics of Weights,21/08/2024,"David Yunis, Kumar Kshitij Patel, Samuel Wheeler, Pedro Savarese, Gal Vardi, Karen Livescu, Michael Maire, Matthew R. Walter","We propose an empirical approach centered on the spectral dynamics of weights
-- the behavior of singular values and vectors during optimization -- to unify
and clarify several phenomena in deep learning. We identify a consistent bias
in optimization across various experiments, from small-scale ``grokking'' to
large-scale tasks like image classification with ConvNets, image generation
with UNets, speech recognition with LSTMs, and language modeling with
Transformers. We also demonstrate that weight decay enhances this bias beyond
its role as a norm regularizer, even in practical systems. Moreover, we show
that these spectral dynamics distinguish memorizing networks from generalizing
ones, offering a novel perspective on this longstanding conundrum.
Additionally, we leverage spectral dynamics to explore the emergence of
well-performing sparse subnetworks (lottery tickets) and the structure of the
loss surface through linear mode connectivity. Our findings suggest that
spectral dynamics provide a coherent framework to better understand the
behavior of neural networks across diverse settings.",http://arxiv.org/pdf/2408.11804v1,,False
Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests,21/08/2024,"Amirhossein Deljouyi, Roham Koohestani, Maliheh Izadi, Andy Zaidman","Automated unit test generators, particularly search-based software testing
tools like EvoSuite, are capable of generating tests with high coverage.
Although these generators alleviate the burden of writing unit tests, they
often pose challenges for software engineers in terms of understanding the
generated tests. To address this, we introduce UTGen, which combines
search-based software testing and large language models to enhance the
understandability of automatically generated test cases. We achieve this
enhancement through contextualizing test data, improving identifier naming, and
adding descriptive comments. Through a controlled experiment with 32
participants from both academia and industry, we investigate how the
understandability of unit tests affects a software engineer's ability to
perform bug-fixing tasks. We selected bug-fixing to simulate a real-world
scenario that emphasizes the importance of understandable test cases. We
observe that participants working on assignments with UTGen test cases fix up
to 33% more bugs and use up to 20% less time when compared to baseline test
cases. From the post-test questionnaire, we gathered that participants found
that enhanced test names, test data, and variable names improved their
bug-fixing process.",http://arxiv.org/pdf/2408.11710v1,,False
5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges,21/08/2024,"Desire Guel, Arsene Kabore, Didier Bassole","In this paper, we present a novel approach to interference detection in 5G
New Radio (5G-NR) networks using Convolutional Neural Networks (CNN).
Interference in 5G networks challenges high-quality service due to dense user
equipment deployment and increased wireless environment complexity. Our
CNN-based model is designed to detect Physical Random Access Channel (PRACH)
sequences amidst various interference scenarios, leveraging the spatial and
temporal characteristics of PRACH signals to enhance detection accuracy and
robustness. Comprehensive datasets of simulated PRACH signals under controlled
interference conditions were generated to train and validate the model.
Experimental results show that our CNN-based approach outperforms traditional
PRACH detection methods in accuracy, precision, recall and F1-score. This study
demonstrates the potential of AI/ML techniques in advancing interference
management in 5G networks, providing a foundation for future research and
practical applications in optimizing network performance and reliability.",http://arxiv.org/pdf/2408.11659v1,,False
CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher,21/08/2024,"Derry Pratama, Naufal Suryanto, Andro Aprila Adiputra, Thi-Thu-Huong Le, Ahmada Yusril Kadiptya, Muhammad Iqbal, Howon Kim","Penetration testing, a critical component of cybersecurity, typically
requires extensive time and effort to find vulnerabilities. Beginners in this
field often benefit from collaborative approaches with the community or
experts. To address this, we develop CIPHER (Cybersecurity Intelligent
Penetration-testing Helper for Ethical Researchers), a large language model
specifically trained to assist in penetration testing tasks. We trained CIPHER
using over 300 high-quality write-ups of vulnerable machines, hacking
techniques, and documentation of open-source penetration testing tools.
Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR)
Flow augmentation, a novel method to augment penetration testing write-ups to
establish a fully automated pentesting simulation benchmark tailored for large
language models. This approach fills a significant gap in traditional
cybersecurity Q\&A benchmarks and provides a realistic and rigorous standard
for evaluating AI's technical knowledge, reasoning capabilities, and practical
utility in dynamic penetration testing scenarios. In our assessments, CIPHER
achieved the best overall performance in providing accurate suggestion
responses compared to other open-source penetration testing models of similar
size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B
Chat, particularly on insane difficulty machine setups. This demonstrates that
the current capabilities of general LLMs are insufficient for effectively
guiding users through the penetration testing process. We also discuss the
potential for improvement through scaling and the development of better
benchmarks using FARR Flow augmentation results. Our benchmark will be released
publicly at https://github.com/ibndias/CIPHER.",http://arxiv.org/pdf/2408.11650v1,,False
Don't Kill the Baby: The Case for AI in Arbitration,21/08/2024,"Michael Broyde, Yiyang Mei","Since the introduction of Generative AI (GenAI) in 2022, its ability to
simulate human intelligence and generate content has sparked both enthusiasm
and concern. While much criticism focuses on AI's potential to perpetuate bias,
create emotional dissonance, displace jobs, and raise ethical questions, these
concerns often overlook the practical benefits of AI, particularly in legal
contexts.
  This article examines the integration of AI into arbitration, arguing that
the Federal Arbitration Act (FAA) allows parties to contractually choose
AI-driven arbitration, despite traditional reservations. The article makes
three key contributions: (1) It shifts the focus from debates over AI's
personhood to the practical aspects of incorporating AI into arbitration,
asserting that AI can effectively serve as an arbitrator if both parties agree;
(2) It positions arbitration as an ideal starting point for broader AI adoption
in the legal field, given its flexibility and the autonomy it grants parties to
define their standards of fairness; and (3) It outlines future research
directions, emphasizing the importance of empirically comparing AI and human
arbitration, which could lead to the development of distinct systems.
  By advocating for the use of AI in arbitration, this article underscores the
importance of respecting contractual autonomy and creating an environment that
allows AI's potential to be fully realized. Drawing on the insights of Judge
Richard Posner, the article argues that the ethical obligations of AI in
arbitration should be understood within the context of its technological
strengths and the voluntary nature of arbitration agreements. Ultimately, it
calls for a balanced, open-minded approach to AI in arbitration, recognizing
its potential to enhance the efficiency, fairness, and flexibility of dispute
resolution",http://arxiv.org/pdf/2408.11608v1,,False
Explainable Deep Learning Framework for Human Activity Recognition,21/08/2024,"Yiran Huang, Yexu Zhou, Haibin Zhao, Till Riedel, Michael Beigl","In the realm of human activity recognition (HAR), the integration of
explainable Artificial Intelligence (XAI) emerges as a critical necessity to
elucidate the decision-making processes of complex models, fostering
transparency and trust. Traditional explanatory methods like Class Activation
Mapping (CAM) and attention mechanisms, although effective in highlighting
regions vital for decisions in various contexts, prove inadequate for HAR. This
inadequacy stems from the inherently abstract nature of HAR data, rendering
these explanations obscure. In contrast, state-of-th-art post-hoc
interpretation techniques for time series can explain the model from other
perspectives. However, this requires extra effort. It usually takes 10 to 20
seconds to generate an explanation. To overcome these challenges, we proposes a
novel, model-agnostic framework that enhances both the interpretability and
efficacy of HAR models through the strategic use of competitive data
augmentation. This innovative approach does not rely on any particular model
architecture, thereby broadening its applicability across various HAR models.
By implementing competitive data augmentation, our framework provides intuitive
and accessible explanations of model decisions, thereby significantly advancing
the interpretability of HAR systems without compromising on performance.",http://arxiv.org/pdf/2408.11552v1,,False
Learning Deep Dissipative Dynamics,21/08/2024,"Yuji Okamoto, Ryosuke Kojima","This study challenges strictly guaranteeing ``dissipativity'' of a dynamical
system represented by neural networks learned from given time-series data.
Dissipativity is a crucial indicator for dynamical systems that generalizes
stability and input-output stability, known to be valid across various systems
including robotics, biological systems, and molecular dynamics. By analytically
proving the general solution to the nonlinear Kalman-Yakubovich-Popov (KYP)
lemma, which is the necessary and sufficient condition for dissipativity, we
propose a differentiable projection that transforms any dynamics represented by
neural networks into dissipative ones and a learning method for the transformed
dynamics. Utilizing the generality of dissipativity, our method strictly
guarantee stability, input-output stability, and energy conservation of trained
dynamical systems. Finally, we demonstrate the robustness of our method against
out-of-domain input through applications to robotic arms and fluid dynamics.
Code here https://github.com/kojima-r/DeepDissipativeModel",http://arxiv.org/pdf/2408.11479v1,,False
Bidirectional Gated Mamba for Sequential Recommendation,21/08/2024,"Ziwei Liu, Qidong Liu, Yejing Wang, Wanyu Wang, Pengyue Jia, Maolin Wang, Zitao Liu, Yi Chang, Xiangyu Zhao","In various domains, Sequential Recommender Systems (SRS) have become
essential due to their superior capability to discern intricate user
preferences. Typically, SRS utilize transformer-based architectures to forecast
the subsequent item within a sequence. Nevertheless, the quadratic
computational complexity inherent in these models often leads to
inefficiencies, hindering the achievement of real-time recommendations. Mamba,
a recent advancement, has exhibited exceptional performance in time series
prediction, significantly enhancing both efficiency and accuracy. However,
integrating Mamba directly into SRS poses several challenges. Its inherently
unidirectional nature may constrain the model's capacity to capture the full
context of user-item interactions, while its instability in state estimation
can compromise its ability to detect short-term patterns within interaction
sequences.
  To overcome these issues, we introduce a new framework named
\textbf{\underline{S}}elect\textbf{\underline{I}}ve \textbf{\underline{G}}ated
\textbf{\underline{MA}}mba (SIGMA). This framework leverages a Partially
Flipped Mamba (PF-Mamba) to construct a bidirectional architecture specifically
tailored to improve contextual modeling. Additionally, an input-sensitive Dense
Selective Gate (DS Gate) is employed to optimize directional weights and
enhance the processing of sequential information in PF-Mamba. For short
sequence modeling, we have also developed a Feature Extract GRU (FE-GRU) to
efficiently capture short-term dependencies. Empirical results indicate that
SIGMA outperforms current models on five real-world datasets. Our
implementation code is available at \url{https://github.com/ziwliu-cityu/SIMGA}
to ease reproducibility.",http://arxiv.org/pdf/2408.11451v1,,False
DABench: A Benchmark Dataset for Data-Driven Weather Data Assimilation,21/08/2024,"Wuxin Wang, Weicheng Ni, Tao Han, Lei Bai, Boheng Duan, Kaijun Ren","Recent advancements in deep learning (DL) have led to the development of
several Large Weather Models (LWMs) that rival state-of-the-art (SOTA)
numerical weather prediction (NWP) systems. Up to now, these models still rely
on traditional NWP-generated analysis fields as input and are far from being an
autonomous system. While researchers are exploring data-driven data
assimilation (DA) models to generate accurate initial fields for LWMs, the lack
of a standard benchmark impedes the fair evaluation among different data-driven
DA algorithms. Here, we introduce DABench, a benchmark dataset utilizing ERA5
data as ground truth to guide the development of end-to-end data-driven weather
prediction systems. DABench contributes four standard features: (1) sparse and
noisy simulated observations under the guidance of the observing system
simulation experiment method; (2) a skillful pre-trained weather prediction
model to generate background fields while fairly evaluating the impact of
assimilation outcomes on predictions; (3) standardized evaluation metrics for
model comparison; (4) a strong baseline called the DA Transformer (DaT). DaT
integrates the four-dimensional variational DA prior knowledge into the
Transformer model and outperforms the SOTA in physical state reconstruction,
named 4DVarNet. Furthermore, we exemplify the development of an end-to-end
data-driven weather prediction system by integrating DaT with the prediction
model. Researchers can leverage DABench to develop their models and compare
performance against established baselines, which will benefit the future
advancements of data-driven weather prediction systems. The code is available
on this Github repository and the dataset is available at the Baidu Drive.",http://arxiv.org/pdf/2408.11438v1,,False
First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models,21/08/2024,"Chi Ma, Mincong Huang, Ying Zhang, Chao Wang, Yujie Wang, Lei Yu, Chuan Liu, Wei Lin","Dynamic activation (DA) techniques, such as DejaVu and MoEfication, have
demonstrated their potential to significantly enhance the inference efficiency
of large language models (LLMs). However, these techniques often rely on ReLU
activation functions or require additional parameters and training to maintain
performance. This paper introduces a training-free Threshold-based Dynamic
Activation(TDA) method that leverage sequence information to exploit the
inherent sparsity of models across various architectures. This method is
designed to accelerate generation speed by 18-25\% without significantly
compromising task performance, thereby addressing the limitations of existing
DA techniques. Moreover, we delve into the root causes of LLM sparsity and
theoretically analyze two of its critical features: history-related activation
uncertainty and semantic-irrelevant activation inertia. Our comprehensive
analyses not only provide a robust theoretical foundation for DA methods but
also offer valuable insights to guide future research in optimizing LLMs for
greater efficiency and effectiveness.",http://arxiv.org/pdf/2408.11393v1,,False
Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features,21/08/2024,"Hiba Najjar, Marlon Nuske, Andreas Dengel","The availability of temporal geospatial data in multiple modalities has been
extensively leveraged to enhance the performance of machine learning models.
While efforts on the design of adequate model architectures are approaching a
level of saturation, focusing on a data-centric perspective can complement
these efforts to achieve further enhancements in data usage efficiency and
model generalization capacities. This work contributes to this direction. We
leverage model explanation methods to identify the features crucial for the
model to reach optimal performance and the smallest set of features sufficient
to achieve this performance. We evaluate our approach on three temporal
multimodal geospatial datasets and compare multiple model explanation
techniques. Our results reveal that some datasets can reach their optimal
accuracy with less than 20% of the temporal instances, while in other datasets,
the time series of a single band from a single modality is sufficient.",http://arxiv.org/pdf/2408.11384v1,,False
Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation,21/08/2024,"Hao Wang, Yongqiang Han, Kefan Wang, Kai Cheng, Zhen Wang, Wei Guo, Yong Liu, Defu Lian, Enhong Chen","In the realm of recommendation systems, users exhibit a diverse array of
behaviors when interacting with items. This phenomenon has spurred research
into learning the implicit semantic relationships between these behaviors to
enhance recommendation performance. However, these methods often entail high
computational complexity. To address concerns regarding efficiency,
pre-training presents a viable solution. Its objective is to extract knowledge
from extensive pre-training data and fine-tune the model for downstream tasks.
Nevertheless, previous pre-training methods have primarily focused on
single-behavior data, while multi-behavior data contains significant noise.
Additionally, the fully fine-tuning strategy adopted by these methods still
imposes a considerable computational burden. In response to this challenge, we
propose DPCPL, the first pre-training and prompt-tuning paradigm tailored for
Multi-Behavior Sequential Recommendation. Specifically, in the pre-training
stage, we commence by proposing a novel Efficient Behavior Miner (EBM) to
filter out the noise at multiple time scales, thereby facilitating the
comprehension of the contextual semantics of multi-behavior sequences.
Subsequently, we propose to tune the pre-trained model in a highly efficient
manner with the proposed Customized Prompt Learning (CPL) module, which
generates personalized, progressive, and diverse prompts to fully exploit the
potential of the pre-trained model effectively. Extensive experiments on three
real-world datasets have unequivocally demonstrated that DPCPL not only
exhibits high efficiency and effectiveness, requiring minimal parameter
adjustments but also surpasses the state-of-the-art performance across a
diverse range of downstream tasks.",http://arxiv.org/pdf/2408.11372v1,,False
ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding,21/08/2024,"Yijia Xiao, Edward Sun, Yiqiao Jin, Qifan Wang, Wei Wang","Understanding biological processes, drug development, and biotechnological
advancements requires detailed analysis of protein structures and sequences, a
task in protein research that is inherently complex and time-consuming when
performed manually. To streamline this process, we introduce ProteinGPT, a
state-of-the-art multi-modal protein chat system, that allows users to upload
protein sequences and/or structures for comprehensive protein analysis and
responsive inquiries. ProteinGPT seamlessly integrates protein sequence and
structure encoders with linear projection layers for precise representation
adaptation, coupled with a large language model (LLM) to generate accurate and
contextually relevant responses. To train ProteinGPT, we construct a
large-scale dataset of 132,092 proteins with annotations, and optimize the
instruction-tuning process using GPT-4o. This innovative system ensures
accurate alignment between the user-uploaded data and prompts, simplifying
protein analysis. Experiments show that ProteinGPT can produce promising
responses to proteins and their corresponding questions.",http://arxiv.org/pdf/2408.11363v1,,False
Clinical Context-aware Radiology Report Generation from Medical Images using Transformers,21/08/2024,Sonit Singh,"Recent developments in the field of Natural Language Processing, especially
language models such as the transformer have brought state-of-the-art results
in language understanding and language generation. In this work, we investigate
the use of the transformer model for radiology report generation from chest
X-rays. We also highlight limitations in evaluating radiology report generation
using only the standard language generation metrics. We then applied a
transformer based radiology report generation architecture, and also compare
the performance of a transformer based decoder with the recurrence based
decoder. Experiments were performed using the IU-CXR dataset, showing superior
results to its LSTM counterpart and being significantly faster. Finally, we
identify the need of evaluating radiology report generation system using both
language generation metrics and classification metrics, which helps to provide
robust measure of generated reports in terms of their coherence and diagnostic
value.",http://arxiv.org/pdf/2408.11344v1,,False
Taming Generative Diffusion for Universal Blind Image Restoration,21/08/2024,"Siwei Tu, Weidong Yang, Ben Fei","Diffusion models have been widely utilized for image restoration. However,
previous blind image restoration methods still need to assume the type of
degradation model while leaving the parameters to be optimized, limiting their
real-world applications. Therefore, we aim to tame generative diffusion prior
for universal blind image restoration dubbed BIR-D, which utilizes an
optimizable convolutional kernel to simulate the degradation model and
dynamically update the parameters of the kernel in the diffusion steps,
enabling it to achieve blind image restoration results even in various complex
situations. Besides, based on mathematical reasoning, we have provided an
empirical formula for the chosen of adaptive guidance scale, eliminating the
need for a grid search for the optimal parameter. Experimentally, Our BIR-D has
demonstrated superior practicality and versatility than off-the-shelf
unsupervised methods across various tasks both on real-world and synthetic
datasets, qualitatively and quantitatively. BIR-D is able to fulfill
multi-guidance blind image restoration. Moreover, BIR-D can also restore images
that undergo multiple and complicated degradations, demonstrating the practical
applications.",http://arxiv.org/pdf/2408.11287v1,,False
Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers,21/08/2024,"Prashant Serai, Peidong Wang, Eric Fosler-Lussier","Modeling the errors of a speech recognizer can help simulate errorful
recognized speech data from plain text, which has proven useful for tasks like
discriminative language modeling, improving robustness of NLP systems, where
limited or even no audio data is available at train time. Previous work
typically considered replicating behavior of GMM-HMM based systems, but the
behavior of more modern posterior-based neural network acoustic models is not
the same and requires adjustments to the error prediction model. In this work,
we extend a prior phonetic confusion based model for predicting speech
recognition errors in two ways: first, we introduce a sampling-based paradigm
that better simulates the behavior of a posterior-based acoustic model. Second,
we investigate replacing the confusion matrix with a sequence-to-sequence model
in order to introduce context dependency into the prediction. We evaluate the
error predictors in two ways: first by predicting the errors made by a
Switchboard ASR system on unseen data (Fisher), and then using that same
predictor to estimate the behavior of an unrelated cloud-based ASR system on a
novel task. Sampling greatly improves predictive accuracy within a 100-guess
paradigm, while the sequence model performs similarly to the confusion matrix.",http://arxiv.org/pdf/2408.11258v1,,False
A case study on different one-factor Cheyette models for short maturity caplet calibration,21/08/2024,"Arun Kumar Polala, Bernhard Hientzsch","In [1], we calibrated a one-factor Cheyette SLV model with a local volatility
that is linear in the benchmark forward rate and an uncorrelated CIR stochastic
variance to 3M caplets of various maturities. While caplet smiles for many
maturities could be reasonably well calibrated across the range of strikes, for
instance the 1Y maturity could not be calibrated well across that entire range
of strikes. Here, we study whether models with alternative local volatility
terms and/or alternative stochastic volatility or variance models can calibrate
the 1Y caplet smile better across the strike range better than the model
studied in [1]. This is made possible and feasible by the generic simulation,
pricing, and calibration frameworks introduced in [1] and some new frameworks
presented in this paper. We find that some model settings calibrate well to the
1Y smile across the strike range under study. In particular, a model setting
with a local volatility that is piece-wise linear in the benchmark forward rate
together with an uncorrelated CIR stochastic variance and one with a local
volatility that is linear in the benchmark rate together with a correlated
lognormal stochastic volatility with quadratic drift (QDLNSV) as in [2]
calibrate well. We discuss why the later might be a preferable model.
  [1] Arun Kumar Polala and Bernhard Hientzsch. Parametric differential machine
learning for pricing and calibration. arXiv preprint arXiv:2302.06682 , 2023.
  [2] Artur Sepp and Parviz Rakhmonov. A Robust Stochastic Volatility Model for
Interest Rate Dynamics. Risk Magazine, 2023",http://arxiv.org/pdf/2408.11257v1,,False
