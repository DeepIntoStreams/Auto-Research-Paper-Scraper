Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
ImageChain: Advancing Sequential Image-to-Text Reasoning in Multimodal Large Language Models,26/02/2025,"Danae Sánchez Villegas, Ingo Ziegler, Desmond Elliott","Reasoning over sequences of images remains a challenge for multimodal large
language models (MLLMs). While recent models incorporate multi-image data
during pre-training, they still struggle to recognize sequential structures,
often treating images independently. This work introduces ImageChain, a
framework that enhances MLLMs with sequential reasoning capabilities over image
data by modeling visual sequences as a multi-turn conversation. In ImageChain,
images are interleaved with corresponding textual descriptions to form a
controlled dialogue that explicitly captures temporal dependencies and
narrative progression. Our method optimizes for the task of next-scene
description, where the model generates a context-aware description of an
upcoming scene based on preceding visual and textual cues. We demonstrate that
our approach improves performance on the next-scene description task --
achieving an average improvement from 3.7% to 19% in SimRate, a metric that
quantifies semantic similarity to human-annotated ground truths. Moreover,
ImageChain achieves robust zero-shot out-of-domain performance in applications
ranging from comics to robotics. Extensive experiments validate that
instruction-tuning in a multimodal, multi-turn conversation design is key to
bridging the gap between static image understanding and temporally-aware
reasoning.",http://arxiv.org/pdf/2502.19409v1,,False
Deep Learning For Time Series Analysis With Application On Human Motion,26/02/2025,Ali Ismail-Fawaz,"Time series data, defined by equally spaced points over time, is essential in
fields like medicine, telecommunications, and energy. Analyzing it involves
tasks such as classification, clustering, prototyping, and regression.
Classification identifies normal vs. abnormal movements in skeleton-based
motion sequences, clustering detects stock market behavior patterns,
prototyping expands physical therapy datasets, and regression predicts patient
recovery. Deep learning has recently gained traction in time series analysis
due to its success in other domains. This thesis leverages deep learning to
enhance classification with feature engineering, introduce foundation models,
and develop a compact yet state-of-the-art architecture. We also address
limited labeled data with self-supervised learning. Our contributions apply to
real-world tasks, including human motion analysis for action recognition and
rehabilitation. We introduce a generative model for human motion data, valuable
for cinematic production and gaming. For prototyping, we propose a shape-based
synthetic sample generation method to support regression models when data is
scarce. Lastly, we critically evaluate discriminative and generative models,
identifying limitations in current methodologies and advocating for a robust,
standardized evaluation framework. Our experiments on public datasets provide
novel insights and methodologies, advancing time series analysis with practical
applications.",http://arxiv.org/pdf/2502.19364v1,,False
Partition Tree Weighting for Non-Stationary Stochastic Bandits,26/02/2025,"Joel Veness, Marcus Hutter, Andras Gyorgy, Jordi Grau-Moya","This paper considers a generalisation of universal source coding for
interaction data, namely data streams that have actions interleaved with
observations. Our goal will be to construct a coding distribution that is both
universal \emph{and} can be used as a control policy. Allowing for action
generation needs careful treatment, as naive approaches which do not
distinguish between actions and observations run into the self-delusion problem
in universal settings. We showcase our perspective in the context of the
challenging non-stationary stochastic Bernoulli bandit problem. Our main
contribution is an efficient and high performing algorithm for this problem
that generalises the Partition Tree Weighting universal source coding technique
for passive prediction to the control setting.",http://arxiv.org/pdf/2502.19325v1,,False
AI-Powered Bayesian Inference,26/02/2025,"Veronika Ročková, Sean O'Hagan","The advent of Generative Artificial Intelligence (GAI) has heralded an
inflection point that changed how society thinks about knowledge acquisition.
While GAI cannot be fully trusted for decision-making, it may still provide
valuable information that can be integrated into a decision pipeline. Rather
than seeing the lack of certitude and inherent randomness of GAI as a problem,
we view it as an opportunity. Indeed, variable answers to given prompts can be
leveraged to construct a prior distribution which reflects assuredness of AI
predictions. This prior distribution may be combined with tailored datasets for
a fully Bayesian analysis with an AI-driven prior. In this paper, we explore
such a possibility within a non-parametric Bayesian framework. The basic idea
consists of assigning a Dirichlet process prior distribution on the
data-generating distribution with AI generative model as its baseline.
Hyper-parameters of the prior can be tuned out-of-sample to assess the
informativeness of the AI prior. Posterior simulation is achieved by computing
a suitably randomized functional on an augmented data that consists of observed
(labeled) data as well as fake data whose labels have been imputed using AI.
This strategy can be parallelized and rapidly produces iid samples from the
posterior by optimization as opposed to sampling from conditionals. Our method
enables (predictive) inference and uncertainty quantification leveraging AI
predictions in a coherent probabilistic manner.",http://arxiv.org/pdf/2502.19231v1,,False
Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms,26/02/2025,"Jinyu Cai, Yusei Ishimizu, Mingyue Zhang, Munan Li, Jialong Li, Kenji Tei","Social media platforms frequently impose restrictive policies to moderate
user content, prompting the emergence of creative evasion language strategies.
This paper presents a multi-agent framework based on Large Language Models
(LLMs) to simulate the iterative evolution of language strategies under
regulatory constraints. In this framework, participant agents, as social media
users, continuously evolve their language expression, while supervisory agents
emulate platform-level regulation by assessing policy violations. To achieve a
more faithful simulation, we employ a dual design of language strategies
(constraint and expression) to differentiate conflicting goals and utilize an
LLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of
language strategies. The framework is evaluated using two distinct scenarios:
an abstract password game and a realistic simulated illegal pet trade scenario.
Experimental results demonstrate that as the number of dialogue rounds
increases, both the number of uninterrupted dialogue turns and the accuracy of
information transmission improve significantly. Furthermore, a user study with
40 participants validates the real-world relevance of the generated dialogues
and strategies. Moreover, ablation studies validate the importance of the GA,
emphasizing its contribution to long-term adaptability and improved overall
results.",http://arxiv.org/pdf/2502.19193v1,,False
A Model-Centric Review of Deep Learning for Protein Design,26/02/2025,"Gregory W. Kyro, Tianyin Qiu, Victor S. Batista","Deep learning has transformed protein design, enabling accurate structure
prediction, sequence optimization, and de novo protein generation. Advances in
single-chain protein structure prediction via AlphaFold2, RoseTTAFold, ESMFold,
and others have achieved near-experimental accuracy, inspiring successive work
extended to biomolecular complexes via AlphaFold Multimer, RoseTTAFold
All-Atom, AlphaFold 3, Chai-1, Boltz-1 and others. Generative models such as
ProtGPT2, ProteinMPNN, and RFdiffusion have enabled sequence and backbone
design beyond natural evolution-based limitations. More recently, joint
sequence-structure co-design models, including ESM3, have integrated both
modalities into a unified framework, resulting in improved designability.
Despite these advances, challenges still exist pertaining to modeling
sequence-structure-function relationships and ensuring robust generalization
beyond the regions of protein space spanned by the training data. Future
advances will likely focus on joint sequence-structure-function co-design
frameworks that are able to model the fitness landscape more effectively than
models that treat these modalities independently. Current capabilities, coupled
with the dizzying rate of progress, suggest that the field will soon enable
rapid, rational design of proteins with tailored structures and functions that
transcend the limitations imposed by natural evolution. In this review, we
discuss the current capabilities of deep learning methods for protein design,
focusing on some of the most revolutionary and capable models with respect to
their functionality and the applications that they enable, leading up to the
current challenges of the field and the optimal path forward.",http://arxiv.org/pdf/2502.19173v1,,False
Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems,26/02/2025,"Pierre Peigne-Lefebvre, Mikolaj Kniejski, Filip Sondej, Matthieu David, Jason Hoelscher-Obermaier, Christian Schroeder de Witt, Esben Kran","As AI agents are increasingly adopted to collaborate on complex objectives,
ensuring the security of autonomous multi-agent systems becomes crucial. We
develop simulations of agents collaborating on shared objectives to study these
security risks and security trade-offs. We focus on scenarios where an attacker
compromises one agent, using it to steer the entire system toward misaligned
outcomes by corrupting other agents. In this context, we observe infectious
malicious prompts - the multi-hop spreading of malicious instructions. To
mitigate this risk, we evaluated several strategies: two ""vaccination""
approaches that insert false memories of safely handling malicious input into
the agents' memory stream, and two versions of a generic safety instruction
strategy. While these defenses reduce the spread and fulfillment of malicious
instructions in our experiments, they tend to decrease collaboration capability
in the agent network. Our findings illustrate potential trade-off between
security and collaborative efficiency in multi-agent systems, providing
insights for designing more secure yet effective AI collaborations.",http://arxiv.org/pdf/2502.19145v1,,False
Efficient and Accurate Spatial Mixing of Machine Learned Interatomic Potentials for Materials Science,26/02/2025,"Fraser Birks, Thomas D Swinburne, James R Kermode","Machine-learned interatomic potentials offer near first-principles accuracy
but are computationally expensive, limiting their application in large-scale
molecular dynamics simulations. Inspired by quantum mechanics/molecular
mechanics methods, we present ML-MIX, an efficient and flexible LAMMPS package
for accelerating simulations by spatially mixing interatomic potentials of
different complexities. Through constrained linear fitting, we show it is
possible to generate a 'cheap' approximate model which closely matches an
'expensive' reference in relevant regions of configuration space. We
demonstrate the capability of ML-MIX through case-studies in Si, Fe, and W-He
systems, achieving up to an 11x speedup on 8,000 atom systems without
sacrificing accuracy on static and dynamic quantities, including calculation of
minimum energy paths and dynamical simulations of defect diffusion. For larger
domain sizes, we show that the achievable speedup of ML-MIX simulations is
limited only by the relative speed of the cheap potential over the expensive
potential. The ease of use and flexible nature of this method will extend the
practical reach of MLIPs throughout computational materials science, enabling
parsimonious application to large spatial and temporal domains.",http://arxiv.org/pdf/2502.19081v1,,False
Fatigue-PINN: Physics-Informed Fatigue-Driven Motion Modulation and Synthesis,26/02/2025,"Iliana Loi, Konstantinos Moustakas","Fatigue modeling is essential for motion synthesis tasks to model human
motions under fatigued conditions and biomechanical engineering applications,
such as investigating the variations in movement patterns and posture due to
fatigue, defining injury risk mitigation and prevention strategies, formulating
fatigue minimization schemes and creating improved ergonomic designs.
Nevertheless, employing data-driven methods for synthesizing the impact of
fatigue on motion, receives little to no attention in the literature. In this
work, we present Fatigue-PINN, a deep learning framework based on
Physics-Informed Neural Networks, for modeling fatigued human movements, while
providing joint-specific fatigue configurations for adaptation and mitigation
of motion artifacts on a joint level, resulting in more realistic animations.
To account for muscle fatigue, we simulate the fatigue-induced fluctuations in
the maximum exerted joint torques by leveraging a PINN adaptation of the
Three-Compartment Controller model to exploit physics-domain knowledge for
improving accuracy. This model also introduces parametric motion alignment with
respect to joint-specific fatigue, hence avoiding sharp frame transitions. Our
results indicate that Fatigue-PINN accurately simulates the effects of
externally perceived fatigue on open-type human movements being consistent with
findings from real-world experimental fatigue studies. Since fatigue is
incorporated in torque space, Fatigue-PINN provides an end-to-end
encoder-decoder-like architecture, to ensure transforming joint angles to joint
torques and vice-versa, thus, being compatible with motion synthesis frameworks
operating on joint angles.",http://arxiv.org/pdf/2502.19056v1,,False
A HEART for the environment: Transformer-Based Spatiotemporal Modeling for Air Quality Prediction,26/02/2025,Norbert Bodendorfer,"Accurate and reliable air pollution forecasting is crucial for effective
environmental management and policy-making. llull-environment is a
sophisticated and scalable forecasting system for air pollution, inspired by
previous models currently operational in Madrid and Valladolid (Spain). It
contains (among other key components) an encoder-decoder convolutional neural
network to forecast mean pollution levels for four key pollutants (NO$_2$,
O$_3$, PM$_{10}$, PM$_{2.5}$) using historical data, external forecasts, and
other contextual features. This paper investigates the augmentation of this
neural network with an attention mechanism to improve predictive accuracy. The
proposed attention mechanism pre-processes tensors containing the input
features before passing them to the existing mean forecasting model. The
resulting model is a combination of several architectures and ideas and can be
described as a ""Hybrid Enhanced Autoregressive Transformer"", or HEART. The
effectiveness of the approach is evaluated by comparing the mean square error
(MSE) across different attention layouts against the system without such a
mechanism. We observe a significant reduction in MSE of up to 22%, with an
average of 7.5% across tested cities and pollutants. The performance of a given
attention mechanism turns out to depend on the pollutant, highlighting the
differences in their creation and dissipation processes. Our findings are not
restricted to optimizing air quality prediction models, but are applicable
generally to (fixed length) time series forecasting.",http://arxiv.org/pdf/2502.19042v1,,False
Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments,26/02/2025,"Zerui Li, Gengze Zhou, Haodong Hong, Yanyan Shao, Wenqi Lyu, Yanyuan Qiao, Qi Wu","Vision-and-Language Navigation (VLN) empowers agents to associate
time-sequenced visual observations with corresponding instructions to make
sequential decisions. However, generalization remains a persistent challenge,
particularly when dealing with visually diverse scenes or transitioning from
simulated environments to real-world deployment. In this paper, we address the
mismatch between human-centric instructions and quadruped robots with a
low-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav)
approach to mitigate this issue. This work represents the first attempt to
highlight the generalization gap in VLN across varying heights of visual
observation in realistic robot deployments. Our approach leverages weighted
historical observations as enriched spatiotemporal contexts for instruction
following, effectively managing feature collisions within cells by assigning
appropriate weights to identical features across different viewpoints. This
enables low-height robots to overcome challenges such as visual obstructions
and perceptual mismatches. Additionally, we transfer the connectivity graph
from the HM3D and Gibson datasets as an extra resource to enhance spatial
priors and a more comprehensive representation of real-world scenarios, leading
to improved performance and generalizability of the waypoint predictor in
real-world environments. Extensive experiments demonstrate that our
Ground-level Viewpoint Navigation (GVnav) approach significantly improves
performance in both simulated environments and real-world deployments with
quadruped robots.",http://arxiv.org/pdf/2502.19024v1,,False
Robust Over-the-Air Computation with Type-Based Multiple Access,26/02/2025,"Marc Martinez-Gost, Ana Pérez-Neira, Miguel Ángel Lagunas","This paper utilizes the properties of type-based multiple access (TBMA) to
investigate its effectiveness as a robust approach for over-the-air computation
(AirComp) in the presence of Byzantine attacks, this is, adversarial strategies
where malicious nodes intentionally distort their transmissions to corrupt the
aggregated result. Unlike classical direct aggregation (DA) AirComp, which
aggregates data in the amplitude of the signals and are highly vulnerable to
attacks, TBMA distributes data over multiple radio resources, enabling the
receiver to construct a histogram representation of the transmitted data. This
structure allows the integration of classical robust estimators and supports
the computation of diverse functions beyond the arithmetic mean, which is not
feasible with DA. Through extensive simulations, we demonstrate that robust
TBMA significantly outperforms DA, maintaining high accuracy even under
adversarial conditions, and showcases its applicability in federated learning
(FEEL) scenarios. Additionally, TBMA reduces channel state information (CSI)
requirements, lowers energy consumption, and enhances resiliency by leveraging
the diversity of the transmitted data. These results establish TBMA as a
scalable and robust solution for AirComp, paving the way for secure and
efficient aggregation in next-generation networks.",http://arxiv.org/pdf/2502.19014v1,,False
Evaluating Membership Inference Attacks in heterogeneous-data setups,26/02/2025,"Bram van Dartel, Marc Damie, Florian Hahn","Among all privacy attacks against Machine Learning (ML), membership inference
attacks (MIA) attracted the most attention. In these attacks, the attacker is
given an ML model and a data point, and they must infer whether the data point
was used for training. The attacker also has an auxiliary dataset to tune their
inference algorithm.
  Attack papers commonly simulate setups in which the attacker's and the
target's datasets are sampled from the same distribution. This setting is
convenient to perform experiments, but it rarely holds in practice. ML
literature commonly starts with similar simplifying assumptions (i.e., ""i.i.d.""
datasets), and later generalizes the results to support heterogeneous data
distributions. Similarly, our work makes a first step in the generalization of
the MIA evaluation to heterogeneous data.
  First, we design a metric to measure the heterogeneity between any pair of
tabular data distributions. This metric provides a continuous scale to analyze
the phenomenon. Second, we compare two methodologies to simulate a data
heterogeneity between the target and the attacker. These setups provide
opposite performances: 90% attack accuracy vs. 50% (i.e., random guessing). Our
results show that the MIA accuracy depends on the experimental setup; and even
if research on MIA considers heterogeneous data setups, we have no standardized
baseline of how to simulate it. The lack of such a baseline for MIA experiments
poses a significant challenge to risk assessments in real-world machine
learning scenarios.",http://arxiv.org/pdf/2502.18986v1,,False
END: Early Noise Dropping for Efficient and Effective Context Denoising,26/02/2025,"Hongye Jin, Pei Chen, Jingfeng Yang, Zhengyang Wang, Meng Jiang, Yifan Gao, Binxuan Huang, Xinyang Zhang, Zheng Li, Tianyi Liu, Huasheng Li, Bing Yin","Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing tasks. However, they are often
distracted by irrelevant or noisy context in input sequences that degrades
output quality. This problem affects both long- and short-context scenarios,
such as retrieval-augmented generation, table question-answering, and
in-context learning. We reveal that LLMs can implicitly identify whether input
sequences contain useful information at early layers, prior to token
generation. Leveraging this insight, we introduce Early Noise Dropping
(\textsc{END}), a novel approach to mitigate this issue without requiring
fine-tuning the LLMs. \textsc{END} segments input sequences into chunks and
employs a linear prober on the early layers of LLMs to differentiate between
informative and noisy chunks. By discarding noisy chunks early in the process,
\textsc{END} preserves critical information, reduces distraction, and lowers
computational overhead. Extensive experiments demonstrate that \textsc{END}
significantly improves both performance and efficiency across different LLMs on
multiple evaluation datasets. Furthermore, by investigating LLMs' implicit
understanding to the input with the prober, this work also deepens
understanding of how LLMs do reasoning with contexts internally.",http://arxiv.org/pdf/2502.18915v1,,False
A Pipeline of Augmentation and Sequence Embedding for Classification of Imbalanced Network Traffic,26/02/2025,"Matin Shokri, Ramin Hasibi","Network Traffic Classification (NTC) is one of the most important tasks in
network management. The imbalanced nature of classes on the internet presents a
critical challenge in classification tasks. For example, some classes of
applications are much more prevalent than others, such as HTTP. As a result,
machine learning classification models do not perform well on those classes
with fewer data. To address this problem, we propose a pipeline to balance the
dataset and classify it using a robust and accurate embedding technique. First,
we generate artificial data using Long Short-Term Memory (LSTM) networks and
Kernel Density Estimation (KDE). Next, we propose replacing one-hot encoding
for categorical features with a novel embedding framework based on the ""Flow as
a Sentence"" perspective, which we name FS-Embedding. This framework treats the
source and destination ports, along with the packet's direction, as one word in
a flow, then trains an embedding vector space based on these new features
through the learning classification task. Finally, we compare our pipeline with
the training of a Convolutional Recurrent Neural Network (CRNN) and
Transformers, both with imbalanced and sampled datasets, as well as with the
one-hot encoding approach. We demonstrate that the proposed augmentation
pipeline, combined with FS-Embedding, increases convergence speed and leads to
a significant reduction in the number of model parameters, all while
maintaining the same performance in terms of accuracy.",http://arxiv.org/pdf/2502.18909v1,,False
Investigating Generalization of One-shot LLM Steering Vectors,26/02/2025,"Jacob Dunefsky, Arman Cohan","Steering vectors have emerged as a promising approach for interpreting and
controlling LLMs, but current methods typically require large contrastive
datasets that are often impractical to construct and may capture spurious
correlations. We propose directly optimizing steering vectors through gradient
descent on a single training example, and systematically investigate how these
vectors generalize. We consider several steering optimization techniques,
including multiple novel ones, and find that the resulting vectors effectively
mediate safety-relevant behaviors in multiple models. Indeed, in experiments on
an alignment-faking model, we are able to optimize one-shot steering vectors
that induce harmful behavior on benign examples and whose negations suppress
harmful behavior on malign examples. And in experiments on refusal suppression,
we demonstrate that one-shot optimized steering vectors can transfer across
inputs, yielding a Harmbench attack success rate of 96.9%. Furthermore, to
quantitatively assess steering effectiveness in instruction-tuned models, we
develop a novel evaluation framework using sequence probabilities from the
corresponding base model. With this framework, we analyze how steering vectors
modulate an instruction-tuned LLM's ability to recover from outputting false
information, and find that this ability derives from the base model. Overall,
our findings suggest that optimizing steering vectors on a single example can
mediate misaligned behavior in LLMs, and provide a path toward better
understanding the relationship between LLM behavior and activation space
structure.",http://arxiv.org/pdf/2502.18862v1,,False
Intelligence Test,26/02/2025,"Jingtao Zhan, Jiahao Zhao, Jiayu Li, Yiqun Liu, Bo Zhang, Qingyao Ai, Jiaxin Mao, Hongning Wang, Min Zhang, Shaoping Ma","How does intelligence emerge? We propose that intelligence is not a sudden
gift or random occurrence, but rather a necessary trait for species to survive
through Natural Selection. If a species passes the test of Natural Selection,
it demonstrates the intelligence to survive in nature. Extending this
perspective, we introduce Intelligence Test, a method to quantify the
intelligence of any subject on any task. Like how species evolve by trial and
error, Intelligence Test quantifies intelligence by the number of failed
attempts before success. Fewer failures correspond to higher intelligence. When
the expectation and variance of failure counts are both finite, it signals the
achievement of an autonomous level of intelligence. Using Intelligence Test, we
comprehensively evaluate existing AI systems. Our results show that while AI
systems achieve a level of autonomy in simple tasks, they are still far from
autonomous in more complex tasks, such as vision, search, recommendation, and
language. While scaling model size might help, this would come at an
astronomical cost. Projections suggest that achieving general autonomy would
require unimaginable $10^{26}$ parameters. Even if Moore's Law continuously
holds, such a parameter scale would take $70$ years. This staggering cost
highlights the complexity of human tasks and the inadequacies of current AI. To
further understand this phenomenon, we conduct a theoretical analysis. Our
simulations suggest that human tasks possess a criticality property. As a
result, autonomy requires a deep understanding of the task's underlying
mechanisms. Current AI, however, does not fully grasp these mechanisms and
instead relies on superficial mimicry, making it difficult to reach an
autonomous level. We believe Intelligence Test can not only guide the future
development of AI but also offer profound insights into the intelligence of
humans ourselves.",http://arxiv.org/pdf/2502.18858v1,,False
Data-Driven and Theory-Guided Pseudo-Spectral Seismic Imaging Using Deep Neural Network Architectures,26/02/2025,Christopher Zerafa,"Full Waveform Inversion (FWI) reconstructs high-resolution subsurface models
via multi-variate optimization but faces challenges with solver selection and
data availability. Deep Learning (DL) offers a promising alternative, bridging
data-driven and physics-based methods. While FWI in DL has been explored in the
time domain, the pseudo-spectral approach remains underutilized, despite its
success in classical FWI.
  This thesis integrates pseudo-spectral FWI into DL, formulating both
data-driven and theory-guided approaches using Deep Neural Networks (DNNs) and
Recurrent Neural Networks (RNNs). These methods were theoretically derived,
tested on synthetic and Marmousi datasets, and compared with deterministic and
time-domain approaches.
  Results show that data-driven pseudo-spectral DNNs outperform classical FWI
in deeper and over-thrust regions due to their global approximation capability.
Theory-guided RNNs yield greater accuracy, with lower error and better fault
identification. While DNNs excel in velocity contrast recovery, RNNs provide
superior edge definition and stability in shallow and deep sections.
  Beyond enhancing FWI performance, this research identifies broader
applications of DL-based inversion and outlines future directions for these
frameworks.",http://arxiv.org/pdf/2502.18852v1,,False
Optimal Stochastic Trace Estimation in Generative Modeling,26/02/2025,"Xinyang Liu, Hengrong Du, Wei Deng, Ruqi Zhang","Hutchinson estimators are widely employed in training divergence-based
likelihoods for diffusion models to ensure optimal transport (OT) properties.
However, this estimator often suffers from high variance and scalability
concerns. To address these challenges, we investigate Hutch++, an optimal
stochastic trace estimator for generative models, designed to minimize training
variance while maintaining transport optimality. Hutch++ is particularly
effective for handling ill-conditioned matrices with large condition numbers,
which commonly arise when high-dimensional data exhibits a low-dimensional
structure. To mitigate the need for frequent and costly QR decompositions, we
propose practical schemes that balance frequency and accuracy, backed by
theoretical guarantees. Our analysis demonstrates that Hutch++ leads to
generations of higher quality. Furthermore, this method exhibits effective
variance reduction in various applications, including simulations, conditional
time series forecasts, and image generation.",http://arxiv.org/pdf/2502.18808v1,,False
M2-omni: Advancing Omni-MLLM for Comprehensive Modality Support with Competitive Performance,26/02/2025,"Qingpei Guo, Kaiyou Song, Zipeng Feng, Ziping Ma, Qinglong Zhang, Sirui Gao, Xuzheng Yu, Yunxiao Sun, Tai-WeiChang, Jingdong Chen, Ming Yang, Jun Zhou","We present M2-omni, a cutting-edge, open-source omni-MLLM that achieves
competitive performance to GPT-4o. M2-omni employs a unified multimodal
sequence modeling framework, which empowers Large Language Models(LLMs) to
acquire comprehensive cross-modal understanding and generation capabilities.
Specifically, M2-omni can process arbitrary combinations of audio, video,
image, and text modalities as input, generating multimodal sequences
interleaving with audio, image, or text outputs, thereby enabling an advanced
and interactive real-time experience. The training of such an omni-MLLM is
challenged by significant disparities in data quantity and convergence rates
across modalities. To address these challenges, we propose a step balance
strategy during pre-training to handle the quantity disparities in
modality-specific data. Additionally, a dynamically adaptive balance strategy
is introduced during the instruction tuning stage to synchronize the
modality-wise training progress, ensuring optimal convergence. Notably, we
prioritize preserving strong performance on pure text tasks to maintain the
robustness of M2-omni's language understanding capability throughout the
training process. To our best knowledge, M2-omni is currently a very
competitive open-source model to GPT-4o, characterized by its comprehensive
modality and task support, as well as its exceptional performance. We expect
M2-omni will advance the development of omni-MLLMs, thus facilitating future
research in this domain.",http://arxiv.org/pdf/2502.18778v1,,False
Nonlinear Sparse Generalized Canonical Correlation Analysis for Multi-view High-dimensional Data,26/02/2025,"Rong Wu, Ziqi Chen, Gen Li, Hai Shu","Motivation: Biomedical studies increasingly produce multi-view
high-dimensional datasets (e.g., multi-omics) that demand integrative analysis.
Existing canonical correlation analysis (CCA) and generalized CCA methods
address at most two of the following three key aspects simultaneously: (i)
nonlinear dependence, (ii) sparsity for variable selection, and (iii)
generalization to more than two data views. There is a pressing need for CCA
methods that integrate all three aspects to effectively analyze multi-view
high-dimensional data.
  Results: We propose three nonlinear, sparse, generalized CCA methods,
HSIC-SGCCA, SA-KGCCA, and TS-KGCCA, for variable selection in multi-view
high-dimensional data. These methods extend existing SCCA-HSIC, SA-KCCA, and
TS-KCCA from two-view to multi-view settings. While SA-KGCCA and TS-KGCCA yield
multi-convex optimization problems solved via block coordinate descent,
HSIC-SGCCA introduces a necessary unit-variance constraint previously ignored
in SCCA-HSIC, resulting in a nonconvex, non-multiconvex problem. We efficiently
address this challenge by integrating the block prox-linear method with the
linearized alternating direction method of multipliers. Simulations and
TCGA-BRCA data analysis demonstrate that HSIC-SGCCA outperforms competing
methods in multi-view variable selection.",http://arxiv.org/pdf/2502.18756v1,,False
TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation,26/02/2025,"Chenlu Ju, Jiaxin Liu, Shobhit Sinha, Hao Xue, Flora Salim","This work leverages Large Language Models (LLMs) to simulate human mobility,
addressing challenges like high costs and privacy concerns in traditional
models. Our hierarchical framework integrates persona generation, activity
selection, and destination prediction, using real-world demographic and
psychological data to create realistic movement patterns. Both physical models
and language models are employed to explore and demonstrate different
methodologies for human mobility simulation. By structuring data with
summarization and weighted density metrics, the system ensures scalable memory
management while retaining actionable insights. Preliminary results indicate
that LLM-driven simulations align with observed real-world patterns, offering
scalable, interpretable insights for social problems such as urban planning,
traffic management, and public health. The framework's ability to dynamically
generate personas and activities enables it to provide adaptable and realistic
daily routines. This study demonstrates the transformative potential of LLMs in
advancing mobility modeling for societal and urban applications. The source
code and interactive demo for our framework are available at
https://github.com/cju0/TrajLLM.",http://arxiv.org/pdf/2502.18712v1,,False
