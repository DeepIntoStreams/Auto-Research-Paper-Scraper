Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations,26/08/2024,"Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak","In this paper, we propose a domain-decomposition-based deep learning (DL)
framework, named transient-CoMLSim, for accurately modeling unsteady and
nonlinear partial differential equations (PDEs). The framework consists of two
key components: (a) a convolutional neural network (CNN)-based autoencoder
architecture and (b) an autoregressive model composed of fully connected
layers. Unlike existing state-of-the-art methods that operate on the entire
computational domain, our CNN-based autoencoder computes a lower-dimensional
basis for solution and condition fields represented on subdomains. Timestepping
is performed entirely in the latent space, generating embeddings of the
solution variables from the time history of embeddings of solution and
condition variables. This approach not only reduces computational complexity
but also enhances scalability, making it well-suited for large-scale
simulations. Furthermore, to improve the stability of our rollouts, we employ a
curriculum learning (CL) approach during the training of the autoregressive
model. The domain-decomposition strategy enables scaling to out-of-distribution
domain sizes while maintaining the accuracy of predictions -- a feature not
easily integrated into popular DL-based approaches for physics simulations. We
benchmark our model against two widely-used DL architectures, Fourier Neural
Operator (FNO) and U-Net, and demonstrate that our framework outperforms them
in terms of accuracy, extrapolation to unseen timesteps, and stability for a
wide range of use cases.",http://arxiv.org/pdf/2408.14461v1,,False
LoG-VMamba: Local-Global Vision Mamba for Medical Image Segmentation,26/08/2024,"Trung Dinh Quoc Dang, Huy Hoang Nguyen, Aleksei Tiulpin","Mamba, a State Space Model (SSM), has recently shown competitive performance
to Convolutional Neural Networks (CNNs) and Transformers in Natural Language
Processing and general sequence modeling. Various attempts have been made to
adapt Mamba to Computer Vision tasks, including medical image segmentation
(MIS). Vision Mamba (VM)-based networks are particularly attractive due to
their ability to achieve global receptive fields, similar to Vision
Transformers, while also maintaining linear complexity in the number of tokens.
However, the existing VM models still struggle to maintain both spatially local
and global dependencies of tokens in high dimensional arrays due to their
sequential nature. Employing multiple and/or complicated scanning strategies is
computationally costly, which hinders applications of SSMs to high-dimensional
2D and 3D images that are common in MIS problems. In this work, we propose
Local-Global Vision Mamba, LoG-VMamba, that explicitly enforces spatially
adjacent tokens to remain nearby on the channel axis, and retains the global
context in a compressed form. Our method allows the SSMs to access the local
and global contexts even before reaching the last token while requiring only a
simple scanning strategy. Our segmentation models are computationally efficient
and substantially outperform both CNN and Transformers-based baselines on a
diverse set of 2D and 3D MIS tasks. The implementation of LoG-VMamba is
available at \url{https://github.com/Oulu-IMEDS/LoG-VMamba}.",http://arxiv.org/pdf/2408.14415v1,,False
Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning,26/08/2024,"Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana","Spatio-temporal forecasting plays a crucial role in various sectors such as
transportation systems, logistics, and supply chain management. However,
existing methods are limited by their ability to handle large, complex
datasets. To overcome this limitation, we introduce a hybrid approach that
combines the strengths of open-source large and small-scale language models
(LLMs and LMs) with traditional forecasting methods. We augment traditional
methods with dynamic prompting and a grouped-query, multi-head attention
mechanism to more effectively capture both intra-series and inter-series
dependencies in evolving nonlinear time series data. In addition, we facilitate
on-premises customization by fine-tuning smaller open-source LMs for time
series trend analysis utilizing descriptions generated by open-source large LMs
on consumer-grade hardware using Low-Rank Adaptation with Activation Memory
Reduction (LoRA-AMR) technique to reduce computational overhead and activation
storage memory demands while preserving inference latency. We combine language
model processing for time series trend analysis with traditional time series
representation learning method for cross-modal integration, achieving robust
and accurate forecasts. The framework effectiveness is demonstrated through
extensive experiments on various real-world datasets, outperforming existing
methods by significant margins in terms of forecast accuracy.",http://arxiv.org/pdf/2408.14387v1,,False
Learning Tree-Structured Composition of Data Augmentation,26/08/2024,"Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang","Data augmentation is widely used for training a neural network given little
labeled data. A common practice of augmentation training is applying a
composition of multiple transformations sequentially to the data. Existing
augmentation methods such as RandAugment randomly sample from a list of
pre-selected transformations, while methods such as AutoAugment apply advanced
search to optimize over an augmentation set of size $k^d$, which is the number
of transformation sequences of length $d$, given a list of $k$ transformations.
  In this paper, we design efficient algorithms whose running time complexity
is much faster than the worst-case complexity of $O(k^d)$, provably. We propose
a new algorithm to search for a binary tree-structured composition of $k$
transformations, where each tree node corresponds to one transformation. The
binary tree generalizes sequential augmentations, such as the SimCLR
augmentation scheme for contrastive learning. Using a top-down, recursive
search procedure, our algorithm achieves a runtime complexity of $O(2^d k)$,
which is much faster than $O(k^d)$ as $k$ increases above $2$. We apply our
algorithm to tackle data distributions with heterogeneous subpopulations by
searching for one tree in each subpopulation and then learning a weighted
combination, resulting in a forest of trees.
  We validate our proposed algorithms on numerous graph and image datasets,
including a multi-label graph classification dataset we collected. The dataset
exhibits significant variations in the sizes of graphs and their average
degrees, making it ideal for studying data augmentation. We show that our
approach can reduce the computation cost by 43% over existing search methods
while improving performance by 4.3%. The tree structures can be used to
interpret the relative importance of each transformation, such as identifying
the important transformations on small vs. large graphs.",http://arxiv.org/pdf/2408.14381v1,,False
GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal Conditioned Policy,26/08/2024,"Peiyan Li, Hongtao Wu, Yan Huang, Chilam Cheang, Liang Wang, Tao Kong","The robotics community has consistently aimed to achieve generalizable robot
manipulation with flexible natural language instructions. One of the primary
challenges is that obtaining robot data fully annotated with both actions and
texts is time-consuming and labor-intensive. However, partially annotated data,
such as human activity videos without action labels and robot play data without
language labels, is much easier to collect. Can we leverage these data to
enhance the generalization capability of robots? In this paper, we propose
GR-MG, a novel method which supports conditioning on both a language
instruction and a goal image. During training, GR-MG samples goal images from
trajectories and conditions on both the text and the goal image or solely on
the image when text is unavailable. During inference, where only the text is
provided, GR-MG generates the goal image via a diffusion-based image-editing
model and condition on both the text and the generated image. This approach
enables GR-MG to leverage large amounts of partially annotated data while still
using language to flexibly specify tasks. To generate accurate goal images, we
propose a novel progress-guided goal image generation model which injects task
progress information into the generation process, significantly improving the
fidelity and the performance. In simulation experiments, GR-MG improves the
average number of tasks completed in a row of 5 from 3.35 to 4.04. In
real-robot experiments, GR-MG is able to perform 47 different tasks and
improves the success rate from 62.5% to 75.0% and 42.4% to 57.6% in simple and
generalization settings, respectively. Code and checkpoints will be available
at the project page: https://gr-mg.github.io/.",http://arxiv.org/pdf/2408.14368v1,,False
Assessing Contamination in Large Language Models: Introducing the LogProber method,26/08/2024,"Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri","In machine learning, contamination refers to situations where testing data
leak into the training set. The issue is particularly relevant for the
evaluation of the performance of Large Language Models (LLMs), which are
generally trained on gargantuan, and generally opaque, corpora of text scraped
from the world wide web. Developing tools to detect contamination is therefore
crucial to be able to fairly and properly track the evolution of the
performance of LLMs. Most recent works in the field are not tailored to
quantify contamination on short sequences of text like we find in psychology
questionnaires. In the present paper we introduce LogProber, a novel,
efficient, algorithm that we show able to detect contamination using token
probability in given sentences. In the second part we investigate the
limitations of the method and discuss how different training methods can
contaminate models without leaving traces in the token probabilities.",http://arxiv.org/pdf/2408.14352v1,,False
Foundation Models for Music: A Survey,26/08/2024,"Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elio Quinton, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wehhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang","In recent years, foundation models (FMs) such as large language models (LLMs)
and latent diffusion models (LDMs) have profoundly impacted diverse sectors,
including music. This comprehensive review examines state-of-the-art (SOTA)
pre-trained models and foundation models in music, spanning from representation
learning, generative learning and multimodal learning. We first contextualise
the significance of music in various industries and trace the evolution of AI
in music. By delineating the modalities targeted by foundation models, we
discover many of the music representations are underexplored in FM development.
Then, emphasis is placed on the lack of versatility of previous methods on
diverse music applications, along with the potential of FMs in music
understanding, generation and medical application. By comprehensively exploring
the details of the model pre-training paradigm, architectural choices,
tokenisation, finetuning methodologies and controllability, we emphasise the
important topics that should have been well explored, like instruction tuning
and in-context learning, scaling law and emergent ability, as well as
long-sequence modelling etc. A dedicated section presents insights into music
agents, accompanied by a thorough analysis of datasets and evaluations
essential for pre-training and downstream tasks. Finally, by underscoring the
vital importance of ethical considerations, we advocate that following research
on FM for music should focus more on such issues as interpretability,
transparency, human responsibility, and copyright issues. The paper offers
insights into future challenges and trends on FMs for music, aiming to shape
the trajectory of human-AI collaboration in the music realm.",http://arxiv.org/pdf/2408.14340v1,,False
Hierarchical Learning and Computing over Space-Ground Integrated Networks,26/08/2024,"Jingyang Zhu, Yuanming Shi, Yong Zhou, Chunxiao Jiang, Linling Kuang","Space-ground integrated networks hold great promise for providing global
connectivity, particularly in remote areas where large amounts of valuable data
are generated by Internet of Things (IoT) devices, but lacking terrestrial
communication infrastructure. The massive data is conventionally transferred to
the cloud server for centralized artificial intelligence (AI) models training,
raising huge communication overhead and privacy concerns. To address this, we
propose a hierarchical learning and computing framework, which leverages the
lowlatency characteristic of low-earth-orbit (LEO) satellites and the global
coverage of geostationary-earth-orbit (GEO) satellites, to provide global
aggregation services for locally trained models on ground IoT devices. Due to
the time-varying nature of satellite network topology and the energy
constraints of LEO satellites, efficiently aggregating the received local
models from ground devices on LEO satellites is highly challenging. By
leveraging the predictability of inter-satellite connectivity, modeling the
space network as a directed graph, we formulate a network energy minimization
problem for model aggregation, which turns out to be a Directed Steiner Tree
(DST) problem. We propose a topologyaware energy-efficient routing (TAEER)
algorithm to solve the DST problem by finding a minimum spanning arborescence
on a substitute directed graph. Extensive simulations under realworld
space-ground integrated network settings demonstrate that the proposed TAEER
algorithm significantly reduces energy consumption and outperforms benchmarks.",http://arxiv.org/pdf/2408.14116v1,,False
Beyond Detection: Leveraging Large Language Models for Cyber Attack Prediction in IoT Networks,26/08/2024,"Alaeddine Diaf, Abdelaziz Amara Korba, Nour Elislem Karabadji, Yacine Ghamri-Doudane","In recent years, numerous large-scale cyberattacks have exploited Internet of
Things (IoT) devices, a phenomenon that is expected to escalate with the
continuing proliferation of IoT technology. Despite considerable efforts in
attack detection, intrusion detection systems remain mostly reactive,
responding to specific patterns or observed anomalies. This work proposes a
proactive approach to anticipate and mitigate malicious activities before they
cause damage. This paper proposes a novel network intrusion prediction
framework that combines Large Language Models (LLMs) with Long Short Term
Memory (LSTM) networks. The framework incorporates two LLMs in a feedback loop:
a fine-tuned Generative Pre-trained Transformer (GPT) model for predicting
network traffic and a fine-tuned Bidirectional Encoder Representations from
Transformers (BERT) for evaluating the predicted traffic. The LSTM classifier
model then identifies malicious packets among these predictions. Our framework,
evaluated on the CICIoT2023 IoT attack dataset, demonstrates a significant
improvement in predictive capabilities, achieving an overall accuracy of 98%,
offering a robust solution to IoT cybersecurity challenges.",http://arxiv.org/pdf/2408.14045v1,,False
SurGen: Text-Guided Diffusion Model for Surgical Video Generation,26/08/2024,"Joseph Cho, Samuel Schmidgall, Cyril Zakka, Mrudang Mathur, Rohan Shad, William Hiesinger","Diffusion-based video generation models have made significant strides,
producing outputs with improved visual fidelity, temporal coherence, and user
control. These advancements hold great promise for improving surgical education
by enabling more realistic, diverse, and interactive simulation environments.
In this study, we introduce SurGen, a text-guided diffusion model tailored for
surgical video synthesis, producing the highest resolution and longest duration
videos among existing surgical video generation models. We validate the visual
and temporal quality of the outputs using standard image and video generation
metrics. Additionally, we assess their alignment to the corresponding text
prompts through a deep learning classifier trained on surgical data. Our
results demonstrate the potential of diffusion models to serve as valuable
educational tools for surgical trainees.",http://arxiv.org/pdf/2408.14028v1,,False
LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models,26/08/2024,"Qihang Ge, Wei Sun, Yu Zhang, Yunhao Li, Zhongpeng Ji, Fengyu Sun, Shangling Jui, Xiongkuo Min, Guangtao Zhai","The explosive growth of videos on streaming media platforms has underscored
the urgent need for effective video quality assessment (VQA) algorithms to
monitor and perceptually optimize the quality of streaming videos. However, VQA
remains an extremely challenging task due to the diverse video content and the
complex spatial and temporal distortions, thus necessitating more advanced
methods to address these issues. Nowadays, large multimodal models (LMMs), such
as GPT-4V, have exhibited strong capabilities for various visual understanding
tasks, motivating us to leverage the powerful multimodal representation ability
of LMMs to solve the VQA task. Therefore, we propose the first Large
Multi-Modal Video Quality Assessment (LMM-VQA) model, which introduces a novel
spatiotemporal visual modeling strategy for quality-aware feature extraction.
Specifically, we first reformulate the quality regression problem into a
question and answering (Q&A) task and construct Q&A prompts for VQA instruction
tuning. Then, we design a spatiotemporal vision encoder to extract spatial and
temporal features to represent the quality characteristics of videos, which are
subsequently mapped into the language space by the spatiotemporal projector for
modality alignment. Finally, the aligned visual tokens and the quality-inquired
text tokens are aggregated as inputs for the large language model (LLM) to
generate the quality score and level. Extensive experiments demonstrate that
LMM-VQA achieves state-of-the-art performance across five VQA benchmarks,
exhibiting an average improvement of $5\%$ in generalization ability over
existing methods. Furthermore, due to the advanced design of the spatiotemporal
encoder and projector, LMM-VQA also performs exceptionally well on general
video understanding tasks, further validating its effectiveness. Our code will
be released at https://github.com/Sueqk/LMM-VQA.",http://arxiv.org/pdf/2408.14008v1,,False
