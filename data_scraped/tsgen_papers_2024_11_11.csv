Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway Tree Segmentation,08/11/2024,"Maxime Jacovella, Ali Keshavarzi, Elsa Angelini","Despite advances with deep learning (DL), automated airway segmentation from
chest CT scans continues to face challenges in segmentation quality and
generalization across cohorts. To address these, we propose integrating
Curriculum Learning (CL) into airway segmentation networks, distributing the
training set into batches according to ad-hoc complexity scores derived from CT
scans and corresponding ground-truth tree features. We specifically investigate
few-shot domain adaptation, targeting scenarios where manual annotation of a
full fine-tuning dataset is prohibitively expensive. Results are reported on
two large open-cohorts (ATM22 and AIIB23) with high performance using CL for
full training (Source domain) and few-shot fine-tuning (Target domain), but
with also some insights on potential detrimental effects if using a classic
Bootstrapping scoring function or if not using proper scan sequencing.",http://arxiv.org/pdf/2411.05779v1,,False
SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection,08/11/2024,"Tamara R. Lenhard, Andreas Weinmann, Kai Franke, Tobias Koch","Developing robust drone detection systems is often constrained by the limited
availability of large-scale annotated training data and the high costs
associated with real-world data collection. However, leveraging synthetic data
generated via game engine-based simulations provides a promising and
cost-effective solution to overcome this issue. Therefore, we present
SynDroneVision, a synthetic dataset specifically designed for RGB-based drone
detection in surveillance applications. Featuring diverse backgrounds, lighting
conditions, and drone models, SynDroneVision offers a comprehensive training
foundation for deep learning algorithms. To evaluate the dataset's
effectiveness, we perform a comparative analysis across a selection of recent
YOLO detection models. Our findings demonstrate that SynDroneVision is a
valuable resource for real-world data enrichment, achieving notable
enhancements in model performance and robustness, while significantly reducing
the time and costs of real-world data acquisition. SynDroneVision will be
publicly released upon paper acceptance.",http://arxiv.org/pdf/2411.05633v1,,False
Physics-constrained coupled neural differential equations for one dimensional blood flow modeling,08/11/2024,"Hunor Csala, Arvind Mohan, Daniel Livescu, Amirhossein Arzani","Computational cardiovascular flow modeling plays a crucial role in
understanding blood flow dynamics. While 3D models provide acute details, they
are computationally expensive, especially with fluid-structure interaction
(FSI) simulations. 1D models offer a computationally efficient alternative, by
simplifying the 3D Navier-Stokes equations through axisymmetric flow assumption
and cross-sectional averaging. However, traditional 1D models based on finite
element methods (FEM) often lack accuracy compared to 3D averaged solutions.
This study introduces a novel physics-constrained machine learning technique
that enhances the accuracy of 1D blood flow models while maintaining
computational efficiency. Our approach, utilizing a physics-constrained coupled
neural differential equation (PCNDE) framework, demonstrates superior
performance compared to conventional FEM-based 1D models across a wide range of
inlet boundary condition waveforms and stenosis blockage ratios. A key
innovation lies in the spatial formulation of the momentum conservation
equation, departing from the traditional temporal approach and capitalizing on
the inherent temporal periodicity of blood flow. This spatial neural
differential equation formulation switches space and time and overcomes issues
related to coupling stability and smoothness, while simplifying boundary
condition implementation. The model accurately captures flow rate, area, and
pressure variations for unseen waveforms and geometries. We evaluate the
model's robustness to input noise and explore the loss landscapes associated
with the inclusion of different physics terms. This advanced 1D modeling
technique offers promising potential for rapid cardiovascular simulations,
achieving computational efficiency and accuracy. By combining the strengths of
physics-based and data-driven modeling, this approach enables fast and accurate
cardiovascular simulations.",http://arxiv.org/pdf/2411.05631v1,,False
Cross-validating causal discovery via Leave-One-Variable-Out,08/11/2024,"Daniela Schkoda, Philipp Faller, Patrick Blöbaum, Dominik Janzing","We propose a new approach to falsify causal discovery algorithms without
ground truth, which is based on testing the causal model on a pair of variables
that has been dropped when learning the causal model. To this end, we use the
""Leave-One-Variable-Out (LOVO)"" prediction where $Y$ is inferred from $X$
without any joint observations of $X$ and $Y$, given only training data from
$X,Z_1,\dots,Z_k$ and from $Z_1,\dots,Z_k,Y$. We demonstrate that causal models
on the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often
entail conclusions on the dependencies between $X$ and $Y$, enabling this type
of prediction. The prediction error can then be estimated since the joint
distribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only
been omitted for the purpose of falsification. After presenting this graphical
method, which is applicable to general causal discovery algorithms, we
illustrate how to construct a LOVO predictor tailored towards algorithms
relying on specific a priori assumptions, such as linear additive noise models.
Simulations indicate that the LOVO prediction error is indeed correlated with
the accuracy of the causal outputs, affirming the method's effectiveness.",http://arxiv.org/pdf/2411.05625v1,,False
WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making,08/11/2024,"Zhilong Zhang, Ruifeng Chen, Junyin Ye, Yihao Sun, Pengyuan Wang, Jingcheng Pang, Kaiyuan Li, Tianshuo Liu, Haoxin Lin, Yang Yu, Zhi-Hua Zhou","World models play a crucial role in decision-making within embodied
environments, enabling cost-free explorations that would otherwise be expensive
in the real world. To facilitate effective decision-making, world models must
be equipped with strong generalizability to support faithful imagination in
out-of-distribution (OOD) regions and provide reliable uncertainty estimation
to assess the credibility of the simulated experiences, both of which present
significant challenges for prior scalable approaches. This paper introduces
WHALE, a framework for learning generalizable world models, consisting of two
key techniques: behavior-conditioning and retracing-rollout.
Behavior-conditioning addresses the policy distribution shift, one of the
primary sources of the world model generalization error, while
retracing-rollout enables efficient uncertainty estimation without the
necessity of model ensembles. These techniques are universal and can be
combined with any neural network architecture for world model learning.
Incorporating these two techniques, we present Whale-ST, a scalable
spatial-temporal transformer-based world model with enhanced generalizability.
We demonstrate the superiority of Whale-ST in simulation tasks by evaluating
both value estimation accuracy and video generation fidelity. Additionally, we
examine the effectiveness of our uncertainty estimation technique, which
enhances model-based policy optimization in fully offline scenarios.
Furthermore, we propose Whale-X, a 414M parameter world model trained on 970K
trajectories from Open X-Embodiment datasets. We show that Whale-X exhibits
promising scalability and strong generalizability in real-world manipulation
scenarios using minimal demonstrations.",http://arxiv.org/pdf/2411.05619v1,,False
A Two-Step Concept-Based Approach for Enhanced Interpretability and Trust in Skin Lesion Diagnosis,08/11/2024,"Cristiano Patrício, Luís F. Teixeira, João C. Neves","The main challenges hindering the adoption of deep learning-based systems in
clinical settings are the scarcity of annotated data and the lack of
interpretability and trust in these systems. Concept Bottleneck Models (CBMs)
offer inherent interpretability by constraining the final disease prediction on
a set of human-understandable concepts. However, this inherent interpretability
comes at the cost of greater annotation burden. Additionally, adding new
concepts requires retraining the entire system. In this work, we introduce a
novel two-step methodology that addresses both of these challenges. By
simulating the two stages of a CBM, we utilize a pretrained Vision Language
Model (VLM) to automatically predict clinical concepts, and a Large Language
Model (LLM) to generate disease diagnoses based on the predicted concepts. We
validate our approach on three skin lesion datasets, demonstrating that it
outperforms traditional CBMs and state-of-the-art explainable methods, all
without requiring any training and utilizing only a few annotated examples. The
code is available at
https://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.",http://arxiv.org/pdf/2411.05609v1,,False
Towards a Real-Time Simulation of Elastoplastic Deformation Using Multi-Task Neural Networks,08/11/2024,"Ruben Schmeitz, Joris Remmers, Olga Mula, Olaf van der Sluis","This study introduces a surrogate modeling framework merging proper
orthogonal decomposition, long short-term memory networks, and multi-task
learning, to accurately predict elastoplastic deformations in real-time.
Superior to single-task neural networks, this approach achieves a mean absolute
error below 0.40\% across various state variables, with the multi-task model
showing enhanced generalization by mitigating overfitting through shared
layers. Moreover, in our use cases, a pre-trained multi-task model can
effectively train additional variables with as few as 20 samples, demonstrating
its deep understanding of complex scenarios. This is notably efficient compared
to single-task models, which typically require around 100 samples.
  Significantly faster than traditional finite element analysis, our model
accelerates computations by approximately a million times, making it a
substantial advancement for real-time predictive modeling in engineering
applications. While it necessitates further testing on more intricate models,
this framework shows substantial promise in elevating both efficiency and
accuracy in engineering applications, particularly for real-time scenarios.",http://arxiv.org/pdf/2411.05575v1,,False
Model-free portfolio allocation in continuous-time,08/11/2024,Henry Chiu,"We present a non-probabilistic, path-by-path framework for studying
path-dependent (i.e., where weight is a functional of time and historical
time-series), long-only portfolio allocation in continuous-time based on [Chiu
& Cont '23], where the fundamental concept of self-financing was introduced,
independent of any integration theory. In this article, we extend this concept
to a portfolio allocation strategy and characterize it by a path-dependent
partial differential equation. We derive the general explicit solution that
describes the evolution of wealth in generic markets, including price paths
that may not evolve continuously or exhibit variation of any order. Explicit
solution examples are provided.
  As an application of our continuous-time, path-dependent framework, we extend
an aggregating algorithm of [Vovk '90] and the universal algorithm of [Cover
'91] to continuous-time algorithms that combine multiple strategies into a
single strategy. These continuous-time (meta) algorithms take multiple
strategies as input (which may themselves be generated by other algorithms) and
track the wealth generated by the best individual strategy and the best convex
combination of strategies, with tracking error bounds in log wealth of order
O(1) and O(ln t), respectively. This work extends Cover's theorem [Cover '91,
Thm 6.1] to a continuous-time, model-free setting.",http://arxiv.org/pdf/2411.05470v1,,False
Benchmarking Distributional Alignment of Large Language Models,08/11/2024,"Nicole Meister, Carlos Guestrin, Tatsunori Hashimoto","Language models (LMs) are increasingly used as simulacra for people, yet
their ability to match the distribution of views of a specific demographic
group and be \textit{distributionally aligned} remains uncertain. This notion
of distributional alignment is complex, as there is significant variation in
the types of attributes that are simulated. Prior works have underexplored the
role of three critical variables -- the question domain, steering method, and
distribution expression method -- which motivates our contribution of a
benchmark explicitly addressing these dimensions. We construct a dataset
expanding beyond political values, create human baselines for this task, and
evaluate the extent to which an LM can align with a particular group's opinion
distribution to inform design choices of such simulation systems. Our analysis
reveals open problems regarding if, and how, LMs can be used to simulate
humans, and that LLMs can more accurately describe the opinion distribution
than simulate such distributions.",http://arxiv.org/pdf/2411.05403v1,,False
Discovering Latent Structural Causal Models from Spatio-Temporal Data,08/11/2024,"Kun Wang, Sumanth Varambally, Duncan Watson-Parris, Yi-An Ma, Rose Yu","Many important phenomena in scientific fields such as climate, neuroscience,
and epidemiology are naturally represented as spatiotemporal gridded data with
complex interactions. For example, in climate science, researchers aim to
uncover how large-scale events, such as the North Atlantic Oscillation (NAO)
and the Antarctic Oscillation (AAO), influence other global processes.
Inferring causal relationships from these data is a challenging problem
compounded by the high dimensionality of such data and the correlations between
spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY),
a novel framework based on variational inference, designed to explicitly model
latent time-series and their causal relationships from spatially confined modes
in the data. Our method uses an end-to-end training process that maximizes an
evidence-lower bound (ELBO) for the data likelihood. Theoretically, we show
that, under some conditions, the latent variables are identifiable up to
transformation by an invertible matrix. Empirically, we show that SPACY
outperforms state-of-the-art baselines on synthetic data, remains scalable for
large grids, and identifies key known phenomena from real-world climate data.",http://arxiv.org/pdf/2411.05331v1,,False
Differentiable Calibration of Inexact Stochastic Simulation Models via Kernel Score Minimization,08/11/2024,"Ziwei Su, Diego Klabjan","Stochastic simulation models are generative models that mimic complex systems
to help with decision-making. The reliability of these models heavily depends
on well-calibrated input model parameters. However, in many practical
scenarios, only output-level data are available to learn the input model
parameters, which is challenging due to the often intractable likelihood of the
stochastic simulation model. Moreover, stochastic simulation models are
frequently inexact, with discrepancies between the model and the target system.
No existing methods can effectively learn and quantify the uncertainties of
input parameters using only output-level data. In this paper, we propose to
learn differentiable input parameters of stochastic simulation models using
output-level data via kernel score minimization with stochastic gradient
descent. We quantify the uncertainties of the learned input parameters using a
frequentist confidence set procedure based on a new asymptotic normality result
that accounts for model inexactness. The proposed method is evaluated on exact
and inexact G/G/1 queueing models.",http://arxiv.org/pdf/2411.05315v1,,False
SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding,08/11/2024,"Ryan Sun, Tianyi Zhou, Xun Chen, Lichao Sun","Large Language Models (LLMs) have become essential in advancing natural
language processing (NLP) tasks, but their sequential token generation limits
inference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising
solution by using a smaller draft model to generate multiple token sequences,
which the target LLM verifies in parallel. However, current heuristic
approaches, such as Recursive Rejection Sampling (RRS), suffer from low
acceptance rates in subsequent drafts, limiting the advantages of using
multiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can
theoretically improve acceptance rates, but its computational cost is too high
for real-time use. We present SpecHub, a novel, efficient sampling-verification
method for MDSD that improves acceptance rates with only linear computational
overhead. By simplifying the OTM problem into a compact Linear Programming
model, SpecHub significantly reduces computational complexity. It further
accelerates sampling by leveraging a sparse joint distribution, focusing
computation on high-probability token sequences. In extensive experiments,
Spechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step
than RRS and RRS without replacement. We attach our code at
\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.",http://arxiv.org/pdf/2411.05289v1,,False
Real-World Offline Reinforcement Learning from Vision Language Model Feedback,08/11/2024,"Sreyas Venkataraman, Yufei Wang, Ziyu Wang, Zackory Erickson, David Held","Offline reinforcement learning can enable policy learning from pre-collected,
sub-optimal datasets without online interactions. This makes it ideal for
real-world robots and safety-critical scenarios, where collecting online data
or expert demonstrations is slow, costly, and risky. However, most existing
offline RL works assume the dataset is already labeled with the task rewards, a
process that often requires significant human effort, especially when
ground-truth states are hard to ascertain (e.g., in the real-world). In this
paper, we build on prior work, specifically RL-VLM-F, and propose a novel
system that automatically generates reward labels for offline datasets using
preference feedback from a vision-language model and a text description of the
task. Our method then learns a policy using offline RL with the reward-labeled
dataset. We demonstrate the system's applicability to a complex real-world
robot-assisted dressing task, where we first learn a reward function using a
vision-language model on a sub-optimal offline dataset, and then we use the
learned reward to employ Implicit Q learning to develop an effective dressing
policy. Our method also performs well in simulation tasks involving the
manipulation of rigid and deformable objects, and significantly outperform
baselines such as behavior cloning and inverse RL. In summary, we propose a new
system that enables automatic reward labeling and policy learning from
unlabeled, sub-optimal offline datasets.",http://arxiv.org/pdf/2411.05273v1,,False
