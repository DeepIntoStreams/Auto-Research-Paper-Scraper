Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
"Computational, Data-Driven, and Physics-Informed Machine Learning Approaches for Microstructure Modeling in Metal Additive Manufacturing",02/05/2025,"D. Patel, R. Sharma, Y. B. Guo","Metal additive manufacturing enables unprecedented design freedom and the
production of customized, complex components. However, the rapid melting and
solidification dynamics inherent to metal AM processes generate heterogeneous,
non-equilibrium microstructures that significantly impact mechanical properties
and subsequent functionality. Predicting microstructure and its evolution
across spatial and temporal scales remains a central challenge for process
optimization and defect mitigation. While conventional experimental techniques
and physics-based simulations provide a physical foundation and valuable
insights, they face critical limitations. In contrast, data-driven machine
learning offers an alternative prediction approach and powerful pattern
recognition but often operate as black-box, lacking generalizability and
physical consistency. To overcome these limitations, physics-informed machine
learning, including physics-informed neural networks, has emerged as a
promising paradigm by embedding governing physical laws into neural network
architectures, thereby enhancing accuracy, transparency, data efficiency, and
extrapolation capabilities. This work presents a comprehensive evaluation of
modeling strategies for microstructure prediction in metal AM. The strengths
and limitations of experimental, computational, and data-driven methods are
analyzed in depth, and highlight recent advances in hybrid PIML frameworks that
integrate physical knowledge with ML. Key challenges, such as data scarcity,
multi-scale coupling, and uncertainty quantification, are discussed alongside
future directions. Ultimately, this assessment underscores the importance of
PIML-based hybrid approaches in enabling predictive, scalable, and physically
consistent microstructure modeling for site-specific, microstructure-aware
process control and the reliable production of high-performance AM components.",http://arxiv.org/pdf/2505.01424v1,,False
VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models,02/05/2025,"Mohammadreza Teymoorianfard, Shiqing Ma, Amir Houmansadr","The rapid rise of video diffusion models has enabled the generation of highly
realistic and temporally coherent videos, raising critical concerns about
content authenticity, provenance, and misuse. Existing watermarking approaches,
whether passive, post-hoc, or adapted from image-based techniques, often
struggle to withstand video-specific manipulations such as frame insertion,
dropping, or reordering, and typically degrade visual quality. In this work, we
introduce VIDSTAMP, a watermarking framework that embeds per-frame or
per-segment messages directly into the latent space of temporally-aware video
diffusion models. By fine-tuning the model's decoder through a two-stage
pipeline, first on static image datasets to promote spatial message separation,
and then on synthesized video sequences to restore temporal consistency,
VIDSTAMP learns to embed high-capacity, flexible watermarks with minimal
perceptual impact. Leveraging architectural components such as 3D convolutions
and temporal attention, our method imposes no additional inference cost and
offers better perceptual quality than prior methods, while maintaining
comparable robustness against common distortions and tampering. VIDSTAMP embeds
768 bits per video (48 bits per frame) with a bit accuracy of 95.0%, achieves a
log P-value of -166.65 (lower is better), and maintains a video quality score
of 0.836, comparable to unwatermarked outputs (0.838) and surpassing prior
methods in capacity-quality tradeoffs. Code: Code:
\url{https://github.com/SPIN-UMass/VidStamp}",http://arxiv.org/pdf/2505.01406v1,,False
SIME: Enhancing Policy Self-Improvement with Modal-level Exploration,02/05/2025,"Yang Jin, Jun Lv, Wenye Yu, Hongjie Fang, Yong-Lu Li, Cewu Lu","Self-improvement requires robotic systems to initially learn from
human-provided data and then gradually enhance their capabilities through
interaction with the environment. This is similar to how humans improve their
skills through continuous practice. However, achieving effective
self-improvement is challenging, primarily because robots tend to repeat their
existing abilities during interactions, often failing to generate new, valuable
data for learning. In this paper, we identify the key to successful
self-improvement: modal-level exploration and data selection. By incorporating
a modal-level exploration mechanism during policy execution, the robot can
produce more diverse and multi-modal interactions. At the same time, we select
the most valuable trials and high-quality segments from these interactions for
learning. We successfully demonstrate effective robot self-improvement on both
simulation benchmarks and real-world experiments. The capability for
self-improvement will enable us to develop more robust and high-success-rate
robotic control strategies at a lower cost. Our code and experiment scripts are
available at https://ericjin2002.github.io/SIME/",http://arxiv.org/pdf/2505.01396v1,,False
"Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability",02/05/2025,"Anass Grini, Oumaima Taheri, Btissam El Khamlichi, Amal El Fallah-Seghrouchni","While machine learning has significantly advanced Network Intrusion Detection
Systems (NIDS), particularly within IoT environments where devices generate
large volumes of data and are increasingly susceptible to cyber threats, these
models remain vulnerable to adversarial attacks. Our research reveals a
critical flaw in existing adversarial attack methodologies: the frequent
violation of domain-specific constraints, such as numerical and categorical
limits, inherent to IoT and network traffic. This leads to up to 80.3% of
adversarial examples being invalid, significantly overstating real-world
vulnerabilities. These invalid examples, though effective in fooling models, do
not represent feasible attacks within practical IoT deployments. Consequently,
relying on these results can mislead resource allocation for defense, inflating
the perceived susceptibility of IoT-enabled NIDS models to adversarial
manipulation. Furthermore, we demonstrate that simpler surrogate models like
Multi-Layer Perceptron (MLP) generate more valid adversarial examples compared
to complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate,
we analyze the transferability of adversarial severity to other ML/DL models
commonly used in IoT contexts. This work underscores the importance of
considering both domain constraints and model architecture when evaluating and
designing robust ML/DL models for security-critical IoT and network
applications.",http://arxiv.org/pdf/2505.01328v1,,False
Reduced-order structure-property linkages for stochastic metamaterials,02/05/2025,"Hooman Danesh, Maruthi Annamaraju, Tim Brepols, Stefanie Reese, Surya R. Kalidindi","The capabilities of additive manufacturing have facilitated the design and
production of mechanical metamaterials with diverse unit cell geometries.
Establishing linkages between the vast design space of unit cells and their
effective mechanical properties is critical for the efficient design and
performance evaluation of such metamaterials. However, physics-based
simulations of metamaterial unit cells across the entire design space are
computationally expensive, necessitating a materials informatics framework to
efficiently capture complex structure-property relationships. In this work,
principal component analysis of 2-point correlation functions is performed to
extract the salient features from a large dataset of randomly generated 2D
metamaterials. Physics-based simulations are performed using a fast Fourier
transform (FFT)-based homogenization approach to efficiently compute the
homogenized effective elastic stiffness across the extensive unit cell designs.
Subsequently, Gaussian process regression is used to generate reduced-order
surrogates, mapping unit cell designs to their homogenized effective elastic
constant. It is demonstrated that the adopted workflow enables a high-value
low-dimensional representation of the voluminous stochastic metamaterial
dataset, facilitating the construction of robust structure-property maps.
Finally, an uncertainty-based active learning framework is utilized to train a
surrogate model with a significantly smaller number of data points compared to
the original full dataset. It is shown that a dataset as small as $0.61\%$ of
the entire dataset is sufficient to generate accurate and robust
structure-property maps.",http://arxiv.org/pdf/2505.01283v1,,False
TSTMotion: Training-free Scene-awarenText-to-motion Generation,02/05/2025,"Ziyan Guo, Haoxuan Qu, Hossein Rahmani, Dewen Soh, Ping Hu, Qiuhong Ke, Jun Liu","Text-to-motion generation has recently garnered significant research
interest, primarily focusing on generating human motion sequences in blank
backgrounds. However, human motions commonly occur within diverse 3D scenes,
which has prompted exploration into scene-aware text-to-motion generation
methods. Yet, existing scene-aware methods often rely on large-scale
ground-truth motion sequences in diverse 3D scenes, which poses practical
challenges due to the expensive cost. To mitigate this challenge, we are the
first to propose a \textbf{T}raining-free \textbf{S}cene-aware
\textbf{T}ext-to-\textbf{Motion} framework, dubbed as \textbf{TSTMotion}, that
efficiently empowers pre-trained blank-background motion generators with the
scene-aware capability. Specifically, conditioned on the given 3D scene and
text description, we adopt foundation models together to reason, predict and
validate a scene-aware motion guidance. Then, the motion guidance is
incorporated into the blank-background motion generators with two
modifications, resulting in scene-aware text-driven motion sequences. Extensive
experiments demonstrate the efficacy and generalizability of our proposed
framework. We release our code in \href{https://tstmotion.github.io/}{Project
Page}.",http://arxiv.org/pdf/2505.01182v1,,False
Empirical Comparison of Lightweight Forecasting Models for Seasonal and Non-Seasonal Time Series,02/05/2025,"Thanh Son Nguyen, Dang Minh Duc Nguyen, Van Thanh Nguyen","Accurate time series forecasting is essential in many real-time applications
that demand both high predictive accuracy and computational efficiency. This
study provides an empirical comparison between a Polynomial Classifier and a
Radial Basis Function Neural Network (RBFNN) across four real-world time series
datasets (weather conditions, gold prices, crude oil prices, and beer
production volumes) that cover both seasonal and nonseasonal patterns. Model
performance is evaluated by forecasting accuracy (using Mean Absolute Error,
Root Mean Squared Error, and Coefficient of Variation of Root Mean Squared
Error) and computational time to assess each model's viability for real time
forecasting. The results show that the PC yields more accurate and faster
forecasts for non seasonal series, whereas the RBFNN performs better on series
with pronounced seasonal patterns. From an interpretability standpoint, the
polynomial model offers a simpler, more transparent structure (in contrast to
the black box nature of neural network), which is advantageous for
understanding and trust in real time decision making. The performance
differences between PC and RBFNN are statistically significant, as confirmed by
paired t tests and Wilcoxon signed rank tests. These findings provide practical
guidance for model selection in time series forecasting, indicating that PC may
be preferable for quick, interpretable forecasts in non-seasonal contexts,
whereas RBFNN is superior for capturing complex seasonal behaviors",http://arxiv.org/pdf/2505.01163v1,,False
Machine Learning for Physical Simulation Challenge Results and Retrospective Analysis: Power Grid Use Case,02/05/2025,"Milad Leyli-Abadi, Jérôme Picault, Antoine Marot, Jean-Patrick Brunet, Agathe Gilain, Amarsagar Reddy Ramapuram Matavalam, Shaban Ghias Satti, Quingbin Jiang, Yang Liu, Dean Justin Ninalga","This paper addresses the growing computational challenges of power grid
simulations, particularly with the increasing integration of renewable energy
sources like wind and solar. As grid operators must analyze significantly more
scenarios in near real-time to prevent failures and ensure stability,
traditional physical-based simulations become computationally impractical. To
tackle this, a competition was organized to develop AI-driven methods that
accelerate power flow simulations by at least an order of magnitude while
maintaining operational reliability. This competition utilized a regional-scale
grid model with a 30\% renewable energy mix, mirroring the anticipated
near-future composition of the French power grid. A key contribution of this
work is through the use of LIPS (Learning Industrial Physical Systems), a
benchmarking framework that evaluates solutions based on four critical
dimensions: machine learning performance, physical compliance, industrial
readiness, and generalization to out-of-distribution scenarios. The paper
provides a comprehensive overview of the Machine Learning for Physical
Simulation (ML4PhySim) competition, detailing the benchmark suite, analyzing
top-performing solutions that outperformed traditional simulation methods, and
sharing key organizational insights and best practices for running large-scale
AI competitions. Given the promising results achieved, the study aims to
inspire further research into more efficient, scalable, and sustainable power
network simulation methodologies.",http://arxiv.org/pdf/2505.01156v1,,False
On Simulating Thin-Film Processes at the Atomic Scale Using Machine Learned Force Fields,02/05/2025,"S. Kondati Natarajan, J. Schneider, N. Pandey, J. Wellendorff, S. Smidstrup","Atomistic modeling of thin-film processes provides an avenue not only for
discovering key chemical mechanisms of the processes but also to extract
quantitative metrics on the events and reactions taking place at the
gas-surface interface. Molecular dynamics (MD) is a powerful computational
method to study the evolution of a process at the atomic scale, but studies of
industrially relevant processes usually require suitable force fields, which
are in general not available for all processes of interest. However, machine
learned force fields (MLFF) are conquering the field of computational materials
and surface science. In this paper, we demonstrate how to efficiently build
MLFFs suitable for process simulations and provide two examples for
technologically relevant processes: precursor pulse in the atomic layer
deposition of HfO2 and atomic layer etching of MoS2.",http://arxiv.org/pdf/2505.01118v1,10.1116/6.0004288,False
Monotone Peridynamic Neural Operator for Nonlinear Material Modeling with Conditionally Unique Solutions,02/05/2025,"Jihong Wang, Xiaochuan Tian, Zhongqiang Zhang, Stewart Silling, Siavash Jafarzadeh, Yue Yu","Data-driven methods have emerged as powerful tools for modeling the responses
of complex nonlinear materials directly from experimental measurements. Among
these methods, the data-driven constitutive models present advantages in
physical interpretability and generalizability across different boundary
conditions/domain settings. However, the well-posedness of these learned models
is generally not guaranteed a priori, which makes the models prone to
non-physical solutions in downstream simulation tasks. In this study, we
introduce monotone peridynamic neural operator (MPNO), a novel data-driven
nonlocal constitutive model learning approach based on neural operators. Our
approach learns a nonlocal kernel together with a nonlinear constitutive
relation, while ensuring solution uniqueness through a monotone gradient
network. This architectural constraint on gradient induces convexity of the
learnt energy density function, thereby guaranteeing solution uniqueness of
MPNO in small deformation regimes. To validate our approach, we evaluate MPNO's
performance on both synthetic and real-world datasets. On synthetic datasets
with manufactured kernel and constitutive relation, we show that the learnt
model converges to the ground-truth as the measurement grid size decreases both
theoretically and numerically. Additionally, our MPNO exhibits superior
generalization capabilities than the conventional neural networks: it yields
smaller displacement solution errors in down-stream tasks with new and unseen
loadings. Finally, we showcase the practical utility of our approach through
applications in learning a homogenized model from molecular dynamics data,
highlighting its expressivity and robustness in real-world scenarios.",http://arxiv.org/pdf/2505.01060v1,,False
Improving Large Language Model Planning with Action Sequence Similarity,02/05/2025,"Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova","Planning is essential for artificial intelligence systems to look ahead and
proactively determine a course of actions to reach objectives in the virtual
and real world. Recent work on large language models (LLMs) sheds light on
their planning capability in various tasks. However, it remains unclear what
signals in the context influence the model performance. In this work, we
explore how to improve the model planning capability through in-context
learning (ICL), specifically, what signals can help select the exemplars.
Through extensive experiments, we observe that commonly used problem similarity
may result in false positives with drastically different plans, which can
mislead the model. In response, we propose to sample and filter exemplars
leveraging plan side action sequence similarity (AS). We propose GRASE-DC: a
two-stage pipeline that first re-samples high AS exemplars and then curates the
selected exemplars with dynamic clustering on AS to achieve a balance of
relevance and diversity. Our experimental result confirms that GRASE-DC
achieves significant performance improvement on various planning tasks (up to
~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on
average). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a
validator, we are able to even boost the performance by 18.9% more.
  Extensive analysis validates the consistent performance improvement of
GRASE-DC with various backbone LLMs and on both classical planning and natural
language planning benchmarks. GRASE-DC can further boost the planning accuracy
by ~24 absolute points on harder problems using simpler problems as exemplars
over a random baseline. This demonstrates its ability to generalize to
out-of-distribution problems.",http://arxiv.org/pdf/2505.01009v1,,False
Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models,02/05/2025,"Yuewen Mei, Tong Nie, Jian Sun, Ye Tian","Simulation-based testing is crucial for validating autonomous vehicles (AVs),
yet existing scenario generation methods either overfit to common driving
patterns or operate in an offline, non-interactive manner that fails to expose
rare, safety-critical corner cases. In this paper, we introduce an online,
retrieval-augmented large language model (LLM) framework for generating
safety-critical driving scenarios. Our method first employs an LLM-based
behavior analyzer to infer the most dangerous intent of the background vehicle
from the observed state, then queries additional LLM agents to synthesize
feasible adversarial trajectories. To mitigate catastrophic forgetting and
accelerate adaptation, we augment the framework with a dynamic memorization and
retrieval bank of intent-planner pairs, automatically expanding its behavioral
library when novel intents arise. Evaluations using the Waymo Open Motion
Dataset demonstrate that our model reduces the mean minimum time-to-collision
from 1.62 to 1.08 s and incurs a 75% collision rate, substantially
outperforming baselines.",http://arxiv.org/pdf/2505.00972v1,,False
Enhancing User Sequence Modeling through Barlow Twins-based Self-Supervised Learning,02/05/2025,"Yuhan Liu, Lin Ning, Neo Wu, Karan Singhal, Philip Andrew Mansfield, Devora Berlowitz, Sushant Prakash, Bradley Green","User sequence modeling is crucial for modern large-scale recommendation
systems, as it enables the extraction of informative representations of users
and items from their historical interactions. These user representations are
widely used for a variety of downstream tasks to enhance users' online
experience. A key challenge for learning these representations is the lack of
labeled training data. While self-supervised learning (SSL) methods have
emerged as a promising solution for learning representations from unlabeled
data, many existing approaches rely on extensive negative sampling, which can
be computationally expensive and may not always be feasible in real-world
scenario. In this work, we propose an adaptation of Barlow Twins, a
state-of-the-art SSL methods, to user sequence modeling by incorporating
suitable augmentation methods. Our approach aims to mitigate the need for large
negative sample batches, enabling effective representation learning with
smaller batch sizes and limited labeled data. We evaluate our method on the
MovieLens-1M, MovieLens-20M, and Yelp datasets, demonstrating that our method
consistently outperforms the widely-used dual encoder model across three
downstream tasks, achieving an 8%-20% improvement in accuracy. Our findings
underscore the effectiveness of our approach in extracting valuable
sequence-level information for user modeling, particularly in scenarios where
labeled data is scarce and negative examples are limited.",http://arxiv.org/pdf/2505.00953v1,,False
FreCT: Frequency-augmented Convolutional Transformer for Robust Time Series Anomaly Detection,02/05/2025,"Wenxin Zhang, Ding Xu, Guangzhen Yao, Xiaojian Lin, Renxiang Guan, Chengze Du, Renda Han, Xi Xuan, Cuicui Luo","Time series anomaly detection is critical for system monitoring and risk
identification, across various domains, such as finance and healthcare.
However, for most reconstruction-based approaches, detecting anomalies remains
a challenge due to the complexity of sequential patterns in time series data.
On the one hand, reconstruction-based techniques are susceptible to
computational deviation stemming from anomalies, which can lead to impure
representations of normal sequence patterns. On the other hand, they often
focus on the time-domain dependencies of time series, while ignoring the
alignment of frequency information beyond the time domain. To address these
challenges, we propose a novel Frequency-augmented Convolutional Transformer
(FreCT). FreCT utilizes patch operations to generate contrastive views and
employs an improved Transformer architecture integrated with a convolution
module to capture long-term dependencies while preserving local topology
information. The introduced frequency analysis based on Fourier transformation
could enhance the model's ability to capture crucial characteristics beyond the
time domain. To protect the training quality from anomalies and improve the
robustness, FreCT deploys stop-gradient Kullback-Leibler (KL) divergence and
absolute error to optimize consistency information in both time and frequency
domains. Extensive experiments on four public datasets demonstrate that FreCT
outperforms existing methods in identifying anomalies.",http://arxiv.org/pdf/2505.00941v1,,False
Compact Recurrent Transformer with Persistent Memory,02/05/2025,"Edison Mucllari, Zachary Daniels, David Zhang, Qiang Ye","The Transformer architecture has shown significant success in many language
processing and visual tasks. However, the method faces challenges in
efficiently scaling to long sequences because the self-attention computation is
quadratic with respect to the input length. To overcome this limitation,
several approaches scale to longer sequences by breaking long sequences into a
series of segments, restricting self-attention to local dependencies between
tokens within each segment and using a memory mechanism to manage information
flow between segments. However, these approached generally introduce additional
compute overhead that restricts them from being used for applications where
limited compute memory and power are of great concern (such as edge computing).
We propose a novel and efficient Compact Recurrent Transformer (CRT), which
combines shallow Transformer models that process short local segments with
recurrent neural networks to compress and manage a single persistent memory
vector that summarizes long-range global information between segments. We
evaluate CRT on WordPTB and WikiText-103 for next-token-prediction tasks, as
well as on the Toyota Smarthome video dataset for classification. CRT achieves
comparable or superior prediction results to full-length Transformers in the
language datasets while using significantly shorter segments (half or quarter
size) and substantially reduced FLOPs. Our approach also demonstrates
state-of-the-art performance on the Toyota Smarthome video dataset.",http://arxiv.org/pdf/2505.00929v1,,False
