Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Deep Discrete Encoders: Identifiable Deep Generative Models for Rich Data with Discrete Latent Layers,02/01/2025,"Seunghyun Lee, Yuqi Gu","In the era of generative AI, deep generative models (DGMs) with latent
representations have gained tremendous popularity. Despite their impressive
empirical performance, the statistical properties of these models remain
underexplored. DGMs are often overparametrized, non-identifiable, and
uninterpretable black boxes, raising serious concerns when deploying them in
high-stakes applications. Motivated by this, we propose an interpretable deep
generative modeling framework for rich data types with discrete latent layers,
called Deep Discrete Encoders (DDEs). A DDE is a directed graphical model with
multiple binary latent layers. Theoretically, we propose transparent
identifiability conditions for DDEs, which imply progressively smaller sizes of
the latent layers as they go deeper. Identifiability ensures consistent
parameter estimation and inspires an interpretable design of the deep
architecture. Computationally, we propose a scalable estimation pipeline of a
layerwise nonlinear spectral initialization followed by a penalized stochastic
approximation EM algorithm. This procedure can efficiently estimate models with
exponentially many latent components. Extensive simulation studies validate our
theoretical results and demonstrate the proposed algorithms' excellent
performance. We apply DDEs to three diverse real datasets for hierarchical
topic modeling, image representation learning, response time modeling in
educational testing, and obtain interpretable findings.",http://arxiv.org/pdf/2501.01414v1,,False
A Unified Hyperparameter Optimization Pipeline for Transformer-Based Time Series Forecasting Models,02/01/2025,"Jingjing Xu, Caesar Wu, Yuan-Fang Li, Grégoire Danoy, Pascal Bouvry","Transformer-based models for time series forecasting (TSF) have attracted
significant attention in recent years due to their effectiveness and
versatility. However, these models often require extensive hyperparameter
optimization (HPO) to achieve the best possible performance, and a unified
pipeline for HPO in transformer-based TSF remains lacking. In this paper, we
present one such pipeline and conduct extensive experiments on several
state-of-the-art (SOTA) transformer-based TSF models. These experiments are
conducted on standard benchmark datasets to evaluate and compare the
performance of different models, generating practical insights and examples.
Our pipeline is generalizable beyond transformer-based architectures and can be
applied to other SOTA models, such as Mamba and TimeMixer, as demonstrated in
our experiments. The goal of this work is to provide valuable guidance to both
industry practitioners and academic researchers in efficiently identifying
optimal hyperparameters suited to their specific domain applications. The code
and complete experimental results are available on GitHub.",http://arxiv.org/pdf/2501.01394v1,,False
ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI,02/01/2025,"Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago López-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim","Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.",http://arxiv.org/pdf/2501.01372v1,,False
TabTreeFormer: Tree Augmented Tabular Data Generation using Transformers,02/01/2025,"Jiayu Li, Bingyin Zhao, Zilong Zhao, Kevin Yee, Uzair Javaid, Yingjie Lao, Biplab Sikdar","Transformers have achieved remarkable success in tabular data generation.
However, they lack domain-specific inductive biases which are critical to
preserving the intrinsic characteristics of tabular data. Meanwhile, they
suffer from poor scalability and efficiency due to quadratic computational
complexity. In this paper, we propose TabTreeFormer, a hybrid transformer
architecture that incorporates a tree-based model that retains tabular-specific
inductive biases of non-smooth and potentially low-correlated patterns due to
its discreteness and non-rotational invariance, and hence enhances the fidelity
and utility of synthetic data. In addition, we devise a dual-quantization
tokenizer to capture the multimodal continuous distribution and further
facilitate the learning of numerical value distribution. Moreover, our proposed
tokenizer reduces the vocabulary size and sequence length due to the limited
dimension-wise semantic meaning and training set size of tabular data,
rendering a significant model size shrink without sacrificing the capability of
the transformer model. We evaluate TabTreeFormer on 10 datasets against
multiple generative models on various metrics; our experimental results show
that TabTreeFormer achieves superior fidelity, utility, privacy, and
efficiency. Our best model yields a 40% utility improvement with 1/16 of the
baseline model size.",http://arxiv.org/pdf/2501.01216v1,,False
Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects,02/01/2025,"Abdullah Mushtaq, Muhammad Rafay Naeem, Ibrahim Ghaznavi, Muhammad Imran Taj, Imran Hashmi, Junaid Qadir","Multi-Agent Large Language Models (LLMs) are gaining significant attention
for their ability to harness collective intelligence in complex
problem-solving, decision-making, and planning tasks. This aligns with the
concept of the wisdom of crowds, where diverse agents contribute collectively
to generating effective solutions, making it particularly suitable for
educational settings. Senior design projects, also known as capstone or final
year projects, are pivotal in engineering education as they integrate
theoretical knowledge with practical application, fostering critical thinking,
teamwork, and real-world problem-solving skills. In this paper, we explore the
use of Multi-Agent LLMs in supporting these senior design projects undertaken
by engineering students, which often involve multidisciplinary considerations
and conflicting objectives, such as optimizing technical performance while
addressing ethical, social, and environmental concerns. We propose a framework
where distinct LLM agents represent different expert perspectives, such as
problem formulation agents, system complexity agents, societal and ethical
agents, or project managers, thus facilitating a holistic problem-solving
approach. This implementation leverages standard multi-agent system (MAS)
concepts such as coordination, cooperation, and negotiation, incorporating
prompt engineering to develop diverse personas for each agent. These agents
engage in rich, collaborative dialogues to simulate human engineering teams,
guided by principles from swarm AI to efficiently balance individual
contributions towards a unified solution. We adapt these techniques to create a
collaboration structure for LLM agents, encouraging interdisciplinary reasoning
and negotiation similar to real-world senior design projects. To assess the
efficacy of this framework, we collected six proposals of engineering and
computer science of...",http://arxiv.org/pdf/2501.01205v1,,False
RingFormer: A Neural Vocoder with Ring Attention and Convolution-Augmented Transformer,02/01/2025,"Seongho Hong, Yong-Hoon Choi","While transformers demonstrate outstanding performance across various audio
tasks, their application to neural vocoders remains challenging. Neural
vocoders require the generation of long audio signals at the sample level,
which demands high temporal resolution. This results in significant
computational costs for attention map generation and limits their ability to
efficiently process both global and local information. Additionally, the
sequential nature of sample generation in neural vocoders poses difficulties
for real-time processing, making the direct adoption of transformers
impractical. To address these challenges, we propose RingFormer, a neural
vocoder that incorporates the ring attention mechanism into a lightweight
transformer variant, the convolution-augmented transformer (Conformer). Ring
attention effectively captures local details while integrating global
information, making it well-suited for processing long sequences and enabling
real-time audio generation. RingFormer is trained using adversarial training
with two discriminators. The proposed model is applied to the decoder of the
text-to-speech model VITS and compared with state-of-the-art vocoders such as
HiFi-GAN, iSTFT-Net, and BigVGAN under identical conditions using various
objective and subjective metrics. Experimental results show that RingFormer
achieves comparable or superior performance to existing models, particularly
excelling in real-time audio generation. Our code and audio samples are
available on GitHub.",http://arxiv.org/pdf/2501.01182v1,,False
TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions,02/01/2025,"Vriksha Srihari, R. Bhavya, Shruti Jayaraman, V. Mary Anita Rajam","While generative models such as text-to-image, large language models and
text-to-video have seen significant progress, the extension to
text-to-virtual-reality remains largely unexplored, due to a deficit in
training data and the complexity of achieving realistic depth and motion in
virtual environments. This paper proposes an approach to coalesce existing
generative systems to form a stereoscopic virtual reality video from text.
  Carried out in three main stages, we start with a base text-to-image model
that captures context from an input text. We then employ Stable Diffusion on
the rudimentary image produced, to generate frames with enhanced realism and
overall quality. These frames are processed with depth estimation algorithms to
create left-eye and right-eye views, which are stitched side-by-side to create
an immersive viewing experience. Such systems would be highly beneficial in
virtual reality production, since filming and scene building often require
extensive hours of work and post-production effort.
  We utilize image evaluation techniques, specifically Fr\'echet Inception
Distance and CLIP Score, to assess the visual quality of frames produced for
the video. These quantitative measures establish the proficiency of the
proposed method.
  Our work highlights the exciting possibilities of using natural
language-driven graphics in fields like virtual reality simulations.",http://arxiv.org/pdf/2501.01156v1,10.1109/CVMI61877.2024.10782691,False
Missing Data as Augmentation in the Earth Observation Domain: A Multi-View Learning Approach,02/01/2025,"Francisco Mena, Diego Arenas, Andreas Dengel","Multi-view learning (MVL) leverages multiple sources or views of data to
enhance machine learning model performance and robustness. This approach has
been successfully used in the Earth Observation (EO) domain, where views have a
heterogeneous nature and can be affected by missing data. Despite the negative
effect that missing data has on model predictions, the ML literature has used
it as an augmentation technique to improve model generalization, like masking
the input data. Inspired by this, we introduce novel methods for EO
applications tailored to MVL with missing views. Our methods integrate the
combination of a set to simulate all combinations of missing views as different
training samples. Instead of replacing missing data with a numerical value, we
use dynamic merge functions, like average, and more complex ones like
Transformer. This allows the MVL model to entirely ignore the missing views,
enhancing its predictive robustness. We experiment on four EO datasets with
temporal and static views, including state-of-the-art methods from the EO
domain. The results indicate that our methods improve model robustness under
conditions of moderate missingness, and improve the predictive performance when
all views are present. The proposed methods offer a single adaptive solution to
operate effectively with any combination of available views.",http://arxiv.org/pdf/2501.01132v1,,False
Long-range Brain Graph Transformer,02/01/2025,"Shuo Yu, Shan Jin, Ming Li, Tabinda Sarwar, Feng Xia","Understanding communication and information processing among brain regions of
interest (ROIs) is highly dependent on long-range connectivity, which plays a
crucial role in facilitating diverse functional neural integration across the
entire brain. However, previous studies generally focused on the short-range
dependencies within brain networks while neglecting the long-range
dependencies, limiting an integrated understanding of brain-wide communication.
To address this limitation, we propose Adaptive Long-range aware TransformER
(ALTER), a brain graph transformer to capture long-range dependencies between
brain ROIs utilizing biased random walk. Specifically, we present a novel
long-range aware strategy to explicitly capture long-range dependencies between
brain ROIs. By guiding the walker towards the next hop with higher correlation
value, our strategy simulates the real-world brain-wide communication.
Furthermore, by employing the transformer framework, ALERT adaptively
integrates both short- and long-range dependencies between brain ROIs, enabling
an integrated understanding of multi-level communication across the entire
brain. Extensive experiments on ABIDE and ADNI datasets demonstrate that ALTER
consistently outperforms generalized state-of-the-art graph learning methods
(including SAN, Graphormer, GraphTrans, and LRGNN) and other graph learning
based brain network analysis methods (including FBNETGEN, BrainNetGNN,
BrainGNN, and BrainNETTF) in neurological disease diagnosis. Cases of
long-range dependencies are also presented to further illustrate the
effectiveness of ALTER. The implementation is available at
\url{https://github.com/yushuowiki/ALTER}.",http://arxiv.org/pdf/2501.01100v1,,False
Graph Generative Pre-trained Transformer,02/01/2025,"Xiaohui Chen, Yinkai Wang, Jiaxing He, Yuanqi Du, Soha Hassoun, Xiaolin Xu, Li-Ping Liu","Graph generation is a critical task in numerous domains, including molecular
design and social network analysis, due to its ability to model complex
relationships and structured data. While most modern graph generative models
utilize adjacency matrix representations, this work revisits an alternative
approach that represents graphs as sequences of node set and edge set. We
advocate for this approach due to its efficient encoding of graphs and propose
a novel representation. Based on this representation, we introduce the Graph
Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns
graph structures via next-token prediction. To further exploit G2PT's
capabilities as a general-purpose foundation model, we explore fine-tuning
strategies for two downstream applications: goal-oriented generation and graph
property prediction. We conduct extensive experiments across multiple datasets.
Results indicate that G2PT achieves superior generative performance on both
generic graph and molecule datasets. Furthermore, G2PT exhibits strong
adaptability and versatility in downstream tasks from molecular design to
property prediction.",http://arxiv.org/pdf/2501.01073v1,,False
A Novel Diffusion Model for Pairwise Geoscience Data Generation with Unbalanced Training Dataset,01/01/2025,"Junhuan Yang, Yuzhou Zhang, Yi Sheng, Youzuo Lin, Lei Yang","Recently, the advent of generative AI technologies has made transformational
impacts on our daily lives, yet its application in scientific applications
remains in its early stages. Data scarcity is a major, well-known barrier in
data-driven scientific computing, so physics-guided generative AI holds
significant promise. In scientific computing, most tasks study the conversion
of multiple data modalities to describe physical phenomena, for example,
spatial and waveform in seismic imaging, time and frequency in signal
processing, and temporal and spectral in climate modeling; as such, multi-modal
pairwise data generation is highly required instead of single-modal data
generation, which is usually used in natural images (e.g., faces, scenery).
Moreover, in real-world applications, the unbalance of available data in terms
of modalities commonly exists; for example, the spatial data (i.e., velocity
maps) in seismic imaging can be easily simulated, but real-world seismic
waveform is largely lacking. While the most recent efforts enable the powerful
diffusion model to generate multi-modal data, how to leverage the unbalanced
available data is still unclear. In this work, we use seismic imaging in
subsurface geophysics as a vehicle to present ``UB-Diff'', a novel diffusion
model for multi-modal paired scientific data generation. One major innovation
is a one-in-two-out encoder-decoder network structure, which can ensure
pairwise data is obtained from a co-latent representation. Then, the co-latent
representation will be used by the diffusion process for pairwise data
generation. Experimental results on the OpenFWI dataset show that UB-Diff
significantly outperforms existing techniques in terms of Fr\'{e}chet Inception
Distance (FID) score and pairwise evaluation, indicating the generation of
reliable and useful multi-modal pairwise data.",http://arxiv.org/pdf/2501.00941v1,,False
Population Aware Diffusion for Time Series Generation,01/01/2025,"Yang Li, Han Meng, Zhenyu Bi, Ingolv T. Urnes, Haipeng Chen","Diffusion models have shown promising ability in generating high-quality time
series (TS) data. Despite the initial success, existing works mostly focus on
the authenticity of data at the individual level, but pay less attention to
preserving the population-level properties on the entire dataset. Such
population-level properties include value distributions for each dimension and
distributions of certain functional dependencies (e.g., cross-correlation, CC)
between different dimensions. For instance, when generating house energy
consumption TS data, the value distributions of the outside temperature and the
kitchen temperature should be preserved, as well as the distribution of CC
between them. Preserving such TS population-level properties is critical in
maintaining the statistical insights of the datasets, mitigating model bias,
and augmenting downstream tasks like TS prediction. Yet, it is often overlooked
by existing models. Hence, data generated by existing models often bear
distribution shifts from the original data. We propose Population-aware
Diffusion for Time Series (PaD-TS), a new TS generation model that better
preserves the population-level properties. The key novelties of PaD-TS include
1) a new training method explicitly incorporating TS population-level property
preservation, and 2) a new dual-channel encoder model architecture that better
captures the TS data structure. Empirical results in major benchmark datasets
show that PaD-TS can improve the average CC distribution shift score between
real and synthetic data by 5.9x while maintaining a performance comparable to
state-of-the-art models on individual-level authenticity.",http://arxiv.org/pdf/2501.00910v1,,False
A Graphical Approach to State Variable Selection in Off-policy Learning,01/01/2025,"Joakim Blach Andersen, Qingyuan Zhao","Sequential decision problems are widely studied across many areas of science.
A key challenge when learning policies from historical data - a practice
commonly referred to as off-policy learning - is how to ``identify'' the impact
of a policy of interest when the observed data are not randomized. Off-policy
learning has mainly been studied in two settings: dynamic treatment regimes
(DTRs), where the focus is on controlling confounding in medical problems with
short decision horizons, and offline reinforcement learning (RL), where the
focus is on dimension reduction in closed systems such as games. The gap
between these two well studied settings has limited the wider application of
off-policy learning to many real-world problems. Using the theory for causal
inference based on acyclic directed mixed graph (ADMGs), we provide a set of
graphical identification criteria in general decision processes that encompass
both DTRs and MDPs. We discuss how our results relate to the often implicit
causal assumptions made in the DTR and RL literatures and further clarify
several common misconceptions. Finally, we present a realistic simulation study
for the dynamic pricing problem encountered in container logistics, and
demonstrate how violations of our graphical criteria can lead to suboptimal
policies.",http://arxiv.org/pdf/2501.00854v1,,False
Beyond Static Datasets: A Behavior-Driven Entity-Specific Simulation to Overcome Data Scarcity and Train Effective Crypto Anti-Money Laundering Models,01/01/2025,"Dinesh Srivasthav P, Manoj Apte","For different factors/reasons, ranging from inherent characteristics and
features providing decentralization, enhanced privacy, ease of transactions,
etc., to implied external hardships in enforcing regulations, contradictions in
data sharing policies, etc., cryptocurrencies have been severely abused for
carrying out numerous malicious and illicit activities including money
laundering, darknet transactions, scams, terrorism financing, arm trades.
However, money laundering is a key crime to be mitigated to also suspend the
movement of funds from other illicit activities. Billions of dollars are
annually being laundered. It is getting extremely difficult to identify money
laundering in crypto transactions owing to many layering strategies available
today, and rapidly evolving tactics, and patterns the launderers use to
obfuscate the illicit funds. Many detection methods have been proposed ranging
from naive approaches involving complete manual investigation to machine
learning models. However, there are very limited datasets available for
effectively training machine learning models. Also, the existing datasets are
static and class-imbalanced, posing challenges for scalability and suitability
to specific scenarios, due to lack of customization to varying requirements.
This has been a persistent challenge in literature. In this paper, we propose
behavior embedded entity-specific money laundering-like transaction simulation
that helps in generating various transaction types and models the transactions
embedding the behavior of several entities observed in this space. The paper
discusses the design and architecture of the simulator, a custom dataset we
generated using the simulator, and the performance of models trained on this
synthetic data in detecting real addresses involved in money laundering.",http://arxiv.org/pdf/2501.00757v1,,False
A Distributional Evaluation of Generative Image Models,01/01/2025,"Edric Tam, Barbara E Engelhardt","Generative models are ubiquitous in modern artificial intelligence (AI)
applications. Recent advances have led to a variety of generative modeling
approaches that are capable of synthesizing highly realistic samples. Despite
these developments, evaluating the distributional match between the synthetic
samples and the target distribution in a statistically principled way remains a
core challenge. We focus on evaluating image generative models, where studies
often treat human evaluation as the gold standard. Commonly adopted metrics,
such as the Fr\'echet Inception Distance (FID), do not sufficiently capture the
differences between the learned and target distributions, because the
assumption of normality ignores differences in the tails. We propose the
Embedded Characteristic Score (ECS), a comprehensive metric for evaluating the
distributional match between the learned and target sample distributions, and
explore its connection with moments and tail behavior. We derive natural
properties of ECS and show its practical use via simulations and an empirical
study.",http://arxiv.org/pdf/2501.00744v1,,False
Enhancing Unsupervised Feature Selection via Double Sparsity Constrained Optimization,01/01/2025,"Xianchao Xiu, Anning Yang, Chenyi Huang, Xinrong Li, Wanquan Liu","Unsupervised feature selection (UFS) is widely applied in machine learning
and pattern recognition. However, most of the existing methods only consider a
single sparsity, which makes it difficult to select valuable and discriminative
feature subsets from the original high-dimensional feature set. In this paper,
we propose a new UFS method called DSCOFS via embedding double sparsity
constrained optimization into the classical principal component analysis (PCA)
framework. Double sparsity refers to using $\ell_{2,0}$-norm and $\ell_0$-norm
to simultaneously constrain variables, by adding the sparsity of different
types, to achieve the purpose of improving the accuracy of identifying
differential features. The core is that $\ell_{2,0}$-norm can remove irrelevant
and redundant features, while $\ell_0$-norm can filter out irregular noisy
features, thereby complementing $\ell_{2,0}$-norm to improve discrimination. An
effective proximal alternating minimization method is proposed to solve the
resulting nonconvex nonsmooth model. Theoretically, we rigorously prove that
the sequence generated by our method globally converges to a stationary point.
Numerical experiments on three synthetic datasets and eight real-world datasets
demonstrate the effectiveness, stability, and convergence of the proposed
method. In particular, the average clustering accuracy (ACC) and normalized
mutual information (NMI) are improved by at least 3.34% and 3.02%,
respectively, compared with the state-of-the-art methods. More importantly, two
common statistical tests and a new feature similarity metric verify the
advantages of double sparsity. All results suggest that our proposed DSCOFS
provides a new perspective for feature selection.",http://arxiv.org/pdf/2501.00726v1,,False
Rethinking Addressing in Language Models via Contexualized Equivariant Positional Encoding,01/01/2025,"Jiajun Zhu, Peihao Wang, Ruisi Cai, Jason D. Lee, Pan Li, Zhangyang Wang","Transformers rely on both content-based and position-based addressing
mechanisms to make predictions, but existing positional encoding techniques
often diminish the effectiveness of position-based addressing. Many current
methods enforce rigid patterns in attention maps, limiting the ability to model
long-range dependencies and adapt to diverse tasks. Additionally, most
positional encodings are learned as general biases, lacking the specialization
required for different instances within a dataset. To address this, we propose
con$\textbf{T}$extualized equivari$\textbf{A}$nt $\textbf{P}$osition
$\textbf{E}$mbedding ($\textbf{TAPE}$), a novel framework that enhances
positional embeddings by incorporating sequence content across layers. TAPE
introduces dynamic, context-aware positional encodings, overcoming the
constraints of traditional fixed patterns. By enforcing permutation and
orthogonal equivariance, TAPE ensures the stability of positional encodings
during updates, improving robustness and adaptability. Our method can be easily
integrated into pre-trained transformers, offering parameter-efficient
fine-tuning with minimal overhead. Extensive experiments shows that TAPE
achieves superior performance in language modeling, arithmetic reasoning, and
long-context retrieval tasks compared to existing positional embedding
techniques.",http://arxiv.org/pdf/2501.00712v1,,False
Labels Generated by Large Language Model Helps Measuring People's Empathy in Vitro,01/01/2025,"Md Rakibul Hasan, Yue Yao, Md Zakir Hossain, Aneesh Krishna, Imre Rudas, Shafin Rahman, Tom Gedeon","Large language models (LLMs) have revolutionised numerous fields, with
LLM-as-a-service (LLMSaaS) having a strong generalisation ability that offers
accessible solutions directly without the need for costly training. In contrast
to the widely studied prompt engineering for task solving directly (in vivo),
this paper explores its potential in in-vitro applications. These involve using
LLM to generate labels to help the supervised training of mainstream models by
(1) noisy label correction and (2) training data augmentation with
LLM-generated labels. In this paper, we evaluate this approach in the emerging
field of empathy computing -- automating the prediction of psychological
questionnaire outcomes from inputs like text sequences. Specifically,
crowdsourced datasets in this domain often suffer from noisy labels that
misrepresent underlying empathy. By leveraging LLM-generated labels to train
pre-trained language models (PLMs) like RoBERTa, we achieve statistically
significant accuracy improvements over baselines, achieving a state-of-the-art
Pearson correlation coefficient of 0.648 on NewsEmp benchmarks. In addition, we
bring insightful discussions, including current challenges in empathy
computing, data biases in training data and evaluation metric selection. Code
and LLM-generated data are available at
https://github.com/hasan-rakibul/LLMPathy (available once the paper is
accepted).",http://arxiv.org/pdf/2501.00691v1,,False
Taming Feed-forward Reconstruction Models as Latent Encoders for 3D Generative Models,31/12/2024,"Suttisak Wizadwongsa, Jinfan Zhou, Edward Li, Jeong Joon Park","Recent AI-based 3D content creation has largely evolved along two paths:
feed-forward image-to-3D reconstruction approaches and 3D generative models
trained with 2D or 3D supervision. In this work, we show that existing
feed-forward reconstruction methods can serve as effective latent encoders for
training 3D generative models, thereby bridging these two paradigms. By reusing
powerful pre-trained reconstruction models, we avoid computationally expensive
encoder network training and obtain rich 3D latent features for generative
modeling for free. However, the latent spaces of reconstruction models are not
well-suited for generative modeling due to their unstructured nature. To enable
flow-based model training on these latent features, we develop post-processing
pipelines, including protocols to standardize the features and spatial
weighting to concentrate on important regions. We further incorporate a 2D
image space perceptual rendering loss to handle the high-dimensional latent
spaces. Finally, we propose a multi-stream transformer-based rectified flow
architecture to achieve linear scaling and high-quality text-conditioned 3D
generation. Our framework leverages the advancements of feed-forward
reconstruction models to enhance the scalability of 3D generative modeling,
achieving both high computational efficiency and state-of-the-art performance
in text-to-3D generation.",http://arxiv.org/pdf/2501.00651v1,,False
Different thresholding methods on Nearest Shrunken Centroid algorithm,31/12/2024,"Mohammad Omar Sahtout, Haiyan Wang, Santosh Ghimire","This article considers the impact of different thresholding methods to the
Nearest Shrunken Centroid algorithm, which is popularly referred as the
Prediction Analysis of Microarrays (PAM) for high-dimensional classification.
PAM uses soft thresholding to achieve high computational efficiency and high
classification accuracy but in the price of retaining too many features. When
applied to microarray human cancers, PAM selected 2611 features on average from
10 multi-class datasets. Such a large number of features make it difficult to
perform follow up study. One reason behind this problem is the soft
thresholding, which is known to produce biased parameter estimate in regression
analysis. In this article, we extend the PAM algorithm with two other
thresholding methods, hard and order thresholding, and a deep search algorithm
to achieve better thresholding parameter estimate. The modified algorithms are
extensively tested and compared to the original one based on real data and
Monte Carlo studies. In general, the modification not only gave better cancer
status prediction accuracy, but also resulted in more parsimonious models with
significantly smaller number of features.",http://arxiv.org/pdf/2501.00632v1,10.1080/03610918.2022.2047201,False
Matrix factorization and prediction for high dimensional co-occurrence count data via shared parameter alternating zero inflated Gamma model,31/12/2024,"Taejoon Kim, Haiyan Wang","High-dimensional sparse matrix data frequently arise in various applications.
A notable example is the weighted word-word co-occurrence count data, which
summarizes the weighted frequency of word pairs appearing within the same
context window. This type of data typically contains highly skewed non-negative
values with an abundance of zeros. Another example is the co-occurrence of
item-item or user-item pairs in e-commerce, which also generates
high-dimensional data. The objective is to utilize this data to predict the
relevance between items or users. In this paper, we assume that items or users
can be represented by unknown dense vectors. The model treats the co-occurrence
counts as arising from zero-inflated Gamma random variables and employs cosine
similarity between the unknown vectors to summarize item-item relevance. The
unknown values are estimated using the shared parameter alternating
zero-inflated Gamma regression models (SA-ZIG). Both canonical link and log
link models are considered. Two parameter updating schemes are proposed, along
with an algorithm to estimate the unknown parameters. Convergence analysis is
presented analytically. Numerical studies demonstrate that the SA-ZIG using
Fisher scoring without learning rate adjustment may fail to fi nd the maximum
likelihood estimate. However, the SA-ZIG with learning rate adjustment performs
satisfactorily in our simulation studies.",http://arxiv.org/pdf/2501.00628v1,,False
Time-Varying Graph Learning for Data with Heavy-Tailed Distribution,31/12/2024,"Amirhossein Javaheri, Jiaxi Ying, Daniel P. Palomar, Farokh Marvasti","Graph models provide efficient tools to capture the underlying structure of
data defined over networks. Many real-world network topologies are subject to
change over time. Learning to model the dynamic interactions between entities
in such networks is known as time-varying graph learning. Current methodology
for learning such models often lacks robustness to outliers in the data and
fails to handle heavy-tailed distributions, a common feature in many real-world
datasets (e.g., financial data). This paper addresses the problem of learning
time-varying graph models capable of efficiently representing heavy-tailed
data. Unlike traditional approaches, we incorporate graph structures with
specific spectral properties to enhance data clustering in our model. Our
proposed method, which can also deal with noise and missing values in the data,
is based on a stochastic approach, where a non-negative vector auto-regressive
(VAR) model captures the variations in the graph and a Student-t distribution
models the signal originating from this underlying time-varying graph. We
propose an iterative method to learn time-varying graph topologies within a
semi-online framework where only a mini-batch of data is used to update the
graph. Simulations with both synthetic and real datasets demonstrate the
efficacy of our model in analyzing heavy-tailed data, particularly those found
in financial markets.",http://arxiv.org/pdf/2501.00606v1,,False
DreamDrive: Generative 4D Scene Modeling from Street View Images,31/12/2024,"Jiageng Mao, Boyi Li, Boris Ivanovic, Yuxiao Chen, Yan Wang, Yurong You, Chaowei Xiao, Danfei Xu, Marco Pavone, Yue Wang","Synthesizing photo-realistic visual observations from an ego vehicle's
driving trajectory is a critical step towards scalable training of self-driving
models. Reconstruction-based methods create 3D scenes from driving logs and
synthesize geometry-consistent driving videos through neural rendering, but
their dependence on costly object annotations limits their ability to
generalize to in-the-wild driving scenarios. On the other hand, generative
models can synthesize action-conditioned driving videos in a more generalizable
way but often struggle with maintaining 3D visual consistency. In this paper,
we present DreamDrive, a 4D spatial-temporal scene generation approach that
combines the merits of generation and reconstruction, to synthesize
generalizable 4D driving scenes and dynamic driving videos with 3D consistency.
Specifically, we leverage the generative power of video diffusion models to
synthesize a sequence of visual references and further elevate them to 4D with
a novel hybrid Gaussian representation. Given a driving trajectory, we then
render 3D-consistent driving videos via Gaussian splatting. The use of
generative priors allows our method to produce high-quality 4D scenes from
in-the-wild driving data, while neural rendering ensures 3D-consistent video
generation from the 4D scenes. Extensive experiments on nuScenes and street
view images demonstrate that DreamDrive can generate controllable and
generalizable 4D driving scenes, synthesize novel views of driving videos with
high fidelity and 3D consistency, decompose static and dynamic elements in a
self-supervised manner, and enhance perception and planning tasks for
autonomous driving.",http://arxiv.org/pdf/2501.00601v1,,False
Unrolled Creative Adversarial Network For Generating Novel Musical Pieces,31/12/2024,Pratik Nag,"Music generation has been established as a prominent topic in artificial
intelligence and machine learning over recent years. In most recent works on
RNN-based neural network methods have been applied for sequence generation. In
contrast, generative adversarial networks (GANs) and their counterparts have
been explored by very few researchersfor music generation.
  In this paper, a classical system was employed alongside a new system to
generate creative music. Both systems were designed based on adversarial
networks to generate music by learning from examples. The classical system was
trained to learn a set of music pieces without differentiating between classes,
whereas the new system was trained to learn the different composers and their
styles to generate a creative music piece by deviating from the learned
composers' styles.
  The base structure utilized was generative adversarial networks (GANs), which
are capable of generating novel outputs given a set of inputs to learn from and
mimic their distribution. It has been shown in previous work that GANs are
limited in their original design with respect to creative outputs. Building on
the Creative Adversarial Networks (CAN) , this work applied them in the music
domain rather than the visual art domain. Additionally, unrolled CAN was
introduced to prevent mode collapse. Experiments were conducted on both GAN and
CAN for generating music, and their capabilities were measured in terms of
deviation from the input set.",http://arxiv.org/pdf/2501.00452v1,,False
RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented Instructions,31/12/2024,"Wanlong Liu, Junying Chen, Ke Ji, Li Zhou, Wenyu Chen, Benyou Wang","Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for
enhancing large language models (LLMs) by incorporating external knowledge.
However, current RAG methods face two limitations: (1) they only cover limited
RAG scenarios. (2) They suffer from limited task diversity due to the lack of a
general RAG dataset. To address these limitations, we propose RAG-Instruct, a
general method for synthesizing diverse and high-quality RAG instruction data
based on any source corpus. Our approach leverages (1) five RAG paradigms,
which encompass diverse query-document relationships, and (2) instruction
simulation, which enhances instruction diversity and quality by utilizing the
strengths of existing instruction datasets. Using this method, we construct a
40K instruction dataset from Wikipedia, comprehensively covering diverse RAG
scenarios and tasks. Experiments demonstrate that RAG-Instruct effectively
enhances LLMs' RAG capabilities, achieving strong zero-shot performance and
significantly outperforming various RAG baselines across a diverse set of
tasks. RAG-Instruct is publicly available at
https://github.com/FreedomIntelligence/RAG-Instruct.",http://arxiv.org/pdf/2501.00353v1,,False
Predicate Invention from Pixels via Pretrained Vision-Language Models,31/12/2024,"Ashay Athalye, Nishanth Kumar, Tom Silver, Yichao Liang, Tomás Lozano-Pérez, Leslie Pack Kaelbling","Our aim is to learn to solve long-horizon decision-making problems in
highly-variable, combinatorially-complex robotics domains given raw sensor
input in the form of images. Previous work has shown that one way to achieve
this aim is to learn a structured abstract transition model in the form of
symbolic predicates and operators, and then plan within this model to solve
novel tasks at test time. However, these learned models do not ground directly
into pixels from just a handful of demonstrations. In this work, we propose to
invent predicates that operate directly over input images by leveraging the
capabilities of pretrained vision-language models (VLMs). Our key idea is that,
given a set of demonstrations, a VLM can be used to propose a set of predicates
that are potentially relevant for decision-making and then to determine the
truth values of these predicates in both the given demonstrations and new image
inputs. We build upon an existing framework for predicate invention, which
generates feature-based predicates operating on object-centric states, to also
generate visual predicates that operate on images. Experimentally, we show that
our approach -- pix2pred -- is able to invent semantically meaningful
predicates that enable generalization to novel, complex, and long-horizon tasks
across two simulated robotic environments.",http://arxiv.org/pdf/2501.00296v1,,False
