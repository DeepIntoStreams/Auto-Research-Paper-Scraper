Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
AdaWorld: Learning Adaptable World Models with Latent Actions,24/03/2025,"Shenyuan Gao, Siyuan Zhou, Yilun Du, Jun Zhang, Chuang Gan","World models aim to learn action-controlled prediction models and have proven
essential for the development of intelligent agents. However, most existing
world models rely heavily on substantial action-labeled data and costly
training, making it challenging to adapt to novel environments with
heterogeneous actions through limited interactions. This limitation can hinder
their applicability across broader domains. To overcome this challenge, we
propose AdaWorld, an innovative world model learning approach that enables
efficient adaptation. The key idea is to incorporate action information during
the pretraining of world models. This is achieved by extracting latent actions
from videos in a self-supervised manner, capturing the most critical
transitions between frames. We then develop an autoregressive world model that
conditions on these latent actions. This learning paradigm enables highly
adaptable world models, facilitating efficient transfer and learning of new
actions even with limited interactions and finetuning. Our comprehensive
experiments across multiple environments demonstrate that AdaWorld achieves
superior performance in both simulation quality and visual planning.",http://arxiv.org/pdf/2503.18938v1,,False
A semantic communication-based workload-adjustable transceiver for wireless AI-generated content (AIGC) delivery,24/03/2025,"Runze Cheng, Yao Sun, Lan Zhang, Lei Feng, Lei Zhang, Muhammad Ali Imran","With the significant advances in generative AI (GAI) and the proliferation of
mobile devices, providing high-quality AI-generated content (AIGC) services via
wireless networks is becoming the future direction. However, the primary
challenges of AIGC service delivery in wireless networks lie in unstable
channels, limited bandwidth resources, and unevenly distributed computational
resources. In this paper, we employ semantic communication (SemCom) in
diffusion-based GAI models to propose a Resource-aware wOrkload-adjUstable
TransceivEr (ROUTE) for AIGC delivery in dynamic wireless networks.
Specifically, to relieve the communication resource bottleneck, SemCom is
utilized to prioritize semantic information of the generated content. Then, to
improve computational resource utilization in both edge and local and reduce
AIGC semantic distortion in transmission, modified diffusion-based models are
applied to adjust the computing workload and semantic density in cooperative
content generation. Simulations verify the superiority of our proposed ROUTE in
terms of latency and content quality compared to conventional AIGC approaches.",http://arxiv.org/pdf/2503.18874v1,,False
Streaming Federated Learning with Markovian Data,24/03/2025,"Tan-Khiem Huynh, Malcolm Egan, Giovanni Neglia, Jean-Marie Gorce","Federated learning (FL) is now recognized as a key framework for
communication-efficient collaborative learning. Most theoretical and empirical
studies, however, rely on the assumption that clients have access to
pre-collected data sets, with limited investigation into scenarios where
clients continuously collect data. In many real-world applications,
particularly when data is generated by physical or biological processes, client
data streams are often modeled by non-stationary Markov processes. Unlike
standard i.i.d. sampling, the performance of FL with Markovian data streams
remains poorly understood due to the statistical dependencies between client
samples over time. In this paper, we investigate whether FL can still support
collaborative learning with Markovian data streams. Specifically, we analyze
the performance of Minibatch SGD, Local SGD, and a variant of Local SGD with
momentum. We answer affirmatively under standard assumptions and smooth
non-convex client objectives: the sample complexity is proportional to the
inverse of the number of clients with a communication complexity comparable to
the i.i.d. scenario. However, the sample complexity for Markovian data streams
remains higher than for i.i.d. sampling.",http://arxiv.org/pdf/2503.18807v1,,False
BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache,24/03/2025,"Dayou Du, Shijie Cao, Jianyi Cheng, Ting Cao, Mao Yang","The growing adoption of long-context Large Language Models (LLMs) has
introduced significant memory and computational challenges in autoregressive
decoding due to the expanding Key-Value (KV) cache. KV cache quantization has
emerged as a promising solution, with prior work showing that 4-bit or even
2-bit quantization can maintain model accuracy while reducing memory costs.
However, despite these benefits, preliminary implementations for the low-bit KV
cache struggle to deliver the expected speedup due to quantization and
dequantization overheads and the lack of Tensor Cores utilization. In this
work, we propose BitDecoding, a GPU-optimized framework that unlocks Tensor
Cores for efficient decoding with low-bit KV cache. Efficiently leveraging
Tensor Cores for low-bit KV cache is challenging due to the dynamic nature of
KV cache generation at each decoding step. BitDecoding addresses these
challenges with a Tensor Cores-Centric BitFusion Scheme that ensures data
layout compatibility to enable high utilization of Tensor Cores. Additionally,
BitDecoding incorporates a warp-efficient parallel decoding kernel and a
fine-grained asynchronous pipeline, minimizing dequantization overhead and
improving computational efficiency. Experiments show that BitDecoding achieves
up to 7.5x speedup on RTX 4090, 4.8x on A100, and 8.9x on H100, compared to
FP16 FlashDecoding-v2. It also outperforms the state-of-the-art low-bit KV
cache implementation (QServe) by up to 4.3x. On LLaMA-3.1-8B with a 128K
sequence length, BitDecoding reduces single-batch decoding latency by 3x,
demonstrating its effectiveness in long-context generation scenarios. The code
is available at https://github.com/DD-DuDa/BitDecoding.",http://arxiv.org/pdf/2503.18773v1,,False
Simulation-Driven Balancing of Competitive Game Levels with Reinforcement Learning,24/03/2025,"Florian Rupp, Manuel Eberhardinger, Kai Eckert","The balancing process for game levels in competitive two-player contexts
involves a lot of manual work and testing, particularly for non-symmetrical
game levels. In this work, we frame game balancing as a procedural content
generation task and propose an architecture for automatically balancing of
tile-based levels within the PCGRL framework (procedural content generation via
reinforcement learning). Our architecture is divided into three parts: (1) a
level generator, (2) a balancing agent, and (3) a reward modeling simulation.
Through repeated simulations, the balancing agent receives rewards for
adjusting the level towards a given balancing objective, such as equal win
rates for all players. To this end, we propose new swap-based representations
to improve the robustness of playability, thereby enabling agents to balance
game levels more effectively and quickly compared to traditional PCGRL. By
analyzing the agent's swapping behavior, we can infer which tile types have the
most impact on the balance. We validate our approach in the Neural MMO (NMMO)
environment in a competitive two-player scenario. In this extended conference
paper, we present improved results, explore the applicability of the method to
various forms of balancing beyond equal balancing, compare the performance to
another search-based approach, and discuss the application of existing fairness
metrics to game balancing.",http://arxiv.org/pdf/2503.18748v1,10.1109/TG.2024.3399536,False
Energy-Efficient Dynamic Training and Inference for GNN-Based Network Modeling,24/03/2025,"Chetna Singhal, Yassine Hadjadj-Aoul","Efficient network modeling is essential for resource optimization and network
planning in next-generation large-scale complex networks. Traditional
approaches, such as queuing theory-based modeling and packet-based simulators,
can be inefficient due to the assumption made and the computational expense,
respectively. To address these challenges, we propose an innovative
energy-efficient dynamic orchestration of Graph Neural Networks (GNN) based
model training and inference framework for context-aware network modeling and
predictions. We have developed a low-complexity solution framework, QAG, that
is a Quantum approximation optimization (QAO) algorithm for Adaptive
orchestration of GNN-based network modeling. We leverage the tripartite graph
model to represent a multi-application system with many compute nodes.
Thereafter, we apply the constrained graph-cutting using QAO to find the
feasible energy-efficient configurations of the GNN-based model and deploying
them on the available compute nodes to meet the network modeling application
requirements. The proposed QAG scheme closely matches the optimum and offers
atleast a 50% energy saving while meeting the application requirements with 60%
lower churn-rate.",http://arxiv.org/pdf/2503.18706v1,,False
Efficient Continual Adaptation of Pretrained Robotic Policy with Online Meta-Learned Adapters,24/03/2025,"Ruiqi Zhu, Endong Sun, Guanhe Huang, Oya Celiktutan","Continual adaptation is essential for general autonomous agents. For example,
a household robot pretrained with a repertoire of skills must still adapt to
unseen tasks specific to each household. Motivated by this, building upon
parameter-efficient fine-tuning in language models, prior works have explored
lightweight adapters to adapt pretrained policies, which can preserve learned
features from the pretraining phase and demonstrate good adaptation
performances. However, these approaches treat task learning separately,
limiting knowledge transfer between tasks. In this paper, we propose Online
Meta-Learned adapters (OMLA). Instead of applying adapters directly, OMLA can
facilitate knowledge transfer from previously learned tasks to current learning
tasks through a novel meta-learning objective. Extensive experiments in both
simulated and real-world environments demonstrate that OMLA can lead to better
adaptation performances compared to the baseline methods. The project link:
https://ricky-zhu.github.io/OMLA/.",http://arxiv.org/pdf/2503.18684v1,,False
Adaptive Machine Learning for Resource-Constrained Environments,24/03/2025,"Sebastián A. Cajas Ordóñez, Jaydeep Samanta, Andrés L. Suárez-Cetrulo, Ricardo Simón Carbajo","The Internet of Things is an example domain where data is perpetually
generated in ever-increasing quantities, reflecting the proliferation of
connected devices and the formation of continuous data streams over time.
Consequently, the demand for ad-hoc, cost-effective machine learning solutions
must adapt to this evolving data influx. This study tackles the task of
offloading in small gateways, exacerbated by their dynamic availability over
time. An approach leveraging CPU utilization metrics using online and continual
machine learning techniques is proposed to predict gateway availability. These
methods are compared to popular machine learning algorithms and a recent
time-series foundation model, Lag-Llama, for fine-tuned and zero-shot setups.
Their performance is benchmarked on a dataset of CPU utilization measurements
over time from an IoT gateway and focuses on model metrics such as prediction
errors, training and inference times, and memory consumption. Our primary
objective is to study new efficient ways to predict CPU performance in IoT
environments. Across various scenarios, our findings highlight that ensemble
and online methods offer promising results for this task in terms of accuracy
while maintaining a low resource footprint.",http://arxiv.org/pdf/2503.18634v1,10.1007/978-3-031-82346-6_1,False
EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation,24/03/2025,"Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu","Conditional human animation transforms a static reference image into a
dynamic sequence by applying motion cues such as poses. These motion cues are
typically derived from video data but are susceptible to limitations including
low temporal resolution, motion blur, overexposure, and inaccuracies under
low-light conditions. In contrast, event cameras provide data streams with
exceptionally high temporal resolution, a wide dynamic range, and inherent
resistance to motion blur and exposure issues. In this work, we propose
EvAnimate, a framework that leverages event streams as motion cues to animate
static human images. Our approach employs a specialized event representation
that transforms asynchronous event streams into 3-channel slices with
controllable slicing rates and appropriate slice density, ensuring
compatibility with diffusion models. Subsequently, a dual-branch architecture
generates high-quality videos by harnessing the inherent motion dynamics of the
event streams, thereby enhancing both video quality and temporal consistency.
Specialized data augmentation strategies further enhance cross-person
generalization. Finally, we establish a new benchmarking, including simulated
event data for training and validation, and a real-world event dataset
capturing human actions under normal and extreme scenarios. The experiment
results demonstrate that EvAnimate achieves high temporal fidelity and robust
performance in scenarios where traditional video-derived cues fall short.",http://arxiv.org/pdf/2503.18552v1,,False
Discriminative protein sequence modelling with Latent Space Diffusion,24/03/2025,"Eoin Quinn, Ghassene Jebali, Maxime Seince, Oliver Bent","We explore a framework for protein sequence representation learning that
decomposes the task between manifold learning and distributional modelling.
Specifically we present a Latent Space Diffusion architecture which combines a
protein sequence autoencoder with a denoising diffusion model operating on its
latent space. We obtain a one-parameter family of learned representations from
the diffusion model, along with the autoencoder's latent representation. We
propose and evaluate two autoencoder architectures: a homogeneous model forcing
amino acids of the same type to be identically distributed in the latent space,
and an inhomogeneous model employing a noise-based variant of masking. As a
baseline we take a latent space learned by masked language modelling, and
evaluate discriminative capability on a range of protein property prediction
tasks. Our finding is twofold: the diffusion models trained on both our
proposed variants display higher discriminative power than the one trained on
the masked language model baseline, none of the diffusion representations
achieve the performance of the masked language model embeddings themselves.",http://arxiv.org/pdf/2503.18551v1,,False
RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation,24/03/2025,"Xiaolong Yin, Xingyu Lu, Jiahang Shen, Jingzhe Ni, Hailong Li, Ruofeng Tong, Min Tang, Peng Du","A CAD command sequence is a typical parametric design paradigm in 3D CAD
systems where a model is constructed by overlaying 2D sketches with operations
such as extrusion, revolution, and Boolean operations. Although there is
growing academic interest in the automatic generation of command sequences,
existing methods and datasets only support operations such as 2D sketching,
extrusion,and Boolean operations. This limitation makes it challenging to
represent more complex geometries. In this paper, we present a reinforcement
learning (RL) training environment (gym) built on a CAD geometric engine. Given
an input boundary representation (B-Rep) geometry, the policy network in the RL
algorithm generates an action. This action, along with previously generated
actions, is processed within the gym to produce the corresponding CAD geometry,
which is then fed back into the policy network. The rewards, determined by the
difference between the generated and target geometries within the gym, are used
to update the RL network. Our method supports operations beyond sketches,
Boolean, and extrusion, including revolution operations. With this training
gym, we achieve state-of-the-art (SOTA) quality in generating command sequences
from B-Rep geometries. In addition, our method can significantly improve the
efficiency of command sequence generation by a factor of 39X compared with the
previous training gym.",http://arxiv.org/pdf/2503.18549v1,,False
ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation,24/03/2025,"Jiahui Xiang, Tong Ye, Peiyu Liu, Yinan Zhang, Wenhai Wang","Modelica is a widely adopted language for simulating complex physical
systems, yet effective model creation and optimization require substantial
domain expertise. Although large language models (LLMs) have demonstrated
promising capabilities in code generation, their application to modeling
remains largely unexplored. To address this gap, we have developed benchmark
datasets specifically designed to evaluate the performance of LLMs in
generating Modelica component models and test cases. Our evaluation reveals
substantial limitations in current LLMs, as the generated code often fails to
simulate successfully. To overcome these challenges, we propose a specialized
workflow that integrates supervised fine-tuning, graph retrieval-augmented
generation, and feedback optimization to improve the accuracy and reliability
of Modelica code generation. The evaluation results demonstrate significant
performance gains: the maximum improvement in pass@1 reached 0.3349 for the
component generation task and 0.2457 for the test case generation task. This
research underscores the potential of LLMs to advance intelligent modeling
tools and offers valuable insights for future developments in system modeling
and engineering applications.",http://arxiv.org/pdf/2503.18460v1,,False
Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance,24/03/2025,"Sicong Feng, Jielong Yang, Li Peng","Recent advances in diffusion models bring new vitality to visual content
creation. However, current text-to-video generation models still face
significant challenges such as high training costs, substantial data
requirements, and difficulties in maintaining consistency between given text
and motion of the foreground object. To address these challenges, we propose
mask-guided video generation, which can control video generation through mask
motion sequences, while requiring limited training data. Our model enhances
existing architectures by incorporating foreground masks for precise
text-position matching and motion trajectory control. Through mask motion
sequences, we guide the video generation process to maintain consistent
foreground objects throughout the sequence. Additionally, through a first-frame
sharing strategy and autoregressive extension approach, we achieve more stable
and longer video generation. Extensive qualitative and quantitative experiments
demonstrate that this approach excels in various video generation tasks, such
as video editing and generating artistic videos, outperforming previous methods
in terms of consistency and quality. Our generated results can be viewed in the
supplementary materials.",http://arxiv.org/pdf/2503.18386v1,,False
Optimizing Influence Campaigns: Nudging under Bounded Confidence,24/03/2025,"Yen-Shao Chen, Tauhid Zaman","Influence campaigns in online social networks are often run by organizations,
political parties, and nation states to influence large audiences. These
campaigns are employed through the use of agents in the network that share
persuasive content. Yet, their impact might be minimal if the audiences remain
unswayed, often due to the bounded confidence phenomenon, where only a narrow
spectrum of viewpoints can influence them. Here we show that to persuade under
bounded confidence, an agent must nudge its targets to gradually shift their
opinions. Using a control theory approach, we show how to construct an agent's
nudging policy under the bounded confidence opinion dynamics model and also how
to select targets for multiple agents in an influence campaign on a social
network. Simulations on real Twitter networks show that a multi-agent nudging
policy can shift the mean opinion, decrease opinion polarization, or even
increase it. We find that our nudging based policies outperform other common
techniques that do not consider the bounded confidence effect. Finally, we show
how to craft prompts for large language models, such as ChatGPT, to generate
text-based content for real nudging policies. This illustrates the practical
feasibility of our approach, allowing one to go from mathematical nudging
policies to real social media content.",http://arxiv.org/pdf/2503.18331v1,,False
A New Stochastic Approximation Method for Gradient-based Simulated Parameter Estimation,24/03/2025,"Zehao Li, Yijie Peng","This paper tackles the challenge of parameter calibration in stochastic
models, particularly in scenarios where the likelihood function is unavailable
in an analytical form. We introduce a gradient-based simulated parameter
estimation framework, which employs a multi-time scale stochastic approximation
algorithm. This approach effectively addresses the ratio bias that arises in
both maximum likelihood estimation and posterior density estimation problems.
The proposed algorithm enhances estimation accuracy and significantly reduces
computational costs, as demonstrated through extensive numerical experiments.
Our work extends the GSPE framework to handle complex models such as hidden
Markov models and variational inference-based problems, offering a robust
solution for parameter estimation in challenging stochastic environments.",http://arxiv.org/pdf/2503.18319v1,,False
Efficient Transformed Gaussian Process State-Space Models for Non-Stationary High-Dimensional Dynamical Systems,24/03/2025,"Zhidi Lin, Ying Li, Feng Yin, Juan Maroñas, Alexandre H. Thiéry","Gaussian process state-space models (GPSSMs) have emerged as a powerful
framework for modeling dynamical systems, offering interpretable uncertainty
quantification and inherent regularization. However, existing GPSSMs face
significant challenges in handling high-dimensional, non-stationary systems due
to computational inefficiencies, limited scalability, and restrictive
stationarity assumptions. In this paper, we propose an efficient transformed
Gaussian process state-space model (ETGPSSM) to address these limitations. Our
approach leverages a single shared Gaussian process (GP) combined with
normalizing flows and Bayesian neural networks, enabling efficient modeling of
complex, high-dimensional state transitions while preserving scalability. To
address the lack of closed-form expressions for the implicit process in the
transformed GP, we follow its generative process and introduce an efficient
variational inference algorithm, aided by the ensemble Kalman filter (EnKF), to
enable computationally tractable learning and inference. Extensive empirical
evaluations on synthetic and real-world datasets demonstrate the superior
performance of our ETGPSSM in system dynamics learning, high-dimensional state
estimation, and time-series forecasting, outperforming existing GPSSMs and
neural network-based methods in both accuracy and computational efficiency.",http://arxiv.org/pdf/2503.18309v1,,False
PNN: A Novel Progressive Neural Network for Fault Classification in Rotating Machinery under Small Dataset Constraint,24/03/2025,"Praveen Chopra, Himanshu Kumar, Sandeep Yadav","Fault detection in rotating machinery is a complex task, particularly in
small and heterogeneous dataset scenarios. Variability in sensor placement,
machinery configurations, and structural differences further increase the
complexity of the problem. Conventional deep learning approaches often demand
large, homogeneous datasets, limiting their applicability in data-scarce
industrial environments. While transfer learning and few-shot learning have
shown potential, however, they are often constrained by the need for extensive
fault datasets. This research introduces a unified framework leveraging a novel
progressive neural network (PNN) architecture designed to address these
challenges. The PNN sequentially estimates the fixed-size refined features of
the higher order with the help of all previously estimated features and appends
them to the feature set. This fixed-size feature output at each layer controls
the complexity of the PNN and makes it suitable for effective learning from
small datasets. The framework's effectiveness is validated on eight datasets,
including six open-source datasets, one in-house fault simulator, and one
real-world industrial dataset. The PNN achieves state-of-the-art performance in
fault detection across varying dataset sizes and machinery types, highlighting
superior generalization and classification capabilities.",http://arxiv.org/pdf/2503.18263v1,,False
