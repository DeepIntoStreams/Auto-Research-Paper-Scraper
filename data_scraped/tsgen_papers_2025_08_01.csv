Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model,31/07/2025,"Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing","AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.",http://arxiv.org/pdf/2507.23773v1,,False
Distributed AI Agents for Cognitive Underwater Robot Autonomy,31/07/2025,"Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot","Achieving robust cognitive autonomy in robots navigating complex,
unpredictable environments remains a fundamental challenge in robotics. This
paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a
groundbreaking architecture leveraging distributed Large Language Model AI
agents integrated within the Robot Operating System 2 (ROS 2) framework to
enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA
decentralises cognition into specialised AI agents responsible for multimodal
perception, adaptive reasoning, dynamic mission planning, and real-time
decision-making. Central innovations include flexible agents dynamically
adapting their roles, retrieval-augmented generation utilising vector databases
for efficient knowledge management, reinforcement learning-driven behavioural
optimisation, and autonomous on-the-fly ROS 2 node generation for runtime
functional extensibility. Extensive empirical validation demonstrates UROSA's
promising adaptability and reliability through realistic underwater missions in
simulation and real-world deployments, showing significant advantages over
traditional rule-based architectures in handling unforeseen scenarios,
environmental uncertainties, and novel mission objectives. This work not only
advances underwater autonomy but also establishes a scalable, safe, and
versatile cognitive robotics framework capable of generalising to a diverse
array of real-world applications.",http://arxiv.org/pdf/2507.23735v1,,False
Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents,31/07/2025,"Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang","While Reinforcement Learning (RL) has achieved remarkable success in language
modeling, its triumph hasn't yet fully translated to visuomotor agents. A
primary challenge in RL models is their tendency to overfit specific tasks or
environments, thereby hindering the acquisition of generalizable behaviors
across diverse settings. This paper provides a preliminary answer to this
challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can
achieve zero-shot generalization to unseen worlds. Specifically, we explore
RL's potential to enhance generalizable spatial reasoning and interaction
capabilities in 3D worlds. To address challenges in multi-task RL
representation, we analyze and establish cross-view goal specification as a
unified multi-task goal space for visuomotor policies. Furthermore, to overcome
the significant bottleneck of manual task design, we propose automated task
synthesis within the highly customizable Minecraft environment for large-scale
multi-task RL training, and we construct an efficient distributed RL framework
to support this. Experimental results show RL significantly boosts interaction
success rates by $4\times$ and enables zero-shot generalization of spatial
reasoning across diverse environments, including real-world settings. Our
findings underscore the immense potential of RL training in 3D simulated
environments, especially those amenable to large-scale task generation, for
significantly advancing visuomotor agents' spatial reasoning.",http://arxiv.org/pdf/2507.23698v1,,False
A survey of multi-agent geosimulation methodologies: from ABM to LLM,31/07/2025,"Virginia Padilla, Jacinto Dávila","We provide a comprehensive examination of agent-based approaches that codify
the principles and linkages underlying multi-agent systems, simulations, and
information systems. Based on two decades of study, this paper confirms a
framework intended as a formal specification for geosimulation platforms. Our
findings show that large language models (LLMs) can be effectively incorporated
as agent components if they follow a structured architecture specific to
fundamental agent activities such as perception, memory, planning, and action.
This integration is precisely consistent with the architecture that we
formalize, providing a solid platform for next-generation geosimulation
systems.",http://arxiv.org/pdf/2507.23694v1,,False
villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models,31/07/2025,"Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian","Visual-Language-Action (VLA) models have emerged as a popular paradigm for
learning robot manipulation policies that can follow language instructions and
generalize to novel scenarios. Recent work has begun to explore the
incorporation of latent actions, an abstract representation of visual change
between two frames, into VLA pre-training. In this paper, we introduce villa-X,
a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent
action modeling for learning generalizable robot manipulation policies. Our
approach improves both how latent actions are learned and how they are
incorporated into VLA pre-training. Together, these contributions enable
villa-X to achieve superior performance across simulated environments including
SIMPLER and LIBERO, as well as on two real-world robot setups including gripper
and dexterous hand manipulation. We believe the ViLLA paradigm holds
significant promise, and that our villa-X provides a strong foundation for
future research.",http://arxiv.org/pdf/2507.23682v1,,False
L-GTA: Latent Generative Modeling for Time Series Augmentation,31/07/2025,"Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo","Data augmentation is gaining importance across various aspects of time series
analysis, from forecasting to classification and anomaly detection tasks. We
introduce the Latent Generative Transformer Augmentation (L-GTA) model, a
generative approach using a transformer-based variational recurrent
autoencoder. This model uses controlled transformations within the latent space
of the model to generate new time series that preserve the intrinsic properties
of the original dataset. L-GTA enables the application of diverse
transformations, ranging from simple jittering to magnitude warping, and
combining these basic transformations to generate more complex synthetic time
series datasets. Our evaluation of several real-world datasets demonstrates the
ability of L-GTA to produce more reliable, consistent, and controllable
augmented data. This translates into significant improvements in predictive
accuracy and similarity measures compared to direct transformation methods.",http://arxiv.org/pdf/2507.23615v1,,False
Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study,31/07/2025,"Kai Goebel, Patrik Zips","Recent advancements in Large Language Models have sparked interest in their
potential for robotic task planning. While these models demonstrate strong
generative capabilities, their effectiveness in producing structured and
executable plans remains uncertain. This paper presents a systematic evaluation
of a broad spectrum of current state of the art language models, each directly
prompted using Planning Domain Definition Language domain and problem files,
and compares their planning performance with the Fast Downward planner across a
variety of benchmarks. In addition to measuring success rates, we assess how
faithfully the generated plans translate into sequences of actions that can
actually be executed, identifying both strengths and limitations of using these
models in this setting. Our findings show that while the models perform well on
simpler planning tasks, they continue to struggle with more complex scenarios
that require precise resource management, consistent state tracking, and strict
constraint compliance. These results underscore fundamental challenges in
applying language models to robotic planning in real world environments. By
outlining the gaps that emerge during execution, we aim to guide future
research toward combined approaches that integrate language models with
classical planners in order to enhance the reliability and scalability of
planning in autonomous robotics.",http://arxiv.org/pdf/2507.23589v1,,False
Barycentric subspace analysis of network-valued data,31/07/2025,"Elodie Maignant, Xavier Pennec, Alain Trouvé, Anna Calissano","Certain data are naturally modeled by networks or weighted graphs, be they
arterial networks or mobility networks. When there is no canonical labeling of
the nodes across the dataset, we talk about unlabeled networks. In this paper,
we focus on the question of dimensionality reduction for this type of data.
More specifically, we address the issue of interpreting the feature subspace
constructed by dimensionality reduction methods. Most existing methods for
network-valued data are derived from principal component analysis (PCA) and
therefore rely on subspaces generated by a set of vectors, which we identify as
a major limitation in terms of interpretability. Instead, we propose to
implement the method called barycentric subspace analysis (BSA), which relies
on subspaces generated by a set of points. In order to provide a
computationally feasible framework for BSA, we introduce a novel embedding for
unlabeled networks where we replace their usual representation by equivalence
classes of isomorphic networks with that by equivalence classes of cospectral
networks. We then illustrate BSA on simulated and real-world datasets, and
compare it to tangent PCA.",http://arxiv.org/pdf/2507.23559v1,,False
Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models,31/07/2025,"Ailiang Lin, Zhuoyun Li, Kotaro Funakoshi","Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.",http://arxiv.org/pdf/2507.23386v1,,False
Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications,31/07/2025,"Mahmoud Ghorab, Matthias Lorenzen","There is a growing demand for autonomous mobile robots capable of navigating
unstructured agricultural environments. Tasks such as weed control in meadows
require efficient path planning through an unordered set of coordinates while
minimizing travel distance and adhering to curvature constraints to prevent
soil damage and protect vegetation. This paper presents an integrated
navigation framework combining a global path planner based on the Dubins
Traveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control
(NMPC) strategy for local path planning and control. The DTSP generates a
minimum-length, curvature-constrained path that efficiently visits all targets,
while the NMPC leverages this path to compute control signals to accurately
reach each waypoint. The system's performance was validated through comparative
simulation analysis on real-world field datasets, demonstrating that the
coupled DTSP-based planner produced smoother and shorter paths, with a
reduction of about 16% in the provided scenario, compared to decoupled methods.
Based thereon, the NMPC controller effectively steered the robot to the desired
waypoints, while locally optimizing the trajectory and ensuring adherence to
constraints. These findings demonstrate the potential of the proposed framework
for efficient autonomous navigation in agricultural environments.",http://arxiv.org/pdf/2507.23350v1,10.34749/3061-0710.2025.17,False
Simulation-based inference for Precision Neutrino Physics through Neural Monte Carlo tuning,31/07/2025,"A. Gavrikov, A. Serafini, D. Dolzhikov, A. Garfagnini, M. Gonchar, M. Grassi, R. Brugnera, V. Cerrone, L. V. D'Auria, R. M. Guizzetti, L. Lastrucci, G. Andronico, V. Antonelli, A. Barresi, D. Basilico, M. Beretta, A. Bergnoli, M. Borghesi, A. Brigatti, R. Bruno, A. Budano, B. Caccianiga, A. Cammi, R. Caruso, D. Chiesa, C. Clementi, C. Coletta, S. Dusini, A. Fabbri, G. Felici, G. Ferrante, M. G. Giammarchi, N. Giudice, N. Guardone, F. Houria, C. Landini, I. Lippi, L. Loi, P. Lombardi, F. Mantovani, S. M. Mari, A. Martini, L. Miramonti, M. Montuschi, M. Nastasi, D. Orestano, F. Ortica, A. Paoloni, L. Pelicci, E. Percalli, F. Petrucci, E. Previtali, G. Ranucci, A. C. Re, B. Ricci, A. Romani, C. Sirignano, M. Sisti, L. Stanco, E. Stanescu Farilla, V. Strati, M. D. C Torri, C. Tuvè, C. Venettacci, G. Verde, L. Votano","Precise modeling of detector energy response is crucial for next-generation
neutrino experiments which present computational challenges due to lack of
analytical likelihoods. We propose a solution using neural likelihood
estimation within the simulation-based inference framework. We develop two
complementary neural density estimators that model likelihoods of calibration
data: conditional normalizing flows and a transformer-based regressor. We adopt
JUNO - a large neutrino experiment - as a case study. The energy response of
JUNO depends on several parameters, all of which should be tuned, given their
non-linear behavior and strong correlations in the calibration data. To this
end, we integrate the modeled likelihoods with Bayesian nested sampling for
parameter inference, achieving uncertainties limited only by statistics with
near-zero systematic biases. The normalizing flows model enables unbinned
likelihood analysis, while the transformer provides an efficient binned
alternative. By providing both options, our framework offers flexibility to
choose the most appropriate method for specific needs. Finally, our approach
establishes a template for similar applications across experimental neutrino
and broader particle physics.",http://arxiv.org/pdf/2507.23297v1,,False
SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy,31/07/2025,"RJ Skerry-Ryan, Julian Salazar, Soroosh Mariooryad, David Kao, Daisy Stanton, Eric Battenberg, Matt Shannon, Ron J. Weiss, Robin Scheibler, Jonas Rothfuss, Tom Bagby","We introduce a neural network layer API and library for sequence modeling,
designed for easy creation of sequence models that can be executed both
layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,
autoregressive sampling). To achieve this, layers define an explicit
representation of their state over time (e.g., a Transformer KV cache, a
convolution buffer, an RNN hidden state), and a step method that evolves that
state, tested to give identical results to a stateless layer-wise invocation.
This and other aspects of the SequenceLayers contract enables complex models to
be immediately streamable, mitigates a wide range of common bugs arising in
both streaming and parallel sequence processing, and can be implemented in any
deep learning library. A composable and declarative API, along with a
comprehensive suite of layers and combinators, streamlines the construction of
production-scale models from simple streamable components while preserving
strong correctness guarantees. Our current implementations of SequenceLayers
(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.",http://arxiv.org/pdf/2507.23292v1,,False
A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations,31/07/2025,"Charles O'Neill, Slava Chalnev, Chi Chi Zhao, Max Kirkby, Mudith Jayasekara","Contextual hallucinations -- statements unsupported by given context --
remain a significant challenge in AI. We demonstrate a practical
interpretability insight: a generator-agnostic observer model detects
hallucinations via a single forward pass and a linear probe on its residual
stream. This probe isolates a single, transferable linear direction separating
hallucinated from faithful text, outperforming baselines by 5-27 points and
showing robust mid-layer performance across Gemma-2 models (2B to 27B).
Gradient-times-activation localises this signal to sparse, late-layer MLP
activity. Critically, manipulating this direction causally steers generator
hallucination rates, proving its actionability. Our results offer novel
evidence of internal, low-dimensional hallucination tracking linked to specific
MLP sub-circuits, exploitable for detection and mitigation. We release the
2000-example ContraTales benchmark for realistic assessment of such solutions.",http://arxiv.org/pdf/2507.23221v1,,False
