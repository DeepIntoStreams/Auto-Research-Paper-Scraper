Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning,31/10/2024,"Zhenyu Jiang, Yuqi Xie, Kevin Lin, Zhenjia Xu, Weikang Wan, Ajay Mandlekar, Linxi Fan, Yuke Zhu","Imitation learning from human demonstrations is an effective means to teach
robots manipulation skills. But data acquisition is a major bottleneck in
applying this paradigm more broadly, due to the amount of cost and human effort
involved. There has been significant interest in imitation learning for
bimanual dexterous robots, like humanoids. Unfortunately, data collection is
even more challenging here due to the challenges of simultaneously controlling
multiple arms and multi-fingered hands. Automated data generation in simulation
is a compelling, scalable alternative to fuel this need for data. To this end,
we introduce DexMimicGen, a large-scale automated data generation system that
synthesizes trajectories from a handful of human demonstrations for humanoid
robots with dexterous hands. We present a collection of simulation environments
in the setting of bimanual dexterous manipulation, spanning a range of
manipulation behaviors and different requirements for coordination among the
two arms. We generate 21K demos across these tasks from just 60 source human
demos and study the effect of several data generation and policy learning
decisions on agent performance. Finally, we present a real-to-sim-to-real
pipeline and deploy it on a real-world humanoid can sorting task. Videos and
more are at https://dexmimicgen.github.io/",http://arxiv.org/pdf/2410.24185v1,,False
AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties,31/10/2024,"Xiayan Ji, Anton Xue, Eric Wong, Oleg Sokolsky, Insup Lee","Anomaly detection is widely used for identifying critical errors and
suspicious behaviors, but current methods lack interpretability. We leverage
common properties of existing methods and recent advances in generative models
to introduce counterfactual explanations for anomaly detection. Given an input,
we generate its counterfactual as a diffusion-based repair that shows what a
non-anomalous version should have looked like. A key advantage of this approach
is that it enables a domain-independent formal specification of explainability
desiderata, offering a unified framework for generating and evaluating
explanations. We demonstrate the effectiveness of our anomaly explainability
framework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI)
anomaly datasets. The code used for the experiments is accessible at:
https://github.com/xjiae/arpro.",http://arxiv.org/pdf/2410.24178v1,,False
Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing,31/10/2024,"Akash Dhruv, Anshu Dubey","The emergence of foundational models and generative artificial intelligence
(GenAI) is poised to transform productivity in scientific computing, especially
in code development, refactoring, and translating from one programming language
to another. However, because the output of GenAI cannot be guaranteed to be
correct, manual intervention remains necessary. Some of this intervention can
be automated through task-specific tools, alongside additional methodologies
for correctness verification and effective prompt development. We explored the
application of GenAI in assisting with code translation, language
interoperability, and codebase inspection within a legacy Fortran codebase used
to simulate particle interactions at the Large Hadron Collider (LHC). In the
process, we developed a tool, CodeScribe, which combines prompt engineering
with user supervision to establish an efficient process for code conversion. In
this paper, we demonstrate how CodeScribe assists in converting Fortran code to
C++, generating Fortran-C APIs for integrating legacy systems with modern C++
libraries, and providing developer support for code organization and algorithm
implementation. We also address the challenges of AI-driven code translation
and highlight its benefits for enhancing productivity in scientific computing
workflows.",http://arxiv.org/pdf/2410.24119v1,,False
AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization,31/10/2024,"Amir Kazemi, Qurat ul ain Fatima, Volodymyr Kindratenko, Christopher Tessum","Image labeling is a critical bottleneck in the development of computer vision
technologies, often constraining the potential of machine learning models due
to the time-intensive nature of manual annotations. This work introduces a
novel approach that leverages outpainting to address the problem of annotated
data scarcity by generating artificial contexts and annotations, significantly
reducing manual labeling efforts. We apply this technique to a particularly
acute challenge in autonomous driving, urban planning, and environmental
monitoring: the lack of diverse, eye-level vehicle images in desired classes.
Our dataset comprises AI-generated vehicle images obtained by detecting and
cropping vehicles from manually selected seed images, which are then outpainted
onto larger canvases to simulate varied real-world conditions. The outpainted
images include detailed annotations, providing high-quality ground truth data.
Advanced outpainting techniques and image quality assessments ensure visual
fidelity and contextual relevance. Augmentation with outpainted vehicles
improves overall performance metrics by up to 8\% and enhances prediction of
underrepresented classes by up to 20\%. This approach, exemplifying outpainting
as a self-annotating paradigm, presents a solution that enhances dataset
versatility across multiple domains of machine learning. The code and links to
datasets used in this study are available for further research and replication
at https://github.com/amir-kazemi/aidovecl.",http://arxiv.org/pdf/2410.24116v1,,False
SFM-Protein: Integrative Co-evolutionary Pre-training for Advanced Protein Sequence Representation,31/10/2024,"Liang He, Peiran Jin, Yaosen Min, Shufang Xie, Lijun Wu, Tao Qin, Xiaozhuan Liang, Kaiyuan Gao, Yuliang Jiang, Tie-Yan Liu","Proteins, essential to biological systems, perform functions intricately
linked to their three-dimensional structures. Understanding the relationship
between protein structures and their amino acid sequences remains a core
challenge in protein modeling. While traditional protein foundation models
benefit from pre-training on vast unlabeled datasets, they often struggle to
capture critical co-evolutionary information, which evolutionary-based methods
excel at. In this study, we introduce a novel pre-training strategy for protein
foundation models that emphasizes the interactions among amino acid residues to
enhance the extraction of both short-range and long-range co-evolutionary
features from sequence data. Trained on a large-scale protein sequence dataset,
our model demonstrates superior generalization ability, outperforming
established baselines of similar size, including the ESM model, across diverse
downstream tasks. Experimental results confirm the model's effectiveness in
integrating co-evolutionary information, marking a significant step forward in
protein sequence-based modeling.",http://arxiv.org/pdf/2410.24022v1,,False
Ada-MSHyper: Adaptive Multi-Scale Hypergraph Transformer for Time Series Forecasting,31/10/2024,"Zongjiang Shang, Ling Chen, Binqing wu, Dongliang Cui","Although transformer-based methods have achieved great success in multi-scale
temporal pattern interaction modeling, two key challenges limit their further
development: (1) Individual time points contain less semantic information, and
leveraging attention to model pair-wise interactions may cause the information
utilization bottleneck. (2) Multiple inherent temporal variations (e.g.,
rising, falling, and fluctuating) entangled in temporal patterns. To this end,
we propose Adaptive Multi-Scale Hypergraph Transformer (Ada-MSHyper) for time
series forecasting. Specifically, an adaptive hypergraph learning module is
designed to provide foundations for modeling group-wise interactions, then a
multi-scale interaction module is introduced to promote more comprehensive
pattern interactions at different scales. In addition, a node and hyperedge
constraint mechanism is introduced to cluster nodes with similar semantic
information and differentiate the temporal variations within each scales.
Extensive experiments on 11 real-world datasets demonstrate that Ada-MSHyper
achieves state-of-the-art performance, reducing prediction errors by an average
of 4.56%, 10.38%, and 4.97% in MSE for long-range, short-range, and
ultra-long-range time series forecasting, respectively. Code is available at
https://github.com/shangzongjiang/Ada-MSHyper.",http://arxiv.org/pdf/2410.23992v1,,False
Transformer-based Model Predictive Control: Trajectory Optimization via Sequence Modeling,31/10/2024,"Davide Celestini, Daniele Gammelli, Tommaso Guffanti, Simone D'Amico, Elisa Capello, Marco Pavone","Model predictive control (MPC) has established itself as the primary
methodology for constrained control, enabling general-purpose robot autonomy in
diverse real-world scenarios. However, for most problems of interest, MPC
relies on the recursive solution of highly non-convex trajectory optimization
problems, leading to high computational complexity and strong dependency on
initialization. In this work, we present a unified framework to combine the
main strengths of optimization-based and learning-based methods for MPC. Our
approach entails embedding high-capacity, transformer-based neural network
models within the optimization process for trajectory generation, whereby the
transformer provides a near-optimal initial guess, or target plan, to a
non-convex optimization problem. Our experiments, performed in simulation and
the real world onboard a free flyer platform, demonstrate the capabilities of
our framework to improve MPC convergence and runtime. Compared to purely
optimization-based approaches, results show that our approach can improve
trajectory generation performance by up to 75%, reduce the number of solver
iterations by up to 45%, and improve overall MPC runtime by 7x without loss in
performance.",http://arxiv.org/pdf/2410.23916v1,10.1109/LRA.2024.3466069,False
DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis,31/10/2024,"Hamidreza Eivazi, André Hebenbrock, Raphael Ginster, Steffen Blömeke, Stefan Wittek, Christoph Hermann, Thomas S. Spengler, Thomas Turek, Andreas Rausch","Battery degradation remains a critical challenge in the pursuit of green
technologies and sustainable energy solutions. Despite significant research
efforts, predicting battery capacity loss accurately remains a formidable task
due to its complex nature, influenced by both aging and cycling behaviors. To
address this challenge, we introduce a novel general-purpose model for battery
degradation prediction and synthesis, DiffBatt. Leveraging an innovative
combination of conditional and unconditional diffusion models with
classifier-free guidance and transformer architecture, DiffBatt achieves high
expressivity and scalability. DiffBatt operates as a probabilistic model to
capture uncertainty in aging behaviors and a generative model to simulate
battery degradation. The performance of the model excels in prediction tasks
while also enabling the generation of synthetic degradation curves,
facilitating enhanced model training by data augmentation. In the remaining
useful life prediction task, DiffBatt provides accurate results with a mean
RMSE of 196 cycles across all datasets, outperforming all other models and
demonstrating superior generalizability. This work represents an important step
towards developing foundational models for battery degradation.",http://arxiv.org/pdf/2410.23893v1,,False
Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models,31/10/2024,"Pedro Morão, Joao Santinha, Yasna Forghani, Nuno Loução, Pedro Gouveia, Mario A. T. Figueiredo","Deep learning (DL) models in medical imaging face challenges in
generalizability and robustness due to variations in image acquisition
parameters (IAP). In this work, we introduce a novel method using conditional
denoising diffusion generative models (cDDGMs) to generate counterfactual
magnetic resonance (MR) images that simulate different IAP without altering
patient anatomy. We demonstrate that using these counterfactual images for data
augmentation can improve segmentation accuracy, particularly in
out-of-distribution settings, enhancing the overall generalizability and
robustness of DL models across diverse imaging conditions. Our approach shows
promise in addressing domain and covariate shifts in medical imaging. The code
is publicly available at https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation",http://arxiv.org/pdf/2410.23835v1,,False
DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios,31/10/2024,"Junchao Wu, Runzhe Zhan, Derek F. Wong, Shu Yang, Xinyi Yang, Yulin Yuan, Lidia S. Chao","Detecting text generated by large language models (LLMs) is of great recent
interest. With zero-shot methods like DetectGPT, detection capabilities have
reached impressive levels. However, the reliability of existing detectors in
real-world applications remains underexplored. In this study, we present a new
benchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection
techniques still underperformed in this task. We collected human-written
datasets from domains where LLMs are particularly prone to misuse. Using
popular LLMs, we generated data that better aligns with real-world
applications. Unlike previous studies, we employed heuristic rules to create
adversarial LLM-generated text, simulating advanced prompt usages, human
revisions like word substitutions, and writing errors. Our development of
DetectRL reveals the strengths and limitations of current SOTA detectors. More
importantly, we analyzed the potential impact of writing styles, model types,
attack methods, the text lengths, and real-world human writing factors on
different types of detectors. We believe DetectRL could serve as an effective
benchmark for assessing detectors in real-world scenarios, evolving with
advanced attack methods, thus providing more stressful evaluation to drive the
development of more efficient detectors. Data and code are publicly available
at: https://github.com/NLP2CT/DetectRL.",http://arxiv.org/pdf/2410.23746v1,,False
OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models,31/10/2024,"Junda Wu, Xintong Li, Ruoyu Wang, Yu Xia, Yuxin Xiong, Jianing Wang, Tong Yu, Xiang Chen, Branislav Kveton, Lina Yao, Jingbo Shang, Julian McAuley","Offline evaluation of LLMs is crucial in understanding their capacities,
though current methods remain underexplored in existing research. In this work,
we focus on the offline evaluation of the chain-of-thought capabilities and
show how to optimize LLMs based on the proposed evaluation method. To enable
offline feedback with rich knowledge and reasoning paths, we use knowledge
graphs (e.g., Wikidata5m) to provide feedback on the generated chain of
thoughts. Due to the heterogeneity between LLM reasoning and KG structures,
direct interaction and feedback from KGs on LLM behavior are challenging, as
they require accurate entity linking and grounding of LLM-generated chains of
thought in the KG. To address the above challenge, we propose an offline
chain-of-thought evaluation framework, OCEAN, which models chain-of-thought
reasoning in LLMs as an MDP and evaluate the policy's alignment with KG
preference modeling. To overcome the reasoning heterogeneity and grounding
problems, we leverage on-policy KG exploration and RL to model a KG policy that
generates token-level likelihood distributions for LLM-generated
chain-of-thought reasoning paths, simulating KG reasoning preference. Then we
incorporate the knowledge-graph feedback on the validity and alignment of the
generated reasoning paths into inverse propensity scores and propose KG-IPS
estimator. Theoretically, we prove the unbiasedness of the proposed KG-IPS
estimator and provide a lower bound on its variance. With the off-policy
evaluated value function, we can directly enable off-policy optimization to
further enhance chain-of-thought alignment. Our empirical study shows that
OCEAN can be efficiently optimized for generating chain-of-thought reasoning
paths with higher estimated values without affecting LLMs' general abilities in
downstream tasks or their internal knowledge.",http://arxiv.org/pdf/2410.23703v1,,False
Automatically Learning Hybrid Digital Twins of Dynamical Systems,31/10/2024,"Samuel Holt, Tennison Liu, Mihaela van der Schaar","Digital Twins (DTs) are computational models that simulate the states and
temporal dynamics of real-world systems, playing a crucial role in prediction,
understanding, and decision-making across diverse domains. However, existing
approaches to DTs often struggle to generalize to unseen conditions in
data-scarce settings, a crucial requirement for such models. To address these
limitations, our work begins by establishing the essential desiderata for
effective DTs. Hybrid Digital Twins ($\textbf{HDTwins}$) represent a promising
approach to address these requirements, modeling systems using a composition of
both mechanistic and neural components. This hybrid architecture simultaneously
leverages (partial) domain knowledge and neural network expressiveness to
enhance generalization, with its modular design facilitating improved
evolvability. While existing hybrid models rely on expert-specified
architectures with only parameters optimized on data, $\textit{automatically}$
specifying and optimizing HDTwins remains intractable due to the complex search
space and the need for flexible integration of domain priors. To overcome this
complexity, we propose an evolutionary algorithm ($\textbf{HDTwinGen}$) that
employs Large Language Models (LLMs) to autonomously propose, evaluate, and
optimize HDTwins. Specifically, LLMs iteratively generate novel model
specifications, while offline tools are employed to optimize emitted
parameters. Correspondingly, proposed models are evaluated and evolved based on
targeted feedback, enabling the discovery of increasingly effective hybrid
models. Our empirical results reveal that HDTwinGen produces generalizable,
sample-efficient, and evolvable models, significantly advancing DTs' efficacy
in real-world applications.",http://arxiv.org/pdf/2410.23691v1,,False
Online Consistency of the Nearest Neighbor Rule,31/10/2024,"Sanjoy Dasgupta, Geelon So","In the realizable online setting, a learner is tasked with making predictions
for a stream of instances, where the correct answer is revealed after each
prediction. A learning rule is online consistent if its mistake rate eventually
vanishes. The nearest neighbor rule (Fix and Hodges, 1951) is a fundamental
prediction strategy, but it is only known to be consistent under strong
statistical or geometric assumptions: the instances come i.i.d. or the label
classes are well-separated. We prove online consistency for all measurable
functions in doubling metric spaces under the mild assumption that the
instances are generated by a process that is uniformly absolutely continuous
with respect to a finite, upper doubling measure.",http://arxiv.org/pdf/2410.23644v1,,False
EMGBench: Benchmarking Out-of-Distribution Generalization and Adaptation for Electromyography,31/10/2024,"Jehan Yang, Maxwell Soh, Vivianna Lieu, Douglas J Weber, Zackory Erickson","This paper introduces the first generalization and adaptation benchmark using
machine learning for evaluating out-of-distribution performance of
electromyography (EMG) classification algorithms. The ability of an EMG
classifier to handle inputs drawn from a different distribution than the
training distribution is critical for real-world deployment as a control
interface. By predicting the user's intended gesture using EMG signals, we can
create a wearable solution to control assistive technologies, such as
computers, prosthetics, and mobile manipulator robots. This new
out-of-distribution benchmark consists of two major tasks that have utility for
building robust and adaptable control interfaces: 1) intersubject
classification and 2) adaptation using train-test splits for time-series. This
benchmark spans nine datasets--the largest collection of EMG datasets in a
benchmark. Among these, a new dataset is introduced, featuring a novel,
easy-to-wear high-density EMG wearable for data collection. The lack of
open-source benchmarks has made comparing accuracy results between papers
challenging for the EMG research community. This new benchmark provides
researchers with a valuable resource for analyzing practical measures of
out-of-distribution performance for EMG datasets. Our code and data from our
new dataset can be found at emgbench.github.io.",http://arxiv.org/pdf/2410.23625v1,,False
Simulating User Agents for Embodied Conversational-AI,31/10/2024,"Daniel Philipov, Vardhan Dongre, Gokhan Tur, Dilek Hakkani-Tür","Embodied agents designed to assist users with tasks must engage in natural
language interactions, interpret instructions, execute actions, and communicate
effectively to resolve issues. However, collecting large-scale, diverse
datasets of situated human-robot dialogues to train and evaluate such agents is
expensive, labor-intensive, and time-consuming. To address this challenge, we
propose building a large language model (LLM)-based user agent that can
simulate user behavior during interactions with an embodied agent in a virtual
environment. Given a user goal (e.g., make breakfast), at each time step, the
user agent may observe"" the robot actions or speak"" to either intervene with
the robot or answer questions. Such a user agent assists in improving the
scalability and efficiency of embodied dialogues dataset generation and is
critical for enhancing and evaluating the robot's interaction and task
completion ability, as well as for research in reinforcement learning using AI
feedback. We evaluate our user agent's ability to generate human-like behaviors
by comparing its simulated dialogues with the TEACh dataset. We perform three
experiments: zero-shot prompting to predict dialogue acts, few-shot prompting,
and fine-tuning on the TEACh training subset. Results show the LLM-based user
agent achieves an F-measure of 42% with zero-shot prompting and 43.4% with
few-shot prompting in mimicking human speaking behavior. Through fine-tuning,
performance in deciding when to speak remained stable, while deciding what to
say improved from 51.1% to 62.5%. These findings showcase the feasibility of
the proposed approach for assessing and enhancing the effectiveness of robot
task completion through natural language communication.",http://arxiv.org/pdf/2410.23535v1,,False
