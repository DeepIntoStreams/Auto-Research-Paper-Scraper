Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Training Datasets Generation for Machine Learning: Application to Vision Based Navigation,17/09/2024,"Jérémy Lebreton, Ingo Ahrns, Roland Brochard, Christoph Haskamp, Matthieu Le Goff, Nicolas Menga, Nicolas Ollagnier, Ralf Regele, Francesco Capolupo, Massimo Casasco","Vision Based Navigation consists in utilizing cameras as precision sensors
for GNC after extracting information from images. To enable the adoption of
machine learning for space applications, one of obstacles is the demonstration
that available training datasets are adequate to validate the algorithms. The
objective of the study is to generate datasets of images and metadata suitable
for training machine learning algorithms. Two use cases were selected and a
robust methodology was developed to validate the datasets including the ground
truth. The first use case is in-orbit rendezvous with a man-made object: a
mockup of satellite ENVISAT. The second use case is a Lunar landing scenario.
Datasets were produced from archival datasets (Chang'e 3), from the laboratory
at DLR TRON facility and at Airbus Robotic laboratory, from SurRender software
high fidelity image simulator using Model Capture and from Generative
Adversarial Networks. The use case definition included the selection of
algorithms as benchmark: an AI-based pose estimation algorithm and a dense
optical flow algorithm were selected. Eventually it is demonstrated that
datasets produced with SurRender and selected laboratory facilities are
adequate to train machine learning algorithms.",http://arxiv.org/pdf/2409.11383v1,,False
Towards Time Series Reasoning with LLMs,17/09/2024,"Winnie Chow, Lauren Gardiner, Haraldur T. Hallgrímsson, Maxwell A. Xu, Shirley You Ren","Multi-modal large language models (MLLMs) have enabled numerous advances in
understanding and reasoning in domains like vision, but we have not yet seen
this broad success for time-series. Although prior works on time-series MLLMs
have shown promising performance in time-series forecasting, very few works
show how an LLM could be used for time-series reasoning in natural language. We
propose a novel multi-modal time-series LLM approach that learns generalizable
information across various domains with powerful zero-shot performance. First,
we train a lightweight time-series encoder on top of an LLM to directly extract
time-series information. Then, we fine-tune our model with chain-of-thought
augmented time-series tasks to encourage the model to generate reasoning paths.
We show that our model learns a latent representation that reflects specific
time-series features (e.g. slope, frequency), as well as outperforming GPT-4o
on a set of zero-shot reasoning tasks on a variety of domains.",http://arxiv.org/pdf/2409.11376v1,,False
Integrating Reinforcement Learning and Model Predictive Control with Applications to Microgrids,17/09/2024,"Caio Fabio Oliveira da Silva, Azita Dabiri, Bart De Schutter","This work proposes an approach that integrates reinforcement learning and
model predictive control (MPC) to efficiently solve finite-horizon optimal
control problems in mixed-logical dynamical systems. Optimization-based control
of such systems with discrete and continuous decision variables entails the
online solution of mixed-integer quadratic or linear programs, which suffer
from the curse of dimensionality. Our approach aims at mitigating this issue by
effectively decoupling the decision on the discrete variables and the decision
on the continuous variables. Moreover, to mitigate the combinatorial growth in
the number of possible actions due to the prediction horizon, we conceive the
definition of decoupled Q-functions to make the learning problem more
tractable. The use of reinforcement learning reduces the online optimization
problem of the MPC controller from a mixed-integer linear (quadratic) program
to a linear (quadratic) program, greatly reducing the computational time.
Simulation experiments for a microgrid, based on real-world data, demonstrate
that the proposed method significantly reduces the online computation time of
the MPC approach and that it generates policies with small optimality gaps and
high feasibility rates.",http://arxiv.org/pdf/2409.11267v1,,False
Performance of Cross-Validated Targeted Maximum Likelihood Estimation,17/09/2024,"Matthew J. Smith, Rachael V. Phillips, Camille Maringe, Miguel Angel Luque Fernandez","Background: Advanced methods for causal inference, such as targeted maximum
likelihood estimation (TMLE), require certain conditions for statistical
inference. However, in situations where there is not differentiability due to
data sparsity or near-positivity violations, the Donsker class condition is
violated. In such situations, TMLE variance can suffer from inflation of the
type I error and poor coverage, leading to conservative confidence intervals.
Cross-validation of the TMLE algorithm (CVTMLE) has been suggested to improve
on performance compared to TMLE in settings of positivity or Donsker class
violations. We aim to investigate the performance of CVTMLE compared to TMLE in
various settings.
  Methods: We utilised the data-generating mechanism as described in Leger et
al. (2022) to run a Monte Carlo experiment under different Donsker class
violations. Then, we evaluated the respective statistical performances of TMLE
and CVTMLE with different super learner libraries, with and without regression
tree methods.
  Results: We found that CVTMLE vastly improves confidence interval coverage
without adversely affecting bias, particularly in settings with small sample
sizes and near-positivity violations. Furthermore, incorporating regression
trees using standard TMLE with ensemble super learner-based initial estimates
increases bias and variance leading to invalid statistical inference.
  Conclusions: It has been shown that when using CVTMLE the Donsker class
condition is no longer necessary to obtain valid statistical inference when
using regression trees and under either data sparsity or near-positivity
violations. We show through simulations that CVTMLE is much less sensitive to
the choice of the super learner library and thereby provides better estimation
and inference in cases where the super learner library uses more flexible
candidates and is prone to overfitting.",http://arxiv.org/pdf/2409.11265v1,,False
"Federated Learning with Integrated Sensing, Communication, and Computation: Frameworks and Performance Analysis",17/09/2024,"Yipeng Liang, Qimei Chen, Hao Jiang","With the emergence of integrated sensing, communication, and computation
(ISCC) in the upcoming 6G era, federated learning with ISCC (FL-ISCC),
integrating sample collection, local training, and parameter exchange and
aggregation, has garnered increasing interest for enhancing training
efficiency. Currently, FL-ISCC primarily includes two algorithms: FedAVG-ISCC
and FedSGD-ISCC. However, the theoretical understanding of the performance and
advantages of these algorithms remains limited. To address this gap, we
investigate a general FL-ISCC framework, implementing both FedAVG-ISCC and
FedSGD-ISCC. We experimentally demonstrate the substantial potential of the
ISCC framework in reducing latency and energy consumption in FL. Furthermore,
we provide a theoretical analysis and comparison. The results reveal that:1)
Both sample collection and communication errors negatively impact algorithm
performance, highlighting the need for careful design to optimize FL-ISCC
applications. 2) FedAVG-ISCC performs better than FedSGD-ISCC under IID data
due to its advantage with multiple local updates. 3) FedSGD-ISCC is more robust
than FedAVG-ISCC under non-IID data, where the multiple local updates in
FedAVG-ISCC worsen performance as non-IID data increases. FedSGD-ISCC maintains
performance levels similar to IID conditions. 4) FedSGD-ISCC is more resilient
to communication errors than FedAVG-ISCC, which suffers from significant
performance degradation as communication errors increase.Extensive simulations
confirm the effectiveness of the FL-ISCC framework and validate our theoretical
analysis.",http://arxiv.org/pdf/2409.11240v1,,False
Learning Generalized Hamiltonians using fully Symplectic Mappings,17/09/2024,"Harsh Choudhary, Chandan Gupta, Vyacheslav kungrutsev, Melvin Leok, Georgios Korpas","Many important physical systems can be described as the evolution of a
Hamiltonian system, which has the important property of being conservative,
that is, energy is conserved throughout the evolution. Physics Informed Neural
Networks and in particular Hamiltonian Neural Networks have emerged as a
mechanism to incorporate structural inductive bias into the NN model. By
ensuring physical invariances are conserved, the models exhibit significantly
better sample complexity and out-of-distribution accuracy than standard NNs.
Learning the Hamiltonian as a function of its canonical variables, typically
position and velocity, from sample observations of the system thus becomes a
critical task in system identification and long-term prediction of system
behavior. However, to truly preserve the long-run physical conservation
properties of Hamiltonian systems, one must use symplectic integrators for a
forward pass of the system's simulation. While symplectic schemes have been
used in the literature, they are thus far limited to situations when they
reduce to explicit algorithms, which include the case of separable Hamiltonians
or augmented non-separable Hamiltonians. We extend it to generalized
non-separable Hamiltonians, and noting the self-adjoint property of symplectic
integrators, we bypass computationally intensive backpropagation through an ODE
solver. We show that the method is robust to noise and provides a good
approximation of the system Hamiltonian when the state variables are sampled
from a noisy observation. In the numerical results, we show the performance of
the method concerning Hamiltonian reconstruction and conservation, indicating
its particular advantage for non-separable systems.",http://arxiv.org/pdf/2409.11138v1,,False
HMF: A Hybrid Multi-Factor Framework for Dynamic Intraoperative Hypotension Prediction,17/09/2024,"Mingyue Cheng, Jintao Zhang, Zhiding Liu, Chunli Liu, Yanhu Xie","Intraoperative hypotension (IOH) prediction using Mean Arterial Pressure
(MAP) is a critical research area with significant implications for patient
outcomes during surgery. However, existing approaches predominantly employ
static modeling paradigms that overlook the dynamic nature of physiological
signals. In this paper, we introduce a novel Hybrid Multi-Factor (HMF)
framework that reformulates IOH prediction as a blood pressure forecasting
task. Our framework leverages a Transformer encoder, specifically designed to
effectively capture the temporal evolution of MAP series through a patch-based
input representation, which segments the input physiological series into
informative patches for accurate analysis. To address the challenges of
distribution shift in physiological series, our approach incorporates two key
innovations: (1) Symmetric normalization and de-normalization processes help
mitigate distributional drift in statistical properties, thereby ensuring the
model's robustness across varying conditions, and (2) Sequence decomposition,
which disaggregates the input series into trend and seasonal components,
allowing for a more precise modeling of inherent sequence dependencies.
Extensive experiments conducted on two real-world datasets demonstrate the
superior performance of our approach compared to competitive baselines,
particularly in capturing the nuanced variations in input series that are
crucial for accurate IOH prediction.",http://arxiv.org/pdf/2409.11064v1,,False
D2Vformer: A Flexible Time Series Prediction Model Based on Time Position Embedding,17/09/2024,"Xiaobao Song, Hao Wang, Liwei Deng, Yuxin He, Wenming Cao, Chi-Sing Leungc","Time position embeddings capture the positional information of time steps,
often serving as auxiliary inputs to enhance the predictive capabilities of
time series models. However, existing models exhibit limitations in capturing
intricate time positional information and effectively utilizing these
embeddings. To address these limitations, this paper proposes a novel model
called D2Vformer. Unlike typical prediction methods that rely on RNNs or
Transformers, this approach can directly handle scenarios where the predicted
sequence is not adjacent to the input sequence or where its length dynamically
changes. In comparison to conventional methods, D2Vformer undoubtedly saves a
significant amount of training resources. In D2Vformer, the Date2Vec module
uses the timestamp information and feature sequences to generate time position
embeddings. Afterward, D2Vformer introduces a new fusion block that utilizes an
attention mechanism to explore the similarity in time positions between the
embeddings of the input sequence and the predicted sequence, thereby generating
predictions based on this similarity. Through extensive experiments on six
datasets, we demonstrate that Date2Vec outperforms other time position
embedding methods, and D2Vformer surpasses state-of-the-art methods in both
fixed-length and variable-length prediction tasks.",http://arxiv.org/pdf/2409.11024v1,,False
Enhanced segmentation of femoral bone metastasis in CT scans of patients using synthetic data generation with 3D diffusion models,17/09/2024,"Emile Saillard, Aurélie Levillain, David Mitton, Jean-Baptiste Pialat, Cyrille Confavreux, Hélène Follet, Thomas Grenier","Purpose: Bone metastasis have a major impact on the quality of life of
patients and they are diverse in terms of size and location, making their
segmentation complex. Manual segmentation is time-consuming, and expert
segmentations are subject to operator variability, which makes obtaining
accurate and reproducible segmentations of bone metastasis on CT-scans a
challenging yet important task to achieve. Materials and Methods: Deep learning
methods tackle segmentation tasks efficiently but require large datasets along
with expert manual segmentations to generalize on new images. We propose an
automated data synthesis pipeline using 3D Denoising Diffusion Probabilistic
Models (DDPM) to enchance the segmentation of femoral metastasis from CT-scan
volumes of patients. We used 29 existing lesions along with 26 healthy femurs
to create new realistic synthetic metastatic images, and trained a DDPM to
improve the diversity and realism of the simulated volumes. We also
investigated the operator variability on manual segmentation. Results: We
created 5675 new volumes, then trained 3D U-Net segmentation models on real and
synthetic data to compare segmentation performance, and we evaluated the
performance of the models depending on the amount of synthetic data used in
training. Conclusion: Our results showed that segmentation models trained with
synthetic data outperformed those trained on real volumes only, and that those
models perform especially well when considering operator variability.",http://arxiv.org/pdf/2409.11011v1,,False
Latent mixed-effect models for high-dimensional longitudinal data,17/09/2024,"Priscilla Ong, Manuel Haußmann, Otto Lönnroth, Harri Lähdesmäki","Modelling longitudinal data is an important yet challenging task. These
datasets can be high-dimensional, contain non-linear effects and time-varying
covariates. Gaussian process (GP) prior-based variational autoencoders (VAEs)
have emerged as a promising approach due to their ability to model time-series
data. However, they are costly to train and struggle to fully exploit the rich
covariates characteristic of longitudinal data, making them difficult for
practitioners to use effectively. In this work, we leverage linear mixed models
(LMMs) and amortized variational inference to provide conditional priors for
VAEs, and propose LMM-VAE, a scalable, interpretable and identifiable model. We
highlight theoretical connections between it and GP-based techniques, providing
a unified framework for this class of methods. Our proposal performs
competitively compared to existing approaches across simulated and real-world
datasets.",http://arxiv.org/pdf/2409.11008v1,,False
Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification,17/09/2024,"Jiaxing Xu, Kai He, Mengcheng Lan, Qingtian Bian, Wei Li, Tieying Li, Yiping Ke, Miao Qiao","Understanding neurological disorder is a fundamental problem in neuroscience,
which often requires the analysis of brain networks derived from functional
magnetic resonance imaging (fMRI) data. Despite the prevalence of Graph Neural
Networks (GNNs) and Graph Transformers in various domains, applying them to
brain networks faces challenges. Specifically, the datasets are severely
impacted by the noises caused by distribution shifts across sub-populations and
the neglect of node identities, both obstruct the identification of
disease-specific patterns. To tackle these challenges, we propose
Contrasformer, a novel contrastive brain network Transformer. It generates a
prior-knowledge-enhanced contrast graph to address the distribution shifts
across sub-populations by a two-stream attention mechanism. A cross attention
with identity embedding highlights the identity of nodes, and three auxiliary
losses ensure group consistency. Evaluated on 4 functional brain network
datasets over 4 different diseases, Contrasformer outperforms the
state-of-the-art methods for brain networks by achieving up to 10.8\%
improvement in accuracy, which demonstrates its efficacy in neurological
disorder identification. Case studies illustrate its interpretability,
especially in the context of neuroscience. This paper provides a solution for
analyzing brain networks, offering valuable insights into neurological
disorders. Our code is available at
\url{https://github.com/AngusMonroe/Contrasformer}.",http://arxiv.org/pdf/2409.10944v1,,False
BAD: Bidirectional Auto-regressive Diffusion for Text-to-Motion Generation,17/09/2024,"S. Rohollah Hosseyni, Ali Ahmad Rahmani, S. Jamal Seyedmohammadi, Sanaz Seyedin, Arash Mohammadi","Autoregressive models excel in modeling sequential dependencies by enforcing
causal constraints, yet they struggle to capture complex bidirectional patterns
due to their unidirectional nature. In contrast, mask-based models leverage
bidirectional context, enabling richer dependency modeling. However, they often
assume token independence during prediction, which undermines the modeling of
sequential dependencies. Additionally, the corruption of sequences through
masking or absorption can introduce unnatural distortions, complicating the
learning process. To address these issues, we propose Bidirectional
Autoregressive Diffusion (BAD), a novel approach that unifies the strengths of
autoregressive and mask-based generative models. BAD utilizes a
permutation-based corruption technique that preserves the natural sequence
structure while enforcing causal dependencies through randomized ordering,
enabling the effective capture of both sequential and bidirectional
relationships. Comprehensive experiments show that BAD outperforms
autoregressive and mask-based models in text-to-motion generation, suggesting a
novel pre-training strategy for sequence modeling. The codebase for BAD is
available on https://github.com/RohollahHS/BAD.",http://arxiv.org/pdf/2409.10847v1,,False
Implicit Reasoning in Deep Time Series Forecasting,17/09/2024,"Willa Potosnak, Cristian Challu, Mononito Goswami, Michał Wiliński, Nina Żukowska","Recently, time series foundation models have shown promising zero-shot
forecasting performance on time series from a wide range of domains. However,
it remains unclear whether their success stems from a true understanding of
temporal dynamics or simply from memorizing the training data. While implicit
reasoning in language models has been studied, similar evaluations for time
series models have been largely unexplored. This work takes an initial step
toward assessing the reasoning abilities of deep time series forecasting
models. We find that certain linear, MLP-based, and patch-based Transformer
models generalize effectively in systematically orchestrated
out-of-distribution scenarios, suggesting underexplored reasoning capabilities
beyond simple pattern memorization.",http://arxiv.org/pdf/2409.10840v1,,False
Multi-frequency Electrical Impedance Tomography Reconstruction with Multi-Branch Attention Image Prior,17/09/2024,"Hao Fang, Zhe Liu, Yi Feng, Zhen Qiu, Pierre Bagnaninchi, Yunjie Yang","Multi-frequency Electrical Impedance Tomography (mfEIT) is a promising
biomedical imaging technique that estimates tissue conductivities across
different frequencies. Current state-of-the-art (SOTA) algorithms, which rely
on supervised learning and Multiple Measurement Vectors (MMV), require
extensive training data, making them time-consuming, costly, and less practical
for widespread applications. Moreover, the dependency on training data in
supervised MMV methods can introduce erroneous conductivity contrasts across
frequencies, posing significant concerns in biomedical applications. To address
these challenges, we propose a novel unsupervised learning approach based on
Multi-Branch Attention Image Prior (MAIP) for mfEIT reconstruction. Our method
employs a carefully designed Multi-Branch Attention Network (MBA-Net) to
represent multiple frequency-dependent conductivity images and simultaneously
reconstructs mfEIT images by iteratively updating its parameters. By leveraging
the implicit regularization capability of the MBA-Net, our algorithm can
capture significant inter- and intra-frequency correlations, enabling robust
mfEIT reconstruction without the need for training data. Through simulation and
real-world experiments, our approach demonstrates performance comparable to, or
better than, SOTA algorithms while exhibiting superior generalization
capability. These results suggest that the MAIP-based method can be used to
improve the reliability and applicability of mfEIT in various settings.",http://arxiv.org/pdf/2409.10794v1,,False
