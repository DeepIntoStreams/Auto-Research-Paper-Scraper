Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
PepThink-R1: LLM for Interpretable Cyclic Peptide Optimization with CoT SFT and Reinforcement Learning,20/08/2025,"Ruheng Wang, Hang Zhang, Trieu Nguyen, Shasha Feng, Hao-Wei Pang, Xiang Yu, Li Xiao, Peter Zhiping Zhang","Designing therapeutic peptides with tailored properties is hindered by the
vastness of sequence space, limited experimental data, and poor
interpretability of current generative models. To address these challenges, we
introduce PepThink-R1, a generative framework that integrates large language
models (LLMs) with chain-of-thought (CoT) supervised fine-tuning and
reinforcement learning (RL). Unlike prior approaches, PepThink-R1 explicitly
reasons about monomer-level modifications during sequence generation, enabling
interpretable design choices while optimizing for multiple pharmacological
properties. Guided by a tailored reward function balancing chemical validity
and property improvements, the model autonomously explores diverse sequence
variants. We demonstrate that PepThink-R1 generates cyclic peptides with
significantly enhanced lipophilicity, stability, and exposure, outperforming
existing general LLMs (e.g., GPT-5) and domain-specific baseline in both
optimization success and interpretability. To our knowledge, this is the first
LLM-based peptide design framework that combines explicit reasoning with
RL-driven property control, marking a step toward reliable and transparent
peptide optimization for therapeutic discovery.",http://arxiv.org/pdf/2508.14765v1,,False
UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling,20/08/2025,"Peiming Li, Ziyi Wang, Yulin Yuan, Hong Liu, Xiangming Meng, Junsong Yuan, Mengyuan Liu","Point cloud videos capture dynamic 3D motion while reducing the effects of
lighting and viewpoint variations, making them highly effective for recognizing
subtle and continuous human actions. Although Selective State Space Models
(SSMs) have shown good performance in sequence modeling with linear complexity,
the spatio-temporal disorder of point cloud videos hinders their unidirectional
modeling when directly unfolding the point cloud video into a 1D sequence
through temporally sequential scanning. To address this challenge, we propose
the Unified Spatio-Temporal State Space Model (UST-SSM), which extends the
latest advancements in SSMs to point cloud videos. Specifically, we introduce
Spatial-Temporal Selection Scanning (STSS), which reorganizes unordered points
into semantic-aware sequences through prompt-guided clustering, thereby
enabling the effective utilization of points that are spatially and temporally
distant yet similar within the sequence. For missing 4D geometric and motion
details, Spatio-Temporal Structure Aggregation (STSA) aggregates
spatio-temporal features and compensates. To improve temporal interaction
within the sampled sequence, Temporal Interaction Sampling (TIS) enhances
fine-grained temporal dependencies through non-anchor frame utilization and
expanded receptive fields. Experimental results on the MSR-Action3D, NTU RGB+D,
and Synthia 4D datasets validate the effectiveness of our method. Our code is
available at https://github.com/wangzy01/UST-SSM.",http://arxiv.org/pdf/2508.14604v1,,False
Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs,20/08/2025,"Luca Annese, Sabrina Patania, Silvia Serino, Tom Foulsham, Silvia Rossi, Azzurra Ruggeri, Dimitri Ognibene","Recent advances in large language models (LLMs) and reasoning frameworks have
opened new possibilities for improving the perspective -taking capabilities of
autonomous agents. However, tasks that involve active perception, collaborative
reasoning, and perspective taking (understanding what another agent can see or
knows) pose persistent challenges for current LLM-based systems. This study
investigates the potential of structured examples derived from transformed
solution graphs generated by the Fast Downward planner to improve the
performance of LLM-based agents within a ReAct framework. We propose a
structured solution-processing pipeline that generates three distinct
categories of examples: optimal goal paths (G-type), informative node paths
(E-type), and step-by-step optimal decision sequences contrasting alternative
actions (L-type). These solutions are further converted into ``thought-action''
examples by prompting an LLM to explicitly articulate the reasoning behind each
decision. While L-type examples slightly reduce clarification requests and
overall action steps, they do not yield consistent improvements. Agents are
successful in tasks requiring basic attentional filtering but struggle in
scenarios that required mentalising about occluded spaces or weighing the costs
of epistemic actions. These findings suggest that structured examples alone are
insufficient for robust perspective-taking, underscoring the need for explicit
belief tracking, cost modelling, and richer environments to enable socially
grounded collaboration in LLM-based agents.",http://arxiv.org/pdf/2508.14564v1,,False
Adaptively Robust LLM Inference Optimization under Prediction Uncertainty,20/08/2025,"Zixi Chen, Yinyu Ye, Zijie Zhou","We study the problem of optimizing Large Language Model (LLM) inference
scheduling to minimize total latency. LLM inference is an online and multi-task
service process and also heavily energy consuming by which a pre-trained LLM
processes input requests and generates output tokens sequentially. Therefore,
it is vital to improve its scheduling efficiency and reduce the power
consumption while a great amount of prompt requests are arriving. A key
challenge in LLM inference scheduling is that while the prompt length is known
upon arrival, the output length, which critically impacts memory usage and
processing time, is unknown. To address this uncertainty, we propose algorithms
that leverage machine learning to predict output lengths, assuming the
prediction provides an interval classification (min-max range) for each
request.
  We first design a conservative algorithm, $\mathcal{A}_{\max}$, which
schedules requests based on the upper bound of predicted output lengths to
prevent memory overflow. However, this approach is overly conservative: as
prediction accuracy decreases, performance degrades significantly due to
potential overestimation. To overcome this limitation, we propose
$\mathcal{A}_{\min}$, an adaptive algorithm that initially treats the predicted
lower bound as the output length and dynamically refines this estimate during
inferencing. We prove that $\mathcal{A}_{\min}$ achieves a log-scale
competitive ratio. Through numerical simulations, we demonstrate that
$\mathcal{A}_{\min}$ often performs nearly as well as the hindsight scheduler,
highlighting both its efficiency and robustness in practical scenarios.
Moreover, $\mathcal{A}_{\min}$ relies solely on the lower bound of the
prediction interval--an advantageous design choice since upper bounds on output
length are typically more challenging to predict accurately.",http://arxiv.org/pdf/2508.14544v1,,False
MISS: Multi-Modal Tree Indexing and Searching with Lifelong Sequential Behavior for Retrieval Recommendation,20/08/2025,"Chengcheng Guo, Junda She, Kuo Cai, Shiyao Wang, Qigen Hu, Qiang Luo, Kun Gai, Guorui Zhou","Large-scale industrial recommendation systems typically employ a two-stage
paradigm of retrieval and ranking to handle huge amounts of information. Recent
research focuses on improving the performance of retrieval model. A promising
way is to introduce extensive information about users and items. On one hand,
lifelong sequential behavior is valuable. Existing lifelong behavior modeling
methods in ranking stage focus on the interaction of lifelong behavior and
candidate items from retrieval stage. In retrieval stage, it is difficult to
utilize lifelong behavior because of a large corpus of candidate items. On the
other hand, existing retrieval methods mostly relay on interaction information,
potentially disregarding valuable multi-modal information. To solve these
problems, we represent the pioneering exploration of leveraging multi-modal
information and lifelong sequence model within the advanced tree-based
retrieval model. We propose Multi-modal Indexing and Searching with lifelong
Sequence (MISS), which contains a multi-modal index tree and a multi-modal
lifelong sequence modeling module. Specifically, for better index structure, we
propose multi-modal index tree, which is built using the multi-modal embedding
to precisely represent item similarity. To precisely capture diverse user
interests in user lifelong sequence, we propose collaborative general search
unit (Co-GSU) and multi-modal general search unit (MM-GSU) for
multi-perspective interests searching.",http://arxiv.org/pdf/2508.14515v1,,False
Personalized Counterfactual Framework: Generating Potential Outcomes from Wearable Data,20/08/2025,"Ajan Subramanian, Amir M. Rahmani","Wearable sensor data offer opportunities for personalized health monitoring,
yet deriving actionable insights from their complex, longitudinal data streams
is challenging. This paper introduces a framework to learn personalized
counterfactual models from multivariate wearable data. This enables exploring
what-if scenarios to understand potential individual-specific outcomes of
lifestyle choices. Our approach first augments individual datasets with data
from similar patients via multi-modal similarity analysis. We then use a
temporal PC (Peter-Clark) algorithm adaptation to discover predictive
relationships, modeling how variables at time t-1 influence physiological
changes at time t. Gradient Boosting Machines are trained on these discovered
relationships to quantify individual-specific effects. These models drive a
counterfactual engine projecting physiological trajectories under hypothetical
interventions (e.g., activity or sleep changes). We evaluate the framework via
one-step-ahead predictive validation and by assessing the plausibility and
impact of interventions. Evaluation showed reasonable predictive accuracy
(e.g., mean heart rate MAE 4.71 bpm) and high counterfactual plausibility
(median 0.9643). Crucially, these interventions highlighted significant
inter-individual variability in response to hypothetical lifestyle changes,
showing the framework's potential for personalized insights. This work provides
a tool to explore personalized health dynamics and generate hypotheses on
individual responses to lifestyle changes.",http://arxiv.org/pdf/2508.14432v1,,False
Organ-Agents: Virtual Human Physiology Simulator via LLMs,20/08/2025,"Rihao Chang, He Jiao, Weizhi Nie, Honglin Guo, Keliang Xie, Zhenhua Wu, Lina Zhao, Yunpeng Bai, Yongtao Ma, Lanjun Wang, Yuting Su, Xi Gao, Weijie Wang, Nicu Sebe, Bruno Lepri, Bingwei Sun","Recent advances in large language models (LLMs) have enabled new
possibilities in simulating complex physiological systems. We introduce
Organ-Agents, a multi-agent framework that simulates human physiology via
LLM-driven agents. Each Simulator models a specific system (e.g.,
cardiovascular, renal, immune). Training consists of supervised fine-tuning on
system-specific time-series data, followed by reinforcement-guided coordination
using dynamic reference selection and error correction. We curated data from
7,134 sepsis patients and 7,895 controls, generating high-resolution
trajectories across 9 systems and 125 variables. Organ-Agents achieved high
simulation accuracy on 4,509 held-out patients, with per-system MSEs <0.16 and
robustness across SOFA-based severity strata. External validation on 22,689 ICU
patients from two hospitals showed moderate degradation under distribution
shifts with stable simulation. Organ-Agents faithfully reproduces critical
multi-system events (e.g., hypotension, hyperlactatemia, hypoxemia) with
coherent timing and phase progression. Evaluation by 15 critical care
physicians confirmed realism and physiological plausibility (mean Likert
ratings 3.9 and 3.7). Organ-Agents also enables counterfactual simulations
under alternative sepsis treatment strategies, generating trajectories and
APACHE II scores aligned with matched real-world patients. In downstream early
warning tasks, classifiers trained on synthetic data showed minimal AUROC drops
(<0.04), indicating preserved decision-relevant patterns. These results
position Organ-Agents as a credible, interpretable, and generalizable digital
twin for precision diagnosis, treatment simulation, and hypothesis testing in
critical care.",http://arxiv.org/pdf/2508.14357v1,,False
Pixels to Play: A Foundation Model for 3D Gameplay,19/08/2025,"Yuguang Yue, Chris Green, Samuel Hunt, Irakli Salia, Wenzhe Shi, Jonathan J Hunt","We introduce Pixels2Play-0.1 (P2P0.1), a foundation model that learns to play
a wide range of 3D video games with recognizable human-like behavior. Motivated
by emerging consumer and developer use cases - AI teammates, controllable NPCs,
personalized live-streamers, assistive testers - we argue that an agent must
rely on the same pixel stream available to players and generalize to new titles
with minimal game-specific engineering. P2P0.1 is trained end-to-end with
behavior cloning: labeled demonstrations collected from instrumented human
game-play are complemented by unlabeled public videos, to which we impute
actions via an inverse-dynamics model. A decoder-only transformer with
auto-regressive action output handles the large action space while remaining
latency-friendly on a single consumer GPU. We report qualitative results
showing competent play across simple Roblox and classic MS-DOS titles,
ablations on unlabeled data, and outline the scaling and evaluation steps
required to reach expert-level, text-conditioned control.",http://arxiv.org/pdf/2508.14295v1,,False
Comparing Model-agnostic Feature Selection Methods through Relative Efficiency,19/08/2025,"Chenghui Zheng, Garvesh Raskutti","Feature selection and importance estimation in a model-agnostic setting is an
ongoing challenge of significant interest. Wrapper methods are commonly used
because they are typically model-agnostic, even though they are computationally
intensive. In this paper, we focus on feature selection methods related to the
Generalized Covariance Measure (GCM) and Leave-One-Covariate-Out (LOCO)
estimation, and provide a comparison based on relative efficiency. In
particular, we present a theoretical comparison under three model settings:
linear models, non-linear additive models, and single index models that mimic a
single-layer neural network. We complement this with extensive simulations and
real data examples. Our theoretical results, along with empirical findings,
demonstrate that GCM-related methods generally outperform LOCO under suitable
regularity conditions. Furthermore, we quantify the asymptotic relative
efficiency of these approaches. Our simulations and real data analysis include
widely used machine learning methods such as neural networks and gradient
boosting trees.",http://arxiv.org/pdf/2508.14268v1,,False
BLIPs: Bayesian Learned Interatomic Potentials,19/08/2025,"Dario Coscia, Pim de Haan, Max Welling","Machine Learning Interatomic Potentials (MLIPs) are becoming a central tool
in simulation-based chemistry. However, like most deep learning models, MLIPs
struggle to make accurate predictions on out-of-distribution data or when
trained in a data-scarce regime, both common scenarios in simulation-based
chemistry. Moreover, MLIPs do not provide uncertainty estimates by
construction, which are fundamental to guide active learning pipelines and to
ensure the accuracy of simulation results compared to quantum calculations. To
address this shortcoming, we propose BLIPs: Bayesian Learned Interatomic
Potentials. BLIP is a scalable, architecture-agnostic variational Bayesian
framework for training or fine-tuning MLIPs, built on an adaptive version of
Variational Dropout. BLIP delivers well-calibrated uncertainty estimates and
minimal computational overhead for energy and forces prediction at inference
time, while integrating seamlessly with (equivariant) message-passing
architectures. Empirical results on simulation-based computational chemistry
tasks demonstrate improved predictive accuracy with respect to standard MLIPs,
and trustworthy uncertainty estimates, especially in data-scarse or heavy
out-of-distribution regimes. Moreover, fine-tuning pretrained MLIPs with BLIP
yields consistent performance gains and calibrated uncertainties.",http://arxiv.org/pdf/2508.14022v1,,False
Typed Topological Structures Of Datasets,19/08/2025,Wanjun Hu,"A datatset $X$ on $R^2$ is a finite topological space. Current research of a
dataset focuses on statistical methods and the algebraic topological method
\cite{carlsson}. In \cite{hu}, the concept of typed topological space was
introduced and showed to have the potential for studying finite topological
spaces, such as a dataset. It is a new method from the general topology
perspective. A typed topological space is a topological space whose open sets
are assigned types. Topological concepts and methods can be redefined using
open sets of certain types. In this article, we develop a special set of types
and its related typed topology on a dataset $X$. Using it, we can investigate
the inner structure of $X$. In particular, $R^2$ has a natural quotient space,
in which $X$ is organized into tracks, and each track is split into components.
Those components are in a order. Further, they can be represented by an integer
sequence. Components crossing tracks form branches, and the relationship can be
well represented by a type of pseudotree (called typed-II pseudotree). Such
structures provide a platform for new algorithms for problems such as
calculating convex hull, holes, clustering and anomaly detection.",http://arxiv.org/pdf/2508.14008v1,,False
DPad: Efficient Diffusion Language Models with Suffix Dropout,19/08/2025,"Xinhua Chen, Sitao Huang, Cong Guo, Chiyue Wei, Yintao He, Jianyi Zhang, Hai ""Hellen"" Li, Yiran Chen","Diffusion-based Large Language Models (dLLMs) parallelize text generation by
framing decoding as a denoising process, but suffer from high computational
overhead since they predict all future suffix tokens at each step while
retaining only a small fraction. We propose Diffusion Scratchpad (DPad), a
training-free method that restricts attention to a small set of nearby suffix
tokens, preserving fidelity while eliminating redundancy. DPad integrates two
strategies: (i) a sliding window, which maintains a fixed-length suffix window,
and (ii) distance-decay dropout, which deterministically removes distant suffix
tokens before attention computation. This simple design is compatible with
existing optimizations such as prefix caching and can be implemented with only
a few lines of code. Comprehensive evaluations across multiple benchmarks on
LLaDA-1.5 and Dream models demonstrate that DPad delivers up to
$\mathbf{61.4\times}$ speedup over vanilla dLLMs while maintaining comparable
accuracy, highlighting its potential for efficient and scalable long-sequence
inference. Our code is available at https://github.com/Crys-Chen/DPad.",http://arxiv.org/pdf/2508.14148v1,,False
ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation,19/08/2025,"Jingquan Wang, Andrew Negrut, Harry Zhang, Khailanii Slaton, Shu Wang, Radu Serban, Jinlong Wu, Dan Negrut","This contribution is concerned with the following issue: can pretrained large
language models (LLMs) be refined and customized to the point where they become
virtual assistants helping experts with the effective use of a simulation tool?
In this case study, the ``simulation tool'' considered is PyChrono, an open
source multi-physics dynamics engine for multibody systems. We present a
framework for refining and customizing both open- and closed-source LLMs to
harness the power of AI in generating scripts that perform PyChrono virtual
experiments. We refine and customize several classes of LLMs through a process
that leads to a quantifiable improvement in the quality of the generated
PyChrono simulation scripts. These scripts can range from simple
single-pendulum simulations to complex virtual experiments involving full
vehicles on deformable terrain. While the generated scripts are rarely perfect,
they often serve as strong starting points for the user to modify and improve
on. Additionally, the LLM can answer specific API questions about the
simulator, or recommend modeling approaches. The framework discussed is general
and can be applied to lower the entry barrier for simulation tools associated
with other application domains.",http://arxiv.org/pdf/2508.13975v1,,False
The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management,19/08/2025,Soumyadeep Dhar,"The rise of autonomous, AI-driven agents in economic settings raises critical
questions about their emergent strategic behavior. This paper investigates
these dynamics in the cooperative context of a multi-echelon supply chain, a
system famously prone to instabilities like the bullwhip effect. We conduct
computational experiments with generative AI agents, powered by Large Language
Models (LLMs), within a controlled supply chain simulation designed to isolate
their behavioral tendencies. Our central finding is the ""collaboration
paradox"": a novel, catastrophic failure mode where theoretically superior
collaborative AI agents, designed with Vendor-Managed Inventory (VMI)
principles, perform even worse than non-AI baselines. We demonstrate that this
paradox arises from an operational flaw where agents hoard inventory, starving
the system. We then show that resilience is only achieved through a synthesis
of two distinct layers: high-level, AI-driven proactive policy-setting to
establish robust operational targets, and a low-level, collaborative execution
protocol with proactive downstream replenishment to maintain stability. Our
final framework, which implements this synthesis, can autonomously generate,
evaluate, and quantify a portfolio of viable strategic choices. The work
provides a crucial insight into the emergent behaviors of collaborative AI
agents and offers a blueprint for designing stable, effective AI-driven systems
for business analytics.",http://arxiv.org/pdf/2508.13942v1,,False
Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback,19/08/2025,"Yihao Ang, Yifan Bao, Lei Jiang, Jiajie Tao, Anthony K. H. Tung, Lukasz Szpruch, Hao Ni","Time-series data is central to decision-making in financial markets, yet
building high-performing, interpretable, and auditable models remains a major
challenge. While Automated Machine Learning (AutoML) frameworks streamline
model development, they often lack adaptability and responsiveness to
domain-specific needs and evolving objectives. Concurrently, Large Language
Models (LLMs) have enabled agentic systems capable of reasoning, memory
management, and dynamic code generation, offering a path toward more flexible
workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular
agentic framework designed to automate and enhance time-series modeling
workflows for financial applications. The agent formalizes the pipeline as a
structured, iterative decision process across three stages: model selection,
code refinement, and fine-tuning, guided by contextual reasoning and
experimental feedback. Central to our architecture is a planner agent equipped
with structured knowledge banks, curated libraries of models and refinement
strategies, which guide exploration, while improving interpretability and
reducing error propagation. \textsf{TS-Agent} supports adaptive learning,
robust debugging, and transparent auditing, key requirements for high-stakes
environments such as financial services. Empirical evaluations on diverse
financial forecasting and synthetic data generation tasks demonstrate that
\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic
baselines, achieving superior accuracy, robustness, and decision traceability.",http://arxiv.org/pdf/2508.13915v1,,False
Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management,19/08/2025,"Tianheng Ling, Vipin Singh, Chao Qian, Felix Biessmann, Gregor Schiele","Extreme weather events, intensified by climate change, increasingly challenge
aging combined sewer systems, raising the risk of untreated wastewater
overflow. Accurate forecasting of sewer overflow basin filling levels can
provide actionable insights for early intervention, helping mitigating
uncontrolled discharge. In recent years, AI-based forecasting methods have
offered scalable alternatives to traditional physics-based models, but their
reliance on cloud computing limits their reliability during communication
outages. To address this, we propose an end-to-end forecasting framework that
enables energy-efficient inference directly on edge devices. Our solution
integrates lightweight Transformer and Long Short-Term Memory (LSTM) models,
compressed via integer-only quantization for efficient on-device execution.
Moreover, an automated hardware-aware deployment pipeline is used to search for
optimal model configurations by jointly minimizing prediction error and energy
consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer
data, the selected 8-bit Transformer model, trained on 24 hours of historical
measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ
per inference. In contrast, the optimal 8-bit LSTM model requires significantly
less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE
0.0432) and much longer training time. This trade-off highlights the need to
align model selection with deployment priorities, favoring LSTM for ultra-low
energy consumption or Transformer for higher predictive accuracy. In general,
our work enables local, energy-efficient forecasting, contributing to more
resilient combined sewer systems. All code can be found in the GitHub
Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).",http://arxiv.org/pdf/2508.13905v1,,False
Diffusion-Driven High-Dimensional Variable Selection,19/08/2025,"Minjie Wang, Xiaotong Shen, Wei Pan","Variable selection for high-dimensional, highly correlated data has long been
a challenging problem, often yielding unstable and unreliable models. We
propose a resample-aggregate framework that exploits diffusion models' ability
to generate high-fidelity synthetic data. Specifically, we draw multiple
pseudo-data sets from a diffusion model fitted to the original data, apply any
off-the-shelf selector (e.g., lasso or SCAD), and store the resulting inclusion
indicators and coefficients. Aggregating across replicas produces a stable
subset of predictors with calibrated stability scores for variable selection.
Theoretically, we show that the proposed method is selection consistent under
mild assumptions. Because the generative model imports knowledge from large
pre-trained weights, the procedure naturally benefits from transfer learning,
boosting power when the observed sample is small or noisy. We also extend the
framework of aggregating synthetic data to other model selection problems,
including graphical model selection, and statistical inference that supports
valid confidence intervals and hypothesis tests. Extensive simulations show
consistent gains over the lasso, stability selection, and knockoff baselines,
especially when predictors are strongly correlated, achieving higher
true-positive rates and lower false-discovery proportions. By coupling
diffusion-based data augmentation with principled aggregation, our method
advances variable selection methodology and broadens the toolkit for
interpretable, statistically rigorous analysis in complex scientific
applications.",http://arxiv.org/pdf/2508.13890v1,,False
Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer,19/08/2025,"Rathnam Vidushika Rasanji, Jin Wei-Kocsis, Jiansong Zhang, Dongming Gan, Ragu Athinarayanan, Paul Asunda","Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.",http://arxiv.org/pdf/2508.13877v1,,False
Smooth Flow Matching,19/08/2025,"Jianbin Tan, Anru R. Zhang","Functional data, i.e., smooth random functions observed over a continuous
domain, are increasingly available in areas such as biomedical research, health
informatics, and epidemiology. However, effective statistical analysis for
functional data is often hindered by challenges such as privacy constraints,
sparse and irregular sampling, infinite dimensionality, and non-Gaussian
structures. To address these challenges, we introduce a novel framework named
Smooth Flow Matching (SFM), tailored for generative modeling of functional data
to enable statistical analysis without exposing sensitive real data. Built upon
flow-matching ideas, SFM constructs a semiparametric copula flow to generate
infinite-dimensional functional data, free from Gaussianity or low-rank
assumptions. It is computationally efficient, handles irregular observations,
and guarantees the smoothness of the generated functions, offering a practical
and flexible solution in scenarios where existing deep generative methods are
not applicable. Through extensive simulation studies, we demonstrate the
advantages of SFM in terms of both synthetic data quality and computational
efficiency. We then apply SFM to generate clinical trajectory data from the
MIMIC-IV patient electronic health records (EHR) longitudinal database. Our
analysis showcases the ability of SFM to produce high-quality surrogate data
for downstream statistical tasks, highlighting its potential to boost the
utility of EHR data for clinical applications.",http://arxiv.org/pdf/2508.13831v1,,False
DegDiT: Controllable Audio Generation with Dynamic Event Graph Guided Diffusion Transformer,19/08/2025,"Yisu Liu, Chenxing Li, Wanqian Zhang, Wenfu Wang, Meng Yu, Ruibo Fu, Zheng Lin, Weiping Wang, Dong Yu","Controllable text-to-audio generation aims to synthesize audio from textual
descriptions while satisfying user-specified constraints, including event
types, temporal sequences, and onset and offset timestamps. This enables
precise control over both the content and temporal structure of the generated
audio. Despite recent progress, existing methods still face inherent trade-offs
among accurate temporal localization, open-vocabulary scalability, and
practical efficiency. To address these challenges, we propose DegDiT, a novel
dynamic event graph-guided diffusion transformer framework for open-vocabulary
controllable audio generation. DegDiT encodes the events in the description as
structured dynamic graphs. The nodes in each graph are designed to represent
three aspects: semantic features, temporal attributes, and inter-event
connections. A graph transformer is employed to integrate these nodes and
produce contextualized event embeddings that serve as guidance for the
diffusion model. To ensure high-quality and diverse training data, we introduce
a quality-balanced data selection pipeline that combines hierarchical event
annotation with multi-criteria quality scoring, resulting in a curated dataset
with semantic diversity. Furthermore, we present consensus preference
optimization, facilitating audio generation through consensus among multiple
reward signals. Extensive experiments on AudioCondition, DESED, and AudioTime
datasets demonstrate that DegDiT achieves state-of-the-art performances across
a variety of objective and subjective evaluation metrics.",http://arxiv.org/pdf/2508.13786v1,,False
Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models,19/08/2025,"Wenxuan Ye, Xueli An, Onur Ayan, Junfan Wang, Xueqiang Yan, Georg Carle","Large models, renowned for superior performance, outperform smaller ones even
without billion-parameter scales. While mobile network servers have ample
computational resources to support larger models than client devices, privacy
constraints prevent clients from directly sharing their raw data. Federated
Learning (FL) enables decentralized clients to collaboratively train a shared
model by exchanging model parameters instead of transmitting raw data. Yet, it
requires a uniform model architecture and multiple communication rounds, which
neglect resource heterogeneity, impose heavy computational demands on clients,
and increase communication overhead. To address these challenges, we propose
FedOL, to construct a larger and more comprehensive server model in one-shot
settings (i.e., in a single communication round). Instead of model parameter
sharing, FedOL employs knowledge distillation, where clients only exchange
model prediction outputs on an unlabeled public dataset. This reduces
communication overhead by transmitting compact predictions instead of full
model weights and enables model customization by allowing heterogeneous model
architectures. A key challenge in this setting is that client predictions may
be biased due to skewed local data distributions, and the lack of ground-truth
labels in the public dataset further complicates reliable learning. To mitigate
these issues, FedOL introduces a specialized objective function that
iteratively refines pseudo-labels and the server model, improving learning
reliability. To complement this, FedOL incorporates a tailored pseudo-label
generation and knowledge distillation strategy that effectively integrates
diverse knowledge. Simulation results show that FedOL significantly outperforms
existing baselines, offering a cost-effective solution for mobile networks
where clients possess valuable private data but limited computational
resources.",http://arxiv.org/pdf/2508.13625v1,,False
Bounding Causal Effects and Counterfactuals,19/08/2025,Tobias Maringgele,"Causal inference often hinges on strong assumptions - such as no unmeasured
confounding or perfect compliance - that are rarely satisfied in practice.
Partial identification offers a principled alternative: instead of relying on
unverifiable assumptions to estimate causal effects precisely, it derives
bounds that reflect the uncertainty inherent in the data. Despite its
theoretical appeal, partial identification remains underutilized in applied
work, in part due to the fragmented nature of existing methods and the lack of
practical guidance. This thesis addresses these challenges by systematically
comparing a diverse set of bounding algorithms across multiple causal
scenarios. We implement, extend, and unify state-of-the-art methods - including
symbolic, optimization-based, and information-theoretic approaches - within a
common evaluation framework. In particular, we propose an extension of a
recently introduced entropy-bounded method, making it applicable to
counterfactual queries such as the Probability of Necessity and Sufficiency
(PNS). Our empirical study spans thousands of randomized simulations involving
both discrete and continuous data-generating processes. We assess each method
in terms of bound tightness, computational efficiency, and robustness to
assumption violations. To support practitioners, we distill our findings into a
practical decision tree for algorithm selection and train a machine learning
model to predict the best-performing method based on observable data
characteristics.
  All implementations are released as part of an open-source Python package,
CausalBoundingEngine, which enables users to apply and compare bounding methods
through a unified interface.",http://arxiv.org/pdf/2508.13607v1,,False
MF-LPR$^2$: Multi-Frame License Plate Image Restoration and Recognition using Optical Flow,19/08/2025,"Kihyun Na, Junseok Oh, Youngkwan Cho, Bumjin Kim, Sungmin Cho, Jinyoung Choi, Injung Kim","License plate recognition (LPR) is important for traffic law enforcement,
crime investigation, and surveillance. However, license plate areas in dash cam
images often suffer from low resolution, motion blur, and glare, which make
accurate recognition challenging. Existing generative models that rely on
pretrained priors cannot reliably restore such poor-quality images, frequently
introducing severe artifacts and distortions. To address this issue, we propose
a novel multi-frame license plate restoration and recognition framework,
MF-LPR$^2$, which addresses ambiguities in poor-quality images by aligning and
aggregating neighboring frames instead of relying on pretrained knowledge. To
achieve accurate frame alignment, we employ a state-of-the-art optical flow
estimator in conjunction with carefully designed algorithms that detect and
correct erroneous optical flow estimations by leveraging the spatio-temporal
consistency inherent in license plate image sequences. Our approach enhances
both image quality and recognition accuracy while preserving the evidential
content of the input images. In addition, we constructed a novel Realistic LPR
(RLPR) dataset to evaluate MF-LPR$^2$. The RLPR dataset contains 200 pairs of
low-quality license plate image sequences and high-quality pseudo ground-truth
images, reflecting the complexities of real-world scenarios. In experiments,
MF-LPR$^2$ outperformed eight recent restoration models in terms of PSNR, SSIM,
and LPIPS by significant margins. In recognition, MF-LPR$^2$ achieved an
accuracy of 86.44%, outperforming both the best single-frame LPR (14.04%) and
the multi-frame LPR (82.55%) among the eleven baseline models. The results of
ablation studies confirm that our filtering and refinement algorithms
significantly contribute to these improvements.",http://arxiv.org/pdf/2508.14797v1,10.1016/j.cviu.2025.104361,False
Prediction of Hospital Associated Infections During Continuous Hospital Stays,19/08/2025,"Rituparna Datta, Methun Kamruzzaman, Eili Y. Klein, Gregory R Madden, Xinwei Deng, Anil Vullikanti, Parantapa Bhattacharya","The US Centers for Disease Control and Prevention (CDC), in 2019, designated
Methicillin-resistant Staphylococcus aureus (MRSA) as a serious antimicrobial
resistance threat. The risk of acquiring MRSA and suffering life-threatening
consequences due to it remains especially high for hospitalized patients due to
a unique combination of factors, including: co-morbid conditions, immuno
suppression, antibiotic use, and risk of contact with contaminated hospital
workers and equipment. In this paper, we present a novel generative
probabilistic model, GenHAI, for modeling sequences of MRSA test results
outcomes for patients during a single hospitalization. This model can be used
to answer many important questions from the perspectives of hospital
administrators for mitigating the risk of MRSA infections. Our model is based
on the probabilistic programming paradigm, and can be used to approximately
answer a variety of predictive, causal, and counterfactual questions. We
demonstrate the efficacy of our model by comparing it against discriminative
and generative machine learning models using two real-world datasets.",http://arxiv.org/pdf/2508.13561v1,,False
Portfolio construction using a sampling-based variational quantum scheme,19/08/2025,"Gabriele Agliardi, Dimitris Alevras, Vaibhaw Kumar, Roberto Lo Nardo, Gabriele Compostella, Sumit Kumar, Manuel Proissl, Bimal Mehta","The efficient and effective construction of portfolios that adhere to
real-world constraints is a challenging optimization task in finance. We
investigate a concrete representation of the problem with a focus on design
proposals of an Exchange Traded Fund. We evaluate the sampling-based CVaR
Variational Quantum Algorithm (VQA), combined with a local-search
post-processing, for solving problem instances that beyond a certain size
become classically hard. We also propose a problem formulation that is suited
for sampling-based VQA. Our utility-scale experiments on IBM Heron processors
involve 109 qubits and up to 4200 gates, achieving a relative solution error of
0.49%. Results indicate that a combined quantum-classical workflow achieves
better accuracy compared to purely classical local search, and that
hard-to-simulate quantum circuits may lead to better convergence than simpler
circuits. Our work paves the path to further explore portfolio construction
with quantum computers.",http://arxiv.org/pdf/2508.13557v1,,False
"MuFlex: A Scalable, Physics-based Platform for Multi-Building Flexibility Analysis and Coordination",19/08/2025,"Ziyan Wu, Ivan Korolija, Rui Tang","With the increasing penetration of renewable generation on the power grid,
maintaining system balance requires coordinated demand flexibility from
aggregations of buildings. Reinforcement learning (RL) has been widely explored
for building controls because of its model-free nature. Open-source simulation
testbeds are essential not only for training RL agents but also for fairly
benchmarking control strategies. However, most building-sector testbeds target
single buildings; multi-building platforms are relatively limited and typically
rely on simplified models (e.g., Resistance-Capacitance) or data-driven
approaches, which lack the ability to fully capture the physical intricacies
and intermediate variables necessary for interpreting control performance.
Moreover, these platforms often impose fixed inputs, outputs, and model
formats, restricting their applicability as benchmarking tools across diverse
control scenarios. To address these gaps, MuFlex, a scalable, open-source
platform for benchmarking and testing control strategies for multi-building
flexibility coordination, was developed in this study. MuFlex enables
synchronous information exchange across EnergyPlus building models and adheres
to the latest OpenAI Gym interface, providing a modular, standardized RL
implementation. The platform capabilities were demonstrated in a case study
coordinating demand flexibility across four office buildings using the Soft
Actor-Critic algorithm with carefully fine-tuned hyperparameters. The results
show that aggregating the four buildings flexibility reduced total peak demand
below a specified threshold while maintaining indoor environmental quality.",http://arxiv.org/pdf/2508.13532v1,,False
EventTSF: Event-Aware Non-Stationary Time Series Forecasting,19/08/2025,"Yunfeng Ge, Ming Jin, Yiji Zhao, Hongyan Li, Bo Du, Chang Xu, Shirui Pan","Time series forecasting plays a vital role in critical domains like energy
and transportation, where non-stationary dynamics are deeply intertwined with
events in other modalities such as texts. However, incorporating natural
language-based external events to improve non-stationary forecasting remains
largely unexplored, as most approaches still rely on a single modality,
resulting in limited contextual knowledge and model underperformance. Enabling
fine-grained multimodal interactions between temporal and textual data is
challenged by three fundamental issues: (1) the difficulty of fine-grained
synchronization between time-varying discrete textual events and continuous
time series; (2) the inherent temporal uncertainty introduced by textual
semantics; and (3) the misalignment between textual event embeddings and
multi-resolution temporal patterns. In this work, we address these challenges
by introducing event-aware non-stationary time series forecasting (EventTSF),
an autoregressive generation framework that integrates historical time series
with textual events to make subsequent forecasts. Specifically, EventTSF uses
autoregressive diffusion with flow matching at each step to capture nuanced
temporal-event interactions. To handle event-induced uncertainty, flow matching
timesteps are adaptively controlled according to event semantic signals. The
underlying denoiser employs a multimodal U-shaped diffusion transformer that
efficiently fuses temporal and textual modalities across different resolutions.
Extensive experiments on 8 synthetic and real-world datasets show that EventTSF
outperforms 12 baselines across diverse event-aware non-stationary time series
forecasting scenarios, achieving substantial improvements of 10.7% higher
forecasting accuracy and $1.13\times$ faster training efficiency.",http://arxiv.org/pdf/2508.13434v1,,False
