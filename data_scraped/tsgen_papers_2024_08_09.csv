Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Risk and cross validation in ridge regression with correlated samples,08/08/2024,"Alexander Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan","Recent years have seen substantial advances in our understanding of
high-dimensional ridge regression, but existing theories assume that training
examples are independent. By leveraging recent techniques from random matrix
theory and free probability, we provide sharp asymptotics for the in- and
out-of-sample risks of ridge regression when the data points have arbitrary
correlations. We demonstrate that in this setting, the generalized cross
validation estimator (GCV) fails to correctly predict the out-of-sample risk.
However, in the case where the noise residuals have the same correlations as
the data points, one can modify the GCV to yield an efficiently-computable
unbiased estimator that concentrates in the high-dimensional limit, which we
dub CorrGCV. We further extend our asymptotic analysis to the case where the
test point has nontrivial correlations with the training set, a setting often
encountered in time series forecasting. Assuming knowledge of the correlation
structure of the time series, this again yields an extension of the GCV
estimator, and sharply characterizes the degree to which such test points yield
an overly optimistic prediction of long-time risk. We validate the predictions
of our theory across a variety of high dimensional data.",http://arxiv.org/pdf/2408.04607v1,,False
SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals,08/08/2024,"Haoran Zheng, Utku Pamuksuz","Explainable Artificial Intelligence (XAI) is essential for enhancing the
transparency and accountability of AI models, especially in natural language
processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual
Evaluation for Natural language Explainability), a novel evaluation method that
leverages large language models (LLMs) to generate Soft Counterfactual
explanations in a zero-shot manner. By focusing on token-based substitutions,
SCENE creates contextually appropriate and seman-tically meaningful Soft
Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and
Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in
text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE
provides valuable insights into the strengths and limitations of various XAI
techniques.",http://arxiv.org/pdf/2408.04575v1,,False
Knowledge-Aided Semantic Communication Leveraging Probabilistic Graphical Modeling,08/08/2024,"Haowen Wan, Qianqian Yang, Jiancheng Tang, Zhiguo shi","In this paper, we propose a semantic communication approach based on
probabilistic graphical model (PGM). The proposed approach involves
constructing a PGM from a training dataset, which is then shared as common
knowledge between the transmitter and receiver. We evaluate the importance of
various semantic features and present a PGM-based compression algorithm
designed to eliminate predictable portions of semantic information.
Furthermore, we introduce a technique to reconstruct the discarded semantic
information at the receiver end, generating approximate results based on the
PGM. Simulation results indicate a significant improvement in transmission
efficiency over existing methods, while maintaining the quality of the
transmitted images.",http://arxiv.org/pdf/2408.04499v1,,False
Robustness investigation of quality measures for the assessment of machine learning models,08/08/2024,"Thomas Most, Lars Gräning, Sebastian Wolff","In this paper the accuracy and robustness of quality measures for the
assessment of machine learning models are investigated. The prediction quality
of a machine learning model is evaluated model-independent based on a
cross-validation approach, where the approximation error is estimated for
unknown data. The presented measures quantify the amount of explained variation
in the model prediction. The reliability of these measures is assessed by means
of several numerical examples, where an additional data set for the
verification of the estimated prediction error is available. Furthermore, the
confidence bounds of the presented quality measures are estimated and local
quality measures are derived from the prediction residuals obtained by the
cross-validation approach.",http://arxiv.org/pdf/2408.04391v1,,False
Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon,08/08/2024,"Jiang You, Arben Cela, René Natowicz, Jacob Ouanounou, Patrick Siarry","Detecting anomalies in time series data is a critical challenge across
various domains. Traditional methods typically focus on identifying anomalies
in immediate subsequent steps, often underestimating the significance of
temporal dynamics such as delay time and horizons of anomalies, which generally
require extensive post-analysis. This paper introduces a novel approach for
time series anomaly prediction, incorporating temporal information directly
into the prediction results. We propose a new dataset specifically designed to
evaluate this approach and conduct comprehensive experiments using several
state-of-the-art methods. results demonstrate the efficacy of our approach in
providing timely and accurate anomaly predictions, setting a new benchmark for
future research in this field.",http://arxiv.org/pdf/2408.04377v1,,False
Generating Fine-Grained Causality in Climate Time Series Data for Forecasting and Anomaly Detection,08/08/2024,"Dongqi Fu, Yada Zhu, Hanghang Tong, Kommy Weldemariam, Onkar Bhardwaj, Jingrui He","Understanding the causal interaction of time series variables can contribute
to time series data analysis for many real-world applications, such as climate
forecasting and extreme weather alerts. However, causal relationships are
difficult to be fully observed in real-world complex settings, such as
spatial-temporal data from deployed sensor networks. Therefore, to capture
fine-grained causal relations among spatial-temporal variables for further a
more accurate and reliable time series analysis, we first design a conceptual
fine-grained causal model named TBN Granger Causality, which adds
time-respecting Bayesian Networks to the previous time-lagged Neural Granger
Causality to offset the instantaneous effects. Second, we propose an end-to-end
deep generative model called TacSas, which discovers TBN Granger Causality in a
generative manner to help forecast time series data and detect possible
anomalies during the forecast. For evaluations, besides the causality discovery
benchmark Lorenz-96, we also test TacSas on climate benchmark ERA5 for climate
forecasting and the extreme weather benchmark of NOAA for extreme weather
alerts.",http://arxiv.org/pdf/2408.04254v1,,False
The Ungrounded Alignment Problem,08/08/2024,"Marc Pickett, Aakash Kumar Nain, Joseph Modayil, Llion Jones","Modern machine learning systems have demonstrated substantial abilities with
methods that either embrace or ignore human-provided knowledge, but combining
benefits of both styles remains a challenge. One particular challenge involves
designing learning systems that exhibit built-in responses to specific abstract
stimulus patterns, yet are still plastic enough to be agnostic about the
modality and exact form of their inputs. In this paper, we investigate what we
call The Ungrounded Alignment Problem, which asks How can we build in
predefined knowledge in a system where we don't know how a given stimulus will
be grounded? This paper examines a simplified version of the general problem,
where an unsupervised learner is presented with a sequence of images for the
characters in a text corpus, and this learner is later evaluated on its ability
to recognize specific (possibly rare) sequential patterns. Importantly, the
learner is given no labels during learning or evaluation, but must map images
from an unknown font or permutation to its correct class label. That is, at no
point is our learner given labeled images, where an image vector is explicitly
associated with a class label. Despite ample work in unsupervised and
self-supervised loss functions, all current methods require a labeled
fine-tuning phase to map the learned representations to correct classes.
Finding this mapping in the absence of labels may seem a fool's errand, but our
main result resolves this seeming paradox. We show that leveraging only letter
bigram frequencies is sufficient for an unsupervised learner both to reliably
associate images to class labels and to reliably identify trigger words in the
sequence of inputs. More generally, this method suggests an approach for
encoding specific desired innate behaviour in modality-agnostic models.",http://arxiv.org/pdf/2408.04242v1,,False
Cluster-Wide Task Slowdown Detection in Cloud System,08/08/2024,"Feiyi Chen, Yingying Zhang, Lunting Fan, Yuxuan Liang, Guansong Pang, Qingsong Wen, Shuiguang Deng","Slow task detection is a critical problem in cloud operation and maintenance
since it is highly related to user experience and can bring substantial
liquidated damages. Most anomaly detection methods detect it from a single-task
aspect. However, considering millions of concurrent tasks in large-scale cloud
computing clusters, it becomes impractical and inefficient. Moreover,
single-task slowdowns are very common and do not necessarily indicate a
malfunction of a cluster due to its violent fluctuation nature in a virtual
environment. Thus, we shift our attention to cluster-wide task slowdowns by
utilizing the duration time distribution of tasks across a cluster, so that the
computation complexity is not relevant to the number of tasks.
  The task duration time distribution often exhibits compound periodicity and
local exceptional fluctuations over time. Though transformer-based methods are
one of the most powerful methods to capture these time series normal variation
patterns, we empirically find and theoretically explain the flaw of the
standard attention mechanism in reconstructing subperiods with low amplitude
when dealing with compound periodicity.
  To tackle these challenges, we propose SORN (i.e., Skimming Off subperiods in
descending amplitude order and Reconstructing Non-slowing fluctuation), which
consists of a Skimming Attention mechanism to reconstruct the compound
periodicity and a Neural Optimal Transport module to distinguish cluster-wide
slowdowns from other exceptional fluctuations. Furthermore, since anomalies in
the training set are inevitable in a practical scenario, we propose a picky
loss function, which adaptively assigns higher weights to reliable time slots
in the training set. Extensive experiments demonstrate that SORN outperforms
state-of-the-art methods on multiple real-world industrial datasets.",http://arxiv.org/pdf/2408.04236v1,,False
