Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading,22/10/2024,"Zimeng Lyu, Amulya Saxena, Rohaan Nadeem, Hao Zhang, Travis Desell","Stock return forecasting is a major component of numerous finance
applications. Predicted stock returns can be incorporated into portfolio
trading algorithms to make informed buy or sell decisions which can optimize
returns. In such portfolio trading applications, the predictive performance of
a time series forecasting model is crucial. In this work, we propose the use of
the Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to
progressively evolve recurrent neural networks (RNNs) for stock return
predictions. RNNs are evolved independently for each stocks and portfolio
trading decisions are made based on the predicted stock returns. The portfolio
used for testing consists of the 30 companies in the Dow-Jones Index (DJI) with
each stock have the same weight. Results show that using these evolved RNNs and
a simple daily long-short strategy can generate higher returns than both the
DJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull
market).",http://arxiv.org/pdf/2410.17212v1,,False
Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding,22/10/2024,"Yasha Ektefaie, Olivia Viessmann, Siddharth Narayanan, Drew Dresser, J. Mark Kim, Armen Mkrtchyan","Protein inverse folding-that is, predicting an amino acid sequence that will
fold into the desired 3D structure-is an important problem for structure-based
protein design. Machine learning based methods for inverse folding typically
use recovery of the original sequence as the optimization objective. However,
inverse folding is a one-to-many problem where several sequences can fold to
the same structure. Moreover, for many practical applications, it is often
desirable to have multiple, diverse sequences that fold into the target
structure since it allows for more candidate sequences for downstream
optimizations. Here, we demonstrate that although recent inverse folding
methods show increased sequence recovery, their ""foldable diversity""-i.e. their
ability to generate multiple non-similar sequences that fold into the
structures consistent with the target-does not increase. To address this, we
present RL-DIF, a categorical diffusion model for inverse folding that is
pre-trained on sequence recovery and tuned via reinforcement learning on
structural consistency. We find that RL-DIF achieves comparable sequence
recovery and structural consistency to benchmark models but shows greater
foldable diversity: experiments show RL-DIF can achieve an foldable diversity
of 29% on CATH 4.2, compared to 23% from models trained on the same dataset.
The PyTorch model weights and sampling code are available on GitHub.",http://arxiv.org/pdf/2410.17173v1,,False
LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting,22/10/2024,"Guoqi Yu, Yaoming Li, Xiaoyu Guo, Dayu Wang, Zirui Liu, Shujun Wang, Tong Yang","Forecasting models are pivotal in a data-driven world with vast volumes of
time series data that appear as a compound of vast Linear and Nonlinear
patterns. Recent deep time series forecasting models struggle to utilize
seasonal and trend decomposition to separate the entangled components. Such a
strategy only explicitly extracts simple linear patterns like trends, leaving
the other linear modes and vast unexplored nonlinear patterns to the residual.
Their flawed linear and nonlinear feature extraction models and shallow-level
decomposition limit their adaptation to the diverse patterns present in
real-world scenarios. Given this, we innovate Recursive Residual Decomposition
by introducing explicit extraction of both linear and nonlinear patterns. This
deeper-level decomposition framework, which is named LiNo, captures linear
patterns using a Li block which can be a moving average kernel, and models
nonlinear patterns using a No block which can be a Transformer encoder. The
extraction of these two patterns is performed alternatively and recursively. To
achieve the full potential of LiNo, we develop the current simple linear
pattern extractor to a general learnable autoregressive model, and design a
novel No block that can handle all essential nonlinear patterns. Remarkably,
the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks
under univariate and multivariate forecasting scenarios. Experiments show that
current forecasting models can deliver more robust and precise results through
this advanced Recursive Residual Decomposition. We hope this work could offer
insight into designing more effective forecasting models. Code is available at
this Repository: https://github.com/Levi-Ackman/LiNo.",http://arxiv.org/pdf/2410.17159v1,,False
Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance,22/10/2024,"Dominik Fuchsgruber, Tim Poštuvan, Stephan Günnemann, Simon Geisler","Many applications in traffic, civil engineering, or electrical engineering
revolve around edge-level signals. Such signals can be categorized as
inherently directed, for example, the water flow in a pipe network, and
undirected, like the diameter of a pipe. Topological methods model edge signals
with inherent direction by representing them relative to a so-called
orientation assigned to each edge. These approaches can neither model
undirected edge signals nor distinguish if an edge itself is directed or
undirected. We address these shortcomings by (i) revising the notion of
orientation equivariance to enable edge direction-aware topological models,
(ii) proposing orientation invariance as an additional requirement to describe
signals without inherent direction, and (iii) developing EIGN, an architecture
composed of novel direction-aware edge-level graph shift operators, that
provably fulfills the aforementioned desiderata. It is the first
general-purpose topological GNN for edge-level signals that can model directed
and undirected signals while distinguishing between directed and undirected
edges. A comprehensive evaluation shows that EIGN outperforms prior work in
edge-level tasks, for example, improving in RMSE on flow simulation tasks by up
to 43.5%.",http://arxiv.org/pdf/2410.16935v1,,False
xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories,22/10/2024,"Maurice Kraus, Felix Divo, Devendra Singh Dhami, Kristian Kersting","Time series data is prevalent across numerous fields, necessitating the
development of robust and accurate forecasting models. Capturing patterns both
within and between temporal and multivariate components is crucial for reliable
predictions. We introduce xLSTM-Mixer, a model designed to effectively
integrate temporal sequences, joint time-variate information, and multiple
perspectives for robust forecasting. Our approach begins with a linear forecast
shared across variates, which is then refined by xLSTM blocks. These blocks
serve as key elements for modeling the complex dynamics of challenging time
series data. xLSTM-Mixer ultimately reconciles two distinct views to produce
the final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's
superior long-term forecasting performance compared to recent state-of-the-art
methods. A thorough model analysis provides further insights into its key
components and confirms its robustness and effectiveness. This work contributes
to the resurgence of recurrent models in time series forecasting.",http://arxiv.org/pdf/2410.16928v1,,False
SleepCoT: A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation,22/10/2024,"Huimin Zheng, Xiaofeng Xing, Xiangmin Xu","We present a novel approach to personalized sleep health management using
few-shot Chain-of-Thought (CoT) distillation, enabling small-scale language
models (> 2B parameters) to rival the performance of large language models
(LLMs) in specialized health domains. Our method simultaneously distills
problem-solving strategies, long-tail expert knowledge, and personalized
recommendation capabilities from larger models into more efficient, compact
models. Unlike existing systems, our approach offers three key functionalities:
generating personalized sleep health recommendations, supporting user-specific
follow-up inquiries, and providing responses to domain-specific knowledge
questions. We focus on sleep health due to its measurability via wearable
devices and its impact on overall well-being. Our experimental setup, involving
GPT-4o for data synthesis, Qwen-max for instruction set creation, and Qwen2.5
1.5B for model distillation, demonstrates significant improvements over
baseline small-scale models in penalization, reasoning, and knowledge
application. Experiments using 100 simulated sleep reports and 1,000
domain-specific questions shows our model achieves comparable performance to
larger models while maintaining efficiency for real-world deployment. This
research not only advances AI-driven health management but also provides a
novel approach to leveraging LLM capabilities in resource-constrained
environments, potentially enhancing the accessibility of personalized
healthcare solutions.",http://arxiv.org/pdf/2410.16924v1,,False
Unsupervised Time Series Anomaly Prediction with Importance-based Generative Contrastive Learning,22/10/2024,"Kai Zhao, Zhihao Zhuang, Chenjuan Guo, Hao Miao, Yunyao Cheng, Bin Yang","Time series anomaly prediction plays an essential role in many real-world
scenarios, such as environmental prevention and prompt maintenance of
cyber-physical systems. However, existing time series anomaly prediction
methods mainly require supervised training with plenty of manually labeled
data, which are difficult to obtain in practice. Besides, unseen anomalies can
occur during inference, which could differ from the labeled training data and
make these models fail to predict such new anomalies. In this paper, we study a
novel problem of unsupervised time series anomaly prediction. We provide a
theoretical analysis and propose Importance-based Generative Contrastive
Learning (IGCL) to address the aforementioned problems. IGCL distinguishes
between normal and anomaly precursors, which are generated by our anomaly
precursor pattern generation module. To address the efficiency issues caused by
the potential complex anomaly precursor combinations, we propose a memory bank
with importance-based scores to adaptively store representative anomaly
precursors and generate more complicated anomaly precursors. Extensive
experiments on seven benchmark datasets show our method outperforms
state-of-the-art baselines on unsupervised time series anomaly prediction
problems.",http://arxiv.org/pdf/2410.16888v1,,False
PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding,22/10/2024,Vinh Nguyen,"Generating detailed descriptions from multiple cameras and viewpoints is
challenging due to the complex and inconsistent nature of visual data. In this
paper, we introduce PerspectiveNet, a lightweight yet efficient model for
generating long descriptions across multiple camera views. Our approach
utilizes a vision encoder, a compact connector module to convert visual
features into a fixed-size tensor, and large language models (LLMs) to harness
the strong natural language generation capabilities of LLMs. The connector
module is designed with three main goals: mapping visual features onto LLM
embeddings, emphasizing key information needed for description generation, and
producing a fixed-size feature matrix. Additionally, we augment our solution
with a secondary task, the correct frame sequence detection, enabling the model
to search for the correct sequence of frames to generate descriptions. Finally,
we integrate the connector module, the secondary task, the LLM, and a visual
feature extraction model into a single architecture, which is trained for the
Traffic Safety Description and Analysis task. This task requires generating
detailed, fine-grained descriptions of events from multiple cameras and
viewpoints. The resulting model is lightweight, ensuring efficient training and
inference, while remaining highly effective.",http://arxiv.org/pdf/2410.16824v1,,False
SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition,22/10/2024,"Jiaqi Chen, Yan Yang, Shizhuo Deng, Da Teng, Liyuan Pan","Human action recognition (HAR) plays a key role in various applications such
as video analysis, surveillance, autonomous driving, robotics, and healthcare.
Most HAR algorithms are developed from RGB images, which capture detailed
visual information. However, these algorithms raise concerns in
privacy-sensitive environments due to the recording of identifiable features.
Event cameras offer a promising solution by capturing scene brightness changes
sparsely at the pixel level, without capturing full images. Moreover, event
cameras have high dynamic ranges that can effectively handle scenarios with
complex lighting conditions, such as low light or high contrast environments.
However, using event cameras introduces challenges in modeling the spatially
sparse and high temporal resolution event data for HAR. To address these
issues, we propose the SpikMamba framework, which combines the energy
efficiency of spiking neural networks and the long sequence modeling capability
of Mamba to efficiently capture global features from spatially sparse and high
a temporal resolution event data. Additionally, to improve the locality of
modeling, a spiking window-based linear attention mechanism is used. Extensive
experiments show that SpikMamba achieves remarkable recognition performance,
surpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on
the PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is
available at https://github.com/Typistchen/SpikMamba.",http://arxiv.org/pdf/2410.16746v1,,False
Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World,22/10/2024,"Joshua Kazdan, Rylan Schaeffer, Apratim Dey, Matthias Gerstgrasser, Rafael Rafailov, David L. Donoho, Sanmi Koyejo","The increasing presence of AI-generated content on the internet raises a
critical question: What happens when generative machine learning models are
pretrained on web-scale datasets containing data created by earlier models?
Some authors prophesy $\textit{model collapse}$ under a ""$\textit{replace}$""
scenario: a sequence of models, the first trained with real data and each later
one trained only on synthetic data from its preceding model. In this scenario,
models successively degrade. Others see collapse as easily avoidable; in an
""$\textit{accumulate}$' scenario, a sequence of models is trained, but each
training uses all real and synthetic data generated so far. In this work, we
deepen and extend the study of these contrasting scenarios. First, collapse
versus avoidance of collapse is studied by comparing the replace and accumulate
scenarios on each of three prominent generative modeling settings; we find the
same contrast emerges in all three settings. Second, we study a compromise
scenario; the available data remains the same as in the accumulate scenario --
but unlike $\textit{accumulate}$ and like $\textit{replace}$, each model is
trained using a fixed compute budget; we demonstrate that model test loss on
real data is larger than in the $\textit{accumulate}$ scenario, but apparently
plateaus, unlike the divergence seen with $\textit{replace}$. Third, we study
the relative importance of cardinality and proportion of real data for avoiding
model collapse. Surprisingly, we find a non-trivial interaction between real
and synthetic data, where the value of synthetic data for reducing test loss
depends on the absolute quantity of real data. Our insights are particularly
important when forecasting whether future frontier generative models will
collapse or thrive, and our results open avenues for empirically and
mathematically studying the context-dependent value of synthetic data.",http://arxiv.org/pdf/2410.16713v1,,False
MPT: A Large-scale Multi-Phytoplankton Tracking Benchmark,22/10/2024,"Yang Yu, Yuezun Li, Xin Sun, Junyu Dong","Phytoplankton are a crucial component of aquatic ecosystems, and effective
monitoring of them can provide valuable insights into ocean environments and
ecosystem changes. Traditional phytoplankton monitoring methods are often
complex and lack timely analysis. Therefore, deep learning algorithms offer a
promising approach for automated phytoplankton monitoring. However, the lack of
large-scale, high-quality training samples has become a major bottleneck in
advancing phytoplankton tracking. In this paper, we propose a challenging
benchmark dataset, Multiple Phytoplankton Tracking (MPT), which covers diverse
background information and variations in motion during observation. The dataset
includes 27 species of phytoplankton and zooplankton, 14 different backgrounds
to simulate diverse and complex underwater environments, and a total of 140
videos. To enable accurate real-time observation of phytoplankton, we introduce
a multi-object tracking method, Deviation-Corrected Multi-Scale Feature Fusion
Tracker(DSFT), which addresses issues such as focus shifts during tracking and
the loss of small target information when computing frame-to-frame similarity.
Specifically, we introduce an additional feature extractor to predict the
residuals of the standard feature extractor's output, and compute multi-scale
frame-to-frame similarity based on features from different layers of the
extractor. Extensive experiments on the MPT have demonstrated the validity of
the dataset and the superiority of DSFT in tracking phytoplankton, providing an
effective solution for phytoplankton monitoring.",http://arxiv.org/pdf/2410.16695v1,,False
GE2E-KWS: Generalized End-to-End Training and Evaluation for Zero-shot Keyword Spotting,22/10/2024,"Pai Zhu, Jacob W. Bartel, Dhruuv Agarwal, Kurt Partridge, Hyun Jin Park, Quan Wang","We propose GE2E-KWS -- a generalized end-to-end training and evaluation
framework for customized keyword spotting. Specifically, enrollment utterances
are separated and grouped by keywords from the training batch and their
embedding centroids are compared to all other test utterance embeddings to
compute the loss. This simulates runtime enrollment and verification stages,
and improves convergence stability and training speed by optimizing matrix
operations compared to SOTA triplet loss approaches. To benchmark different
models reliably, we propose an evaluation process that mimics the production
environment and compute metrics that directly measure keyword matching
accuracy. Trained with GE2E loss, our 419KB quantized conformer model beats a
7.5GB ASR encoder by 23.6% relative AUC, and beats a same size triplet loss
model by 60.7% AUC. Our KWS models are natively streamable with low memory
footprints, and designed to continuously run on-device with no retraining
needed for new keywords (zero-shot).",http://arxiv.org/pdf/2410.16647v1,,False
General Frameworks for Conditional Two-Sample Testing,22/10/2024,"Seongchan Lee, Suman Cha, Ilmun Kim","We study the problem of conditional two-sample testing, which aims to
determine whether two populations have the same distribution after accounting
for confounding factors. This problem commonly arises in various applications,
such as domain adaptation and algorithmic fairness, where comparing two groups
is essential while controlling for confounding variables. We begin by
establishing a hardness result for conditional two-sample testing,
demonstrating that no valid test can have significant power against any single
alternative without proper assumptions. We then introduce two general
frameworks that implicitly or explicitly target specific classes of
distributions for their validity and power. Our first framework allows us to
convert any conditional independence test into a conditional two-sample test in
a black-box manner, while preserving the asymptotic properties of the original
conditional independence test. The second framework transforms the problem into
comparing marginal distributions with estimated density ratios, which allows us
to leverage existing methods for marginal two-sample testing. We demonstrate
this idea in a concrete manner with classification and kernel-based methods.
Finally, simulation studies are conducted to illustrate the proposed frameworks
in finite-sample scenarios.",http://arxiv.org/pdf/2410.16636v1,,False
