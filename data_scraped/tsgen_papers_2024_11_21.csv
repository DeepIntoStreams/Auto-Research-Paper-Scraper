Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Conformal Prediction for Hierarchical Data,20/11/2024,"Guillaume Principato, Yvenn Amara-Ouali, Yannig Goude, Bachir Hamrouche, Jean-Michel Poggi, Gilles Stoltz","Reconciliation has become an essential tool in multivariate point forecasting
for hierarchical time series. However, there is still a lack of understanding
of the theoretical properties of probabilistic Forecast Reconciliation
techniques. Meanwhile, Conformal Prediction is a general framework with growing
appeal that provides prediction sets with probabilistic guarantees in finite
sample. In this paper, we propose a first step towards combining Conformal
Prediction and Forecast Reconciliation by analyzing how including a
reconciliation step in the Split Conformal Prediction (SCP) procedure enhances
the resulting prediction sets. In particular, we show that the validity granted
by SCP remains while improving the efficiency of the prediction sets. We also
advocate a variation of the theoretical procedure for practical use. Finally,
we illustrate these results with simulations.",http://arxiv.org/pdf/2411.13479v1,,False
SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers,20/11/2024,"Hojjat Karami, David Atienza, Anisoara Ionescu","Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.",http://arxiv.org/pdf/2411.13428v1,,False
VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation,20/11/2024,"Ziyang Luo, Haoning Wu, Dongxu Li, Jing Ma, Mohan Kankanhalli, Junnan Li","Large multimodal models (LMMs) with advanced video analysis capabilities have
recently garnered significant attention. However, most evaluations rely on
traditional methods like multiple-choice questions in benchmarks such as
VideoMME and LongVideoBench, which are prone to lack the depth needed to
capture the complex demands of real-world users. To address this limitation-and
due to the prohibitive cost and slow pace of human annotation for video
tasks-we introduce VideoAutoArena, an arena-style benchmark inspired by LMSYS
Chatbot Arena's framework, designed to automatically assess LMMs' video
analysis abilities. VideoAutoArena utilizes user simulation to generate
open-ended, adaptive questions that rigorously assess model performance in
video understanding. The benchmark features an automated, scalable evaluation
framework, incorporating a modified ELO Rating System for fair and continuous
comparisons across multiple LMMs. To validate our automated judging system, we
construct a 'gold standard' using a carefully curated subset of human
annotations, demonstrating that our arena strongly aligns with human judgment
while maintaining scalability. Additionally, we introduce a fault-driven
evolution strategy, progressively increasing question complexity to push models
toward handling more challenging video analysis scenarios. Experimental results
demonstrate that VideoAutoArena effectively differentiates among
state-of-the-art LMMs, providing insights into model strengths and areas for
improvement. To further streamline our evaluation, we introduce VideoAutoBench
as an auxiliary benchmark, where human annotators label winners in a subset of
VideoAutoArena battles. We use GPT-4o as a judge to compare responses against
these human-validated answers. Together, VideoAutoArena and VideoAutoBench
offer a cost-effective, and scalable framework for evaluating LMMs in
user-centric video analysis.",http://arxiv.org/pdf/2411.13281v1,,False
BelHouse3D: A Benchmark Dataset for Assessing Occlusion Robustness in 3D Point Cloud Semantic Segmentation,20/11/2024,"Umamaheswaran Raman Kumar, Abdur Razzaq Fayjie, Jurgen Hannaert, Patrick Vandewalle","Large-scale 2D datasets have been instrumental in advancing machine learning;
however, progress in 3D vision tasks has been relatively slow. This disparity
is largely due to the limited availability of 3D benchmarking datasets. In
particular, creating real-world point cloud datasets for indoor scene semantic
segmentation presents considerable challenges, including data collection within
confined spaces and the costly, often inaccurate process of per-point labeling
to generate ground truths. While synthetic datasets address some of these
challenges, they often fail to replicate real-world conditions, particularly
the occlusions that occur in point clouds collected from real environments.
Existing 3D benchmarking datasets typically evaluate deep learning models under
the assumption that training and test data are independently and identically
distributed (IID), which affects the models' usability for real-world point
cloud segmentation. To address these challenges, we introduce the BelHouse3D
dataset, a new synthetic point cloud dataset designed for 3D indoor scene
semantic segmentation. This dataset is constructed using real-world references
from 32 houses in Belgium, ensuring that the synthetic data closely aligns with
real-world conditions. Additionally, we include a test set with data occlusion
to simulate out-of-distribution (OOD) scenarios, reflecting the occlusions
commonly encountered in real-world point clouds. We evaluate popular
point-based semantic segmentation methods using our OOD setting and present a
benchmark. We believe that BelHouse3D and its OOD setting will advance research
in 3D point cloud semantic segmentation for indoor scenes, providing valuable
insights for the development of more generalizable models.",http://arxiv.org/pdf/2411.13251v1,,False
Transforming the Hybrid Cloud for Emerging AI Workloads,20/11/2024,"Deming Chen, Alaa Youssef, Ruchi Pendse, André Schleife, Bryan K. Clark, Hendrik Hamann, Jingrui He, Teodoro Laino, Lav Varshney, Yuxiong Wang, Avirup Sil, Reyhaneh Jabbarvand, Tianyin Xu, Volodymyr Kindratenko, Carlos Costa, Sarita Adve, Charith Mendis, Minjia Zhang, Santiago Núñez-Corrales, Raghu Ganti, Mudhakar Srivatsa, Nam Sung Kim, Josep Torrellas, Jian Huang, Seetharami Seelam, Klara Nahrstedt, Tarek Abdelzaher, Tamar Eilam, Huimin Zhao, Matteo Manica, Ravishankar Iyer, Martin Hirzel, Vikram Adve, Darko Marinov, Hubertus Franke, Hanghang Tong, Elizabeth Ainsworth, Han Zhao, Deepak Vasisht, Minh Do, Fabio Oliveira, Giovanni Pacifici, Ruchir Puri, Priya Nagpurkar","This white paper, developed through close collaboration between IBM Research
and UIUC researchers within the IIDAI Institute, envisions transforming hybrid
cloud systems to meet the growing complexity of AI workloads through
innovative, full-stack co-design approaches, emphasizing usability,
manageability, affordability, adaptability, efficiency, and scalability. By
integrating cutting-edge technologies such as generative and agentic AI,
cross-layer automation and optimization, unified control plane, and composable
and adaptive system architecture, the proposed framework addresses critical
challenges in energy efficiency, performance, and cost-effectiveness.
Incorporating quantum computing as it matures will enable quantum-accelerated
simulations for materials science, climate modeling, and other high-impact
domains. Collaborative efforts between academia and industry are central to
this vision, driving advancements in foundation models for material design and
climate solutions, scalable multimodal data processing, and enhanced
physics-based AI emulators for applications like weather forecasting and carbon
sequestration. Research priorities include advancing AI agentic systems, LLM as
an Abstraction (LLMaaA), AI model optimization and unified abstractions across
heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient
programming model, middleware and platform, secure infrastructure,
application-adaptive cloud systems, and new quantum-classical collaborative
workflows. These ideas and solutions encompass both theoretical and practical
research questions, requiring coordinated input and support from the research
community. This joint initiative aims to establish hybrid clouds as secure,
efficient, and sustainable platforms, fostering breakthroughs in AI-driven
applications and scientific discovery across academia, industry, and society.",http://arxiv.org/pdf/2411.13239v1,,False
Quantum Kernel-Based Long Short-term Memory,20/11/2024,"Yu-Chao Hsu, Tai-Yu Li, Kuan-Cheng Chen","The integration of quantum computing into classical machine learning
architectures has emerged as a promising approach to enhance model efficiency
and computational capacity. In this work, we introduce the Quantum Kernel-Based
Long Short-Term Memory (QK-LSTM) network, which utilizes quantum kernel
functions within the classical LSTM framework to capture complex, non-linear
patterns in sequential data. By embedding input data into a high-dimensional
quantum feature space, the QK-LSTM model reduces the reliance on large
parameter sets, achieving effective compression while maintaining accuracy in
sequence modeling tasks. This quantum-enhanced architecture demonstrates
efficient convergence, robust loss minimization, and model compactness, making
it suitable for deployment in edge computing environments and resource-limited
quantum devices (especially in the NISQ era). Benchmark comparisons reveal that
QK-LSTM achieves performance on par with classical LSTM models, yet with fewer
parameters, underscoring its potential to advance quantum machine learning
applications in natural language processing and other domains requiring
efficient temporal data processing.",http://arxiv.org/pdf/2411.13225v1,,False
Engagement-Driven Content Generation with Large Language Models,20/11/2024,"Erica Coppolillo, Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco","Large Language Models (LLMs) exhibit significant persuasion capabilities in
one-on-one interactions, but their influence within social networks remains
underexplored. This study investigates the potential social impact of LLMs in
these environments, where interconnected users and complex opinion dynamics
pose unique challenges. In particular, we address the following research
question: can LLMs learn to generate meaningful content that maximizes user
engagement on social networks?
  To answer this question, we define a pipeline to guide the LLM-based content
generation which employs reinforcement learning with simulated feedback. In our
framework, the reward is based on an engagement model borrowed from the
literature on opinion dynamics and information propagation. Moreover, we force
the text generated by the LLM to be aligned with a given topic and to satisfy a
minimum fluency requirement.
  Using our framework, we analyze the capabilities and limitations of LLMs in
tackling the given task, specifically considering the relative positions of the
LLM as an agent within the social network and the distribution of opinions in
the network on the given topic. Our findings show the full potential of LLMs in
creating social engagement. Notable properties of our approach are that the
learning procedure is adaptive to the opinion distribution of the underlying
network and agnostic to the specifics of the engagement model, which is
embedded as a plug-and-play component. In this regard, our approach can be
easily refined for more complex engagement tasks and interventions in
computational social science.
  The code used for the experiments is publicly available at
https://anonymous.4open.science/r/EDCG/.",http://arxiv.org/pdf/2411.13187v1,,False
DRL-Based Optimization for AoI and Energy Consumption in C-V2X Enabled IoV,20/11/2024,"Zheng Zhang, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief","To address communication latency issues, the Third Generation Partnership
Project (3GPP) has defined Cellular-Vehicle to Everything (C-V2X) technology,
which includes Vehicle-to-Vehicle (V2V) communication for direct
vehicle-to-vehicle communication. However, this method requires vehicles to
autonomously select communication resources based on the Semi-Persistent
Scheduling (SPS) protocol, which may lead to collisions due to different
vehicles sharing the same communication resources, thereby affecting
communication effectiveness. Non-Orthogonal Multiple Access (NOMA) is
considered a potential solution for handling large-scale vehicle communication,
as it can enhance the Signal-to-Interference-plus-Noise Ratio (SINR) by
employing Successive Interference Cancellation (SIC), thereby reducing the
negative impact of communication collisions. When evaluating vehicle
communication performance, traditional metrics such as reliability and
transmission delay present certain contradictions. Introducing the new metric
Age of Information (AoI) provides a more comprehensive evaluation of
communication system. Additionally, to ensure service quality, user terminals
need to possess high computational capabilities, which may lead to increased
energy consumption, necessitating a trade-off between communication energy
consumption and effectiveness. Given the complexity and dynamics of
communication systems, Deep Reinforcement Learning (DRL) serves as an
intelligent learning method capable of learning optimal strategies in dynamic
environments. Therefore, this paper analyzes the effects of multi-priority
queues and NOMA on AoI in the C-V2X vehicular communication system and proposes
an energy consumption and AoI optimization method based on DRL. Finally,
through comparative simulations with baseline methods, the proposed approach
demonstrates its advances in terms of energy consumption and AoI.",http://arxiv.org/pdf/2411.13104v1,,False
"Branches, Assemble! Multi-Branch Cooperation Network for Large-Scale Click-Through Rate Prediction at Taobao",20/11/2024,"Xu Chen, Zida Cheng, Yuangang Pan, Shuai Xiao, Xiaoming Liu, Jinsong Lan, Qingwen Liu, Ivor W. Tsang","Existing click-through rate (CTR) prediction works have studied the role of
feature interaction through a variety of techniques. Each interaction technique
exhibits its own strength, and solely using one type could constrain the
model's capability to capture the complex feature relationships, especially for
industrial large-scale data with enormous users and items. Recent research
shows that effective CTR models often combine an MLP network with a dedicated
feature interaction network in a two-parallel structure. However, the interplay
and cooperative dynamics between different streams or branches remain
under-researched. In this work, we introduce a novel Multi-Branch Cooperation
Network (MBCnet) which enables multiple branch networks to collaborate with
each other for better complex feature interaction modeling. Specifically,
MBCnet consists of three branches: the Expert-based Feature Grouping and
Crossing (EFGC) branch that promotes the model's memorization ability of
specific feature fields, the low rank Cross Net branch and Deep branch to
enhance both explicit and implicit feature crossing for improved
generalization. Among branches, a novel cooperation scheme is proposed based on
two principles: branch co-teaching and moderate differentiation. Branch
co-teaching encourages well-learned branches to support poorly-learned ones on
specific training samples. Moderate differentiation advocates branches to
maintain a reasonable level of difference in their feature representations. The
cooperation strategy improves learning through mutual knowledge sharing via
co-teaching and boosts the discovery of diverse feature interactions across
branches. Extensive experiments on large-scale industrial datasets and online
A/B test demonstrate MBCnet's superior performance, delivering a 0.09 point
increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes will
be released soon.",http://arxiv.org/pdf/2411.13057v1,,False
Adaptive Process-Guided Learning: An Application in Predicting Lake DO Concentrations,20/11/2024,"Runlong Yu, Chonghao Qiu, Robert Ladwig, Paul C. Hanson, Yiqun Xie, Yanhua Li, Xiaowei Jia","This paper introduces a \textit{Process-Guided Learning (Pril)} framework
that integrates physical models with recurrent neural networks (RNNs) to
enhance the prediction of dissolved oxygen (DO) concentrations in lakes, which
is crucial for sustaining water quality and ecosystem health. Unlike
traditional RNNs, which may deliver high accuracy but often lack physical
consistency and broad applicability, the \textit{Pril} method incorporates
differential DO equations for each lake layer, modeling it as a first-order
linear solution using a forward Euler scheme with a daily timestep. However,
this method is sensitive to numerical instabilities. When drastic fluctuations
occur, the numerical integration is neither mass-conservative nor stable.
Especially during stratified conditions, exogenous fluxes into each layer cause
significant within-day changes in DO concentrations. To address this challenge,
we further propose an \textit{Adaptive Process-Guided Learning (April)} model,
which dynamically adjusts timesteps from daily to sub-daily intervals with the
aim of mitigating the discrepancies caused by variations in entrainment fluxes.
\textit{April} uses a generator-discriminator architecture to identify days
with significant DO fluctuations and employs a multi-step Euler scheme with
sub-daily timesteps to effectively manage these variations. We have tested our
methods on a wide range of lakes in the Midwestern USA, and demonstrated robust
capability in predicting DO concentrations even with limited training data.
While primarily focused on aquatic ecosystems, this approach is broadly
applicable to diverse scientific and engineering disciplines that utilize
process-based models, such as power engineering, climate science, and
biomedicine.",http://arxiv.org/pdf/2411.12973v1,,False
Shrinking POMCP: A Framework for Real-Time UAV Search and Rescue,20/11/2024,"Yunuo Zhang, Baiting Luo, Ayan Mukhopadhyay, Daniel Stojcsics, Daniel Elenius, Anirban Roy, Susmit Jha, Miklos Maroti, Xenofon Koutsoukos, Gabor Karsai, Abhishek Dubey","Efficient path optimization for drones in search and rescue operations faces
challenges, including limited visibility, time constraints, and complex
information gathering in urban environments. We present a comprehensive
approach to optimize UAV-based search and rescue operations in neighborhood
areas, utilizing both a 3D AirSim-ROS2 simulator and a 2D simulator. The path
planning problem is formulated as a partially observable Markov decision
process (POMDP), and we propose a novel ``Shrinking POMCP'' approach to address
time constraints. In the AirSim environment, we integrate our approach with a
probabilistic world model for belief maintenance and a neurosymbolic navigator
for obstacle avoidance. The 2D simulator employs surrogate ROS2 nodes with
equivalent functionality. We compare trajectories generated by different
approaches in the 2D simulator and evaluate performance across various belief
types in the 3D AirSim-ROS simulator. Experimental results from both simulators
demonstrate that our proposed shrinking POMCP solution achieves significant
improvements in search times compared to alternative methods, showcasing its
potential for enhancing the efficiency of UAV-assisted search and rescue
operations.",http://arxiv.org/pdf/2411.12967v1,,False
Machine learned reconstruction of tsunami dynamics from sparse observations,20/11/2024,"Edward McDugald, Arvind Mohan, Darren Engwirda, Agnese Marcato, Javier Santos","We investigate the use of the Senseiver, a transformer neural network
designed for sparse sensing applications, to estimate full-field surface height
measurements of tsunami waves from sparse observations. The model is trained on
a large ensemble of simulated data generated via a shallow water equations
solver, which we show to be a faithful reproduction for the underlying dynamics
by comparison to historical events. We train the model on a dataset consisting
of 8 tsunami simulations whose epicenters correspond to historical USGS
earthquake records, and where the model inputs are restricted to measurements
obtained at actively deployed buoy locations. We test the Senseiver on a
dataset consisting of 8 simulations not included in training, demonstrating its
capability for extrapolation. The results show remarkable resolution of fine
scale phase and amplitude features from the true field, provided that at least
a few of the sensors have obtained a non-zero signal. Throughout, we discuss
which forecasting techniques can be improved by this method, and suggest ways
in which the flexibility of the architecture can be leveraged to incorporate
arbitrary remote sensing data (eg. HF Radar and satellite measurements) as well
as investigate optimal sensor placements.",http://arxiv.org/pdf/2411.12948v1,,False
