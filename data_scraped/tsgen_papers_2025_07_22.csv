Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
ACS: An interactive framework for conformal selection,21/07/2025,"Yu Gui, Ying Jin, Yash Nair, Zhimei Ren","This paper presents adaptive conformal selection (ACS), an interactive
framework for model-free selection with guaranteed error control. Building on
conformal selection (Jin and Cand\`es, 2023b), ACS generalizes the approach to
support human-in-the-loop adaptive data analysis. Under the ACS framework, we
can partially reuse the data to boost the selection power, make decisions on
the fly while exploring the data, and incorporate new information or
preferences as they arise. The key to ACS is a carefully designed principle
that controls the information available for decision making, allowing the data
analyst to explore the data adaptively while maintaining rigorous control of
the false discovery rate (FDR). Based on the ACS framework, we provide concrete
selection algorithms for various goals, including model update/selection,
diversified selection, and incorporating newly available labeled data. The
effectiveness of ACS is demonstrated through extensive numerical simulations
and real-data applications in large language model (LLM) deployment and drug
discovery.",http://arxiv.org/pdf/2507.15825v1,,False
LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra,21/07/2025,"Seth Karten, Wenzhe Li, Zihan Ding, Samuel Kleiner, Yu Bai, Chi Jin","We present the LLM Economist, a novel framework that uses agent-based
modeling to design and assess economic policies in strategic environments with
hierarchical decision-making. At the lower level, bounded rational worker
agents -- instantiated as persona-conditioned prompts sampled from U.S.
Census-calibrated income and demographic statistics -- choose labor supply to
maximize text-based utility functions learned in-context. At the upper level, a
planner agent employs in-context reinforcement learning to propose
piecewise-linear marginal tax schedules anchored to the current U.S. federal
brackets. This construction endows economic simulacra with three capabilities
requisite for credible fiscal experimentation: (i) optimization of
heterogeneous utilities, (ii) principled generation of large, demographically
realistic agent populations, and (iii) mechanism design -- the ultimate nudging
problem -- expressed entirely in natural language. Experiments with populations
of up to one hundred interacting agents show that the planner converges near
Stackelberg equilibria that improve aggregate social welfare relative to Saez
solutions, while a periodic, persona-level voting procedure furthers these
gains under decentralized governance. These results demonstrate that large
language model-based agents can jointly model, simulate, and govern complex
economic systems, providing a tractable test bed for policy evaluation at the
societal scale to help build better civilizations.",http://arxiv.org/pdf/2507.15815v1,,False
Hypergraphs on high dimensional time series sets using signature transform,21/07/2025,"Rémi Vaucher, Paul Minchella","In recent decades, hypergraphs and their analysis through Topological Data
Analysis (TDA) have emerged as powerful tools for understanding complex data
structures. Various methods have been developed to construct hypergraphs --
referred to as simplicial complexes in the TDA framework -- over datasets,
enabling the formation of edges between more than two vertices. This paper
addresses the challenge of constructing hypergraphs from collections of
multivariate time series. While prior work has focused on the case of a single
multivariate time series, we extend this framework to handle collections of
such time series. Our approach generalizes the method proposed in Chretien and
al. by leveraging the properties of signature transforms to introduce
controlled randomness, thereby enhancing the robustness of the construction
process. We validate our method on synthetic datasets and present promising
results.",http://arxiv.org/pdf/2507.15802v1,,False
Dissociating model architectures from inference computations,21/07/2025,"Noor Sajid, Johan Medrano","Parr et al., 2025 examines how auto-regressive and deep temporal models
differ in their treatment of non-Markovian sequence modelling. Building on
this, we highlight the need for dissociating model architectures, i.e., how the
predictive distribution factorises, from the computations invoked at inference.
We demonstrate that deep temporal computations are mimicked by autoregressive
models by structuring context access during iterative inference. Using a
transformer trained on next-token prediction, we show that inducing
hierarchical temporal factorisation during iterative inference maintains
predictive capacity while instantiating fewer computations. This emphasises
that processes for constructing and refining predictions are not necessarily
bound to their underlying model architectures.",http://arxiv.org/pdf/2507.15776v1,10.1080/17588928.2025.2532604,False
Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity,21/07/2025,"Mingyuan Sun, Zheng Fang, Jiaxu Wang, Kunyi Zhang, Qiang Zhang, Renjing Xu","We present GravLensX, an innovative method for rendering black holes with
gravitational lensing effects using neural networks. The methodology involves
training neural networks to fit the spacetime around black holes and then
employing these trained models to generate the path of light rays affected by
gravitational lensing. This enables efficient and scalable simulations of black
holes with optically thin accretion disks, significantly decreasing the time
required for rendering compared to traditional methods. We validate our
approach through extensive rendering of multiple black hole systems with
superposed Kerr metric, demonstrating its capability to produce accurate
visualizations with significantly $15\times$ reduced computational time. Our
findings suggest that neural networks offer a promising alternative for
rendering complex astrophysical phenomena, potentially paving a new path to
astronomical visualization.",http://arxiv.org/pdf/2507.15775v1,,False
LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization,21/07/2025,"Xingyu Wu, Yuchen Yan, Shangke Lyu, Linjuan Wu, Yiwen Qiu, Yongliang Shen, Weiming Lu, Jian Shao, Jun Xiao, Yueting Zhuang","Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.",http://arxiv.org/pdf/2507.15758v1,,False
DialogueForge: LLM Simulation of Human-Chatbot Dialogue,21/07/2025,"Ruizhe Zhu, Hao Zhu, Yaxuan Li, Syang Zhou, Shijing Cai, Malgorzata Lazuka, Elliott Ash","Collecting human-chatbot dialogues typically demands substantial manual
effort and is time-consuming, which limits and poses challenges for research on
conversational AI. In this work, we propose DialogueForge - a framework for
generating AI-simulated conversations in human-chatbot style. To initialize
each generated conversation, DialogueForge uses seed prompts extracted from
real human-chatbot interactions. We test a variety of LLMs to simulate the
human chatbot user, ranging from state-of-the-art proprietary models to
small-scale open-source LLMs, and generate multi-turn dialogues tailored to
specific tasks. In addition, we explore fine-tuning techniques to enhance the
ability of smaller models to produce indistinguishable human-like dialogues. We
evaluate the quality of the simulated conversations and compare different
models using the UniEval and GTEval evaluation protocols. Our experiments show
that large proprietary models (e.g., GPT-4o) generally outperform others in
generating more realistic dialogues, while smaller open-source models (e.g.,
Llama, Mistral) offer promising performance with greater customization. We
demonstrate that the performance of smaller models can be significantly
improved by employing supervised fine-tuning techniques. Nevertheless,
maintaining coherent and natural long-form human-like dialogues remains a
common challenge across all models.",http://arxiv.org/pdf/2507.15752v1,,False
Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting,21/07/2025,"Edward Holmberg, Pujan Pokhrel, Maximilian Zoch, Elias Ioup, Ken Pathak, Steven Sloan, Kendall Niles, Jay Ratcliff, Maik Flanagin, Christian Guetl, Julian Simeonov, Mahdi Abdelguerfi","Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but
are too computationally intensive for on-the-fly decision-making during flood
events. The central challenge is to accelerate these simulations without
sacrificing accuracy. This paper introduces a deep learning surrogate that
treats HEC-RAS not as a solver but as a data-generation engine. We propose a
hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)
to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural
Operator (Geo-FNO) to model long-range spatial dependencies along a river
reach. The model learns underlying physics implicitly from a minimal
eight-channel feature vector encoding dynamic state, static geometry, and
boundary forcings extracted directly from native HEC-RAS files. Trained on 67
reaches of the Mississippi River Basin, the surrogate was evaluated on a
year-long, unseen hold-out simulation. Results show the model achieves a strong
predictive accuracy, with a median absolute stage error of 0.31 feet.
Critically, for a full 67-reach ensemble forecast, our surrogate reduces the
required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly
3.5 times over the traditional solver. The success of this data-driven approach
demonstrates that robust feature engineering can produce a viable, high-speed
replacement for conventional hydraulic models, improving the computational
feasibility of large-scale ensemble flood forecasting.",http://arxiv.org/pdf/2507.15614v1,,False
LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning,21/07/2025,"Cole Robertson, Philip Wolff","Do large language models (LLMs) construct and manipulate internal world
models, or do they rely solely on statistical associations represented as
output layer token probabilities? We adapt cognitive science methodologies from
human mental models research to test LLMs on pulley system problems using
TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical
advantage (MA). State-of-the-art models performed marginally but significantly
above chance, and their estimates correlated significantly with ground-truth
MA. Significant correlations between number of pulleys and model estimates
suggest that models employed a pulley counting heuristic, without necessarily
simulating pulley systems to derive precise values. Study 2 tested this by
probing whether LLMs represent global features crucial to MA estimation. Models
evaluated a functionally connected pulley system against a fake system with
randomly placed components. Without explicit cues, models identified the
functional system as having greater MA with F1=0.8, suggesting LLMs could
represent systems well enough to differentiate jumbled from functional systems.
Study 3 built on this by asking LLMs to compare functional systems with matched
systems which were connected up but which transferred no force to the weight;
LLMs identified the functional system with F1=0.46, suggesting random guessing.
Insofar as they may generalize, these findings are compatible with the notion
that LLMs manipulate internal world models, sufficient to exploit statistical
associations between pulley count and MA (Study 1), and to approximately
represent system components' spatial relations (Study 2). However, they may
lack the facility to reason over nuanced structural connectivity (Study 3). We
conclude by advocating the utility of cognitive scientific methods to evaluate
the world-modeling capacities of artificial intelligence systems.",http://arxiv.org/pdf/2507.15521v1,,False
ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution,21/07/2025,"Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Pete Boothroyd, Héctor Martinez Alonso, Diarmuid Ó Séaghdha, Anders Johannsen","This work evaluates the potential of large language models (LLMs) to power
digital assistants capable of complex action execution. These assistants rely
on pre-trained programming knowledge to execute multi-step goals by composing
objects and functions defined in assistant libraries into action execution
programs. To achieve this, we develop ASPERA, a framework comprising an
assistant library simulation and a human-assisted LLM data generation engine.
Our engine allows developers to guide LLM generation of high-quality tasks
consisting of complex user queries, simulation state and corresponding
validation programs, tackling data availability and evaluation robustness
challenges. Alongside the framework we release Asper-Bench, an evaluation
dataset of 250 challenging tasks generated using ASPERA, which we use to show
that program generation grounded in custom assistant libraries is a significant
challenge to LLMs compared to dependency-free code generation.",http://arxiv.org/pdf/2507.15501v1,,False
Optimization of Activity Batching Policies in Business Processes,21/07/2025,"Orlenys López-Pintado, Jannis Rosenbaum, Marlon Dumas","In business processes, activity batching refers to packing multiple activity
instances for joint execution. Batching allows managers to trade off cost and
processing effort against waiting time. Larger and less frequent batches may
lower costs by reducing processing effort and amortizing fixed costs, but they
create longer waiting times. In contrast, smaller and more frequent batches
reduce waiting times but increase fixed costs and processing effort. A batching
policy defines how activity instances are grouped into batches and when each
batch is activated. This paper addresses the problem of discovering batching
policies that strike optimal trade-offs between waiting time, processing
effort, and cost. The paper proposes a Pareto optimization approach that starts
from a given set (possibly empty) of activity batching policies and generates
alternative policies for each batched activity via intervention heuristics.
Each heuristic identifies an opportunity to improve an activity's batching
policy with respect to a metric (waiting time, processing time, cost, or
resource utilization) and an associated adjustment to the activity's batching
policy (the intervention). The impact of each intervention is evaluated via
simulation. The intervention heuristics are embedded in an optimization
meta-heuristic that triggers interventions to iteratively update the Pareto
front of the interventions identified so far. The paper considers three
meta-heuristics: hill-climbing, simulated annealing, and reinforcement
learning. An experimental evaluation compares the proposed approach based on
intervention heuristics against the same (non-heuristic guided) meta-heuristics
baseline regarding convergence, diversity, and cycle time gain of
Pareto-optimal policies.",http://arxiv.org/pdf/2507.15457v1,,False
"Language Generation in the Limit: Noise, Loss, and Feedback",21/07/2025,"Yannan Bai, Debmalya Panigrahi, Ian Zhang","Kleinberg and Mullainathan (2024) recently proposed a formal framework called
language generation in the limit and showed that given a sequence of example
strings from an unknown target language drawn from any countable collection, an
algorithm can correctly generate unseen strings from the target language within
finite time. This notion was further refined by Li, Raman, and Tewari (2024),
who defined stricter categories of non-uniform and uniform generation. They
showed that a finite union of uniformly generatable collections is generatable
in the limit, and asked if the same is true for non-uniform generation.
  We begin by resolving the question in the negative: we give a uniformly
generatable collection and a non-uniformly generatable collection whose union
is not generatable in the limit. We then use facets of this construction to
further our understanding of several variants of language generation. The first
two, generation with noise and without samples, were introduced by Raman and
Raman (2025) and Li, Raman, and Tewari (2024) respectively. We show the
equivalence of these models for uniform and non-uniform generation, and provide
a characterization of non-uniform noisy generation. The former paper asked if
there is any separation between noisy and non-noisy generation in the limit --
we show that such a separation exists even with a single noisy string. Finally,
we study the framework of generation with feedback, introduced by Charikar and
Pabbaraju (2025), where the algorithm is strengthened by allowing it to ask
membership queries. We show finite queries add no power, but infinite queries
yield a strictly more powerful model.
  In summary, the results in this paper resolve the union-closedness of
language generation in the limit, and leverage those techniques (and others) to
give precise characterizations for natural variants that incorporate noise,
loss, and feedback.",http://arxiv.org/pdf/2507.15319v1,,False
Machine Unlearning for Streaming Forgetting,21/07/2025,"Shaofei Shen, Chenhao Zhang, Yawen Zhao, Alina Bialkowski, Weitong Chen, Miao Xu","Machine unlearning aims to remove knowledge of the specific training data in
a well-trained model. Currently, machine unlearning methods typically handle
all forgetting data in a single batch, removing the corresponding knowledge all
at once upon request. However, in practical scenarios, requests for data
removal often arise in a streaming manner rather than in a single batch,
leading to reduced efficiency and effectiveness in existing methods. Such
challenges of streaming forgetting have not been the focus of much research. In
this paper, to address the challenges of performance maintenance, efficiency,
and data access brought about by streaming unlearning requests, we introduce a
streaming unlearning paradigm, formalizing the unlearning as a distribution
shift problem. We then estimate the altered distribution and propose a novel
streaming unlearning algorithm to achieve efficient streaming forgetting
without requiring access to the original training data. Theoretical analyses
confirm an $O(\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,
where $V_T$ represents the cumulative total variation in the optimal solution
over $T$ learning rounds. This theoretical guarantee is achieved under mild
conditions without the strong restriction of convex loss function. Experiments
across various models and datasets validate the performance of our proposed
method.",http://arxiv.org/pdf/2507.15280v1,,False
User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks,21/07/2025,"Sourav Mondal, Elaine Wong","The evolution towards future generation of mobile systems and fixed wireless
networks is primarily driven by the urgency to support high-bandwidth and
low-latency services across various vertical sectors. This endeavor is fueled
by smartphones as well as technologies like industrial internet of things,
extended reality (XR), and human-to-machine (H2M) collaborations for fostering
industrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To
ensure an ideal immersive experience and avoid cyber-sickness for users in all
the aforementioned usage scenarios, it is typically challenging to synchronize
XR content from a remote machine to a human collaborator according to their
head movements across a large geographic span in real-time over communication
networks. Thus, we propose a novel H2M collaboration scheme where the human's
head movements are predicted ahead with highly accurate models like
bidirectional long short-term memory networks to orient the machine's camera in
advance. We validate that XR frame size varies in accordance with the human's
head movements and predict the corresponding bandwidth requirements from the
machine's camera to propose a human-machine coordinated dynamic bandwidth
allocation (HMC-DBA) scheme. Through extensive simulations, we show that
end-to-end latency and jitter requirements of XR frames are satisfied with much
lower bandwidth consumption over enterprise networks like
Fiber-To-The-Room-Business. Furthermore, we show that better efficiency in
network resource utilization is achieved by employing our proposed HMC-DBA over
state-of-the-art schemes.",http://arxiv.org/pdf/2507.15254v1,10.1109/JIOT.2025.3587064,False
SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation,21/07/2025,"Yibo He, Shuoran Zhao, Jiaming Huang, Yingjie Fu, Hao Yu, Cunjian Huang, Tao Xie","SIMD (Single Instruction Multiple Data) instructions and their compiler
intrinsics are widely supported by modern processors to accelerate
performance-critical tasks. SIMD intrinsic programming, a trade-off between
coding productivity and high performance, is widely used in the development of
mainstream performance-critical libraries and daily computing tasks. Large
Language Models (LLMs), which have demonstrated strong and comprehensive
capabilities in code generation, show promise in assisting programmers with the
challenges of SIMD intrinsic programming. However, existing code-generation
benchmarks focus on only scalar code, and it is unclear how LLMs perform in
generating vectorized code using SIMD intrinsics. To fill this gap, we propose
SimdBench, the first code benchmark specifically designed for SIMD-intrinsic
code generation, comprising 136 carefully crafted tasks and targeting five
representative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86
Advanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM
Scalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a
systematic evaluation (measuring both correctness and performance) of 18
representative LLMs on SimdBench, resulting in a series of novel and insightful
findings. Our evaluation results demonstrate that LLMs exhibit a universal
decrease in pass@k during SIMD-intrinsic code generation compared to
scalar-code generation. Our in-depth analysis highlights promising directions
for the further advancement of LLMs in the challenging domain of SIMD-intrinsic
code generation. SimdBench is fully open source at
https://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader
research community.",http://arxiv.org/pdf/2507.15224v1,,False
