Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
HiPPO-Prophecy: State-Space Models can Provably Learn Dynamical Systems in Context,12/07/2024,"Federico Arangath Joseph, Kilian Haefeli, Noah Liniger, Caglar Gulcehre","This work explores the in-context learning capabilities of State Space Models
(SSMs) and presents, to the best of our knowledge, the first theoretical
explanation of a possible underlying mechanism. We introduce a novel weight
construction for SSMs, enabling them to predict the next state of any dynamical
system after observing previous states without parameter fine-tuning. This is
accomplished by extending the HiPPO framework to demonstrate that continuous
SSMs can approximate the derivative of any input signal. Specifically, we find
an explicit weight construction for continuous SSMs and provide an asymptotic
error bound on the derivative approximation. The discretization of this
continuous SSM subsequently yields a discrete SSM that predicts the next state.
Finally, we demonstrate the effectiveness of our parameterization empirically.
This work should be an initial step toward understanding how sequence models
based on SSMs learn in context.",http://arxiv.org/pdf/2407.09375v1,,False
Learning High-Frequency Functions Made Easy with Sinusoidal Positional Encoding,12/07/2024,"Chuanhao Sun, Zhihang Yuan, Kai Xu, Luo Mai, Siddharth N, Shuo Chen, Mahesh K. Marina","Fourier features based positional encoding (PE) is commonly used in machine
learning tasks that involve learning high-frequency features from
low-dimensional inputs, such as 3D view synthesis and time series regression
with neural tangent kernels. Despite their effectiveness, existing PEs require
manual, empirical adjustment of crucial hyperparameters, specifically the
Fourier features, tailored to each unique task. Further, PEs face challenges in
efficiently learning high-frequency functions, particularly in tasks with
limited data. In this paper, we introduce sinusoidal PE (SPE), designed to
efficiently learn adaptive frequency features closely aligned with the true
underlying function. Our experiments demonstrate that SPE, without
hyperparameter tuning, consistently achieves enhanced fidelity and faster
training across various tasks, including 3D view synthesis, Text-to-Speech
generation, and 1D regression. SPE is implemented as a direct replacement for
existing PEs. Its plug-and-play nature lets numerous tasks easily adopt and
benefit from SPE.",http://arxiv.org/pdf/2407.09370v1,,False
Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning,12/07/2024,"Thuy Ngoc Nguyen, Kasturi Jamale, Cleotilde Gonzalez","Large Language Models (LLMs) have demonstrated their capabilities across
various tasks, from language translation to complex reasoning. Understanding
and predicting human behavior and biases are crucial for artificial
intelligence (AI) assisted systems to provide useful assistance, yet it remains
an open question whether these models can achieve this. This paper addresses
this gap by leveraging the reasoning and generative capabilities of the LLMs to
predict human behavior in two sequential decision-making tasks. These tasks
involve balancing between exploitative and exploratory actions and handling
delayed feedback, both essential for simulating real-life decision processes.
We compare the performance of LLMs with a cognitive instance-based learning
(IBL) model, which imitates human experiential decision-making. Our findings
indicate that LLMs excel at rapidly incorporating feedback to enhance
prediction accuracy. In contrast, the cognitive IBL model better accounts for
human exploratory behaviors and effectively captures loss aversion bias, i.e.,
the tendency to choose a sub-optimal goal with fewer step-cost penalties rather
than exploring to find the optimal choice, even with limited experience. The
results highlight the benefits of integrating LLMs with cognitive
architectures, suggesting that this synergy could enhance the modeling and
understanding of complex human decision-making patterns.",http://arxiv.org/pdf/2407.09281v1,,False
"Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX",12/07/2024,"Zhiyuan Chen, Tianhao Chen, Chenggang Xie, Yang Xue, Xiaonan Zhang, Jingbo Zhou, Xiaomin Fang","Proteins are fundamental components of biological systems and can be
represented through various modalities, including sequences, structures, and
textual descriptions. Despite the advances in deep learning and scientific
large language models (LLMs) for protein research, current methodologies
predominantly focus on limited specialized tasks -- often predicting one
protein modality from another. These approaches restrict the understanding and
generation of multimodal protein data. In contrast, large multimodal models
have demonstrated potential capabilities in generating any-to-any content like
text, images, and videos, thus enriching user interactions across various
domains. Integrating these multimodal model technologies into protein research
offers significant promise by potentially transforming how proteins are
studied. To this end, we introduce HelixProtX, a system built upon the large
multimodal model, aiming to offer a comprehensive solution to protein research
by supporting any-to-any protein modality generation. Unlike existing methods,
it allows for the transformation of any input protein modality into any desired
protein modality. The experimental results affirm the advanced capabilities of
HelixProtX, not only in generating functional descriptions from amino acid
sequences but also in executing critical tasks such as designing protein
sequences and structures from textual descriptions. Preliminary findings
indicate that HelixProtX consistently achieves superior accuracy across a range
of protein-related tasks, outperforming existing state-of-the-art models. By
integrating multimodal large models into protein research, HelixProtX opens new
avenues for understanding protein biology, thereby promising to accelerate
scientific discovery.",http://arxiv.org/pdf/2407.09274v1,,False
iNeMo: Incremental Neural Mesh Models for Robust Class-Incremental Learning,12/07/2024,"Tom Fischer, Yaoyao Liu, Artur Jesslen, Noor Ahmed, Prakhar Kaushik, Angtian Wang, Alan Yuille, Adam Kortylewski, Eddy Ilg","Different from human nature, it is still common practice today for vision
tasks to train deep learning models only initially and on fixed datasets. A
variety of approaches have recently addressed handling continual data streams.
However, extending these methods to manage out-of-distribution (OOD) scenarios
has not effectively been investigated. On the other hand, it has recently been
shown that non-continual neural mesh models exhibit strong performance in
generalizing to such OOD scenarios. To leverage this decisive property in a
continual learning setting, we propose incremental neural mesh models that can
be extended with new meshes over time. In addition, we present a latent space
initialization strategy that enables us to allocate feature space for future
unseen classes in advance and a positional regularization term that forces the
features of the different classes to consistently stay in respective latent
space regions. We demonstrate the effectiveness of our method through extensive
experiments on the Pascal3D and ObjectNet3D datasets and show that our approach
outperforms the baselines for classification by $2-6\%$ in the in-domain and by
$6-50\%$ in the OOD setting. Our work also presents the first incremental
learning approach for pose estimation. Our code and model can be found at
https://github.com/Fischer-Tom/iNeMo.",http://arxiv.org/pdf/2407.09271v1,,False
Variational Inference via Smoothed Particle Hydrodynamics,12/07/2024,Yongchao Huang,"A new variational inference method, SPH-ParVI, based on smoothed particle
hydrodynamics (SPH), is proposed for sampling partially known densities (e.g.
up to a constant) or sampling using gradients. SPH-ParVI simulates the flow of
a fluid under external effects driven by the target density; transient or
steady state of the fluid approximates the target density. The continuum fluid
is modelled as an interacting particle system (IPS) via SPH, where each
particle carries smoothed properties, interacts and evolves as per the
Navier-Stokes equations. This mesh-free, Lagrangian simulation method offers
fast, flexible, scalable and deterministic sampling and inference for a class
of probabilistic models such as those encountered in Bayesian inference and
generative modelling.",http://arxiv.org/pdf/2407.09186v1,,False
Machine Apophenia: The Kaleidoscopic Generation of Architectural Images,12/07/2024,"Alexey Tikhonov, Dmitry Sinyavin","This study investigates the application of generative artificial intelligence
in architectural design. We present a novel methodology that combines multiple
neural networks to create an unsupervised and unmoderated stream of unique
architectural images. Our approach is grounded in the conceptual framework
called machine apophenia. We hypothesize that neural networks, trained on
diverse human-generated data, internalize aesthetic preferences and tend to
produce coherent designs even from random inputs. The methodology involves an
iterative process of image generation, description, and refinement, resulting
in captioned architectural postcards automatically shared on several social
media platforms. Evaluation and ablation studies show the improvement both in
technical and aesthetic metrics of resulting images on each step.",http://arxiv.org/pdf/2407.09172v1,,False
Robustness of Explainable Artificial Intelligence in Industrial Process Modelling,12/07/2024,"Benedikt Kantz, Clemens Staudinger, Christoph Feilmayr, Johannes Wachlmayr, Alexander Haberl, Stefan Schuster, Franz Pernkopf","eXplainable Artificial Intelligence (XAI) aims at providing understandable
explanations of black box models. In this paper, we evaluate current XAI
methods by scoring them based on ground truth simulations and sensitivity
analysis. To this end, we used an Electric Arc Furnace (EAF) model to better
understand the limits and robustness characteristics of XAI methods such as
SHapley Additive exPlanations (SHAP), Local Interpretable Model-agnostic
Explanations (LIME), as well as Averaged Local Effects (ALE) or Smooth
Gradients (SG) in a highly topical setting. These XAI methods were applied to
various types of black-box models and then scored based on their correctness
compared to the ground-truth sensitivity of the data-generating processes using
a novel scoring evaluation methodology over a range of simulated additive
noise. The resulting evaluation shows that the capability of the Machine
Learning (ML) models to capture the process accurately is, indeed, coupled with
the correctness of the explainability of the underlying data-generating
process. We furthermore show the differences between XAI methods in their
ability to correctly predict the true sensitivity of the modeled industrial
process.",http://arxiv.org/pdf/2407.09127v1,,False
Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training,12/07/2024,"Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu","This study addresses a critical gap in safety tuning practices for Large
Language Models (LLMs) by identifying and tackling a refusal position bias
within safety tuning data, which compromises the models' ability to
appropriately refuse generating unsafe content. We introduce a novel approach,
Decoupled Refusal Training (DeRTa), designed to empower LLMs to refuse
compliance to harmful prompts at any response position, significantly enhancing
their safety capabilities. DeRTa incorporates two novel components: (1) Maximum
Likelihood Estimation (MLE) with Harmful Response Prefix, which trains models
to recognize and avoid unsafe content by appending a segment of harmful
response to the beginning of a safe response, and (2) Reinforced Transition
Optimization (RTO), which equips models with the ability to transition from
potential harm to safety refusal consistently throughout the harmful response
sequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model
families across six attack scenarios, demonstrates that our method not only
improves model safety without compromising performance but also surpasses
well-known models such as GPT-4 in defending against attacks. Importantly, our
approach successfully defends recent advanced attack methods (e.g., CodeAttack)
that have jailbroken GPT-4 and LLaMA3-70B-Instruct. Our code and data can be
found at https://github.com/RobustNLP/DeRTa.",http://arxiv.org/pdf/2407.09121v1,,False
HPC: Hierarchical Progressive Coding Framework for Volumetric Video,12/07/2024,"Zihan Zheng, Houqiang Zhong, Qiang Hu, Xiaoyun Zhang, Li Song, Ya Zhang, Yanfeng Wang","Volumetric video based on Neural Radiance Field (NeRF) holds vast potential
for various 3D applications, but its substantial data volume poses significant
challenges for compression and transmission. Current NeRF compression lacks the
flexibility to adjust video quality and bitrate within a single model for
various network and device capacities. To address these issues, we propose HPC,
a novel hierarchical progressive volumetric video coding framework achieving
variable bitrate using a single model. Specifically, HPC introduces a
hierarchical representation with a multi-resolution residual radiance field to
reduce temporal redundancy in long-duration sequences while simultaneously
generating various levels of detail. Then, we propose an end-to-end progressive
learning approach with a multi-rate-distortion loss function to jointly
optimize both hierarchical representation and compression. Our HPC trained only
once can realize multiple compression levels, while the current methods need to
train multiple fixed-bitrate models for different rate-distortion (RD)
tradeoffs. Extensive experiments demonstrate that HPC achieves flexible quality
levels with variable bitrate by a single model and exhibits competitive RD
performance, even outperforming fixed-bitrate models across various datasets.",http://arxiv.org/pdf/2407.09026v1,,False
AI-Driven Guided Response for Security Operation Centers with Microsoft Copilot for Security,12/07/2024,"Scott Freitas, Jovan Kalajdjieski, Amir Gharib, Rob McCann","Security operation centers contend with a constant stream of security
incidents, ranging from straightforward to highly complex. To address this, we
developed Copilot Guided Response (CGR), an industry-scale ML architecture that
guides security analysts across three key tasks -- (1) investigation, providing
essential historical context by identifying similar incidents; (2) triaging to
ascertain the nature of the incident -- whether it is a true positive, false
positive, or benign positive; and (3) remediation, recommending tailored
containment actions. CGR is integrated into the Microsoft Defender XDR product
and deployed worldwide, generating millions of recommendations across thousands
of customers. Our extensive evaluation, incorporating internal evaluation,
collaboration with security experts, and customer feedback, demonstrates that
CGR delivers high-quality recommendations across all three tasks. We provide a
comprehensive overview of the CGR architecture, setting a precedent as the
first cybersecurity company to openly discuss these capabilities in such depth.
Additionally, we GUIDE, the largest public collection of real-world security
incidents, spanning 13M evidences across 1M annotated incidents. By enabling
researchers and practitioners to conduct research on real-world data, GUIDE
advances the state of cybersecurity and supports the development of
next-generation machine learning systems.",http://arxiv.org/pdf/2407.09017v1,,False
Parameter inference from a non-stationary unknown process,12/07/2024,"Kieran S. Owens, Ben D. Fulcher","Non-stationary systems are found throughout the world, from climate patterns
under the influence of variation in carbon dioxide concentration, to brain
dynamics driven by ascending neuromodulation. Accordingly, there is a need for
methods to analyze non-stationary processes, and yet most time-series analysis
methods that are used in practice, on important problems across science and
industry, make the simplifying assumption of stationarity. One important
problem in the analysis of non-stationary systems is the problem class that we
refer to as Parameter Inference from a Non-stationary Unknown Process (PINUP).
Given an observed time series, this involves inferring the parameters that
drive non-stationarity of the time series, without requiring knowledge or
inference of a mathematical model of the underlying system. Here we review and
unify a diverse literature of algorithms for PINUP. We formulate the problem,
and categorize the various algorithmic contributions. This synthesis will allow
researchers to identify gaps in the literature and will enable systematic
comparisons of different methods. We also demonstrate that the most common
systems that existing methods are tested on - notably the non-stationary Lorenz
process and logistic map - are surprisingly easy to perform well on using
simple statistical features like windowed mean and variance, undermining the
practice of using good performance on these systems as evidence of algorithmic
performance. We then identify more challenging problems that many existing
methods perform poorly on and which can be used to drive methodological
advances in the field. Our results unify disjoint scientific contributions to
analyzing non-stationary systems and suggest new directions for progress on the
PINUP problem and the broader study of non-stationary phenomena.",http://arxiv.org/pdf/2407.08987v1,,False
Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations,12/07/2024,"David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk","Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.",http://arxiv.org/pdf/2407.08983v1,,False
Topology-enhanced machine learning model (Top-ML) for anticancer peptide prediction,12/07/2024,"Joshua Zhi En Tan, JunJie Wee, Xue Gong, Kelin Xia","Recently, therapeutic peptides have demonstrated great promise for cancer
treatment. To explore powerful anticancer peptides, artificial intelligence
(AI)-based approaches have been developed to systematically screen potential
candidates. However, the lack of efficient featurization of peptides has become
a bottleneck for these machine-learning models. In this paper, we propose a
topology-enhanced machine learning model (Top-ML) for anticancer peptide
prediction. Our Top-ML employs peptide topological features derived from its
sequence ""connection"" information characterized by vector and spectral
descriptors. Our Top-ML model has been validated on two widely used AntiCP 2.0
benchmark datasets and has achieved state-of-the-art performance. Our results
highlight the potential of leveraging novel topology-based featurization to
accelerate the identification of anticancer peptides.",http://arxiv.org/pdf/2407.08974v1,,False
PAIL: Performance based Adversarial Imitation Learning Engine for Carbon Neutral Optimization,12/07/2024,"Yuyang Ye, Lu-An Tang, Haoyu Wang, Runlong Yu, Wenchao Yu, Erhu He, Haifeng Chen, Hui Xiong","Achieving carbon neutrality within industrial operations has become
increasingly imperative for sustainable development. It is both a significant
challenge and a key opportunity for operational optimization in industry 4.0.
In recent years, Deep Reinforcement Learning (DRL) based methods offer
promising enhancements for sequential optimization processes and can be used
for reducing carbon emissions. However, existing DRL methods need a pre-defined
reward function to assess the impact of each action on the final sustainable
development goals (SDG). In many real applications, such a reward function
cannot be given in advance. To address the problem, this study proposes a
Performance based Adversarial Imitation Learning (PAIL) engine. It is a novel
method to acquire optimal operational policies for carbon neutrality without
any pre-defined action rewards. Specifically, PAIL employs a Transformer-based
policy generator to encode historical information and predict following actions
within a multi-dimensional space. The entire action sequence will be
iteratively updated by an environmental simulator. Then PAIL uses a
discriminator to minimize the discrepancy between generated sequences and
real-world samples of high SDG. In parallel, a Q-learning framework based
performance estimator is designed to estimate the impact of each action on SDG.
Based on these estimations, PAIL refines generated policies with the rewards
from both discriminator and performance estimator. PAIL is evaluated on
multiple real-world application cases and datasets. The experiment results
demonstrate the effectiveness of PAIL comparing to other state-of-the-art
baselines. In addition, PAIL offers meaningful interpretability for the
optimization in carbon neutrality.",http://arxiv.org/pdf/2407.08910v1,10.1145/3637528.3671611,False
