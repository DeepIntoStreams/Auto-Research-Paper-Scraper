Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies,25/02/2025,"Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio","In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in
Teams), a new framework for generating ToM-conditioned trajectories. It
combines a meta-learning mechanism, that performs ToM reasoning over teammates'
underlying goals and future behavior, with a multiagent denoising-diffusion
model, that generates plans for an agent and its teammates conditioned on both
the agent's goals and its teammates' characteristics, as computed via ToM. We
implemented an online planning system that dynamically samples new trajectories
(replans) from the diffusion model whenever it detects a divergence between a
previously generated plan and the current state of the world. We conducted
several experiments using ToMCAT in a simulated cooking domain. Our results
highlight the importance of the dynamic replanning mechanism in reducing the
usage of resources without sacrificing team performance. We also show that
recent observations about the world and teammates' behavior collected by an
agent over the course of an episode combined with ToM inferences are crucial to
generate team-aware plans for dynamic adaptation to teammates, especially when
no prior information is provided about them.",http://arxiv.org/pdf/2502.18438v1,,False
Enhancing DNA Foundation Models to Address Masking Inefficiencies,25/02/2025,"Monireh Safari, Pablo Millan Arias, Scott C. Lowe, Lila Kari, Angel X. Chang, Graham W. Taylor","Masked language modelling (MLM) as a pretraining objective has been widely
adopted in genomic sequence modelling. While pretrained models can successfully
serve as encoders for various downstream tasks, the distribution shift between
pretraining and inference detrimentally impacts performance, as the pretraining
task is to map [MASK] tokens to predictions, yet the [MASK] is absent during
downstream applications. This means the encoder does not prioritize its
encodings of non-[MASK] tokens, and expends parameters and compute on work only
relevant to the MLM task, despite this being irrelevant at deployment time. In
this work, we propose a modified encoder-decoder architecture based on the
masked autoencoder framework, designed to address this inefficiency within a
BERT-based transformer. We empirically show that the resulting mismatch is
particularly detrimental in genomic pipelines where models are often used for
feature extraction without fine-tuning. We evaluate our approach on the
BIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achieve
substantial performance gains in both closed-world and open-world
classification tasks when compared against causal models and bidirectional
architectures pretrained with MLM tasks.",http://arxiv.org/pdf/2502.18405v1,,False
EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity,25/02/2025,"Dominik Hollidt, Paul Streli, Jiaxi Jiang, Yasaman Haghighi, Changlin Qian, Xintong Liu, Christian Holz","Research on egocentric tasks in computer vision has mostly focused on
head-mounted cameras, such as fisheye cameras or embedded cameras inside
immersive headsets. We argue that the increasing miniaturization of optical
sensors will lead to the prolific integration of cameras into many more
body-worn devices at various locations. This will bring fresh perspectives to
established tasks in computer vision and benefit key areas such as human motion
tracking, body pose estimation, or action recognition -- particularly for the
lower body, which is typically occluded.
  In this paper, we introduce EgoSim, a novel simulator of body-worn cameras
that generates realistic egocentric renderings from multiple perspectives
across a wearer's body. A key feature of EgoSim is its use of real motion
capture data to render motion artifacts, which are especially noticeable with
arm- or leg-worn cameras. In addition, we introduce MultiEgoView, a dataset of
egocentric footage from six body-worn cameras and ground-truth full-body 3D
poses during several activities: 119 hours of data are derived from AMASS
motion sequences in four high-fidelity virtual environments, which we augment
with 5 hours of real-world motion data from 13 participants using six GoPro
cameras and 3D body pose references from an Xsens motion capture suit.
  We demonstrate EgoSim's effectiveness by training an end-to-end video-only 3D
pose estimation network. Analyzing its domain gap, we show that our dataset and
simulator substantially aid training for inference on real-world data.
  EgoSim code & MultiEgoView dataset: https://siplab.org/projects/EgoSim",http://arxiv.org/pdf/2502.18373v1,,False
MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning,25/02/2025,"Sepehr Asgarian, Qayam Jetha, Jouhyun Jeon","In the competitive landscape of advertising, success hinges on effectively
navigating and leveraging complex interactions among consumers, advertisers,
and advertisement platforms. These multifaceted interactions compel advertisers
to optimize strategies for modeling consumer behavior, enhancing brand recall,
and tailoring advertisement content. To address these challenges, we present
MindMem, a multimodal predictive model for advertisement memorability. By
integrating textual, visual, and auditory data, MindMem achieves
state-of-the-art performance, with a Spearman's correlation coefficient of
0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently
surpassing existing methods. Furthermore, our analysis identified key factors
influencing advertisement memorability, such as video pacing, scene complexity,
and emotional resonance. Expanding on this, we introduced MindMem-ReAd
(MindMem-Driven Re-generated Advertisement), which employs Large Language
Model-based simulations to optimize advertisement content and placement,
resulting in up to a 74.12% improvement in advertisement memorability. Our
results highlight the transformative potential of Artificial Intelligence in
advertising, offering advertisers a robust tool to drive engagement, enhance
competitiveness, and maximize impact in a rapidly evolving market.",http://arxiv.org/pdf/2502.18371v1,,False
Self-Supervised Data Generation for Precision Agriculture: Blending Simulated Environments with Real Imagery,25/02/2025,"Leonardo Saraceni, Ionut Marian Motoi, Daniele Nardi, Thomas Alessandro Ciarfuglia","In precision agriculture, the scarcity of labeled data and significant
covariate shifts pose unique challenges for training machine learning models.
This scarcity is particularly problematic due to the dynamic nature of the
environment and the evolving appearance of agricultural subjects as living
things. We propose a novel system for generating realistic synthetic data to
address these challenges. Utilizing a vineyard simulator based on the Unity
engine, our system employs a cut-and-paste technique with geometrical
consistency considerations to produce accurate photo-realistic images and
labels from synthetic environments to train detection algorithms. This approach
generates diverse data samples across various viewpoints and lighting
conditions. We demonstrate considerable performance improvements in training a
state-of-the-art detector by applying our method to table grapes cultivation.
The combination of techniques can be easily automated, an increasingly
important consideration for adoption in agricultural practice.",http://arxiv.org/pdf/2502.18320v1,10.1109/CASE59546.2024.10711594,False
Software implemented fault diagnosis of natural gas pumping unit based on feedforward neural network,25/02/2025,"Mykola Kozlenko, Olena Zamikhovska, Leonid Zamikhovskyi","In recent years, more and more attention has been paid to the use of
artificial neural networks (ANN) for diagnostics of gas pumping units (GPU).
Usually, ANN training is carried out on models of GPU workflows, and generated
sets of diagnostic data are used to simulate defect conditions. At the same
time, the results obtained do not allow assessing the real state of the GPU. It
is proposed to use the values of the characteristics of the acoustic and
vibration processes of the GPU as the input data of the ANN. A descriptive
statistical analysis of real vibration and acoustic processes generated by the
operation of the GPU type GTK-25-i (Nuovo Pignone, Italy) has been carried out.
The formation of packets of diagnostic signs arriving at the input of the ANN
has been carried out. The diagnostic features are the five maximum amplitude
components of the acoustic and vibration signals, as well as the value of the
standard deviation for each sample. Diagnostic signs are calculated directly in
the input pipeline of ANN data in real time for three technical states of the
GPU. Using the frameworks TensorFlow, Keras, NumPy, pandas, in the Python 3
programming language, an architecture was developed for a deep fully connected
feedforward ANN, training on the error backpropagation algorithm. The results
of training and testing of the developed ANN are presented. During testing, it
was found that the signal classification precision for the ""nominal"" state of
all 1475 signal samples is 1.0000, for the ""current"" state, precision equils
0.9853, and for the ""defective"" state, precision is 0.9091. The use of the
developed ANN makes it possible to classify the technical states of the GPU
with an accuracy sufficient for practical use, which will prevent the
occurrence of GPU failures. ANN can be used to diagnose GPU of any type and
power.",http://arxiv.org/pdf/2502.18233v1,10.15587/1729-4061.2021.229859,False
Differentially private synthesis of Spatial Point Processes,25/02/2025,"Dangchan Kim, Chae Young Lim","This paper proposes a method to generate synthetic data for spatial point
patterns within the differential privacy (DP) framework. Specifically, we
define a differentially private Poisson point synthesizer (PPS) and Cox point
synthesizer (CPS) to generate synthetic point patterns with the concept of the
$\alpha$-neighborhood that relaxes the original definition of DP. We present
three example models to construct a differentially private PPS and CPS,
providing sufficient conditions on their parameters to ensure the DP given a
specified privacy budget. In addition, we demonstrate that the synthesizers can
be applied to point patterns on the linear network. Simulation experiments
demonstrate that the proposed approaches effectively maintain the privacy and
utility of synthetic data.",http://arxiv.org/pdf/2502.18198v1,,False
Actively Inferring Optimal Measurement Sequences,25/02/2025,"Catherine F. Higham, Paul Henderson, Roderick Murray-Smith","Measurement of a physical quantity such as light intensity is an integral
part of many reconstruction and decision scenarios but can be costly in terms
of acquisition time, invasion of or damage to the environment and storage. Data
minimisation and compliance with data protection laws is also an important
consideration. Where there are a range of measurements that can be made, some
may be more informative and compliant with the overall measurement objective
than others. We develop an active sequential inference algorithm that uses the
low dimensional representational latent space from a variational autoencoder
(VAE) to choose which measurement to make next. Our aim is to recover high
dimensional data by making as few measurements as possible. We adapt the VAE
encoder to map partial data measurements on to the latent space of the complete
data. The algorithm draws samples from this latent space and uses the VAE
decoder to generate data conditional on the partial measurements. Estimated
measurements are made on the generated data and fed back through the partial
VAE encoder to the latent space where they can be evaluated prior to making a
measurement. Starting from no measurements and a normal prior on the latent
space, we consider alternative strategies for choosing the next measurement and
updating the predictive posterior prior for the next step. The algorithm is
illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard
pattern measurement basis. We see that useful patterns are chosen within 10
steps, leading to the convergence of the guiding generative images. Compared
with using stochastic variational inference to infer the parameters of the
posterior distribution for each generated data point individually, the partial
VAE framework can efficiently process batches of generated data and obtains
superior results with minimal measurements.",http://arxiv.org/pdf/2502.18142v1,,False
Large Language Model Driven Agents for Simulating Echo Chamber Formation,25/02/2025,"Chenhao Gu, Ling Luo, Zainab Razia Zaidi, Shanika Karunasekera","The rise of echo chambers on social media platforms has heightened concerns
about polarization and the reinforcement of existing beliefs. Traditional
approaches for simulating echo chamber formation have often relied on
predefined rules and numerical simulations, which, while insightful, may lack
the nuance needed to capture complex, real-world interactions. In this paper,
we present a novel framework that leverages large language models (LLMs) as
generative agents to simulate echo chamber dynamics within social networks. The
novelty of our approach is that it incorporates both opinion updates and
network rewiring behaviors driven by LLMs, allowing for a context-aware and
semantically rich simulation of social interactions. Additionally, we utilize
real-world Twitter (now X) data to benchmark the LLM-based simulation against
actual social media behaviors, providing insights into the accuracy and realism
of the generated opinion trends. Our results demonstrate the efficacy of LLMs
in modeling echo chamber formation, capturing both structural and semantic
dimensions of opinion clustering. %This work contributes to a deeper
understanding of social influence dynamics and offers a new tool for studying
polarization in online communities.",http://arxiv.org/pdf/2502.18138v1,,False
Controlling dynamics of stochastic systems with deep reinforcement learning,25/02/2025,Ruslan Mukhamadiarov,"A properly designed controller can help improve the quality of experimental
measurements or force a dynamical system to follow a completely new
time-evolution path. Recent developments in deep reinforcement learning have
made steep advances toward designing effective control schemes for fairly
complex systems. However, a general simulation scheme that employs deep
reinforcement learning for exerting control in stochastic systems is yet to be
established. In this paper, we attempt to further bridge a gap between control
theory and deep reinforcement learning by proposing a simulation algorithm that
allows achieving control of the dynamics of stochastic systems through the use
of trained artificial neural networks. Specifically, we use agent-based
simulations where the neural network plays the role of the controller that
drives local state-to-state transitions. We demonstrate the workflow and the
effectiveness of the proposed control methods by considering the following two
stochastic processes: particle coalescence on a lattice and a totally
asymmetric exclusion process.",http://arxiv.org/pdf/2502.18111v1,,False
Golden Ratio Mixing of Real and Synthetic Data for Stabilizing Generative Model Training,25/02/2025,"Hengzhi He, Shirong Xu, Guang Cheng","Recent studies identified an intriguing phenomenon in recursive generative
model training known as model collapse, where models trained on data generated
by previous models exhibit severe performance degradation. Addressing this
issue and developing more effective training strategies have become central
challenges in generative model research. In this paper, we investigate this
phenomenon theoretically within a novel framework, where generative models are
iteratively trained on a combination of newly collected real data and synthetic
data from the previous training step. To develop an optimal training strategy
for integrating real and synthetic data, we evaluate the performance of a
weighted training scheme in various scenarios, including Gaussian distribution
estimation and linear regression. We theoretically characterize the impact of
the mixing proportion and weighting scheme of synthetic data on the final
model's performance. Our key finding is that, across different settings, the
optimal weighting scheme under different proportions of synthetic data
asymptotically follows a unified expression, revealing a fundamental trade-off
between leveraging synthetic data and generative model performance. Notably, in
some cases, the optimal weight assigned to real data corresponds precisely to
the reciprocal of the golden ratio. Finally, we validate our theoretical
results on extensive simulated datasets and a real tabular dataset.",http://arxiv.org/pdf/2502.18049v1,,False
AutoCas: Autoregressive Cascade Predictor in Social Networks via Large Language Models,25/02/2025,"Yuhao Zheng, Chenghua Gong, Rui Sun, Juyuan Zhang, Liming Pan, Linyuan Lv","Popularity prediction in information cascades plays a crucial role in social
computing, with broad applications in viral marketing, misinformation control,
and content recommendation. However, information propagation mechanisms, user
behavior, and temporal activity patterns exhibit significant diversity,
necessitating a foundational model capable of adapting to such variations. At
the same time, the amount of available cascade data remains relatively limited
compared to the vast datasets used for training large language models (LLMs).
Recent studies have demonstrated the feasibility of leveraging LLMs for
time-series prediction by exploiting commonalities across different time-series
domains. Building on this insight, we introduce the Autoregressive Information
Cascade Predictor (AutoCas), an LLM-enhanced model designed specifically for
cascade popularity prediction. Unlike natural language sequences, cascade data
is characterized by complex local topologies, diffusion contexts, and evolving
dynamics, requiring specialized adaptations for effective LLM integration. To
address these challenges, we first tokenize cascade data to align it with
sequence modeling principles. Next, we reformulate cascade diffusion as an
autoregressive modeling task to fully harness the architectural strengths of
LLMs. Beyond conventional approaches, we further introduce prompt learning to
enhance the synergy between LLMs and cascade prediction. Extensive experiments
demonstrate that AutoCas significantly outperforms baseline models in cascade
popularity prediction while exhibiting scaling behavior inherited from LLMs.
Code is available at this repository:
https://anonymous.4open.science/r/AutoCas-85C6",http://arxiv.org/pdf/2502.18040v1,,False
ExPath: Towards Explaining Targeted Pathways for Biological Knowledge Bases,25/02/2025,"Rikuto Kotoge, Ziwei Yang, Zheng Chen, Yushun Dong, Yasuko Matsubara, Jimeng Sun, Yasushi Sakurai","Biological knowledge bases provide systemically functional pathways of cells
or organisms in terms of molecular interaction. However, recognizing more
targeted pathways, particularly when incorporating wet-lab experimental data,
remains challenging and typically requires downstream biological analyses and
expertise. In this paper, we frame this challenge as a solvable graph learning
and explaining task and propose a novel pathway inference framework, ExPath,
that explicitly integrates experimental data, specifically amino acid sequences
(AA-seqs), to classify various graphs (bio-networks) in biological databases.
The links (representing pathways) that contribute more to classification can be
considered as targeted pathways. Technically, ExPath comprises three
components: (1) a large protein language model (pLM) that encodes and embeds
AA-seqs into graph, overcoming traditional obstacles in processing AA-seq data,
such as BLAST; (2) PathMamba, a hybrid architecture combining graph neural
networks (GNNs) with state-space sequence modeling (Mamba) to capture both
local interactions and global pathway-level dependencies; and (3)
PathExplainer, a subgraph learning module that identifies functionally critical
nodes and edges through trainable pathway masks. We also propose ML-oriented
biological evaluations and a new metric. The experiments involving 301
bio-networks evaluations demonstrate that pathways inferred by ExPath maintain
biological meaningfulness. We will publicly release curated 301 bio-network
data soon.",http://arxiv.org/pdf/2502.18026v1,,False
LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena,25/02/2025,"Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou","Recent advancements in large language models (LLMs) have significantly
improved performance in natural language processing tasks. However, their
ability to generalize to dynamic, unseen tasks, particularly in numerical
reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on
problems with predefined optimal solutions, which may not align with real-world
scenarios where clear answers are absent. To bridge this gap, we design the
Agent Trading Arena, a virtual numerical game simulating complex economic
systems through zero-sum games, where agents invest in stock portfolios. Our
experiments reveal that LLMs, including GPT-4o, struggle with algebraic
reasoning when dealing with plain-text stock data, often focusing on local
details rather than global trends. In contrast, LLMs perform significantly
better with geometric reasoning when presented with visual data, such as
scatter plots or K-line charts, suggesting that visual representations enhance
numerical reasoning. This capability is further improved by incorporating the
reflection module, which aids in the analysis and interpretation of complex
data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate
stronger reasoning with visual data compared to text. Our code and data are
publicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.",http://arxiv.org/pdf/2502.17967v1,,False
Structure-prior Informed Diffusion Model for Graph Source Localization with Limited Data,25/02/2025,"Hongyi Chen, Jingtao Ding, Xiaojun Liang, Yong Li, Xiao-Ping Zhang","The source localization problem in graph information propagation is crucial
for managing various network disruptions, from misinformation spread to
infrastructure failures. While recent deep generative approaches have shown
promise in this domain, their effectiveness is limited by the scarcity of
real-world propagation data. This paper introduces SIDSL
(\textbf{S}tructure-prior \textbf{I}nformed \textbf{D}iffusion model for
\textbf{S}ource \textbf{L}ocalization), a novel framework that addresses three
key challenges in limited-data scenarios: unknown propagation patterns, complex
topology-propagation relationships, and class imbalance between source and
non-source nodes. SIDSL incorporates topology-aware priors through graph label
propagation and employs a propagation-enhanced conditional denoiser with a
GNN-parameterized label propagation module (GNN-LP). Additionally, we propose a
structure-prior biased denoising scheme that initializes from structure-based
source estimations rather than random noise, effectively countering class
imbalance issues. Experimental results across four real-world datasets
demonstrate SIDSL's superior performance, achieving 7.5-13.3% improvements in
F1 scores compared to state-of-the-art methods. Notably, when pretrained with
simulation data of synthetic patterns, SIDSL maintains robust performance with
only 10% of training data, surpassing baselines by more than 18.8%. These
results highlight SIDSL's effectiveness in real-world applications where
labeled data is scarce.",http://arxiv.org/pdf/2502.17928v1,,False
Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning,25/02/2025,"Runzhong Wang, Rui-Xi Wang, Mrunali Manjrekar, Connor W. Coley","Molecular machine learning has gained popularity with the advancements of
geometric deep learning. In parallel, retrieval-augmented generation has become
a principled approach commonly used with language models. However, the optimal
integration of retrieval augmentation into molecular machine learning remains
unclear. Graph neural networks stand to benefit from clever matching to
understand the structural alignment of retrieved molecules to a query molecule.
Neural graph matching offers a compelling solution by explicitly modeling node
and edge affinities between two structural graphs while employing a
noise-robust, end-to-end neural network to learn affinity metrics. We apply
this approach to mass spectrum simulation and introduce MARASON, a novel model
that incorporates neural graph matching to enhance a fragmentation-based neural
network. Experimental results highlight the effectiveness of our design, with
MARASON achieving 28% top-1 accuracy, a substantial improvement over the
non-retrieval state-of-the-art accuracy of 19%. Moreover, MARASON outperforms
both naive retrieval-augmented generation methods and traditional graph
matching approaches.",http://arxiv.org/pdf/2502.17874v1,,False
EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling,25/02/2025,"Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane","Deep learning has achieved significant progress in the development of
electroencephalogram (EEG) foundation models, with Transformer-based
architectures excelling at capturing long-range dependencies. However, their
quadratic computational complexity presents challenges in memory efficiency,
training, and inference speed, limiting their scalability and generalizability
as a foundation model. In this paper, we propose EEGM2, a self-supervised
framework based on structured state space duality (SSD) that overcomes these
limitations. EEGM2 introduces three key innovations: (1) a reconstruction-based
framework that captures both local and global EEG features through Mamba-2
structured state space models, (2) a spatiotemporal-aware loss function that
enhances robustness to noise and preserves spectral information, and (3) a
multi-branch receptive field input embedding strategy that improves
cross-subject generalization and stability for EEG sequences of varying
lengths. In comparison to traditional pretraining methods, on raw EEG or latent
representation spaces, EEGM2 shows superior performance on long-sequence tasks,
where conventional models struggle. Our experimental results on six EEG
datasets validate that EEGM2 not only achieves state-of-the-art cross-domain
accuracy but also reduces computational overhead, making it a more efficient
solution for deployment on resource-constrained BCI devices.",http://arxiv.org/pdf/2502.17873v1,,False
ASurvey: Spatiotemporal Consistency in Video Generation,25/02/2025,"Zhiyu Yin, Kehai Chen, Xuefeng Bai, Ruili Jiang, Juntao Li, Hongdong Li, Jin Liu, Yang Xiang, Jun Yu, Min Zhang","Video generation, by leveraging a dynamic visual generation method, pushes
the boundaries of Artificial Intelligence Generated Content (AIGC). Video
generation presents unique challenges beyond static image generation, requiring
both high-quality individual frames and temporal coherence to maintain
consistency across the spatiotemporal sequence. Recent works have aimed at
addressing the spatiotemporal consistency issue in video generation, while few
literature review has been organized from this perspective. This gap hinders a
deeper understanding of the underlying mechanisms for high-quality video
generation. In this survey, we systematically review the recent advances in
video generation, covering five key aspects: foundation models, information
representations, generation schemes, post-processing techniques, and evaluation
metrics. We particularly focus on their contributions to maintaining
spatiotemporal consistency. Finally, we discuss the future directions and
challenges in this field, hoping to inspire further efforts to advance the
development of video generation.",http://arxiv.org/pdf/2502.17863v1,,False
Can Multimodal LLMs Perform Time Series Anomaly Detection?,25/02/2025,"Xiongxiao Xu, Haoran Wang, Yueqing Liang, Philip S. Yu, Yue Zhao, Kai Shu","Large language models (LLMs) have been increasingly used in time series
analysis. However, the potential of multimodal LLMs (MLLMs), particularly
vision-language models, for time series remains largely under-explored. One
natural way for humans to detect time series anomalies is through visualization
and textual description. Motivated by this, we raise a critical and practical
research question: Can multimodal LLMs perform time series anomaly detection?
To answer this, we propose VisualTimeAnomaly benchmark to evaluate MLLMs in
time series anomaly detection (TSAD). Our approach transforms time series
numerical data into the image format and feed these images into various MLLMs,
including proprietary models (GPT-4o and Gemini-1.5) and open-source models
(LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant. In
total, VisualTimeAnomaly contains 12.4k time series images spanning 3 scenarios
and 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with
the univariate case (point- and range-wise anomalies), we extend our evaluation
to more practical scenarios, including multivariate and irregular time series
scenarios, and variate-wise anomalies. Our study reveals several key insights:
  1) MLLMs detect range- and variate-wise anomalies more effectively than
point-wise anomalies.
  2) MLLMs are highly robust to irregular time series, even with 25% of the
data missing.
  3) Open-source MLLMs perform comparably to proprietary models in TSAD. While
open-source MLLMs excel on univariate time series, proprietary MLLMs
demonstrate superior effectiveness on multivariate time series.
  To the best of our knowledge, this is the first work to comprehensively
investigate MLLMs for TSAD, particularly for multivariate and irregular time
series scenarios. We release our dataset and code at
https://github.com/mllm-ts/VisualTimeAnomaly to support future research.",http://arxiv.org/pdf/2502.17812v1,,False
PVBF: A Framework for Mitigating Parameter Variation Imbalance in Online Continual Learning,25/02/2025,"Zelin Tao, Hao Deng, Mingqing Liu, Lijun Zhang, Shengjie Zhao","Online continual learning (OCL), which enables AI systems to adaptively learn
from non-stationary data streams, is commonly achieved using experience replay
(ER)-based methods that retain knowledge by replaying stored past during
training. However, these methods face challenges of prediction bias, stemming
from deviations in parameter update directions during task transitions. This
paper identifies parameter variation imbalance as a critical factor
contributing to prediction bias in ER-based OCL. Specifically, using the
proposed parameter variation evaluation method, we highlight two types of
imbalance: correlation-induced imbalance, where certain parameters are
disproportionately updated across tasks, and layer-wise imbalance, where output
layer parameters update faster than those in preceding layers. To mitigate the
above imbalances, we propose the Parameter Variation Balancing Framework
(PVBF), which incorporates: 1) a novel method to compute parameter correlations
with previous tasks based on parameter variations, 2) an
encourage-and-consolidate (E&C) method utilizing parameter correlations to
perform gradient adjustments across all parameters during training, 3) a
dual-layer copy weights with reinit (D-CWR) strategy to slowly update output
layer parameters for frequently occuring sample categories. Experiments on
short and long task sequences demonstrate that PVBF significantly reduces
prediction bias and improves OCL performance, achieving up to 47\% higher
accuracy compared to existing ER-based methods.",http://arxiv.org/pdf/2502.17794v1,,False
