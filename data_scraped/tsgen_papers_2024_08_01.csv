Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities,31/07/2024,"Ming Zhang, Caishuang Huang, Yilong Wu, Shichun Liu, Huiyuan Zheng, Yurui Dong, Yujiong Shen, Shihan Dou, Jun Zhao, Junjie Ye, Qi Zhang, Tao Gui, Xuanjing Huang","Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented
conversations, including information gathering. How to utilize ToD accurately,
efficiently and effectively for information gathering has always been a
critical and challenging task. Recent studies have demonstrated that Large
Language Models (LLMs) excel in dialogue, instruction generation, and
reasoning, and can significantly enhance the performance of TOD through
fine-tuning. However, current datasets primarily cater to user-led systems and
are limited to predefined specific scenarios and slots, thereby necessitating
improvements in the proactiveness, diversity, and capabilities of TOD. In this
study, we present a detailed multi-domain task-oriented data construction
process for conversations, and a Chinese dialogue dataset generated based on
this process, \textbf{TransferTOD}, which authentically simulates human-machine
dialogues in 30 popular life service scenarios. Leveraging this dataset, we
trained a \textbf{TransferTOD-7B} model using full-parameter fine-tuning,
showcasing notable abilities in slot filling and questioning. Our work has
demonstrated its strong generalization capabilities in various downstream
scenarios, significantly enhancing both data utilization efficiency and system
performance. The data is released in
https://github.com/KongLongGeFDU/TransferTOD.",http://arxiv.org/pdf/2407.21693v1,,False
Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative Priors,31/07/2024,"Shoujin Huang, Guanxiong Luo, Yuwan Wang, Kexin Yang, Lingyan Zhang, Jingzhe Liu, Hua Guo, Min Wang, Mengye Lyu","Simultaneous multislice (SMS) imaging is a powerful technique for
accelerating magnetic resonance imaging (MRI) acquisitions. However, SMS
reconstruction remains challenging due to the complex signal interactions
between and within the excited slices. This study presents a robust SMS MRI
reconstruction method using deep generative priors. Starting from Gaussian
noise, we leverage denoising diffusion probabilistic models (DDPM) to gradually
recover the individual slices through reverse diffusion iterations while
imposing data consistency from the measured k-space under readout concatenation
framework. The posterior sampling procedure is designed such that the DDPM
training can be performed on single-slice images without special adjustments
for SMS tasks. Additionally, our method integrates a low-frequency enhancement
(LFE) module to address a practical issue that SMS-accelerated fast spin echo
(FSE) and echo-planar imaging (EPI) sequences cannot easily embed
autocalibration signals. Extensive experiments demonstrate that our approach
consistently outperforms existing methods and generalizes well to unseen
datasets. The code is available at https://github.com/Solor-pikachu/ROGER after
the review process.",http://arxiv.org/pdf/2407.21600v1,,False
Generative Sentiment Analysis via Latent Category Distribution and Constrained Decoding,31/07/2024,"Jun Zhou, Dongyang Yu, Kamran Aziz, Fangfang Su, Qing Zhang, Fei Li, Donghong Ji","Fine-grained sentiment analysis involves extracting and organizing sentiment
elements from textual data. However, existing approaches often overlook issues
of category semantic inclusion and overlap, as well as inherent structural
patterns within the target sequence. This study introduces a generative
sentiment analysis model. To address the challenges related to category
semantic inclusion and overlap, a latent category distribution variable is
introduced. By reconstructing the input of a variational autoencoder, the model
learns the intensity of the relationship between categories and text, thereby
improving sequence generation. Additionally, a trie data structure and
constrained decoding strategy are utilized to exploit structural patterns,
which in turn reduces the search space and regularizes the generation process.
Experimental results on the Restaurant-ACOS and Laptop-ACOS datasets
demonstrate a significant performance improvement compared to baseline models.
Ablation experiments further confirm the effectiveness of latent category
distribution and constrained decoding strategy.",http://arxiv.org/pdf/2407.21560v1,,False
CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment,31/07/2024,"Akira Kasuga, Ryo Yonetani","This paper presents the Customer Experience (CX) Simulator, a novel framework
designed to assess the effects of untested web-marketing campaigns through user
behavior simulations. The proposed framework leverages large language models
(LLMs) to represent various events in a user's behavioral history, such as
viewing an item, applying a coupon, or purchasing an item, as semantic
embedding vectors. We train a model to predict transitions between events from
their LLM embeddings, which can even generalize to unseen events by learning
from diverse training data. In web-marketing applications, we leverage this
transition prediction model to simulate how users might react differently when
new campaigns or products are presented to them. This allows us to eliminate
the need for costly online testing and enhance the marketers' abilities to
reveal insights. Our numerical evaluation and user study, utilizing BigQuery
Public Datasets from the Google Merchandise Store, demonstrate the
effectiveness of our framework.",http://arxiv.org/pdf/2407.21553v1,10.1145/3627673.3679894,False
Root Cause Analysis Of Productivity Losses In Manufacturing Systems Utilizing Ensemble Machine Learning,31/07/2024,"Jonas Gram, Brandon K. Sai, Thomas Bauernhansl","In today's rapidly evolving landscape of automation and manufacturing
systems, the efficient resolution of productivity losses is paramount. This
study introduces a data-driven ensemble approach, utilizing the cyclic
multivariate time series data from binary sensors and signals from Programmable
Logic Controllers (PLCs) within these systems. The objective is to
automatically analyze productivity losses per cycle and pinpoint their root
causes by assigning the loss to a system element. The ensemble approach
introduced in this publication integrates various methods, including
information theory and machine learning behavior models, to provide a robust
analysis for each production cycle. To expedite the resolution of productivity
losses and ensure short response times, stream processing becomes a necessity.
Addressing this, the approach is implemented as data-stream analysis and can be
transferred to batch processing, seamlessly integrating into existing systems
without the need for extensive historical data analysis. This method has two
positive effects. Firstly, the result of the analysis ensures that the period
of lower productivity is reduced by identifying the likely root cause of the
productivity loss. Secondly, these results are more reliable due to the
ensemble approach and therefore avoid dependency on technical experts. The
approach is validated using a semi-automated welding manufacturing system, an
injection molding automation system, and a synthetically generated test PLC
dataset. The results demonstrate the method's efficacy in offering a
data-driven understanding of process behavior and mark an advancement in
autonomous manufacturing system analysis.",http://arxiv.org/pdf/2407.21503v1,10.15488/17728,False
Deformable 3D Shape Diffusion Model,31/07/2024,"Dengsheng Chen, Jie Hu, Xiaoming Wei, Enhua Wu","The Gaussian diffusion model, initially designed for image generation, has
recently been adapted for 3D point cloud generation. However, these adaptations
have not fully considered the intrinsic geometric characteristics of 3D shapes,
thereby constraining the diffusion model's potential for 3D shape manipulation.
To address this limitation, we introduce a novel deformable 3D shape diffusion
model that facilitates comprehensive 3D shape manipulation, including point
cloud generation, mesh deformation, and facial animation. Our approach
innovatively incorporates a differential deformation kernel, which deconstructs
the generation of geometric structures into successive non-rigid deformation
stages. By leveraging a probabilistic diffusion model to simulate this
step-by-step process, our method provides a versatile and efficient solution
for a wide range of applications, spanning from graphics rendering to facial
expression animation. Empirical evidence highlights the effectiveness of our
approach, demonstrating state-of-the-art performance in point cloud generation
and competitive results in mesh deformation. Additionally, extensive visual
demonstrations reveal the significant potential of our approach for practical
applications. Our method presents a unique pathway for advancing 3D shape
manipulation and unlocking new opportunities in the realm of virtual reality.",http://arxiv.org/pdf/2407.21428v1,,False
Deep Fréchet Regression,31/07/2024,"Su I Iao, Yidong Zhou, Hans-Georg Müller","Advancements in modern science have led to the increasing availability of
non-Euclidean data in metric spaces. This paper addresses the challenge of
modeling relationships between non-Euclidean responses and multivariate
Euclidean predictors. We propose a flexible regression model capable of
handling high-dimensional predictors without imposing parametric assumptions.
Two primary challenges are addressed: the curse of dimensionality in
nonparametric regression and the absence of linear structure in general metric
spaces. The former is tackled using deep neural networks, while for the latter
we demonstrate the feasibility of mapping the metric space where responses
reside to a low-dimensional Euclidean space using manifold learning. We
introduce a reverse mapping approach, employing local Fr\'echet regression, to
map the low-dimensional manifold representations back to objects in the
original metric space. We develop a theoretical framework, investigating the
convergence rate of deep neural networks under dependent sub-Gaussian noise
with bias. The convergence rate of the proposed regression model is then
obtained by expanding the scope of local Fr\'echet regression to accommodate
multivariate predictors in the presence of errors in predictors. Simulations
and case studies show that the proposed model outperforms existing methods for
non-Euclidean responses, focusing on the special cases of probability measures
and networks.",http://arxiv.org/pdf/2407.21407v1,,False
MetaOpenFOAM: an LLM-based multi-agent framework for CFD,31/07/2024,"Yuxuan Chena, Xu Zhua, Hua Zhoua, Zhuyin Rena","Remarkable progress has been made in automated problem solving through
societies of agents based on large language models (LLMs). Computational fluid
dynamics (CFD), as a complex problem, presents unique challenges in automated
simulations that require sophisticated solutions. MetaOpenFOAM, as a novel
multi-agent collaborations framework, aims to complete CFD simulation tasks
with only natural language as input. These simulation tasks include mesh
pre-processing, simulation and post-processing, etc. MetaOpenFOAM harnesses the
power of MetaGPT's assembly line paradigm, which assigns diverse roles to
various agents, efficiently breaking down complex CFD tasks into manageable
subtasks. Langchain further complements MetaOpenFOAM by integrating
Retrieval-Augmented Generation (RAG) technology, which enhances the framework's
ability by integrating a searchable database of OpenFOAM tutorials for LLMs.
Tests on a benchmark for natural language-based CFD solver, consisting of 8 CFD
simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per
test (85%), with each test case costing only $0.22 on average. The 8 CFD
simulation tasks include compressible and incompressible flows, 2D and 3D
flows, heat transfer, and combustion, demonstrating the ability to automate CFD
simulations using only natural language input and iteratively correct errors to
achieve the desired simulation at a low cost. An ablation study was conducted
to verify the necessity of each component in the multi-agent system and the RAG
technology. A sensitivity study on the randomness of LLM showed that LLM with
low randomness can obtain more stable and accurate results. Additionally,
MetaOpenFOAM own the ability to identify and modify key parameters in user
requirements and excels in correcting bugs when failures occur, with or without
human participation, which demonstrates the generalization of MetaOpenFOAM.",http://arxiv.org/pdf/2407.21320v1,,False
Big Cooperative Learning,31/07/2024,Yulai Cong,"Cooperation plays a pivotal role in the evolution of human intelligence;
moreover, it also underlies the recent revolutionary advancement of artificial
intelligence (AI) that is driven by foundation models. Specifically, we reveal
that the training of foundation models can be interpreted as a form of big
cooperative learning (\textit{abbr.} big learning), where massive learning
individuals/tasks \emph{cooperate} to approach the unique essence of data from
diverse perspectives of data prediction, leveraging a universal model. The
presented big learning therefore unifies most training objectives of foundation
models within a consistent framework, where their underlying assumptions are
exposed simultaneously. We design tailored simulations to demonstrate the
principle of big learning, based on which we provide learning-perspective
justifications for the successes of foundation models, with interesting
side-products. Furthermore, we reveal that big learning is a new dimension for
upgrading conventional machine learning paradigms, valuable for endowing
reinvigorations to associated applications; as an illustrative example, we
propose the BigLearn-GAN, which is a novel adversarially-trained foundation
model with versatile data sampling capabilities. Code is available at
\texttt{https://github.com/YulaiCong/BigCooperativeLearning}.",http://arxiv.org/pdf/2407.21319v1,,False
Implementing Streaming algorithm and k-means clusters to RAG,31/07/2024,"Haoyu Kang, Yuzhou Zhu, Yukun Zhong, Ke Wang","Retrieval-augmented generation (RAG) has achieved great success in
information retrieval to assist large models because it builds an external
knowledge database. However, it also has many problems: it consumes a lot of
memory because of the huge database. When faced with massive streaming data, it
is unable to update the established index database in time. To save the memory
of building the database and maintain accuracy simultaneously, we proposed a
new approach combining a streaming algorithm and k-means cluster with RAG. Our
approach applies a streaming algorithm to update the index and reduce memory
consumption. Then use the k-means algorithm to cluster documents with high
similarities together, the query time will be shortened by doing this. We
conducted comparative experiments on four methods, and the results show that
RAG with streaming algorithm and k-means cluster performs well in accuracy and
memory. For massive streaming data, we find that our method behaves better than
traditional RAG",http://arxiv.org/pdf/2407.21300v1,,False
DEF-oriCORN: efficient 3D scene understanding for robust language-directed manipulation without demonstrations,31/07/2024,"Dongwon Son, Sanghyeon Son, Jaehyung Kim, Beomjoon Kim","We present DEF-oriCORN, a framework for language-directed manipulation tasks.
By leveraging a novel object-based scene representation and
diffusion-model-based state estimation algorithm, our framework enables
efficient and robust manipulation planning in response to verbal commands, even
in tightly packed environments with sparse camera views without any
demonstrations. Unlike traditional representations, our representation affords
efficient collision checking and language grounding. Compared to
state-of-the-art baselines, our framework achieves superior estimation and
motion planning performance from sparse RGB images and zero-shot generalizes to
real-world scenarios with diverse materials, including transparent and
reflective objects, despite being trained exclusively in simulation. Our code
for data generation, training, inference, and pre-trained weights are publicly
available at: https://sites.google.com/view/def-oricorn/home.",http://arxiv.org/pdf/2407.21267v1,,False
