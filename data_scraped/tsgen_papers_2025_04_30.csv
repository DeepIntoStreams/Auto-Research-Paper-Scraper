Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Deep Learning Characterizes Depression and Suicidal Ideation from Eye Movements,29/04/2025,"Kleanthis Avramidis, Woojae Jeong, Aditya Kommineni, Sudarsana R. Kadiri, Marcus Ma, Colin McDaniel, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Dani Byrd, Assal Habibi, B. Rael Cahn, Idan A. Blank, Kristina Lerman, Takfarinas Medani, Richard M. Leahy, Shrikanth Narayanan","Identifying physiological and behavioral markers for mental health conditions
is a longstanding challenge in psychiatry. Depression and suicidal ideation, in
particular, lack objective biomarkers, with screening and diagnosis primarily
relying on self-reports and clinical interviews. Here, we investigate eye
tracking as a potential marker modality for screening purposes. Eye movements
are directly modulated by neuronal networks and have been associated with
attentional and mood-related patterns; however, their predictive value for
depression and suicidality remains unclear. We recorded eye-tracking sequences
from 126 young adults as they read and responded to affective sentences, and
subsequently developed a deep learning framework to predict their clinical
status. The proposed model included separate branches for trials of positive
and negative sentiment, and used 2D time-series representations to account for
both intra-trial and inter-trial variations. We were able to identify
depression and suicidal ideation with an area under the receiver operating
curve (AUC) of 0.793 (95% CI: 0.765-0.819) against healthy controls, and
suicidality specifically with 0.826 AUC (95% CI: 0.797-0.852). The model also
exhibited moderate, yet significant, accuracy in differentiating depressed from
suicidal participants, with 0.609 AUC (95% CI 0.571-0.646). Discriminative
patterns emerge more strongly when assessing the data relative to response
generation than relative to the onset time of the final word of the sentences.
The most pronounced effects were observed for negative-sentiment sentences,
that are congruent to depressed and suicidal participants. Our findings
highlight eye tracking as an objective tool for mental health assessment and
underscore the modulatory impact of emotional stimuli on cognitive processes
affecting oculomotor control.",http://arxiv.org/pdf/2504.20944v1,,False
Scenario-based Compositional Verification of Autonomous Systems with Neural Perception,29/04/2025,"Christopher Watson, Rajeev Alur, Divya Gopinath, Ravi Mangal, Corina S. Pasareanu","Recent advances in deep learning have enabled the development of autonomous
systems that use deep neural networks for perception. Formal verification of
these systems is challenging due to the size and complexity of the perception
DNNs as well as hard-to-quantify, changing environment conditions. To address
these challenges, we propose a probabilistic verification framework for
autonomous systems based on the following key concepts: (1) Scenario-based
Modeling: We decompose the task (e.g., car navigation) into a composition of
scenarios, each representing a different environment condition. (2)
Probabilistic Abstractions: For each scenario, we build a compact abstraction
of perception based on the DNN's performance on an offline dataset that
represents the scenario's environment condition. (3) Symbolic Reasoning and
Acceleration: The abstractions enable efficient compositional verification of
the autonomous system via symbolic reasoning and a novel acceleration proof
rule that bounds the error probability of the system under arbitrary variations
of environment conditions. We illustrate our approach on two case studies: an
experimental autonomous system that guides airplanes on taxiways using
high-dimensional perception DNNs and a simulation model of an F1Tenth
autonomous car using LiDAR observations.",http://arxiv.org/pdf/2504.20942v1,,False
Energy-Based Coarse-Graining in Molecular Dynamics: A Flow-Based Framework Without Data,29/04/2025,"Maximilian Stupp, P. S. Koutsourelakis","Coarse-grained (CG) models offer an effective route to reducing the
complexity of molecular simulations, yet conventional approaches depend heavily
on long all-atom molecular dynamics (MD) trajectories to adequately sample
configurational space. This data-driven dependence limits their accuracy and
generalizability, as unvisited configurations remain excluded from the
resulting CG model. We introduce a data-free generative framework for
coarse-graining that directly targets the all-atom Boltzmann distribution. Our
model defines a structured latent space comprising slow collective variables,
which are statistically associated with multimodal marginal densities capturing
metastable states, and fast variables, which represent the remaining degrees of
freedom with simple, unimodal conditional distributions. A potentially
learnable, bijective map from the full latent space to the all-atom
configuration space enables automatic and accurate reconstruction of molecular
structures. The model is trained using an energy-based objective that minimizes
the reverse Kullback-Leibler divergence, relying solely on the interatomic
potential rather than sampled trajectories. A tempering scheme is used to
stabilize training and promote exploration of diverse configurations. Once
trained, the model can generate unbiased, one-shot equilibrium all-atom
samples. We validate the method on two synthetic systems-a double-well
potential and a Gaussian mixture-as well as on the benchmark alanine dipeptide.
The model captures all relevant modes of the Boltzmann distribution, accurately
reconstructs atomic configurations, and learns physically meaningful
coarse-grained representations, all without any simulation data.",http://arxiv.org/pdf/2504.20940v1,,False
Improvements of Dark Experience Replay and Reservoir Sampling towards Better Balance between Consolidation and Plasticity,29/04/2025,Taisuke Kobayashi,"Continual learning is the one of the most essential abilities for autonomous
agents, which can incrementally learn daily-life skills. For this ultimate
goal, a simple but powerful method, dark experience replay (DER), has been
proposed recently. DER mitigates catastrophic forgetting, in which the skills
acquired in the past are unintentionally forgotten, by stochastically storing
the streaming data in a reservoir sampling (RS) buffer and by relearning them
or retaining the past outputs for them. However, since DER considers multiple
objectives, it will not function properly without appropriate weighting of
them. In addition, the ability to retain past outputs inhibits learning if the
past outputs are incorrect due to distribution shift or other effects. This is
due to a tradeoff between memory consolidation and plasticity. The tradeoff is
hidden even in the RS buffer, which gradually stops storing new data for new
skills in it as data is continuously passed to it. To alleviate the tradeoff
and achieve better balance, this paper proposes improvement strategies to each
of DER and RS. Specifically, DER is improved with automatic adaptation of
weights, block of replaying erroneous data, and correction of past outputs. RS
is also improved with generalization of acceptance probability, stratification
of plural buffers, and intentional omission of unnecessary data. These
improvements are verified through multiple benchmarks including regression,
classification, and reinforcement learning problems. As a result, the proposed
methods achieve steady improvements in learning performance by balancing the
memory consolidation and plasticity.",http://arxiv.org/pdf/2504.20932v1,,False
A Domain-Agnostic Scalable AI Safety Ensuring Framework,29/04/2025,"Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn","Ensuring the safety of AI systems has recently emerged as a critical priority
for real-world deployment, particularly in physical AI applications. Current
approaches to AI safety typically address predefined domain-specific safety
conditions, limiting their ability to generalize across contexts.
  We propose a novel AI safety framework that ensures AI systems comply with
\textbf{any user-defined constraint}, with \textbf{any desired probability},
and across \textbf{various domains}.
  In this framework, we combine an AI component (e.g., neural network) with an
optimization problem to produce responses that minimize objectives while
satisfying user-defined constraints with probabilities exceeding user-defined
thresholds. For credibility assessment of the AI component, we propose
\textit{internal test data}, a supplementary set of safety-labeled data, and a
\textit{conservative testing} methodology that provides statistical validity of
using internal test data. We also present an approximation method of a loss
function and how to compute its gradient for training.
  We mathematically prove that probabilistic constraint satisfaction is
guaranteed under specific, mild conditions and prove a scaling law between
safety and the number of internal test data. We demonstrate our framework's
effectiveness through experiments in diverse domains: demand prediction for
production decision, safe reinforcement learning within the SafetyGym
simulator, and guarding AI chatbot outputs. Through these experiments, we
demonstrate that our method guarantees safety for user-specified constraints,
outperforms {for \textbf{up to several order of magnitudes}} existing methods
in low safety threshold regions, and scales effectively with respect to the
size of internal test data.",http://arxiv.org/pdf/2504.20924v1,,False
When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines,29/04/2025,"Sachin R. Pendse, Darren Gergle, Rachel Kornfield, Jonah Meyerhoff, David Mohr, Jina Suh, Annie Wescott, Casey Williams, Jessica Schleider","Red-teaming is a core part of the infrastructure that ensures that AI models
do not produce harmful content. Unlike past technologies, the black box nature
of generative AI systems necessitates a uniquely interactional mode of testing,
one in which individuals on red teams actively interact with the system,
leveraging natural language to simulate malicious actors and solicit harmful
outputs. This interactional labor done by red teams can result in mental health
harms that are uniquely tied to the adversarial engagement strategies necessary
to effectively red team. The importance of ensuring that generative AI models
do not propagate societal or individual harm is widely recognized -- one less
visible foundation of end-to-end AI safety is also the protection of the mental
health and wellbeing of those who work to keep model outputs safe. In this
paper, we argue that the unmet mental health needs of AI red-teamers is a
critical workplace safety concern. Through analyzing the unique mental health
impacts associated with the labor done by red teams, we propose potential
individual and organizational strategies that could be used to meet these
needs, and safeguard the mental health of red-teamers. We develop our proposed
strategies through drawing parallels between common red-teaming practices and
interactional labor common to other professions (including actors, mental
health professionals, conflict photographers, and content moderators),
describing how individuals and organizations within these professional spaces
safeguard their mental health given similar psychological demands. Drawing on
these protective practices, we describe how safeguards could be adapted for the
distinct mental health challenges experienced by red teaming organizations as
they mitigate emerging technological risks on the new digital frontlines.",http://arxiv.org/pdf/2504.20910v1,,False
Evaluating Effects of Augmented SELFIES for Molecular Understanding Using QK-LSTM,29/04/2025,"Collin Beaudoin, Swaroop Ghosh","Identifying molecular properties, including side effects, is a critical yet
time-consuming step in drug development. Failing to detect these side effects
before regulatory submission can result in significant financial losses and
production delays, and overlooking them during the regulatory review can lead
to catastrophic consequences. This challenge presents an opportunity for
innovative machine learning approaches, particularly hybrid quantum-classical
models like the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network.
The QK-LSTM integrates quantum kernel functions into the classical LSTM
framework, enabling the capture of complex, non-linear patterns in sequential
data. By mapping input data into a high-dimensional quantum feature space, the
QK-LSTM model reduces the need for large parameter sets, allowing for model
compression without sacrificing accuracy in sequence-based tasks. Recent
advancements have been made in the classical domain using augmented variations
of the Simplified Molecular Line-Entry System (SMILES). However, to the best of
our knowledge, no research has explored the impact of augmented SMILES in the
quantum domain, nor the role of augmented Self-Referencing Embedded Strings
(SELFIES) in either classical or hybrid quantum-classical settings. This study
presents the first analysis of these approaches, providing novel insights into
their potential for enhancing molecular property prediction and side effect
identification. Results reveal that augmenting SELFIES yields in statistically
significant improvements from SMILES by a 5.97% improvement for the classical
domain and a 5.91% improvement for the hybrid quantum-classical domain.",http://arxiv.org/pdf/2504.20789v1,,False
JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation,29/04/2025,"Ji Shi, Chengxun Xie, Zhonghao Li, Xinming Zhang, Miao Zhang","The discovery of new molecules based on the original chemical molecule
distributions is of great importance in medicine. The graph transformer, with
its advantages of high performance and scalability compared to traditional
graph networks, has been widely explored in recent research for applications of
graph structures. However, current transformer-based graph decoders struggle to
effectively utilize graph information, which limits their capacity to leverage
only sequences of nodes rather than the complex topological structures of
molecule graphs. This paper focuses on building a graph transformer-based
framework for molecular generation, which we call \textbf{JTreeformer} as it
transforms graph generation into junction tree generation. It combines GCN
parallel with multi-head attention as the encoder. It integrates a directed
acyclic GCN into a graph-based Transformer to serve as a decoder, which can
iteratively synthesize the entire molecule by leveraging information from the
partially constructed molecular structure at each step. In addition, a
diffusion model is inserted in the latent space generated by the encoder, to
enhance the efficiency and effectiveness of sampling further. The empirical
results demonstrate that our novel framework outperforms existing molecule
generation methods, thus offering a promising tool to advance drug discovery
(https://anonymous.4open.science/r/JTreeformer-C74C).",http://arxiv.org/pdf/2504.20770v1,,False
Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems,29/04/2025,"Sahil Tomar, Shamshe Alam, Sandeep Kumar, Amit Mathur","In this paper, a novel quantum classical hybrid framework is proposed that
synergizes quantum with Classical Reinforcement Learning. By leveraging the
inherent parallelism of quantum computing, the proposed approach generates
robust Q tables and specialized turn cost estimations, which are then
integrated with a classical Reinforcement Learning pipeline. The Classical
Quantum fusion results in rapid convergence of training, reducing the training
time significantly and improved adaptability in scenarios featuring static,
dynamic, and moving obstacles. Simulator based evaluations demonstrate
significant enhancements in path efficiency, trajectory smoothness, and mission
success rates, underscoring the potential of framework for real time,
autonomous navigation in complex and unpredictable environments. Furthermore,
the proposed framework was tested beyond simulations on practical scenarios,
including real world map data such as the IIT Delhi campus, reinforcing its
potential for real time, autonomous navigation in complex and unpredictable
environments.",http://arxiv.org/pdf/2504.20660v1,,False
DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models,29/04/2025,"Sagi Della Torre, Mirco Pezzoli, Fabio Antonacci, Sharon Gannot","Room Impulse Responses (RIRs) characterize acoustic environments and are
crucial in multiple audio signal processing tasks. High-quality RIR estimates
drive applications such as virtual microphones, sound source localization,
augmented reality, and data augmentation. However, obtaining RIR measurements
with high spatial resolution is resource-intensive, making it impractical for
large spaces or when dense sampling is required. This research addresses the
challenge of estimating RIRs at unmeasured locations within a room using
Denoising Diffusion Probabilistic Models (DDPM). Our method leverages the
analogy between RIR matrices and image inpainting, transforming RIR data into a
format suitable for diffusion-based reconstruction.
  Using simulated RIR data based on the image method, we demonstrate our
approach's effectiveness on microphone arrays of different curvatures, from
linear to semi-circular. Our method successfully reconstructs missing RIRs,
even in large gaps between microphones. Under these conditions, it achieves
accurate reconstruction, significantly outperforming baseline Spline Cubic
Interpolation in terms of Normalized Mean Square Error and Cosine Distance
between actual and interpolated RIRs.
  This research highlights the potential of using generative models for
effective RIR interpolation, paving the way for generating additional data from
limited real-world measurements.",http://arxiv.org/pdf/2504.20625v1,,False
Digital Shielding for Cross-Domain Wi-Fi Signal Adaptation using Relativistic Average Generative Adversarial Network,29/04/2025,"Danilo Avola, Federica Bruni, Gian Luca Foresti, Daniele Pannone, Amedeo Ranaldi","Wi-Fi sensing uses radio-frequency signals from Wi-Fi devices to analyze
environments, enabling tasks such as tracking people, detecting intrusions, and
recognizing gestures. The rise of this technology is driven by the IEEE
802.11bf standard and growing demand for tools that can ensure privacy and
operate through obstacles. However, the performance of Wi-Fi sensing is heavily
influenced by environmental conditions, especially when extracting spatial and
temporal features from the surrounding scene. A key challenge is achieving
robust generalization across domains, ensuring stable performance even when the
sensing environment changes significantly. This paper introduces a novel deep
learning model for cross-domain adaptation of Wi-Fi signals, inspired by
physical signal shielding. The model uses a Relativistic average Generative
Adversarial Network (RaGAN) with Bidirectional Long Short-Term Memory (Bi-LSTM)
architectures for both the generator and discriminator. To simulate physical
shielding, an acrylic box lined with electromagnetic shielding fabric was
constructed, mimicking a Faraday cage. Wi-Fi signal spectra were collected from
various materials both inside (domain-free) and outside (domain-dependent) the
box to train the model. A multi-class Support Vector Machine (SVM) was trained
on domain-free spectra and tested on signals denoised by the RaGAN. The system
achieved 96% accuracy and demonstrated strong material discrimination
capabilities, offering potential for use in security applications to identify
concealed objects based on their composition.",http://arxiv.org/pdf/2504.20568v1,10.1177/10692509251339913,False
PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations,29/04/2025,"Haowen Sun, Han Wang, Chengzhong Ma, Shaolong Zhang, Jiawei Ye, Xingyu Chen, Xuguang Lan","Learning from few demonstrations to develop policies robust to variations in
robot initial positions and object poses is a problem of significant practical
interest in robotics. Compared to imitation learning, which often struggles to
generalize from limited samples, reinforcement learning (RL) can autonomously
explore to obtain robust behaviors. Training RL agents through direct
interaction with the real world is often impractical and unsafe, while building
simulation environments requires extensive manual effort, such as designing
scenes and crafting task-specific reward functions. To address these
challenges, we propose an integrated real-to-sim-to-real pipeline that
constructs simulation environments based on expert demonstrations by
identifying scene objects from images and retrieving their corresponding 3D
models from existing libraries. We introduce a projection-based reward model
for RL policy training that is supervised by a vision-language model (VLM)
using human-guided object projection relationships as prompts, with the policy
further fine-tuned using expert demonstrations. In general, our work focuses on
the construction of simulation environments and RL-based policy training,
ultimately enabling the deployment of reliable robotic control policies in
real-world scenarios.",http://arxiv.org/pdf/2504.20520v1,,False
Full-field surrogate modeling of cardiac function encoding geometric variability,29/04/2025,"Elena Martinez, Beatrice Moscoloni, Matteo Salvador, Fanwei Kong, Mathias Peirlinck, Alison Lesley Marsden","Combining physics-based modeling with data-driven methods is critical to
enabling the translation of computational methods to clinical use in
cardiology. The use of rigorous differential equations combined with machine
learning tools allows for model personalization with uncertainty quantification
in time frames compatible with clinical practice. However, accurate and
efficient surrogate models of cardiac function, built from physics-based
numerical simulation, are still mostly geometry-specific and require retraining
for different patients and pathological conditions. We propose a novel
computational pipeline to embed cardiac anatomies into full-field surrogate
models. We generate a dataset of electrophysiology simulations using a complex
multi-scale mathematical model coupling partial and ordinary differential
equations. We adopt Branched Latent Neural Maps (BLNMs) as an effective
scientific machine learning method to encode activation maps extracted from
physics-based numerical simulations into a neural network. Leveraging large
deformation diffeomorphic metric mappings, we build a biventricular anatomical
atlas and parametrize the anatomical variability of a small and challenging
cohort of 13 pediatric patients affected by Tetralogy of Fallot. We propose a
novel statistical shape modeling based z-score sampling approach to generate a
new synthetic cohort of 52 biventricular geometries that are compatible with
the original geometrical variability. This synthetic cohort acts as the
training set for BLNMs. Our surrogate model demonstrates robustness and great
generalization across the complex original patient cohort, achieving an average
adimensional mean squared error of 0.0034. The Python implementation of our
BLNM model is publicly available under MIT License at
https://github.com/StanfordCBCL/BLNM.",http://arxiv.org/pdf/2504.20479v1,,False
The Estimation of Continual Causal Effect for Dataset Shifting Streams,29/04/2025,"Baining Chen, Yiming Zhang, Yuqiao Han, Ruyue Zhang, Ruihuan Du, Zhishuo Zhou, Zhengdan Zhu, Xun Liu, Jiecheng Guo","Causal effect estimation has been widely used in marketing optimization. The
framework of an uplift model followed by a constrained optimization algorithm
is popular in practice. To enhance performance in the online environment, the
framework needs to be improved to address the complexities caused by temporal
dataset shift. This paper focuses on capturing the dataset shift from user
behavior and domain distribution changing over time. We propose an Incremental
Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle
this challenge. The ICE-PKD framework includes two components: (i) a
multi-treatment uplift network that eliminates confounding bias using
counterfactual regression; (ii) an incremental training strategy that adapts to
the temporal dataset shift by updating with the latest data and protects
generalization via replay-based knowledge distillation. We also revisit the
uplift modeling metrics and introduce a novel metric for more precise online
evaluation in multiple treatment scenarios. Extensive experiments on both
simulated and online datasets show that the proposed framework achieves better
performance. The ICE-PKD framework has been deployed in the marketing system of
Huaxiaozhu, a ride-hailing platform in China.",http://arxiv.org/pdf/2504.20471v1,,False
Multidimensional precipitation index prediction based on CNN-LSTM hybrid framework,29/04/2025,"Yuchen Wang, Pengfei Jia, Zhitao Shu, Keyan Liu, Abdul Rashid Mohamed Shariff","With the intensification of global climate change, accurate prediction of
weather indicators is of great significance in disaster prevention and
mitigation, agricultural production, and transportation. Precipitation, as one
of the key meteorological indicators, plays a crucial role in water resource
management, agricultural production, and urban flood control. This study
proposes a multidimensional precipitation index prediction model based on a
CNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation
forecasts. The dataset is sourced from Pune, Maharashtra, India, covering
monthly mean precipitation data from 1972 to 2002. This dataset includes nearly
31 years (1972-2002) of monthly average precipitation, reflecting the long-term
fluctuations and seasonal variations of precipitation in the region. By
analyzing these time series data, the CNN-LSTM model effectively captures local
features and long-term dependencies. Experimental results show that the model
achieves a root mean square error (RMSE) of 6.752, which demonstrates a
significant advantage over traditional time series prediction methods in terms
of prediction accuracy and generalization ability. Furthermore, this study
provides new research ideas for precipitation prediction. However, the model
requires high computational resources when dealing with large-scale datasets,
and its predictive ability for multidimensional precipitation data still needs
improvement. Future research could extend the model to support and predict
multidimensional precipitation data, thereby promoting the development of more
accurate and efficient meteorological prediction technologies.",http://arxiv.org/pdf/2504.20442v1,,False
ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes,29/04/2025,"Amartya Mukherjee, Ruizhi Deng, He Zhao, Yuzhen Mao, Leonid Sigal, Frederick Tung","This work introduces a novel approach to modeling temporal point processes
using diffusion models with an asynchronous noise schedule. At each step of the
diffusion process, the noise schedule injects noise of varying scales into
different parts of the data. With a careful design of the noise schedules,
earlier events are generated faster than later ones, thus providing stronger
conditioning for forecasting the more distant future. We derive an objective to
effectively train these models for a general family of noise schedules based on
conditional flow matching. Our method models the joint distribution of the
latent representations of events in a sequence and achieves state-of-the-art
results in predicting both the next inter-event time and event type on
benchmark datasets. Additionally, it flexibly accommodates varying lengths of
observation and prediction windows in different forecasting settings by
adjusting the starting and ending points of the generation process. Finally,
our method shows superior performance in long-horizon prediction tasks,
outperforming existing baseline methods.",http://arxiv.org/pdf/2504.20411v1,,False
Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs,29/04/2025,"Paiheng Xu, Gang Wu, Xiang Chen, Tong Yu, Chang Xiao, Franck Dernoncourt, Tianyi Zhou, Wei Ai, Viswanathan Swaminathan","Scripting interfaces enable users to automate tasks and customize software
workflows, but creating scripts traditionally requires programming expertise
and familiarity with specific APIs, posing barriers for many users. While Large
Language Models (LLMs) can generate code from natural language queries, runtime
code generation is severely limited due to unverified code, security risks,
longer response times, and higher computational costs. To bridge the gap, we
propose an offline simulation framework to curate a software-specific skillset,
a collection of verified scripts, by exploiting LLMs and publicly available
scripting guides. Our framework comprises two components: (1) task creation,
using top-down functionality guidance and bottom-up API synergy exploration to
generate helpful tasks; and (2) skill generation with trials, refining and
validating scripts based on execution feedback. To efficiently navigate the
extensive API landscape, we introduce a Graph Neural Network (GNN)-based link
prediction model to capture API synergy, enabling the generation of skills
involving underutilized APIs and expanding the skillset's diversity.
Experiments with Adobe Illustrator demonstrate that our framework significantly
improves automation success rates, reduces response time, and saves runtime
token costs compared to traditional runtime code generation. This is the first
attempt to use software scripting interfaces as a testbed for LLM-based
systems, highlighting the advantages of leveraging execution feedback in a
controlled environment and offering valuable insights into aligning AI
capabilities with user needs in specialized software domains.",http://arxiv.org/pdf/2504.20406v1,,False
Generative Learning for Slow Manifolds and Bifurcation Diagrams,29/04/2025,"Ellis R. Crabtree, Dimitris G. Giovanis, Nikolaos Evangelou, Juan M. Bello-Rivas, Ioannis G. Kevrekidis","In dynamical systems characterized by separation of time scales, the
approximation of so called ``slow manifolds'', on which the long term dynamics
lie, is a useful step for model reduction. Initializing on such slow manifolds
is a useful step in modeling, since it circumvents fast transients, and is
crucial in multiscale algorithms alternating between fine scale (fast) and
coarser scale (slow) simulations. In a similar spirit, when one studies the
infinite time dynamics of systems depending on parameters, the system
attractors (e.g., its steady states) lie on bifurcation diagrams. Sampling
these manifolds gives us representative attractors (here, steady states of ODEs
or PDEs) at different parameter values. Algorithms for the systematic
construction of these manifolds are required parts of the ``traditional''
numerical nonlinear dynamics toolkit.
  In more recent years, as the field of Machine Learning develops, conditional
score-based generative models (cSGMs) have demonstrated capabilities in
generating plausible data from target distributions that are conditioned on
some given label. It is tempting to exploit such generative models to produce
samples of data distributions conditioned on some quantity of interest (QoI).
In this work, we present a framework for using cSGMs to quickly (a) initialize
on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system
consistent with desired value(s) of a QoI (a ``label'') on the manifold, and
(b) approximate steady states in a bifurcation diagram consistent with a (new,
out-of-sample) parameter value. This conditional sampling can help uncover the
geometry of the reduced slow-manifold and/or approximately ``fill in'' missing
segments of steady states in a bifurcation diagram.",http://arxiv.org/pdf/2504.20375v1,,False
