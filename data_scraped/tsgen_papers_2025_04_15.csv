Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Anchors no more: Using peculiar velocities to constrain $H_0$ and the primordial Universe without calibrators,14/04/2025,"Davide Piras, Francesco Sorrenti, Ruth Durrer, Martin Kunz","We develop a novel approach to constrain the Hubble parameter $H_0$ and the
primordial power spectrum amplitude $A_\mathrm{s}$ using supernovae type Ia
(SNIa) data. By considering SNIa as tracers of the peculiar velocity field, we
can model their distance and their covariance as a function of cosmological
parameters without the need of calibrators like Cepheids; this yields a new
independent probe of the large-scale structure based on SNIa data without
distance anchors. Crucially, we implement a differentiable pipeline in JAX,
including efficient emulators and affine sampling, reducing inference time from
years to hours on a single GPU. We first validate our method on mock datasets,
demonstrating that we can constrain $H_0$ and $\log 10^{10}A_\mathrm{s}$ within
$\sim10\%$ using $\sim10^3$ SNIa. We then test our pipeline with SNIa from an
$N$-body simulation, obtaining $7\%$-level unbiased constraints on $H_0$ with a
moderate noise level. We finally apply our method to Pantheon+ data,
constraining $H_0$ at the $10\%$ level without Cepheids when fixing
$A_\mathrm{s}$ to its $\it{Planck}$ value. On the other hand, we obtain
$15\%$-level constraints on $\log 10^{10}A_\mathrm{s}$ in agreement with
$\it{Planck}$ when including Cepheids in the analysis. In light of upcoming
observations of low redshift SNIa from the Zwicky Transient Facility and the
Vera Rubin Legacy Survey of Space and Time, surveys for which our method will
develop its full potential, we make our code publicly available.",http://arxiv.org/pdf/2504.10453v1,,False
M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models,14/04/2025,"Junxiong Wang, Wen-Ding Li, Daniele Paliotta, Daniel Ritter, Alexander M. Rush, Tri Dao","Effective reasoning is crucial to solving complex mathematical problems.
Recent large language models (LLMs) have boosted performance by scaling
test-time computation through long chain-of-thought reasoning. However,
transformer-based models are inherently limited in extending context length due
to their quadratic computational complexity and linear memory requirements. In
this paper, we introduce a novel hybrid linear RNN reasoning model, M1, built
on the Mamba architecture, which allows memory-efficient inference. Our
approach leverages a distillation process from existing reasoning models and is
further enhanced through RL training. Experimental results on the AIME and MATH
benchmarks show that M1 not only outperforms previous linear RNN models but
also matches the performance of state-of-the-art Deepseek R1 distilled
reasoning models at a similar scale. We also compare our generation speed with
a highly performant general purpose inference engine, vLLM, and observe more
than a 3x speedup compared to a same size transformer. With throughput speedup,
we are able to achieve higher accuracy compared to DeepSeek R1 distilled
transformer reasoning models under a fixed generation time budget using
self-consistency voting. Overall, we introduce a hybrid Mamba reasoning model
and provide a more effective approach to scaling test-time generation using
self-consistency or long chain of thought reasoning.",http://arxiv.org/pdf/2504.10449v1,,False
Inferring genotype-phenotype maps using attention models,14/04/2025,"Krishna Rijal, Caroline M. Holmes, Samantha Petti, Gautam Reddy, Michael M. Desai, Pankaj Mehta","Predicting phenotype from genotype is a central challenge in genetics.
Traditional approaches in quantitative genetics typically analyze this problem
using methods based on linear regression. These methods generally assume that
the genetic architecture of complex traits can be parameterized in terms of an
additive model, where the effects of loci are independent, plus (in some cases)
pairwise epistatic interactions between loci. However, these models struggle to
analyze more complex patterns of epistasis or subtle gene-environment
interactions. Recent advances in machine learning, particularly attention-based
models, offer a promising alternative. Initially developed for natural language
processing, attention-based models excel at capturing context-dependent
interactions and have shown exceptional performance in predicting protein
structure and function. Here, we apply attention-based models to quantitative
genetics. We analyze the performance of this attention-based approach in
predicting phenotype from genotype using simulated data across a range of
models with increasing epistatic complexity, and using experimental data from a
recent quantitative trait locus mapping study in budding yeast. We find that
our model demonstrates superior out-of-sample predictions in epistatic regimes
compared to standard methods. We also explore a more general multi-environment
attention-based model to jointly analyze genotype-phenotype maps across
multiple environments and show that such architectures can be used for
""transfer learning"" - predicting phenotypes in novel environments with limited
training data.",http://arxiv.org/pdf/2504.10388v1,,False
DUE: A Deep Learning Framework and Library for Modeling Unknown Equations,14/04/2025,"Junfeng Chen, Kailiang Wu, Dongbin Xiu","Equations, particularly differential equations, are fundamental for
understanding natural phenomena and predicting complex dynamics across various
scientific and engineering disciplines. However, the governing equations for
many complex systems remain unknown due to intricate underlying mechanisms.
Recent advancements in machine learning and data science offer a new paradigm
for modeling unknown equations from measurement or simulation data. This
paradigm shift, known as data-driven discovery or modeling, stands at the
forefront of AI for science, with significant progress made in recent years. In
this paper, we introduce a systematic framework for data-driven modeling of
unknown equations using deep learning. This versatile framework is capable of
learning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed
systems, and non-autonomous differential equations. Based on this framework, we
have developed Deep Unknown Equations (DUE), an open-source software package
designed to facilitate the data-driven modeling of unknown equations using
modern deep learning techniques. DUE serves as an educational tool for
classroom instruction, enabling students and newcomers to gain hands-on
experience with differential equations, data-driven modeling, and contemporary
deep learning approaches such as FNN, ResNet, generalized ResNet, operator
semigroup networks (OSG-Net), and Transformers. Additionally, DUE is a
versatile and accessible toolkit for researchers across various scientific and
engineering fields. It is applicable not only for learning unknown equations
from data but also for surrogate modeling of known, yet complex, equations that
are costly to solve using traditional numerical methods. We provide detailed
descriptions of DUE and demonstrate its capabilities through diverse examples,
which serve as templates that can be easily adapted for other applications.",http://arxiv.org/pdf/2504.10373v1,,False
Siamese Network with Dual Attention for EEG-Driven Social Learning: Bridging the Human-Robot Gap in Long-Tail Autonomous Driving,14/04/2025,"Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat","Robots with wheeled, quadrupedal, or humanoid forms are increasingly
integrated into built environments. However, unlike human social learning, they
lack a critical pathway for intrinsic cognitive development, namely, learning
from human feedback during interaction. To understand human ubiquitous
observation, supervision, and shared control in dynamic and uncertain
environments, this study presents a brain-computer interface (BCI) framework
that enables classification of Electroencephalogram (EEG) signals to detect
cognitively demanding and safety-critical events. As a timely and motivating
co-robotic engineering application, we simulate a human-in-the-loop scenario to
flag risky events in semi-autonomous robotic driving-representative of
long-tail cases that pose persistent bottlenecks to the safety performance of
smart mobility systems and robotic vehicles. Drawing on recent advances in
few-shot learning, we propose a dual-attention Siamese convolutional network
paired with Dynamic Time Warping Barycenter Averaging approach to generate
robust EEG-encoded signal representations. Inverse source localization reveals
activation in Broadman areas 4 and 9, indicating perception-action coupling
during task-relevant mental imagery. The model achieves 80% classification
accuracy under data-scarce conditions and exhibits a nearly 100% increase in
the utility of salient features compared to state-of-the-art methods, as
measured through integrated gradient attribution. Beyond performance, this
study contributes to our understanding of the cognitive architecture required
for BCI agents-particularly the role of attention and memory mechanisms-in
categorizing diverse mental states and supporting both inter- and intra-subject
adaptation. Overall, this research advances the development of cognitive
robotics and socially guided learning for service robots in complex built
environments.",http://arxiv.org/pdf/2504.10296v1,,False
Characterizing LLM-driven Social Network: The Chirper.ai Case,14/04/2025,"Yiming Zhu, Yupeng He, Ehsan-Ul Haq, Gareth Tyson, Pan Hui","Large language models (LLMs) demonstrate the ability to simulate human
decision-making processes, enabling their use as agents in modeling
sophisticated social networks, both offline and online. Recent research has
explored collective behavioral patterns and structural characteristics of LLM
agents within simulated networks. However, empirical comparisons between
LLM-driven and human-driven online social networks remain scarce, limiting our
understanding of how LLM agents differ from human users. This paper presents a
large-scale analysis of Chirper.ai, an X/Twitter-like social network entirely
populated by LLM agents, comprising over 65,000 agents and 7.7 million
AI-generated posts. For comparison, we collect a parallel dataset from
Mastodon, a human-driven decentralized social network, with over 117,000 users
and 16 million posts. We examine key differences between LLM agents and humans
in posting behaviors, abusive content, and social network structures. Our
findings provide critical insights into the evolving landscape of online social
network analysis in the AI era, offering a comprehensive profile of LLM agents
in social simulations.",http://arxiv.org/pdf/2504.10286v1,,False
$α$-Flow: A Unified Framework for Continuous-State Discrete Flow Matching Models,14/04/2025,"Chaoran Cheng, Jiahan Li, Jiajun Fan, Ge Liu","Recent efforts have extended the flow-matching framework to discrete
generative modeling. One strand of models directly works with the continuous
probabilities instead of discrete tokens, which we colloquially refer to as
Continuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ
significantly in their representations and geometric assumptions. This work
presents a unified framework for CS-DFM models, under which the existing
variants can be understood as operating on different $\alpha$-representations
of probabilities. Building upon the theory of information geometry, we
introduce $\alpha$-Flow, a family of CS-DFM models that adheres to the
canonical $\alpha$-geometry of the statistical manifold, and demonstrate its
optimality in minimizing the generalized kinetic energy. Theoretically, we show
that the flow matching loss for $\alpha$-flow establishes a unified variational
bound for the discrete negative log-likelihood. We comprehensively evaluate
different instantiations of $\alpha$-flow on various discrete generation
domains to demonstrate their effectiveness in discrete generative modeling,
including intermediate values whose geometries have never been explored before.
$\alpha$-flow significantly outperforms its discrete-state counterpart in image
and protein sequence generation and better captures the entropy in language
modeling.",http://arxiv.org/pdf/2504.10283v1,,False
ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams,14/04/2025,Vivek Yelleti,"Continuous generation of streaming data from diverse sources, such as online
transactions and digital interactions, necessitates timely fraud detection.
Traditional batch processing methods often struggle to capture the rapidly
evolving patterns of fraudulent activities. This paper highlights the critical
importance of processing streaming data for effective fraud detection. To
address the inherent challenges of latency, scalability, and concept drift in
streaming environments, we propose a robust online streaming fraud detection
(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage
One: Offline Model Initialization. In this initial stage, a model is built in
offline settings using incremental learning principles to overcome the
""cold-start"" problem. (ii) Stage Two: Real-time Model Adaptation. In this
dynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are
employed to identify concept drift in the incoming data stream and
incrementally train the model accordingly. This ""train-only-when-required""
strategy drastically reduces the number of retrains needed without
significantly impacting the area under the receiver operating characteristic
curve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method
demonstrated the best performance among the employed methods. In terms of model
efficacy, Adaptive Random Forest consistently outperformed other models,
achieving the highest AUC in four out of five datasets.",http://arxiv.org/pdf/2504.10229v1,,False
Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?,14/04/2025,"Yuxuan Zhang, Yangyang Feng, Daifeng Li, Kexin Zhang, Junlan Chen, Bowen Deng","Multi-agents-based news-driven time series forecasting is considered as a
potential paradigm shift in the era of large language models (LLMs). The
challenge of this task lies in measuring the influences of different news
events towards the fluctuations of time series. This requires agents to possess
stronger abilities of innovative thinking and the identifying misleading logic.
However, the existing multi-agent discussion framework has limited enhancement
on time series prediction in terms of optimizing these two capabilities.
Inspired by the role of competition in fostering innovation, this study embeds
a competition mechanism within the multi-agent discussion to enhance agents'
capability of generating innovative thoughts. Furthermore, to bolster the
model's proficiency in identifying misleading information, we incorporate a
fine-tuned small-scale LLM model within the reflective stage, offering
auxiliary decision-making support. Experimental results confirm that the
competition can boost agents' capacity for innovative thinking, which can
significantly improve the performances of time series prediction. Similar to
the findings of social science, the intensity of competition within this
framework can influence the performances of agents, providing a new perspective
for studying LLMs-based multi-agent systems.",http://arxiv.org/pdf/2504.10210v1,,False
Sequence models for by-trial decoding of cognitive strategies from neural data,14/04/2025,"Rick den Otter, Gabriel Weindel, Sjoerd Stuit, Leendert van Maanen","Understanding the sequence of cognitive operations that underlie
decision-making is a fundamental challenge in cognitive neuroscience.
Traditional approaches often rely on group-level statistics, which obscure
trial-by-trial variations in cognitive strategies. In this study, we introduce
a novel machine learning method that combines Hidden Multivariate Pattern
analysis with a Structured State Space Sequence model to decode cognitive
strategies from electroencephalography data at the trial level. We apply this
method to a decision-making task, where participants were instructed to
prioritize either speed or accuracy in their responses. Our results reveal an
additional cognitive operation, labeled Confirmation, which seems to occur
predominantly in the accuracy condition but also frequently in the speed
condition. The modeled probability that this operation occurs is associated
with higher probability of responding correctly as well as changes of mind, as
indexed by electromyography data. By successfully modeling cognitive operations
at the trial level, we provide empirical evidence for dynamic variability in
decision strategies, challenging the assumption of homogeneous cognitive
processes within experimental conditions. Our approach shows the potential of
sequence modeling in cognitive neuroscience to capture trial-level variability
that is obscured by aggregate analyses. The introduced method offers a new way
to detect and understand cognitive strategies in a data-driven manner, with
implications for both theoretical research and practical applications in many
fields.",http://arxiv.org/pdf/2504.10028v1,,False
RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework,14/04/2025,"Xiao Wang, Haiyang Wang, Shiao Wang, Qiang Chen, Jiandong Jin, Haoyu Song, Bo Jiang, Chenglong Li","Existing pedestrian attribute recognition methods are generally developed
based on RGB frame cameras. However, these approaches are constrained by the
limitations of RGB cameras, such as sensitivity to lighting conditions and
motion blur, which hinder their performance. Furthermore, current attribute
recognition primarily focuses on analyzing pedestrians' external appearance and
clothing, lacking an exploration of emotional dimensions. In this paper, we
revisit these issues and propose a novel multi-modal RGB-Event attribute
recognition task by drawing inspiration from the advantages of event cameras in
low-light, high-speed, and low-power consumption. Specifically, we introduce
the first large-scale multi-modal pedestrian attribute recognition dataset,
termed EventPAR, comprising 100K paired RGB-Event samples that cover 50
attributes related to both appearance and six human emotions, diverse scenes,
and various seasons. By retraining and evaluating mainstream PAR models on this
dataset, we establish a comprehensive benchmark and provide a solid foundation
for future research in terms of data and algorithmic baselines. In addition, we
propose a novel RWKV-based multi-modal pedestrian attribute recognition
framework, featuring an RWKV visual encoder and an asymmetric RWKV fusion
module. Extensive experiments are conducted on our proposed dataset as well as
two simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving
state-of-the-art results. The source code and dataset will be released on
https://github.com/Event-AHU/OpenPAR",http://arxiv.org/pdf/2504.10018v1,,False
Improving Controller Generalization with Dimensionless Markov Decision Processes,14/04/2025,"Valentin Charvet, Sebastian Stein, Roderick Murray-Smith","Controllers trained with Reinforcement Learning tend to be very specialized
and thus generalize poorly when their testing environment differs from their
training one. We propose a Model-Based approach to increase generalization
where both world model and policy are trained in a dimensionless state-action
space. To do so, we introduce the Dimensionless Markov Decision Process
($\Pi$-MDP): an extension of Contextual-MDPs in which state and action spaces
are non-dimensionalized with the Buckingham-$\Pi$ theorem. This procedure
induces policies that are equivariant with respect to changes in the context of
the underlying dynamics. We provide a generic framework for this approach and
apply it to a model-based policy search algorithm using Gaussian Process
models. We demonstrate the applicability of our method on simulated actuated
pendulum and cartpole systems, where policies trained on a single environment
are robust to shifts in the distribution of the context.",http://arxiv.org/pdf/2504.10006v1,,False
GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control,14/04/2025,"Hanwen Wan, Mengkang Li, Donghao Wu, Yebin Zhong, Yixuan Deng, Zhenglong Sun, Xiaoqiang Ji","Developing bipedal robots capable of traversing diverse real-world terrains
presents a fundamental robotics challenge, as existing methods using predefined
height maps and static environments fail to address the complexity of
unstructured landscapes. To bridge this gap, we propose GenTe, a framework for
generating physically realistic and adaptable terrains to train generalizable
locomotion policies. GenTe constructs an atomic terrain library that includes
both geometric and physical terrains, enabling curriculum training for
reinforcement learning-based locomotion policies. By leveraging
function-calling techniques and reasoning capabilities of Vision-Language
Models (VLMs), GenTe generates complex, contextually relevant terrains from
textual and graphical inputs. The framework introduces realistic force modeling
for terrain interactions, capturing effects such as soil sinkage and
hydrodynamic resistance. To the best of our knowledge, GenTe is the first
framework that systemically generates simulation environments for legged robot
locomotion control. Additionally, we introduce a benchmark of 100 generated
terrains. Experiments demonstrate improved generalization and robustness in
bipedal robot locomotion.",http://arxiv.org/pdf/2504.09997v1,,False
Physical Scales Matter: The Role of Receptive Fields and Advection in Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks,14/04/2025,"Christoph Metzl, Kianusch Vahid Yousefnia, Richard Müller, Virginia Poli, Miria Celano, Tobias Bölle","The focus of nowcasting development is transitioning from physically
motivated advection methods to purely data-driven Machine Learning (ML)
approaches. Nevertheless, recent work indicates that incorporating advection
into the ML value chain has improved skill for radar-based precipitation
nowcasts. However, the generality of this approach and the underlying causes
remain unexplored. This study investigates the generality by probing the
approach on satellite-based thunderstorm nowcasts for the first time. Resorting
to a scale argument, we then put forth an explanation when and why skill
improvements can be expected. In essence, advection guarantees that
thunderstorm patterns relevant for nowcasting are contained in the receptive
field at long lead times. To test our hypotheses, we train ResU-Nets solving
segmentation tasks with lightning observations as ground truth. The input of
the Baseline Neural Network (BNN) are short time series of multispectral
satellite imagery and lightning observations, whereas the Advection-Informed
Neural Network (AINN) additionally receives the Lagrangian persistence nowcast
of all input channels at the desired lead time. Overall, we find only a minor
skill improvement of the AINN over the BNN when considering fully averaged
scores. However, assessing skill conditioned on lead time and wind speed, we
demonstrate that our scale argument correctly predicts the onset of skill
improvement of the AINN over the BNN after 2h lead time. We confirm that
generally advection becomes gradually more important with longer lead times and
higher wind speeds. Our work accentuates the importance of considering and
incorporating the underlying physical scales when designing ML based
forecasting models.",http://arxiv.org/pdf/2504.09994v1,,False
AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification,14/04/2025,"Yuxuan Chen, Shanshan Huang, Yunyao Cheng, Peng Chen, Zhongwen Rao, Yang Shu, Bin Yang, Lujia Pan, Chenjuan Guo","Time series classification (TSC) is an important task in time series
analysis. Existing TSC methods mainly train on each single domain separately,
suffering from a degradation in accuracy when the samples for training are
insufficient in certain domains. The pre-training and fine-tuning paradigm
provides a promising direction for solving this problem. However, time series
from different domains are substantially divergent, which challenges the
effective pre-training on multi-source data and the generalization ability of
pre-trained models. To handle this issue, we introduce Augmented Series and
Image Contrastive Learning for Time Series Classification (AimTS), a
pre-training framework that learns generalizable representations from
multi-source time series data. We propose a two-level prototype-based
contrastive learning method to effectively utilize various augmentations in
multi-source pre-training, which learns representations for TSC that can be
generalized to different domains. In addition, considering augmentations within
the single time series modality are insufficient to fully address
classification problems with distribution shift, we introduce the image
modality to supplement structural information and establish a series-image
contrastive learning to improve the generalization of the learned
representations for TSC tasks. Extensive experiments show that after
multi-source pre-training, AimTS achieves good generalization performance,
enabling efficient learning and even few-shot learning on various downstream
TSC datasets.",http://arxiv.org/pdf/2504.09993v1,,False
Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming,14/04/2025,"Zhiqiang He, Zhi Liu","Adaptive video streaming systems are designed to optimize Quality of
Experience (QoE) and, in turn, enhance user satisfaction. However, differences
in user profiles and video content lead to different weights for QoE factors,
resulting in user-specific QoE functions and, thus, varying optimization
objectives. This variability poses significant challenges for neural networks,
as they often struggle to generalize under evolving targets - a phenomenon
known as plasticity loss that prevents conventional models from adapting
effectively to changing optimization objectives. To address this limitation, we
propose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning
framework that dynamically modulates network plasticity by balancing memory
retention with selective forgetting. In particular, PA-MoE leverages noise
injection to promote the selective forgetting of outdated knowledge, thereby
endowing neural networks with enhanced adaptive capabilities. In addition, we
present a rigorous theoretical analysis of PA-MoE by deriving a regret bound
that quantifies its learning performance. Experimental evaluations demonstrate
that PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in
dynamic streaming environments. Further analysis reveals that the model
effectively mitigates plasticity loss by optimizing neuron utilization.
Finally, a parameter sensitivity study is performed by injecting varying levels
of noise, and the results align closely with our theoretical predictions.",http://arxiv.org/pdf/2504.09906v1,,False
RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence,14/04/2025,"Zengyuan Lai, Jiarui Yang, Songpengcheng Xia, Lizhou Lin, Lan Sun, Renwen Wang, Jianran Liu, Qi Wu, Ling Pei","Millimeter-wave radar provides a privacy-preserving solution for human motion
analysis, yet its sparse point clouds pose significant challenges for semantic
understanding. We present Radar-LLM, the first framework that leverages large
language models (LLMs) for human motion understanding using millimeter-wave
radar as the sensing modality. Our approach introduces two key innovations: (1)
a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture that
incorporates deformable body templates and masked trajectory modeling to encode
spatiotemporal point clouds into compact semantic tokens, and (2) a radar-aware
language model that establishes cross-modal alignment between radar and text in
a shared embedding space. To address data scarcity, we introduce a
physics-aware synthesis pipeline that generates realistic radar-text pairs from
motion-text datasets. Extensive experiments demonstrate that Radar-LLM achieves
state-of-the-art performance across both synthetic and real-world benchmarks,
enabling accurate translation of millimeter-wave signals to natural language
descriptions. This breakthrough facilitates comprehensive motion understanding
in privacy-sensitive applications like healthcare and smart homes. We will
release the full implementation to support further research on
https://inowlzy.github.io/RadarLLM/.",http://arxiv.org/pdf/2504.09862v1,,False
GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals,14/04/2025,"Asiful Arefeen, Saman Khamesian, Maria Adela Grando, Bithika Thompson, Hassan Ghasemzadeh","Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose)
increases the risk of chronic complications such as neuropathy, nephropathy,
and cardiovascular disease. Current technologies like continuous subcutaneous
insulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model
specific aspects of glycemic control-like hypoglycemia prediction or insulin
delivery. Similarly, most digital twin approaches in diabetes management
simulate only physiological processes. These systems lack the ability to offer
alternative treatment scenarios that support proactive behavioral
interventions. To address this, we propose GlyTwin, a novel digital twin
framework that uses counterfactual explanations to simulate optimal treatments
for glucose regulation. Our approach helps patients and caregivers modify
behaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose
events. GlyTwin generates behavioral treatment suggestions that proactively
prevent hyperglycemia by recommending small adjustments to daily choices,
reducing both frequency and duration of these events. Additionally, it
incorporates stakeholder preferences into the intervention design, making
recommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a
newly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D)
patients on automated insulin delivery systems over 26 days. Results show
GlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6%
valid and 86% effective interventions. These findings demonstrate the promise
of counterfactual-driven digital twins in delivering personalized healthcare.",http://arxiv.org/pdf/2504.09846v1,,False
Score Matching Diffusion Based Feedback Control and Planning of Nonlinear Systems,14/04/2025,"Karthik Elamvazhuthi, Darshan Gadginmath, Fabio Pasqualetti","We propose a novel control-theoretic framework that leverages principles from
generative modeling -- specifically, Denoising Diffusion Probabilistic Models
(DDPMs) -- to stabilize control-affine systems with nonholonomic constraints.
Unlike traditional stochastic approaches, which rely on noise-driven dynamics
in both forward and reverse processes, our method crucially eliminates the need
for noise in the reverse phase, making it particularly relevant for control
applications. We introduce two formulations: one where noise perturbs all state
dimensions during the forward phase while the control system enforces time
reversal deterministically, and another where noise is restricted to the
control channels, embedding system constraints directly into the forward
process.
  For controllable nonlinear drift-free systems, we prove that deterministic
feedback laws can exactly reverse the forward process, ensuring that the
system's probability density evolves correctly without requiring artificial
diffusion in the reverse phase. Furthermore, for linear time-invariant systems,
we establish a time-reversal result under the second formulation. By
eliminating noise in the backward process, our approach provides a more
practical alternative to machine learning-based denoising methods, which are
unsuitable for control applications due to the presence of stochasticity. We
validate our results through numerical simulations on benchmark systems,
including a unicycle model in a domain with obstacles, a driftless
five-dimensional system, and a four-dimensional linear system, demonstrating
the potential for applying diffusion-inspired techniques in linear, nonlinear,
and settings with state space constraints.",http://arxiv.org/pdf/2504.09836v1,,False
Understanding and Optimizing Multi-Stage AI Inference Pipelines,14/04/2025,"Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian, Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan, Madhu Kumar, Tushar Krishna","The rapid evolution of Large Language Models (LLMs) has driven the need for
increasingly sophisticated inference pipelines and hardware platforms. Modern
LLM serving extends beyond traditional prefill-decode workflows, incorporating
multi-stage processes such as Retrieval Augmented Generation (RAG), key-value
(KV) cache retrieval, dynamic model routing, and multi step reasoning. These
stages exhibit diverse computational demands, requiring distributed systems
that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,
existing simulators lack the fidelity to model these heterogeneous,
multi-engine workflows, limiting their ability to inform architectural
decisions.
  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM
inference Execution Simulator. HERMES models diverse request stages; including
RAG, KV retrieval, reasoning, prefill, and decode across complex hardware
hierarchies. HERMES supports heterogeneous clients executing multiple models
concurrently unlike prior frameworks while incorporating advanced batching
strategies and multi-level memory hierarchies. By integrating real hardware
traces with analytical modeling, HERMES captures critical trade-offs such as
memory bandwidth contention, inter-cluster communication latency, and batching
efficiency in hybrid CPU-accelerator deployments. Through case studies, we
explore the impact of reasoning stages on end-to-end latency, optimal batching
strategies for hybrid pipelines, and the architectural implications of remote
KV cache retrieval. HERMES empowers system designers to navigate the evolving
landscape of LLM inference, providing actionable insights into optimizing
hardware-software co-design for next-generation AI workloads.",http://arxiv.org/pdf/2504.09775v1,,False
Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems,14/04/2025,"Zaid Khan, Elias Stengel-Eskin, Archiki Prasad, Jaemin Cho, Mohit Bansal","Scientists often infer abstract procedures from specific instances of
problems and use the abstractions to generate new, related instances. For
example, programs encoding the formal rules and properties of a system have
been useful in fields ranging from RL (procedural environments) to physics
(simulation engines). These programs can be seen as functions which execute to
different outputs based on their parameterizations (e.g., gridworld
configuration or initial physical conditions). We introduce the term EFA
(Executable Functional Abstraction) to denote such programs for math problems.
EFA-like constructs have been shown to be useful for math reasoning as problem
generators for stress-testing models. However, prior work has been limited to
abstractions for grade-school math (whose simple rules are easy to encode in
programs), while generating EFAs for advanced math has thus far required human
engineering. We explore the automatic construction of EFAs for advanced math
problems. We operationalize the task of automatically constructing EFAs as a
program synthesis task, and develop EFAGen, which conditions an LLM on a seed
math problem and its step-by-step solution to generate candidate EFA programs
that are faithful to the generalized problem and solution class underlying the
seed problem. Furthermore, we formalize properties any valid EFA must possess
in terms of executable unit tests, and show how the tests can be used as
verifiable rewards to train LLMs to become better writers of EFAs. We
demonstrate that EFAs constructed by EFAGen behave rationally by remaining
faithful to seed problems, produce learnable problem variations, and that
EFAGen can infer EFAs across multiple diverse sources of competition-level math
problems. Finally, we show downstream uses of model-written EFAs e.g. finding
problem variations that are harder or easier for a learner to solve, as well as
data generation.",http://arxiv.org/pdf/2504.09763v1,,False
