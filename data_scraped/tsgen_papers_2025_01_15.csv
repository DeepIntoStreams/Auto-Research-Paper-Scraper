Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Gradient Equilibrium in Online Learning: Theory and Applications,14/01/2025,"Anastasios N. Angelopoulos, Michael I. Jordan, Ryan J. Tibshirani","We present a new perspective on online learning that we refer to as gradient
equilibrium: a sequence of iterates achieves gradient equilibrium if the
average of gradients of losses along the sequence converges to zero. In
general, this condition is not implied by nor implies sublinear regret. It
turns out that gradient equilibrium is achievable by standard online learning
methods such as gradient descent and mirror descent with constant step sizes
(rather than decaying step sizes, as is usually required for no regret).
Further, as we show through examples, gradient equilibrium translates into an
interpretable and meaningful property in online prediction problems spanning
regression, classification, quantile estimation, and others. Notably, we show
that the gradient equilibrium framework can be used to develop a debiasing
scheme for black-box predictions under arbitrary distribution shift, based on
simple post hoc online descent updates. We also show that post hoc gradient
updates can be used to calibrate predicted quantiles under distribution shift,
and that the framework leads to unbiased Elo scores for pairwise preference
prediction.",http://arxiv.org/pdf/2501.08330v1,,False
Continual Deep Active Learning for Medical Imaging: Replay-Base Architecture for Context Adaptation,14/01/2025,"Rui Daniel, M. Rita Verdelho, Catarina Barata, Carlos Santiago","Deep Learning for medical imaging faces challenges in adapting and
generalizing to new contexts. Additionally, it often lacks sufficient labeled
data for specific tasks requiring significant annotation effort. Continual
Learning (CL) tackles adaptability and generalizability by enabling lifelong
learning from a data stream while mitigating forgetting of previously learned
knowledge. Active Learning (AL) reduces the number of required annotations for
effective training. This work explores both approaches (CAL) to develop a novel
framework for robust medical image analysis. Based on the automatic recognition
of shifts in image characteristics, Replay-Base Architecture for Context
Adaptation (RBACA) employs a CL rehearsal method to continually learn from
diverse contexts, and an AL component to select the most informative instances
for annotation. A novel approach to evaluate CAL methods is established using a
defined metric denominated IL-Score, which allows for the simultaneous
assessment of transfer learning, forgetting, and final model performance. We
show that RBACA works in domain and class-incremental learning scenarios, by
assessing its IL-Score on the segmentation and diagnosis of cardiac images. The
results show that RBACA outperforms a baseline framework without CAL, and a
state-of-the-art CAL method across various memory sizes and annotation budgets.
Our code is available in https://github.com/RuiDaniel/RBACA .",http://arxiv.org/pdf/2501.08245v1,,False
Investigating Energy Efficiency and Performance Trade-offs in LLM Inference Across Tasks and DVFS Settings,14/01/2025,"Paul Joe Maliakel, Shashikant Ilager, Ivona Brandic","Large language models (LLMs) have shown significant improvements in many
natural language processing (NLP) tasks, accelerating their rapid adoption
across many industries. These models are resource-intensive, requiring
extensive computational resources both during training and inference, leading
to increased energy consumption and negative environmental impact. As their
adoption accelerates, the sustainability of LLMs has become a critical issue,
necessitating strategies to optimize their runtime efficiency without
compromising performance. Hence, it is imperative to identify the parameters
that significantly influence the performance and energy efficiency of LLMs. To
that end, in this work, we investigate the effect of important parameters on
the performance and energy efficiency of LLMs during inference and examine
their trade-offs.
  First, we analyze how different types of models with varying numbers of
parameters and architectures perform on tasks like text generation, question
answering, and summarization by benchmarking LLMs such as Falcon-7B,
Mistral-7B-v0.1, T5-3B, GPT-2, GPT-J-6B, and GPT-Neo-2.7B. Second, we study
input and output sequence characteristics such as sequence length concerning
energy consumption, performance, and throughput. Finally, we explore the impact
of hardware-based power-saving techniques, i.e., Dynamic Voltage Frequency
Scaling (DVFS), on the models' latency and energy efficiency. Our extensive
benchmarking and statistical analysis reveal many interesting findings,
uncovering how specific optimizations can reduce energy consumption while
maintaining throughput and accuracy. This study provides actionable insights
for researchers and practitioners to design energy-efficient LLM inference
systems.",http://arxiv.org/pdf/2501.08219v1,,False
A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following,14/01/2025,"Yin Fang, Xinle Deng, Kangwei Liu, Ningyu Zhang, Jingyang Qian, Penghui Yang, Xiaohui Fan, Huajun Chen","Large language models excel at interpreting complex natural language
instructions, enabling them to perform a wide range of tasks. In the life
sciences, single-cell RNA sequencing (scRNA-seq) data serves as the ""language
of cellular biology"", capturing intricate gene expression patterns at the
single-cell level. However, interacting with this ""language"" through
conventional tools is often inefficient and unintuitive, posing challenges for
researchers. To address these limitations, we present InstructCell, a
multi-modal AI copilot that leverages natural language as a medium for more
direct and flexible single-cell analysis. We construct a comprehensive
multi-modal instruction dataset that pairs text-based instructions with
scRNA-seq profiles from diverse tissues and species. Building on this, we
develop a multi-modal cell language architecture capable of simultaneously
interpreting and processing both modalities. InstructCell empowers researchers
to accomplish critical tasks-such as cell type annotation, conditional
pseudo-cell generation, and drug sensitivity prediction-using straightforward
natural language commands. Extensive evaluations demonstrate that InstructCell
consistently meets or exceeds the performance of existing single-cell
foundation models, while adapting to diverse experimental conditions. More
importantly, InstructCell provides an accessible and intuitive tool for
exploring complex single-cell data, lowering technical barriers and enabling
deeper biological insights.",http://arxiv.org/pdf/2501.08187v1,,False
LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking,14/01/2025,"Yukai Ma, Tiantian Wei, Naiting Zhong, Jianbiao Mei, Tao Hu, Licheng Wen, Xuemeng Yang, Botian Shi, Yong Liu","While autonomous driving technology has made remarkable strides, data-driven
approaches still struggle with complex scenarios due to their limited reasoning
capabilities. Meanwhile, knowledge-driven autonomous driving systems have
evolved considerably with the popularization of visual language models. In this
paper, we propose LeapVAD, a novel method based on cognitive perception and
dual-process thinking. Our approach implements a human-attentional mechanism to
identify and focus on critical traffic elements that influence driving
decisions. By characterizing these objects through comprehensive attributes -
including appearance, motion patterns, and associated risks - LeapVAD achieves
more effective environmental representation and streamlines the decision-making
process. Furthermore, LeapVAD incorporates an innovative dual-process
decision-making module miming the human-driving learning process. The system
consists of an Analytic Process (System-II) that accumulates driving experience
through logical reasoning and a Heuristic Process (System-I) that refines this
knowledge via fine-tuning and few-shot learning. LeapVAD also includes
reflective mechanisms and a growing memory bank, enabling it to learn from past
mistakes and continuously improve its performance in a closed-loop environment.
To enhance efficiency, we develop a scene encoder network that generates
compact scene representations for rapid retrieval of relevant driving
experiences. Extensive evaluations conducted on two leading autonomous driving
simulators, CARLA and DriveArena, demonstrate that LeapVAD achieves superior
performance compared to camera-only approaches despite limited training data.
Comprehensive ablation studies further emphasize its effectiveness in
continuous learning and domain adaptation. Project page:
https://pjlab-adg.github.io/LeapVAD/.",http://arxiv.org/pdf/2501.08168v1,,False
Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving,14/01/2025,"Guizhe Jin, Zhuoren Li, Bo Leng, Wei Han, Lu Xiong, Chen Sun","Reinforcement Learning (RL) has shown excellent performance in solving
decision-making and control problems of autonomous driving, which is
increasingly applied in diverse driving scenarios. However, driving is a
multi-attribute problem, leading to challenges in achieving multi-objective
compatibility for current RL methods, especially in both policy execution and
policy iteration. On the one hand, the common action space structure with
single action type limits driving flexibility or results in large behavior
fluctuations during policy execution. On the other hand, the multi-attribute
weighted single reward function result in the agent's disproportionate
attention to certain objectives during policy iterations. To this end, we
propose a Multi-objective Ensemble-Critic reinforcement learning method with
Hybrid Parametrized Action for multi-objective compatible autonomous driving.
Specifically, a parameterized action space is constructed to generate hybrid
driving actions, combining both abstract guidance and concrete control
commands. A multi-objective critics architecture is constructed considering
multiple attribute rewards, to ensure simultaneously focusing on different
driving objectives. Additionally, uncertainty-based exploration strategy is
introduced to help the agent faster approach viable driving policy. The
experimental results in both the simulated traffic environment and the HighD
dataset demonstrate that our method can achieve multi-objective compatible
autonomous driving in terms of driving efficiency, action consistency, and
safety. It enhances the general performance of the driving while significantly
increasing training efficiency.",http://arxiv.org/pdf/2501.08096v1,,False
Gen-A: Generalizing Ambisonics Neural Encoding to Unseen Microphone Arrays,14/01/2025,"Mikko Heikkinen, Archontis Politis, Konstantinos Drossos, Tuomas Virtanen","Using deep neural networks (DNNs) for encoding of microphone array (MA)
signals to the Ambisonics spatial audio format can surpass certain limitations
of established conventional methods, but existing DNN-based methods need to be
trained separately for each MA. This paper proposes a DNN-based method for
Ambisonics encoding that can generalize to arbitrary MA geometries unseen
during training. The method takes as inputs the MA geometry and MA signals and
uses a multi-level encoder consisting of separate paths for geometry and signal
data, where geometry features inform the signal encoder at each level. The
method is validated in simulated anechoic and reverberant conditions with one
and two sources. The results indicate improvement over conventional encoding
across the whole frequency range for dry scenes, while for reverberant scenes
the improvement is frequency-dependent.",http://arxiv.org/pdf/2501.08047v1,,False
UFGraphFR: An attempt at a federated recommendation system based on user text characteristics,14/01/2025,Xudong Wang,"Federated learning has become an important research area in 'private
computing' due to the 'useable invisibility' of data during training. Inspired
by Federated learning, the federated recommendation system has gradually become
a new recommendation service architecture that can protect users' privacy. The
use of user diagrams to enhance federated recommendations is a promising topic.
How to use user diagrams to enhance federated recommendations is a promising
research topic. However, it's a great challenge to construct a user diagram
without compromising privacy in a federated learning scenario. Inspired by the
simple idea that similar users often have the same attribute characteristics,
we propose a personalized federated recommendation algorithm based on the user
relationship graph constructed by the user text characteristics(Graph
Federation Recommendation System based on User Text description Features,
UFGraphFR). The method uses the embedding layer weight of the user's text
feature description to construct the user relationship graph. It introduces the
Transformer mechanism to capture the sequence modeling of the user's historical
interaction sequence. Without access to user history interactions and specific
user attributes, the federal learning privacy protection of data 'useable
invisibility' is embodied. Preliminary experiments on some benchmark datasets
demonstrate the superior performance of UFGraphFR. Our experiments show that
this model can protect user privacy to some extent without affecting the
performance of the recommendation system. The code will be easily available on
https://github.com/trueWangSyutung/UFGraphFR.",http://arxiv.org/pdf/2501.08044v1,,False
Enhanced SPS Velocity-adaptive Scheme: Access Fariness in 5G NR V2I Networks,14/01/2025,"Xiao Xu, Qiong Wu, Pingyi Fan, Kezhi Wang","Vehicle-to-Infrastructure (V2I) technology enables information exchange
between vehicles and road infrastructure. Specifically, when a vehicle
approaches a roadside unit (RSU), it can exchange information with the RSU to
obtain accurate data that assists in driving. With the release of the 3rd
Generation Partnership Project (3GPP) Release 16, which includes the 5G New
Radio (NR) Vehicle-to-Everything (V2X) standards, vehicles typically adopt
mode-2 communication using sensing-based semi-persistent scheduling (SPS) for
resource allocation. In this approach, vehicles identify candidate resources
within a selection window and exclude ineligible resources based on information
from a sensing window. However, vehicles often drive at different speeds,
resulting in varying amounts of data transmission with RSUs as they pass by,
which leads to unfair access. Therefore, it is essential to design an access
scheme that accounts for different vehicle speeds to achieve fair access across
the network. This paper formulates an optimization problem for vehicular
networks and proposes a multi-objective optimization scheme to address it by
adjusting the selection window in the SPS mechanism of 5G NR V2I mode-2.
Simulation results demonstrate the effectiveness of the proposed scheme",http://arxiv.org/pdf/2501.08037v1,,False
An AI-driven framework for rapid and localized optimizations of urban open spaces,14/01/2025,"Pegah Eshraghi, Arman Nikkhah Dehnavi, Maedeh Mirdamadi, Riccardo Talami, Zahra-Sadat Zomorodian","As urbanization accelerates, open spaces are increasingly recognized for
their role in enhancing sustainability and well-being, yet they remain
underexplored compared to built spaces. This study introduces an AI-driven
framework that integrates machine learning models (MLMs) and explainable AI
techniques to optimize Sky View Factor (SVF) and visibility, key spatial
metrics influencing thermal comfort and perceived safety in urban spaces.
Unlike global optimization methods, which are computationally intensive and
impractical for localized adjustments, this framework supports incremental
design improvements with lower computational costs and greater flexibility. The
framework employs SHapley Adaptive Explanations (SHAP) to analyze feature
importance and Counterfactual Explanations (CFXs) to propose minimal design
changes. Simulations tested five MLMs, identifying XGBoost as the most
accurate, with building width, park area, and heights of surrounding buildings
as critical for SVF, and distances from southern buildings as key for
visibility. Compared to Genetic Algorithms, which required approximately 15/30
minutes across 3/4 generations to converge, the tested CFX approach achieved
optimized results in 1 minute with a 5% RMSE error, demonstrating significantly
faster performance and suitability for scalable retrofitting strategies. This
interpretable and computationally efficient framework advances urban
performance optimization, providing data-driven insights and practical
retrofitting solutions for enhancing usability and environmental quality across
diverse urban contexts.",http://arxiv.org/pdf/2501.08019v1,,False
GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation,14/01/2025,"Shengyin Sun, Wenhao Yu, Yuxiang Ren, Weitao Du, Liwei Liu, Xuecang Zhang, Ying Hu, Chen Ma","Retrosynthesis prediction focuses on identifying reactants capable of
synthesizing a target product. Typically, the retrosynthesis prediction
involves two phases: Reaction Center Identification and Reactant Generation.
However, we argue that most existing methods suffer from two limitations in the
two phases: (i) Existing models do not adequately capture the ``face''
information in molecular graphs for the reaction center identification. (ii)
Current approaches for the reactant generation predominantly use sequence
generation in a 2D space, which lacks versatility in generating reasonable
distributions for completed reactive groups and overlooks molecules' inherent
3D properties. To overcome the above limitations, we propose GDiffRetro. For
the reaction center identification, GDiffRetro uniquely integrates the original
graph with its corresponding dual graph to represent molecular structures,
which helps guide the model to focus more on the faces in the graph. For the
reactant generation, GDiffRetro employs a conditional diffusion model in 3D to
further transform the obtained synthon into a complete reactant. Our
experimental findings reveal that GDiffRetro outperforms state-of-the-art
semi-template models across various evaluative metrics.",http://arxiv.org/pdf/2501.08001v1,,False
Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness,14/01/2025,"Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei","Facial expression captioning has found widespread application across various
domains. Recently, the emergence of video Multimodal Large Language Models
(MLLMs) has shown promise in general video understanding tasks. However,
describing facial expressions within videos poses two major challenges for
these models: (1) the lack of adequate datasets and benchmarks, and (2) the
limited visual token capacity of video MLLMs. To address these issues, this
paper introduces a new instruction-following dataset tailored for dynamic
facial expression caption. The dataset comprises 5,033 high-quality video clips
annotated manually, containing over 700,000 tokens. Its purpose is to improve
the capability of video MLLMs to discern subtle facial nuances. Furthermore, we
propose FaceTrack-MM, which leverages a limited number of tokens to encode the
main character's face. This model demonstrates superior performance in tracking
faces and focusing on the facial expressions of the main characters, even in
intricate multi-person scenarios. Additionally, we introduce a novel evaluation
metric combining event extraction, relation classification, and the longest
common subsequence (LCS) algorithm to assess the content consistency and
temporal sequence consistency of generated text. Moreover, we present
FEC-Bench, a benchmark designed to assess the performance of existing video
MLLMs in this specific task. All data and source code will be made publicly
available.",http://arxiv.org/pdf/2501.07978v1,,False
Logarithmic Memory Networks (LMNs): Efficient Long-Range Sequence Modeling for Resource-Constrained Environments,14/01/2025,Mohamed A. Taha,"Long-range sequence modeling is a crucial aspect of natural language
processing and time series analysis. However, traditional models like Recurrent
Neural Networks (RNNs) and Transformers suffer from computational and memory
inefficiencies, especially when dealing with long sequences. This paper
introduces Logarithmic Memory Networks (LMNs), a novel architecture that
leverages a hierarchical logarithmic tree structure to efficiently store and
retrieve past information. LMNs dynamically summarize historical context,
significantly reducing the memory footprint and computational complexity of
attention mechanisms from O(n2) to O(log(n)). The model employs a
single-vector, targeted attention mechanism to access stored information, and
the memory block construction worker (summarizer) layer operates in two modes:
a parallel execution mode during training for efficient processing of
hierarchical tree structures and a sequential execution mode during inference,
which acts as a memory management system. It also implicitly encodes positional
information, eliminating the need for explicit positional encodings. These
features make LMNs a robust and scalable solution for processing long-range
sequences in resource-constrained environments, offering practical improvements
in efficiency and scalability. The code is publicly available under the MIT
License on GitHub: https://github.com/AhmedBoin/LogarithmicMemory.",http://arxiv.org/pdf/2501.07905v1,,False
Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision,14/01/2025,"Yaowen Ye, Cassidy Laidlaw, Jacob Steinhardt","Language model (LM) post-training relies on two stages of human supervision:
task demonstrations for supervised finetuning (SFT), followed by preference
comparisons for reinforcement learning from human feedback (RLHF). As LMs
become more capable, the tasks they are given become harder to supervise. Will
post-training remain effective under unreliable supervision? To test this, we
simulate unreliable demonstrations and comparison feedback using small LMs and
time-constrained humans. We find that in the presence of unreliable
supervision, SFT still retains some effectiveness, but DPO (a common RLHF
algorithm) fails to improve the model beyond SFT. To address this, we propose
iterative label refinement (ILR) as an alternative to RLHF. ILR improves the
SFT data by using comparison feedback to decide whether human demonstrations
should be replaced by model-generated alternatives, then retrains the model via
SFT on the updated data. SFT+ILR outperforms SFT+DPO on several tasks with
unreliable supervision (math, coding, and safe instruction-following). Our
findings suggest that as LMs are used for complex tasks where human supervision
is unreliable, RLHF may no longer be the best use of human comparison feedback;
instead, it is better to direct feedback towards improving the training data
rather than continually training the model. Our code and data are available at
https://github.com/helloelwin/iterative-label-refinement.",http://arxiv.org/pdf/2501.07886v1,,False
A Driver Advisory System Based on Large Language Model for High-speed Train,14/01/2025,"Y. C. Luo, J. Xun, W. Wang, R. Z. Zhang, Z. C. Zhao","With the rapid development of China high-speed railway, drivers face
increasingly significant technical challenges during operations, such as fault
handling. Currently, drivers depend on the onboard mechanic when facing
technical issues, for instance, traction loss or sensor faults. This dependency
can hinder effective operation, even lead to accidents, while waiting for
faults to be addressed. To enhance the accuracy and explainability of actions
during fault handling, an Intelligent Driver Advisory System (IDAS) framework
based on a large language model (LLM) named IDAS-LLM, is introduced. Initially,
domain-fine-tuning of the LLM is performed using a constructed railway
knowledge question-and-answer dataset to improve answer accuracy in
railway-related questions. Subsequently, integration of the Retrieval-augmented
Generation (RAG) architecture is pursued for system design to enhance the
explainability of generated responses. Comparative experiments are conducted
using the constructed railway driving knowledge assessment dataset. Results
indicate that domain-fine-tuned LLMs show an improvement in answer accuracy by
an average of 10%, outperforming some current mainstream LLMs. Additionally,
the inclusion of the RAG framework increases the average recall rate of
question-and-answer sessions by about 4%. Finally, the fault handling
capability of IDAS-LLM is demonstrated through simulations of real operational
scenarios, proving that the proposed framework has practical application
prospects.",http://arxiv.org/pdf/2501.07837v1,,False
Real-time Verification and Refinement of Language Model Text Generation,14/01/2025,"Joonho Ko, Jinheon Baek, Sung Ju Hwang","Large language models (LLMs) have shown remarkable performance across a wide
range of natural language tasks. However, a critical challenge remains in that
they sometimes generate factually incorrect answers. To address this, while
many previous work has focused on identifying errors in their generation and
further refining them, they are slow in deployment since they are designed to
verify the response from LLMs only after their entire generation (from the
first to last tokens) is done. Further, we observe that once LLMs generate
incorrect tokens early on, there is a higher likelihood that subsequent tokens
will also be factually incorrect. To this end, in this work, we propose
Streaming-VR (Streaming Verification and Refinement), a novel approach designed
to enhance the efficiency of verification and refinement of LLM outputs.
Specifically, the proposed Streaming-VR enables on-the-fly verification and
correction of tokens as they are being generated, similar to a streaming
process, ensuring that each subset of tokens is checked and refined in
real-time by another LLM as the LLM constructs its response. Through
comprehensive evaluations on multiple datasets, we demonstrate that our
approach not only enhances the factual accuracy of LLMs, but also offers a more
efficient solution compared to prior refinement methods.",http://arxiv.org/pdf/2501.07824v1,,False
Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models,14/01/2025,"Dhruv Dhamani, Mary Lou Maher","Recent advances in prompting techniques and multi-agent systems for Large
Language Models (LLMs) have produced increasingly complex approaches. However,
we lack a framework for characterizing and comparing prompting techniques or
understanding their relationship to multi-agent LLM systems. This position
paper introduces and explains the concepts of linear contexts (a single,
continuous sequence of interactions) and non-linear contexts (branching or
multi-path) in LLM systems. These concepts enable the development of an
agent-centric projection of prompting techniques, a framework that can reveal
deep connections between prompting strategies and multi-agent systems. We
propose three conjectures based on this framework: (1) results from non-linear
prompting techniques can predict outcomes in equivalent multi-agent systems,
(2) multi-agent system architectures can be replicated through single-LLM
prompting techniques that simulate equivalent interaction patterns, and (3)
these equivalences suggest novel approaches for generating synthetic training
data. We argue that this perspective enables systematic cross-pollination of
research findings between prompting and multi-agent domains, while providing
new directions for improving both the design and training of future LLM
systems.",http://arxiv.org/pdf/2501.07815v1,,False
Visual Language Models as Operator Agents in the Space Domain,14/01/2025,"Alejandro Carrasco, Marco Nedungadi, Enrico M. Zucchelli, Amit Jain, Victor Rodriguez-Fernandez, Richard Linares","This paper explores the application of Vision-Language Models (VLMs) as
operator agents in the space domain, focusing on both software and hardware
operational paradigms. Building on advances in Large Language Models (LLMs) and
their multimodal extensions, we investigate how VLMs can enhance autonomous
control and decision-making in space missions. In the software context, we
employ VLMs within the Kerbal Space Program Differential Games (KSPDG)
simulation environment, enabling the agent to interpret visual screenshots of
the graphical user interface to perform complex orbital maneuvers. In the
hardware context, we integrate VLMs with robotic systems equipped with cameras
to inspect and diagnose physical space objects, such as satellites. Our results
demonstrate that VLMs can effectively process visual and textual data to
generate contextually appropriate actions, competing with traditional methods
and non-multimodal LLMs in simulation tasks, and showing promise in real-world
applications.",http://arxiv.org/pdf/2501.07802v1,10.2514/6.2025-1543,False
Symmetry-Aware Generative Modeling through Learned Canonicalization,14/01/2025,"Kusha Sareen, Daniel Levy, Arnab Kumar Mondal, Sékou-Oumar Kaba, Tara Akhound-Sadegh, Siamak Ravanbakhsh","Generative modeling of symmetric densities has a range of applications in AI
for science, from drug discovery to physics simulations. The existing
generative modeling paradigm for invariant densities combines an invariant
prior with an equivariant generative process. However, we observe that this
technique is not necessary and has several drawbacks resulting from the
limitations of equivariant networks. Instead, we propose to model a learned
slice of the density so that only one representative element per orbit is
learned. To accomplish this, we learn a group-equivariant canonicalization
network that maps training samples to a canonical pose and train a
non-equivariant generative model over these canonicalized samples. We implement
this idea in the context of diffusion models. Our preliminary experimental
results on molecular modeling are promising, demonstrating improved sample
quality and faster inference time.",http://arxiv.org/pdf/2501.07773v1,,False
Deep Learning for Disease Outbreak Prediction: A Robust Early Warning Signal for Transcritical Bifurcations,14/01/2025,"Reza Miry, Amit K. Chakraborty, Russell Greiner, Mark A. Lewis, Hao Wang, Tianyu Guan, Pouria Ramazi","Early Warning Signals (EWSs) are vital for implementing preventive measures
before a disease turns into a pandemic. While new diseases exhibit unique
behaviors, they often share fundamental characteristics from a dynamical
systems perspective. Moreover, measurements during disease outbreaks are often
corrupted by different noise sources, posing challenges for Time Series
Classification (TSC) tasks. In this study, we address the problem of having a
robust EWS for disease outbreak prediction using a best-performing deep
learning model in the domain of TSC. We employed two simulated datasets to
train the model: one representing generated dynamical systems with randomly
selected polynomial terms to model new disease behaviors, and another
simulating noise-induced disease dynamics to account for noisy measurements.
The model's performance was analyzed using both simulated data from different
disease models and real-world data, including influenza and COVID-19. Results
demonstrate that the proposed model outperforms previous models, effectively
providing EWSs of impending outbreaks across various scenarios. This study
bridges advancements in deep learning with the ability to provide robust early
warning signals in noisy environments, making it highly applicable to
real-world crises involving emerging disease outbreaks.",http://arxiv.org/pdf/2501.07764v1,,False
On the Statistical Capacity of Deep Generative Models,14/01/2025,"Edric Tam, David B. Dunson","Deep generative models are routinely used in generating samples from complex,
high-dimensional distributions. Despite their apparent successes, their
statistical properties are not well understood. A common assumption is that
with enough training data and sufficiently large neural networks, deep
generative model samples will have arbitrarily small errors in sampling from
any continuous target distribution. We set up a unifying framework that debunks
this belief. We demonstrate that broad classes of deep generative models,
including variational autoencoders and generative adversarial networks, are not
universal generators. Under the predominant case of Gaussian latent variables,
these models can only generate concentrated samples that exhibit light tails.
Using tools from concentration of measure and convex geometry, we give
analogous results for more general log-concave and strongly log-concave latent
variable distributions. We extend our results to diffusion models via a
reduction argument. We use the Gromov--Levy inequality to give similar
guarantees when the latent variables lie on manifolds with positive Ricci
curvature. These results shed light on the limited capacity of common deep
generative models to handle heavy tails. We illustrate the empirical relevance
of our work with simulations and financial data.",http://arxiv.org/pdf/2501.07763v1,,False
