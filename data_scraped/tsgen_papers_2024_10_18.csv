Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction,17/10/2024,"Xuan Zhang, Cunxiao Du, Chao Du, Tianyu Pang, Wei Gao, Min Lin","Recent advancements in large language models (LLMs) have extended their
capabilities to handle long contexts. However, increasing the number of model
layers and the length of input sequences significantly escalates the memory
required to store key-value (KV) cache, posing challenges for efficient
inference. To mitigate this issue, we present SimLayerKV, a simple yet
effective method that reduces inter-layer KV cache redundancies by selectively
dropping cache in identified lazy layers. Our approach is based on the
observation that certain layers in long-context LLMs exhibit ""lazy"" behavior,
contributing less to modeling long-range dependencies compared to non-lazy
layers. By analyzing attention weight patterns, we find that the behavior of
these lazy layers is consistent across tokens during generation for a given
input. This insight motivates our SimLayerKV, which identifies lazy layers and
reduces their KV cache accordingly. SimLayerKV is training-free, generalizable,
and can be implemented with only seven lines of code. We conduct extensive
experiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and
Mistral-7B across 16 tasks from the LongBench benchmark. The results
demonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\times$
with only a 1.2% performance drop when combined with 4-bit quantization. Our
code is available at https://github.com/sail-sg/SimLayerKV.",http://arxiv.org/pdf/2410.13846v1,,False
Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding,17/10/2024,"Tan Dat Nguyen, Ji-Hoon Kim, Jeongsoo Choi, Shukjae Choi, Jinseok Park, Younglo Lee, Joon Son Chung","The goal of this paper is to accelerate codec-based speech synthesis systems
with minimum sacrifice to speech quality. We propose an enhanced inference
method that allows for flexible trade-offs between speed and quality during
inference without requiring additional training. Our core idea is to predict
multiple tokens per inference step of the AR module using multiple prediction
heads, resulting in a linear reduction in synthesis time as the number of heads
increases. Furthermore, we introduce a novel speculative decoding technique
that utilises a Viterbi-based algorithm to select the optimal sequence of
generated tokens at each decoding step. In our experiments, we demonstrate that
the time required to predict each token is reduced by a factor of 4 to 5
compared to baseline models, with minimal quality trade-off or even improvement
in terms of speech intelligibility. Audio samples are available at:
multpletokensprediction.github.io/multipletokensprediction.github.io/.",http://arxiv.org/pdf/2410.13839v1,,False
ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization,17/10/2024,"Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal","Reward shaping is a critical component in reinforcement learning (RL),
particularly for complex tasks where sparse rewards can hinder learning. While
shaping rewards have been introduced to provide additional guidance, selecting
effective shaping functions remains challenging and computationally expensive.
This paper introduces Online Reward Selection and Policy Optimization (ORSO), a
novel approach that frames shaping reward selection as an online model
selection problem. ORSO employs principled exploration strategies to
automatically identify promising shaping reward functions without human
intervention, balancing exploration and exploitation with provable regret
guarantees. We demonstrate ORSO's effectiveness across various continuous
control tasks using the Isaac Gym simulator. Compared to traditional methods
that fully evaluate each shaping reward function, ORSO significantly improves
sample efficiency, reduces computational time, and consistently identifies
high-quality reward functions that produce policies comparable to those
generated by domain experts through hand-engineered rewards.",http://arxiv.org/pdf/2410.13837v1,,False
Adversarial Testing as a Tool for Interpretability: Length-based Overfitting of Elementary Functions in Transformers,17/10/2024,"Patrik Zavoral, Dušan Variš, Ondřej Bojar","The Transformer model has a tendency to overfit various aspects of the
training data, such as the overall sequence length. We study elementary string
edit functions using a defined set of error indicators to interpret the
behaviour of the sequence-to-sequence Transformer. We show that generalization
to shorter sequences is often possible, but confirm that longer sequences are
highly problematic, although partially correct answers are often obtained.
Additionally, we find that other structural characteristics of the sequences,
such as subsegment length, may be equally important. We hypothesize that the
models learn algorithmic aspects of the tasks simultaneously with structural
aspects but adhering to the structural aspects is unfortunately often preferred
by Transformer when they come into conflict.",http://arxiv.org/pdf/2410.13802v1,,False
Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics Emulation,17/10/2024,"Da Long, Zhitong Xu, Guang Yang, Akil Narayan, Shandian Zhe","Modern physics simulation often involves multiple functions of interests, and
traditional numerical approaches are known to be complex and computationally
costly. While machine learning-based surrogate models can offer significant
cost reductions, most focus on a single task, such as forward prediction, and
typically lack uncertainty quantification -- an essential component in many
applications. To overcome these limitations, we propose Arbitrarily-Conditioned
Multi-Functional Diffusion (ACMFD), a versatile probabilistic surrogate model
for multi-physics emulation. ACMFD can perform a wide range of tasks within a
single framework, including forward prediction, various inverse problems, and
simulating data for entire systems or subsets of quantities conditioned on
others. Specifically, we extend the standard Denoising Diffusion Probabilistic
Model (DDPM) for multi-functional generation by modeling noise as Gaussian
processes (GP). We then introduce an innovative denoising loss. The training
involves randomly sampling the conditioned part and fitting the corresponding
predicted noise to zero, enabling ACMFD to flexibly generate function values
conditioned on any other functions or quantities. To enable efficient training
and sampling, and to flexibly handle irregularly sampled data, we use GPs to
interpolate function samples onto a grid, inducing a Kronecker product
structure for efficient computation. We demonstrate the advantages of ACMFD
across several fundamental multi-physics systems.",http://arxiv.org/pdf/2410.13794v1,,False
DPLM-2: A Multimodal Diffusion Protein Language Model,17/10/2024,"Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu","Proteins are essential macromolecules defined by their amino acid sequences,
which determine their three-dimensional structures and, consequently, their
functions in all living organisms. Therefore, generative protein modeling
necessitates a multimodal approach to simultaneously model, understand, and
generate both sequences and structures. However, existing methods typically use
separate models for each modality, limiting their ability to capture the
intricate relationships between sequence and structure. This results in
suboptimal performance in tasks that requires joint understanding and
generation of both modalities. In this paper, we introduce DPLM-2, a multimodal
protein foundation model that extends discrete diffusion protein language model
(DPLM) to accommodate both sequences and structures. To enable structural
learning with the language model, 3D coordinates are converted to discrete
tokens using a lookup-free quantization-based tokenizer. By training on both
experimental and high-quality synthetic structures, DPLM-2 learns the joint
distribution of sequence and structure, as well as their marginals and
conditionals. We also implement an efficient warm-up strategy to exploit the
connection between large-scale evolutionary data and structural inductive
biases from pre-trained sequence-based protein language models. Empirical
evaluation shows that DPLM-2 can simultaneously generate highly compatible
amino acid sequences and their corresponding 3D structures eliminating the need
for a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive
performance in various conditional generation tasks, including folding, inverse
folding, and scaffolding with multimodal motif inputs, as well as providing
structure-aware representations for predictive tasks.",http://arxiv.org/pdf/2410.13782v1,,False
Representing Model Weights with Language using Tree Experts,17/10/2024,"Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen","The increasing availability of public models begs the question: can we train
neural networks that use other networks as input? This paper learns to
represent models within a joint space that embeds both model weights and
language. However, machine learning on model weights is challenging as model
weights often exhibit significant variation unrelated to the models' semantic
properties (nuisance variation). We identify a key property of real-world
models: most public models belong to a small set of Model Trees, where all
models within a tree are fine-tuned from a common ancestor (e.g., a foundation
model). Importantly, we find that within each tree there is less nuisance
variation between models. For example, while classifying models according to
their training dataset generally requires complex architectures, in our case,
even a linear classifier trained on a single layer is often effective. While
effective, linear layers are computationally expensive as model weights are
very high dimensional. To address this, we introduce Probing Experts (ProbeX),
a theoretically motivated, lightweight probing method. Notably, ProbeX is the
first probing method designed to learn from the weights of just a single model
layer. We also construct and release a dataset that simulates the structure of
public model repositories. Our results show that ProbeX can effectively map the
weights of large models into a shared weight-language embedding space.
Furthermore, we demonstrate the impressive generalization of our method,
achieving zero-shot model classification and retrieval.",http://arxiv.org/pdf/2410.13569v1,,False
CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building,17/10/2024,"Walker Byrnes, Miroslav Bogdanovic, Avi Balakirsky, Stephen Balakirsky, Animesh Garg","Intelligent and reliable task planning is a core capability for generalized
robotics, requiring a descriptive domain representation that sufficiently
models all object and state information for the scene. We present CLIMB, a
continual learning framework for robot task planning that leverages foundation
models and execution feedback to guide domain model construction. CLIMB can
build a model from a natural language description, learn non-obvious predicates
while solving tasks, and store that information for future problems. We
demonstrate the ability of CLIMB to improve performance in common planning
environments compared to baseline methods. We also develop the BlocksWorld++
domain, a simulated environment with an easily usable real counterpart,
together with a curriculum of tasks with progressing difficulty for evaluating
continual learning. Additional details and demonstrations for this system can
be found at https://plan-with-climb.github.io/ .",http://arxiv.org/pdf/2410.13756v1,,False
Supervised Kernel Thinning,17/10/2024,"Albert Gong, Kyuseong Choi, Raaz Dwivedi","The kernel thinning algorithm of Dwivedi & Mackey (2024) provides a
better-than-i.i.d. compression of a generic set of points. By generating
high-fidelity coresets of size significantly smaller than the input points, KT
is known to speed up unsupervised tasks like Monte Carlo integration,
uncertainty quantification, and non-parametric hypothesis testing, with minimal
loss in statistical accuracy. In this work, we generalize the KT algorithm to
speed up supervised learning problems involving kernel methods. Specifically,
we combine two classical algorithms--Nadaraya-Watson (NW) regression or kernel
smoothing, and kernel ridge regression (KRR)--with KT to provide a quadratic
speed-up in both training and inference times. We show how distribution
compression with KT in each setting reduces to constructing an appropriate
kernel, and introduce the Kernel-Thinned NW and Kernel-Thinned KRR estimators.
We prove that KT-based regression estimators enjoy significantly superior
computational efficiency over the full-data estimators and improved statistical
efficiency over i.i.d. subsampling of the training data. En route, we also
provide a novel multiplicative error guarantee for compressing with KT. We
validate our design choices with both simulations and real data experiments.",http://arxiv.org/pdf/2410.13749v1,,False
DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation,17/10/2024,"Hanbo Cheng, Limin Lin, Chenyu Liu, Pengcheng Xia, Pengfei Hu, Jiefeng Ma, Jun Du, Jia Pan","Talking head generation intends to produce vivid and realistic talking head
videos from a single portrait and speech audio clip. Although significant
progress has been made in diffusion-based talking head generation, almost all
methods rely on autoregressive strategies, which suffer from limited context
utilization beyond the current generation step, error accumulation, and slower
generation speed. To address these challenges, we present DAWN (Dynamic frame
Avatar With Non-autoregressive diffusion), a framework that enables all-at-once
generation of dynamic-length video sequences. Specifically, it consists of two
main components: (1) audio-driven holistic facial dynamics generation in the
latent motion space, and (2) audio-driven head pose and blink generation.
Extensive experiments demonstrate that our method generates authentic and vivid
videos with precise lip motions, and natural pose/blink movements.
Additionally, with a high generation speed, DAWN possesses strong extrapolation
capabilities, ensuring the stable production of high-quality long videos. These
results highlight the considerable promise and potential impact of DAWN in the
field of talking head video generation. Furthermore, we hope that DAWN sparks
further exploration of non-autoregressive approaches in diffusion models. Our
code will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.",http://arxiv.org/pdf/2410.13726v1,,False
Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design,17/10/2024,"Chenyu Wang, Masatoshi Uehara, Yichun He, Amy Wang, Tommaso Biancalani, Avantika Lal, Tommi Jaakkola, Sergey Levine, Hanchen Wang, Aviv Regev","Recent studies have demonstrated the strong empirical performance of
diffusion models on discrete sequences across domains from natural language to
biological sequence generation. For example, in the protein inverse folding
task, conditional diffusion models have achieved impressive results in
generating natural-like sequences that fold back into the original structure.
However, practical design tasks often require not only modeling a conditional
distribution but also optimizing specific task objectives. For instance, we may
prefer protein sequences with high stability. To address this, we consider the
scenario where we have pre-trained discrete diffusion models that can generate
natural-like sequences, as well as reward models that map sequences to task
objectives. We then formulate the reward maximization problem within discrete
diffusion models, analogous to reinforcement learning (RL), while minimizing
the KL divergence against pretrained diffusion models to preserve naturalness.
To solve this RL problem, we propose a novel algorithm, DRAKES, that enables
direct backpropagation of rewards through entire trajectories generated by
diffusion models, by making the originally non-differentiable trajectories
differentiable using the Gumbel-Softmax trick. Our theoretical analysis
indicates that our approach can generate sequences that are both natural-like
and yield high rewards. While similar tasks have been recently explored in
diffusion models for continuous domains, our work addresses unique algorithmic
and theoretical challenges specific to discrete diffusion models, which arise
from their foundation in continuous-time Markov chains rather than Brownian
motion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA
and protein sequences that optimize enhancer activity and protein stability,
respectively, important tasks for gene therapies and protein-based
therapeutics.",http://arxiv.org/pdf/2410.13643v1,,False
Sample Compression Hypernetworks: From Generalization Bounds to Meta-Learning,17/10/2024,"Benjamin Leblanc, Mathieu Bazinet, Nathaniel D'Amours, Alexandre Drouin, Pascal Germain","Reconstruction functions are pivotal in sample compression theory, a
framework for deriving tight generalization bounds. From a small sample of the
training set (the compression set) and an optional stream of information (the
message), they recover a predictor previously learned from the whole training
set. While usually fixed, we propose to learn reconstruction functions. To
facilitate the optimization and increase the expressiveness of the message, we
derive a new sample compression generalization bound for real-valued messages.
From this theoretical analysis, we then present a new hypernetwork architecture
that outputs predictors with tight generalization guarantees when trained using
an original meta-learning framework. The results of promising preliminary
experiments are then reported.",http://arxiv.org/pdf/2410.13577v1,,False
CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models,17/10/2024,"Yujian Zhao, Chengru Wu, Yinong Xu, Xuanzheng Du, Ruiyu Li, Guanglin Niu","Cloth-changing person re-identification (CC-ReID), also known as Long-Term
Person Re-Identification (LT-ReID) is a critical and challenging research topic
in computer vision that has recently garnered significant attention. However,
due to the high cost of constructing CC-ReID data, the existing data-driven
models are hard to train efficiently on limited data, causing overfitting
issue. To address this challenge, we propose a low-cost and efficient pipeline
for generating controllable and high-quality synthetic data simulating the
surveillance of real scenarios specific to the CC-ReID task. Particularly, we
construct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal
Person (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5
outfits per individual. Based on this large-scale dataset, we introduce an
effective and scalable pretrain-finetune framework for enhancing the
generalization capabilities of the traditional CC-ReID models. The extensive
experiments demonstrate that two typical models namely TransReID and FIRe^2,
when integrated into our framework, outperform other state-of-the-art models
after pretraining on CCUP and finetuning on the benchmarks such as PRCC,
VC-Clothes and NKUP. The CCUP is available at:
https://github.com/yjzhao1019/CCUP.",http://arxiv.org/pdf/2410.13567v1,,False
Generative Adversarial Synthesis of Radar Point Cloud Scenes,17/10/2024,"Muhammad Saad Nawaz, Thomas Dallmann, Torsten Schoen, Dirk Heberling","For the validation and verification of automotive radars, datasets of
realistic traffic scenarios are required, which, how ever, are laborious to
acquire. In this paper, we introduce radar scene synthesis using GANs as an
alternative to the real dataset acquisition and simulation-based approaches. We
train a PointNet++ based GAN model to generate realistic radar point cloud
scenes and use a binary classifier to evaluate the performance of scenes
generated using this model against a test set of real scenes. We demonstrate
that our GAN model achieves similar performance (~87%) to the real scenes test
set.",http://arxiv.org/pdf/2410.13526v1,,False
CERES: Critical-Event Reconstruction via Temporal Scene Graph Completion,17/10/2024,"Efimia Panagiotaki, Georgi Pramatarov, Lars Kunze, Daniele De Martini","This paper proposes a method for on-demand scenario generation in simulation,
grounded on real-world data. Evaluating the behaviour of Autonomous Vehicles
(AVs) in both safety-critical and regular scenarios is essential for assessing
their robustness before real-world deployment. By integrating scenarios derived
from real-world datasets into the simulation, we enhance the plausibility and
validity of testing sets. This work introduces a novel approach that employs
temporal scene graphs to capture evolving spatiotemporal relationships among
scene entities from a real-world dataset, enabling the generation of dynamic
scenarios in simulation through Graph Neural Networks (GNNs). User-defined
action and criticality conditioning are used to ensure flexible, tailored
scenario creation. Our model significantly outperforms the benchmarks in
accurately predicting links corresponding to the requested scenarios. We
further evaluate the validity and compatibility of our generated scenarios in
an off-the-shelf simulator.",http://arxiv.org/pdf/2410.13514v1,,False
"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques",17/10/2024,"Rahimanuddin Shaik, Katikela Sreeharsha Kishore","Text generation is the automated process of producing written or spoken
language using computational methods. It involves generating coherent and
contextually relevant text based on predefined rules or learned patterns.
However, challenges in text generation arise from maintaining coherence,
ensuring diversity and creativity, and avoiding biases or inappropriate
content. This research paper developed a novel approach to improve text
generation in the context of joint Natural Language Generation (NLG) and
Natural Language Understanding (NLU) learning. The data is prepared by
gathering and preprocessing annotated datasets, including cleaning,
tokenization, stemming, and stop-word removal. Feature extraction techniques
such as POS tagging, Bag of words, and Term Frequency-Inverse Document
Frequency (TF-IDF) are applied. Transformer-based encoders and decoders,
capturing long range dependencies and improving source-target sequence
modelling. Pre-trained language models like Optimized BERT are incorporated,
along with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).
Reinforcement learning with policy gradient techniques, semi-supervised
training, improved attention mechanisms, and differentiable approximations like
straight-through Gumbel SoftMax estimator are employed to fine-tune the models
and handle complex linguistic tasks effectively. The proposed model is
implemented using Python.",http://arxiv.org/pdf/2410.13498v1,,False
On uniqueness of the set of k-means,17/10/2024,"Javier Cárcamo, Antonio Cuevas, Luis A. Rodríguez","We provide necessary and sufficient conditions for the uniqueness of the
k-means set of a probability distribution. This uniqueness problem is related
to the choice of k: depending on the underlying distribution, some values of
this parameter could lead to multiple sets of k-means, which hampers the
interpretation of the results and/or the stability of the algorithms. We give a
general assessment on consistency of the empirical k-means adapted to the
setting of non-uniqueness and determine the asymptotic distribution of the
within cluster sum of squares (WCSS). We also provide statistical
characterizations of k-means uniqueness in terms of the asymptotic behavior of
the empirical WCSS. As a consequence, we derive a bootstrap test for uniqueness
of the set of k-means. The results are illustrated with examples of different
types of non-uniqueness and we check by simulations the performance of the
proposed methodology.",http://arxiv.org/pdf/2410.13495v1,,False
Progressive Mixed-Precision Decoding for Efficient LLM Inference,17/10/2024,"Hao Mark Chen, Fuwen Tan, Alexandros Kouris, Royson Lee, Hongxiang Fan, Stylianos I. Venieris","In spite of the great potential of large language models (LLMs) across
various tasks, their deployment on resource-constrained devices remains
challenging due to their excessive computational and memory demands.
Quantization has emerged as an effective solution by storing weights in reduced
precision. However, utilizing low precisions (i.e.~2/3-bit) to substantially
alleviate the memory-boundedness of LLM decoding, still suffers from
prohibitive performance drop. In this work, we argue that existing approaches
fail to explore the diversity in computational patterns, redundancy, and
sensitivity to approximations of the different phases of LLM inference,
resorting to a uniform quantization policy throughout. Instead, we propose a
novel phase-aware method that selectively allocates precision during different
phases of LLM inference, achieving both strong context extraction during
prefill and efficient memory bandwidth utilization during decoding. To further
address the memory-boundedness of the decoding phase, we introduce Progressive
Mixed-Precision Decoding (PMPD), a technique that enables the gradual lowering
of precision deeper in the generated sequence, together with a spectrum of
precision-switching schedulers that dynamically drive the precision-lowering
decisions in either task-adaptive or prompt-adaptive manner. Extensive
evaluation across diverse language tasks shows that when targeting Nvidia GPUs,
PMPD achieves 1.4$-$12.2$\times$ speedup in matrix-vector multiplications over
fp16 models, while when targeting an LLM-optimized NPU, our approach delivers a
throughput gain of 3.8$-$8.0$\times$ over fp16 models and up to 1.54$\times$
over uniform quantization approaches while preserving the output quality.",http://arxiv.org/pdf/2410.13461v1,,False
MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models,17/10/2024,"Donghao Zhou, Jiancheng Huang, Jinbin Bai, Jiaze Wang, Hao Chen, Guangyong Chen, Xiaowei Hu, Pheng-Ann Heng","Recent advancements in text-to-image (T2I) diffusion models have enabled the
creation of high-quality images from text prompts, but they still struggle to
generate images with precise control over specific visual concepts. Existing
approaches can replicate a given concept by learning from reference images, yet
they lack the flexibility for fine-grained customization of the individual
component within the concept. In this paper, we introduce
component-controllable personalization, a novel task that pushes the boundaries
of T2I models by allowing users to reconfigure specific components when
personalizing visual concepts. This task is particularly challenging due to two
primary obstacles: semantic pollution, where unwanted visual elements corrupt
the personalized concept, and semantic imbalance, which causes disproportionate
learning of the concept and component. To overcome these challenges, we design
MagicTailor, an innovative framework that leverages Dynamic Masked Degradation
(DM-Deg) to dynamically perturb undesired visual semantics and Dual-Stream
Balancing (DS-Bal) to establish a balanced learning paradigm for desired visual
semantics. Extensive comparisons, ablations, and analyses demonstrate that
MagicTailor not only excels in this challenging task but also holds significant
promise for practical applications, paving the way for more nuanced and
creative image generation.",http://arxiv.org/pdf/2410.13370v1,,False
Statistical testing on generative AI anomaly detection tools in Alzheimer's Disease diagnosis,17/10/2024,"Rosemary He, Ichiro Takeuchi","Alzheimer's Disease is challenging to diagnose due to our limited
understanding of its mechanism and large heterogeneity among patients.
Neurodegeneration is studied widely as a biomarker for clinical diagnosis,
which can be measured from time series MRI progression. On the other hand,
generative AI has shown promise in anomaly detection in medical imaging and
used for tasks including tumor detection. However, testing the reliability of
such data-driven methods is non-trivial due to the issue of double-dipping in
hypothesis testing. In this work, we propose to solve this issue with selective
inference and develop a reliable generative AI method for Alzheimer's
prediction. We show that compared to traditional statistical methods with
highly inflated p-values, selective inference successfully controls the false
discovery rate under the desired alpha level while retaining statistical power.
In practice, our pipeline could assist clinicians in Alzheimer's diagnosis and
early intervention.",http://arxiv.org/pdf/2410.13363v1,,False
DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone,17/10/2024,"Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang","Probabilistic time series imputation has been widely applied in real-world
scenarios due to its ability to estimate uncertainty of imputation results.
Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great
success in probabilistic time series imputation tasks with its power to model
complex distributions. However, current DDPM-based probabilistic time series
imputation methodologies are confronted with two types of challenges:
1)~\textit{~The backbone modules of the denoising parts are not capable of
achieving sequence modeling with low time complexity.} 2)~\textit{The
architecture of denoising modules can not handle the inter-variable and
bidirectional dependencies in the time series imputation problem effectively.}
To address the first challenge, we integrate the computational efficient state
space model, namely Mamba, as the backbone denosing module for DDPMs. To tackle
the second challenge, we carefully devise several SSM-based blocks for
bidirectional modeling and inter-variable relation understanding. Experimental
results demonstrate that our approach can achieve state-of-the-art time series
imputation results on multiple datasets, different missing scenarios and
missing ratios.",http://arxiv.org/pdf/2410.13338v1,,False
Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding,17/10/2024,"Kyungmin Min, Minbeom Kim, Kang-il Lee, Dongryeol Lee, Kyomin Jung","Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in
generating detailed and coherent responses from visual inputs. However, they
are prone to generate hallucinations due to an over-reliance on language
priors. To address this issue, we investigate the language priors in LVLMs and
make two key observations: (1) Even when predicting the tokens associated with
image-related part-of-speech (POS), models increasingly rely on linguistic
priors as the token sequences grow, thereby amplifying hallucinations. (2)
Methods that directly calibrate LVLM's output distribution to mitigate language
priors can lead to a degradation in text quality or even exacerbate
hallucinations. Based on these findings, we propose a novel method,
Summary-Guided Decoding (SGD). This method naturally encourages the model to
focus more on image information by reducing the text context through summaries,
while controlling only the image-related POS tokens to maintain text quality.
Through experiments, we demonstrate that SGD achieves state-of-the-art
performance on object hallucination benchmarks. Furthermore, in terms of the
trade-off between precision and recall, SGD achieves Pareto optimality among
the existing methods. Lastly, we observe that although existing methods
struggle to balance the reduction of object hallucinations with maintaining
text quality, SGD demonstrates robustness in handling this challenge.",http://arxiv.org/pdf/2410.13321v1,,False
Active inference and deep generative modeling for cognitive ultrasound,17/10/2024,Ruud JG van Sloun,"Ultrasound (US) has the unique potential to offer access to medical imaging
to anyone, everywhere. Devices have become ultra-portable and cost-effective,
akin to the stethoscope. Nevertheless US image quality and diagnostic efficacy
are still highly operator- and patient-dependent. In difficult-to-image
patients, image quality is often insufficient for reliable diagnosis. In this
paper, we put forth that US imaging systems can be recast as
information-seeking agents that engage in reciprocal interactions with their
anatomical environment. Such agents autonomously adapt their transmit-receive
sequences to fully personalize imaging and actively maximize information gain
in-situ. To that end, we will show that the sequence of pulse-echo experiments
that a US system performs can be interpreted as a perception-action loop: the
action is the data acquisition, probing tissue with acoustic waves and
recording reflections at the detection array, and perception is the inference
of the anatomical and or functional state, potentially including associated
diagnostic quantities. We then equip systems with a mechanism to actively
reduce uncertainty and maximize diagnostic value across a sequence of
experiments, treating action and perception jointly using Bayesian inference
given generative models of the environment and action-conditional pulse-echo
observations. Since the representation capacity of the generative models
dictates both the quality of inferred anatomical states and the effectiveness
of inferred sequences of future imaging actions, we will be greatly leveraging
the enormous advances in deep generative modelling that are currently
disrupting many fields and society at large. Finally, we show some examples of
cognitive, closed-loop, US systems that perform active beamsteering and
adaptive scanline selection, based on deep generative models that track
anatomical belief states.",http://arxiv.org/pdf/2410.13310v1,10.1109/TUFFC.2024.3466290,False
An Online Learning Approach to Prompt-based Selection of Generative Models,17/10/2024,"Xiaoyan Hu, Ho-fung Leung, Farzan Farnia","Selecting a sample generation scheme from multiple text-based generative
models is typically addressed by choosing the model that maximizes an averaged
evaluation score. However, this score-based selection overlooks the possibility
that different models achieve the best generation performance for different
types of text prompts. An online identification of the best generation model
for various input prompts can reduce the costs associated with querying
sub-optimal models. In this work, we explore the possibility of varying
rankings of text-based generative models for different text prompts and propose
an online learning framework to predict the best data generation model for a
given input prompt. The proposed framework adapts the kernelized contextual
bandit (CB) methodology to a CB setting with shared context variables across
arms, utilizing the generated data to update a kernel-based function that
predicts which model will achieve the highest score for unseen text prompts.
Additionally, we apply random Fourier features (RFF) to the kernelized CB
algorithm to accelerate the online learning process and establish a
$\widetilde{\mathcal{O}}(\sqrt{T})$ regret bound for the proposed RFF-based CB
algorithm over T iterations. Our numerical experiments on real and simulated
text-to-image and image-to-text generative models show RFF-UCB performs
successfully in identifying the best generation model across different sample
types.",http://arxiv.org/pdf/2410.13287v1,,False
The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion,17/10/2024,"Xu Han, Yuancheng Sun, Kai Chen, Kang Liu, Qiwei Ye","Coarse-grained(CG) molecular dynamics simulations offer computational
efficiency for exploring protein conformational ensembles and thermodynamic
properties. Though coarse representations enable large-scale simulations across
extended temporal and spatial ranges, the sacrifice of atomic-level details
limits their utility in tasks such as ligand docking and protein-protein
interaction prediction. Backmapping, the process of reconstructing all-atom
structures from coarse-grained representations, is crucial for recovering these
fine details. While recent machine learning methods have made strides in
protein structure generation, challenges persist in reconstructing diverse
atomistic conformations that maintain geometric accuracy and chemical validity.
In this paper, we present Latent Diffusion Backmapping (LDB), a novel approach
leveraging denoising diffusion within latent space to address these challenges.
By combining discrete latent encoding with diffusion, LDB bypasses the need for
equivariant and internal coordinate manipulation, significantly simplifying the
training and sampling processes as well as facilitating better and wider
exploration in configuration space. We evaluate LDB's state-of-the-art
performance on three distinct protein datasets, demonstrating its ability to
efficiently reconstruct structures with high structural accuracy and chemical
validity. Moreover, LDB shows exceptional versatility in capturing diverse
protein ensembles, highlighting its capability to explore intricate
conformational spaces. Our results position LDB as a powerful and scalable
approach for backmapping, effectively bridging the gap between CG simulations
and atomic-level analyses in computational biology.",http://arxiv.org/pdf/2410.13264v1,,False
scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers,17/10/2024,"Dian Meng, Bohao Xing, Xinlei Huang, Yanran Liu, Yijun Zhou, Yongjun xiao, Zitong Yu, Xubin Zheng","Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data,
such as Cellular Indexing of Transcriptomes and Epitopes by Sequencing
(CITE-seq), where the regulation of each cell was measured from different
modalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity
inside tumors and understand the distinct genetic properties of diverse cell
types, which is crucial to targeted therapy. Currently, deep learning methods
based on attention structures in the bioinformatics area face two challenges.
The first challenge is the vast number of genes in a single cell. Traditional
attention-based modules struggled to effectively leverage all gene information
due to their limited capacity for long-context learning and high-complexity
computing. The second challenge is that genes in the human genome are ordered
and influence each other's expression. Most of the methods ignored this
sequential information. The recently introduced Test-Time Training (TTT) layer
is a novel sequence modeling approach, particularly suitable for handling long
contexts like genomics data because TTT layer is a linear complexity sequence
modeling structure and is better suited to data with sequential relationships.
In this paper, we propose scFusionTTT, a novel method for Single-Cell
multimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine
the order information of genes and proteins in the human genome with the TTT
layer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the
model employs a three-stage training strategy, which yielded the best
performance across most metrics in four multimodal omics datasets and four
unimodal omics datasets, demonstrating the superior performance of our model.
The dataset and code will be available on
https://github.com/DM0815/scFusionTTT.",http://arxiv.org/pdf/2410.13257v1,,False
Quamba: A Post-Training Quantization Recipe for Selective State Space Models,17/10/2024,"Hung-Yueh Chiang, Chi-Chih Chang, Natalia Frumkin, Kai-Chiang Wu, Diana Marculescu","State Space Models (SSMs) have emerged as an appealing alternative to
Transformers for large language models, achieving state-of-the-art accuracy
with constant memory complexity which allows for holding longer context lengths
than attention-based networks. The superior computational efficiency of SSMs in
long sequence modeling positions them favorably over Transformers in many
scenarios. However, improving the efficiency of SSMs on request-intensive
cloud-serving and resource-limited edge applications is still a formidable
task. SSM quantization is a possible solution to this problem, making SSMs more
suitable for wide deployment, while still maintaining their accuracy.
Quantization is a common technique to reduce the model size and to utilize the
low bit-width acceleration features on modern computing units, yet existing
quantization techniques are poorly suited for SSMs. Most notably, SSMs have
highly sensitive feature maps within the selective scan mechanism (i.e., linear
recurrence) and massive outliers in the output activations which are not
present in the output of token-mixing in the self-attention modules. To address
this issue, we propose a static 8-bit per-tensor SSM quantization method which
suppresses the maximum values of the input activations to the selective SSM for
finer quantization precision and quantizes the output activations in an
outlier-free space with Hadamard transform. Our 8-bit weight-activation
quantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a
1.72x lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9% drop
in average accuracy on zero-shot tasks. The experiments demonstrate the
effectiveness and practical applicability of our approach for deploying
SSM-based models of all sizes on both cloud and edge platforms.",http://arxiv.org/pdf/2410.13229v1,,False
Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration,17/10/2024,"Yun-Yen Chuang, Hung-Min Hsu, Kevin Lin, Chen-Sheng Gu, Ling Zhen Li, Ray-I Chang, Hung-yi Lee","The diffusion model, a new generative modeling paradigm, has achieved
significant success in generating images, audio, video, and text. It has been
adapted for sequence-to-sequence text generation (Seq2Seq) through DiffuSeq,
termed S2S Diffusion. Existing S2S-Diffusion models predominantly rely on fixed
or hand-crafted rules to schedule noise during the diffusion and denoising
processes. However, these models are limited by non-contextualized noise, which
fails to fully consider the characteristics of Seq2Seq tasks. In this paper, we
propose the Meta-DiffuB framework - a novel scheduler-exploiter S2S-Diffusion
paradigm designed to overcome the limitations of existing S2S-Diffusion models.
We employ Meta-Exploration to train an additional scheduler model dedicated to
scheduling contextualized noise for each sentence. Our exploiter model, an
S2S-Diffusion model, leverages the noise scheduled by our scheduler model for
updating and generation. Meta-DiffuB achieves state-of-the-art performance
compared to previous S2S-Diffusion models and fine-tuned pre-trained language
models (PLMs) across four Seq2Seq benchmark datasets. We further investigate
and visualize the impact of Meta-DiffuB's noise scheduling on the generation of
sentences with varying difficulties. Additionally, our scheduler model can
function as a ""plug-and-play"" model to enhance DiffuSeq without the need for
fine-tuning during the inference stage.",http://arxiv.org/pdf/2410.13201v1,,False
GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation,17/10/2024,"Ziwei Yang, Zheng Chen, Xin Liu, Rikuto Kotoge, Peng Chen, Yasuko Matsubara, Yasushi Sakurai, Jimeng Sun","Retrieving gene functional networks from knowledge databases presents a
challenge due to the mismatch between disease networks and subtype-specific
variations. Current solutions, including statistical and deep learning methods,
often fail to effectively integrate gene interaction knowledge from databases
or explicitly learn subtype-specific interactions. To address this mismatch, we
propose GeSubNet, which learns a unified representation capable of predicting
gene interactions while distinguishing between different disease subtypes.
Graphs generated by such representations can be considered subtype-specific
networks. GeSubNet is a multi-step representation learning framework with three
modules: First, a deep generative model learns distinct disease subtypes from
patient gene expression profiles. Second, a graph neural network captures
representations of prior gene networks from knowledge databases, ensuring
accurate physical gene interactions. Finally, we integrate these two
representations using an inference loss that leverages graph generation
capabilities, conditioned on the patient separation loss, to refine
subtype-specific information in the learned representation. GeSubNet
consistently outperforms traditional methods, with average improvements of
30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged
over four cancer datasets. Particularly, we conduct a biological simulation
experiment to assess how the behavior of selected genes from over 11,000
candidates affects subtypes or patient distributions. The results show that the
generated network has the potential to identify subtype-specific genes with an
83% likelihood of impacting patient distribution shifts. The GeSubNet resource
is available: https://anonymous.4open.science/r/GeSubNet/",http://arxiv.org/pdf/2410.13178v1,,False
Scalable Drift Monitoring in Medical Imaging AI,17/10/2024,"Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov","The integration of artificial intelligence (AI) into medical imaging has
advanced clinical diagnostics but poses challenges in managing model drift and
ensuring long-term reliability. To address these challenges, we develop MMC+,
an enhanced framework for scalable drift monitoring, building upon the
CheXstray framework that introduced real-time drift detection for medical
imaging AI models using multi-modal data concordance. This work extends the
original framework's methodologies, providing a more scalable and adaptable
solution for real-world healthcare settings and offers a reliable and
cost-effective alternative to continuous performance monitoring addressing
limitations of both continuous and periodic monitoring methods. MMC+ introduces
critical improvements to the original framework, including more robust handling
of diverse data streams, improved scalability with the integration of
foundation models like MedImageInsight for high-dimensional image embeddings
without site-specific training, and the introduction of uncertainty bounds to
better capture drift in dynamic clinical environments. Validated with
real-world data from Massachusetts General Hospital during the COVID-19
pandemic, MMC+ effectively detects significant data shifts and correlates them
with model performance changes. While not directly predicting performance
degradation, MMC+ serves as an early warning system, indicating when AI systems
may deviate from acceptable performance bounds and enabling timely
interventions. By emphasizing the importance of monitoring diverse data streams
and evaluating data shifts alongside model performance, this work contributes
to the broader adoption and integration of AI solutions in clinical settings.",http://arxiv.org/pdf/2410.13174v1,,False
Distributional Matrix Completion via Nearest Neighbors in the Wasserstein Space,17/10/2024,"Jacob Feitelberg, Kyuseong Choi, Anish Agarwal, Raaz Dwivedi","We introduce the problem of distributional matrix completion: Given a
sparsely observed matrix of empirical distributions, we seek to impute the true
distributions associated with both observed and unobserved matrix entries. This
is a generalization of traditional matrix completion where the observations per
matrix entry are scalar valued. To do so, we utilize tools from optimal
transport to generalize the nearest neighbors method to the distributional
setting. Under a suitable latent factor model on probability distributions, we
establish that our method recovers the distributions in the Wasserstein norm.
We demonstrate through simulations that our method is able to (i) provide
better distributional estimates for an entry compared to using observed samples
for that entry alone, (ii) yield accurate estimates of distributional
quantities such as standard deviation and value-at-risk, and (iii) inherently
support heteroscedastic noise. We also prove novel asymptotic results for
Wasserstein barycenters over one-dimensional distributions.",http://arxiv.org/pdf/2410.13112v1,,False
Controllable Generation via Locally Constrained Resampling,17/10/2024,"Kareem Ahmed, Kai-Wei Chang, Guy Van den Broeck","Autoregressive models have demonstrated an unprecedented ability at modeling
the intricacies of natural language. However, they continue to struggle with
generating complex outputs that adhere to logical constraints. Sampling from a
fully-independent distribution subject to a constraint is hard. Sampling from
an autoregressive distribution subject to a constraint is doubly hard: We have
to contend not only with the hardness of the constraint but also the
distribution's lack of structure. We propose a tractable probabilistic approach
that performs Bayesian conditioning to draw samples subject to a constraint.
Our approach considers the entire sequence, leading to a more globally optimal
constrained generation than current greedy methods. Starting from a model
sample, we induce a local, factorized distribution which we can tractably
condition on the constraint. To generate samples that satisfy the constraint,
we sample from the conditional distribution, correct for biases in the samples
and resample. The resulting samples closely approximate the target distribution
and are guaranteed to satisfy the constraints. We evaluate our approach on
several tasks, including LLM detoxification and solving Sudoku puzzles. We show
that by disallowing a list of toxic expressions our approach is able to steer
the model's outputs away from toxic generations, outperforming similar
approaches to detoxification. We conclude by showing that our approach achieves
a perfect accuracy on Sudoku compared to <50% for GPT4-o and Gemini 1.5.",http://arxiv.org/pdf/2410.13111v1,,False
