Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
On Vanishing Variance in Transformer Length Generalization,03/04/2025,"Ruining Li, Gabrijel Boduljak, Jensen, Zhou","It is a widely known issue that Transformers, when trained on shorter
sequences, fail to generalize robustly to longer ones at test time. This raises
the question of whether Transformer models are real reasoning engines, despite
their impressive abilities in mathematical problem solving and code synthesis.
In this paper, we offer a vanishing variance perspective on this issue. To the
best of our knowledge, we are the first to demonstrate that even for today's
frontier models, a longer sequence length results in a decrease in variance in
the output of the multi-head attention modules. On the argmax retrieval and
dictionary lookup tasks, our experiments show that applying layer normalization
after the attention outputs leads to significantly better length
generalization. Our analyses attribute this improvement to a reduction-though
not a complete elimination-of the distribution shift caused by vanishing
variance.",http://arxiv.org/pdf/2504.02827v1,,False
Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets,03/04/2025,"Chuning Zhu, Raymond Yu, Siyuan Feng, Benjamin Burchfiel, Paarth Shah, Abhishek Gupta","Imitation learning has emerged as a promising approach towards building
generalist robots. However, scaling imitation learning for large robot
foundation models remains challenging due to its reliance on high-quality
expert demonstrations. Meanwhile, large amounts of video data depicting a wide
range of environments and diverse behaviors are readily available. This data
provides a rich source of information about real-world dynamics and
agent-environment interactions. Leveraging this data directly for imitation
learning, however, has proven difficult due to the lack of action annotation
required for most contemporary methods. In this work, we present Unified World
Models (UWM), a framework that allows for leveraging both video and action data
for policy learning. Specifically, a UWM integrates an action diffusion process
and a video diffusion process within a unified transformer architecture, where
independent diffusion timesteps govern each modality. We show that by simply
controlling each diffusion timestep, UWM can flexibly represent a policy, a
forward dynamics, an inverse dynamics, and a video generator. Through simulated
and real-world experiments, we show that: (1) UWM enables effective pretraining
on large-scale multitask robot datasets with both dynamics and action
predictions, resulting in more generalizable and robust policies than imitation
learning, (2) UWM naturally facilitates learning from action-free video data
through independent control of modality-specific diffusion timesteps, further
improving the performance of finetuned policies. Our results suggest that UWM
offers a promising step toward harnessing large, heterogeneous datasets for
scalable robot learning, and provides a simple unification between the often
disparate paradigms of imitation learning and world modeling. Videos and code
are available at https://weirdlabuw.github.io/uwm/.",http://arxiv.org/pdf/2504.02792v1,,False
Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations,03/04/2025,"Selim Ickin, Shruti Bothe, Aman Raparia, Nitin Khanna, Erik Sanders","Optimization of radio hardware and AI-based network management software yield
significant energy savings in radio access networks. The execution of
underlying Machine Learning (ML) models, which enable energy savings through
recommended actions, may require additional compute and energy, highlighting
the opportunity to explore and adopt accurate and energy-efficient ML
technologies. This work evaluates the novel use of sparsely structured Neural
Circuit Policies (NCPs) in a use case to estimate the energy consumption of
base stations. Sparsity in ML models yields reduced memory, computation and
energy demand, hence facilitating a low-cost and scalable solution. We also
evaluate the generalization capability of NCPs in comparison to traditional and
widely used ML models such as Long Short Term Memory (LSTM), via quantifying
their sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a
clear reduction in computational overhead and energy consumption. Moreover,
results indicated that the NCPs are robust to varying HPs such as number of
epochs and neurons in each layer, making them a suitable option to ease model
management and to reduce energy consumption in Machine Learning Operations
(MLOps) in telecommunications.",http://arxiv.org/pdf/2504.02781v1,,False
Autonomous Human-Robot Interaction via Operator Imitation,03/04/2025,"Sammy Christen, David Müller, Agon Serifi, Ruben Grandia, Georg Wiedebach, Michael A. Hopkins, Espen Knoop, Moritz Bächer","Teleoperated robotic characters can perform expressive interactions with
humans, relying on the operators' experience and social intuition. In this
work, we propose to create autonomous interactive robots, by training a model
to imitate operator data. Our model is trained on a dataset of human-robot
interactions, where an expert operator is asked to vary the interactions and
mood of the robot, while the operator commands as well as the pose of the human
and robot are recorded. Our approach learns to predict continuous operator
commands through a diffusion process and discrete commands through a
classifier, all unified within a single transformer architecture. We evaluate
the resulting model in simulation and with a user study on the real system. We
show that our method enables simple autonomous human-robot interactions that
are comparable to the expert-operator baseline, and that users can recognize
the different robot moods as generated by our model. Finally, we demonstrate a
zero-shot transfer of our model onto a different robotic platform with the same
operator interface.",http://arxiv.org/pdf/2504.02724v1,,False
SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions,03/04/2025,"Shengrui XU, Tianchi Lu, Zikun Wang, Jixiu Zhai, Jingwan Wang","Protein-Protein Interaction (PPI) prediction is a key task in uncovering
cellular functional networks and disease mechanisms. However, traditional
experimental methods are time-consuming and costly, and existing computational
models face challenges in cross-modal feature fusion, robustness, and
false-negative suppression. In this paper, we propose a novel supervised
contrastive multimodal framework, SCMPPI, for PPI prediction. By integrating
protein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology
information (Node2Vec graph embedding), and combining an improved supervised
contrastive learning strategy, SCMPPI significantly enhances PPI prediction
performance. For the PPI task, SCMPPI introduces a negative sample filtering
mechanism and modifies the contrastive loss function, effectively optimizing
multimodal features. Experiments on eight benchmark datasets, including yeast,
human, and H.pylori, show that SCMPPI outperforms existing state-of-the-art
methods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)
and AUC (99.62%), and demonstrates strong generalization in cross-species
prediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been
successfully applied to CD9 networks, the Wnt pathway, and cancer-specific
networks, providing a reliable tool for disease target discovery. This
framework also offers a new paradigm for multimodal biological information
fusion and contrastive learning in collaborative optimization for various
combined predictions.",http://arxiv.org/pdf/2504.02698v1,,False
Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication using DRL,03/04/2025,"Achilles Kiwanuka Machumilane, Alberto Gotta, Pietro Cassarà","Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted
next-generation wireless networks is critical for mobility management and
ensuring UAV safety and ubiquitous connectivity, especially in dense urban
environments with street canyons and tall buildings. Traditional statistical
and model-based techniques have been successfully used for path optimization in
communication networks. However, when dynamic channel propagation
characteristics such as line-of-sight (LOS), interference, handover, and
signal-to-interference and noise ratio (SINR) are included in path
optimization, statistical and model-based path planning solutions become
obsolete since they cannot adapt to the dynamic and time-varying wireless
channels, especially in the mmWave bands. In this paper, we propose a novel
model-free actor-critic deep reinforcement learning (AC-DRL) framework for path
optimization in UAV-assisted 5G mmWave wireless networks, which combines four
important aspects of UAV communication: \textit{flight time, handover,
connectivity and SINR}. We train an AC-RL agent that enables a UAV connected to
a gNB to determine the optimal path to a desired destination in the shortest
possible time with minimal gNB handover, while maintaining connectivity and the
highest possible SINR. We train our model with data from a powerful ray tracing
tool called Wireless InSite, which uses 3D images of the propagation
environment and provides data that closely resembles the real propagation
environment. The simulation results show that our system has superior
performance in tracking high SINR compared to other selected RL algorithms.",http://arxiv.org/pdf/2504.02688v1,,False
"A Dynamic, Ordinal Gaussian Process Item Response Theoretic Model",03/04/2025,"Yehu Chen, Jacob Montgomery, Roman Garnett","Social scientists are often interested in using ordinal indicators to
estimate latent traits that change over time. Frequently, this is done with
item response theoretic (IRT) models that describe the relationship between
those latent traits and observed indicators. We combine recent advances in
Bayesian nonparametric IRT, which makes minimal assumptions on shapes of item
response functions, and Gaussian process time series methods to capture dynamic
structures in latent traits from longitudinal observations. We propose a
generalized dynamic Gaussian process item response theory (GD-GPIRT) as well as
a Markov chain Monte Carlo sampling algorithm for estimation of both latent
traits and response functions. We evaluate GD-GPIRT in simulation studies
against baselines in dynamic IRT, and apply it to various substantive studies,
including assessing public opinions on economy environment and congressional
ideology related to abortion debate.",http://arxiv.org/pdf/2504.02643v1,,False
Variational Online Mirror Descent for Robust Learning in Schrödinger Bridge,03/04/2025,"Dong-Sig Han, Jaein Kim, Hee Bin Yoo, Byoung-Tak Zhang","Sch\""odinger bridge (SB) has evolved into a universal class of probabilistic
generative models. In practice, however, estimated learning signals are often
uncertain, and the reliability promised by existing methods is often based on
speculative optimal-case scenarios. Recent studies regarding the Sinkhorn
algorithm through mirror descent (MD) have gained attention, revealing
geometric insights into solution acquisition of the SB problems. In this paper,
we propose a variational online MD (OMD) framework for the SB problems, which
provides further stability to SB solvers. We formally prove convergence and a
regret bound for the novel OMD formulation of SB acquisition. As a result, we
propose a simulation-free SB algorithm called Variational Mirrored
Schr\""odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of
the Gaussian mixture parameterization for Schr\""odinger potentials. Based on
the Wasserstein gradient flow theory, the algorithm offers tractable learning
dynamics that precisely approximate each OMD step. In experiments, we validate
the performance of the proposed VMSB algorithm across an extensive suite of
benchmarks. VMSB consistently outperforms contemporary SB solvers on a range of
SB problems, demonstrating the robustness predicted by our theory.",http://arxiv.org/pdf/2504.02618v1,,False
Towards Generalizing Temporal Action Segmentation to Unseen Views,03/04/2025,"Emad Bahrami, Olga Zatsarynna, Gianpiero Francesca, Juergen Gall","While there has been substantial progress in temporal action segmentation,
the challenge to generalize to unseen views remains unaddressed. Hence, we
define a protocol for unseen view action segmentation where camera views for
evaluating the model are unavailable during training. This includes changing
from top-frontal views to a side view or even more challenging from exocentric
to egocentric views. Furthermore, we present an approach for temporal action
segmentation that tackles this challenge. Our approach leverages a shared
representation at both the sequence and segment levels to reduce the impact of
view differences during training. We achieve this by introducing a sequence
loss and an action loss, which together facilitate consistent video and action
representations across different views. The evaluation on the Assembly101,
IkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a
12.8% increase in F1@50 for unseen exocentric views and a substantial 54%
improvement for unseen egocentric views.",http://arxiv.org/pdf/2504.02512v1,,False
Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation,03/04/2025,"Liangbo Ning, Wenqi Fan, Qing Li","Recently, Large Language Model (LLM)-empowered recommender systems have
revolutionized personalized recommendation frameworks and attracted extensive
attention. Despite the remarkable success, existing LLM-empowered RecSys have
been demonstrated to be highly vulnerable to minor perturbations. To mitigate
the negative impact of such vulnerabilities, one potential solution is to
employ collaborative signals based on item-item co-occurrence to purify the
malicious collaborative knowledge from the user's historical interactions
inserted by attackers. On the other hand, due to the capabilities to expand
insufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)
techniques provide unprecedented opportunities to enhance the robustness of
LLM-empowered recommender systems by introducing external collaborative
knowledge. Therefore, in this paper, we propose a novel framework (RETURN) by
retrieving external collaborative signals to purify the poisoned user profiles
and enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.
Specifically, retrieval-augmented perturbation positioning is proposed to
identify potential perturbations within the users' historical sequences by
retrieving external knowledge from collaborative item graphs. After that, we
further retrieve the collaborative knowledge to cleanse the perturbations by
using either deletion or replacement strategies and introduce a robust ensemble
recommendation strategy to generate final robust predictions. Extensive
experiments on three real-world datasets demonstrate the effectiveness of the
proposed RETURN.",http://arxiv.org/pdf/2504.02458v1,,False
CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles,03/04/2025,"Jingyi Wang, Duanfeng Chu, Zejian Deng, Liping Lu","To address the current challenges of low intelligence and simplistic vehicle
behavior modeling in autonomous driving simulation scenarios, this paper
proposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles
(CHARMS). The model can reason about the behavior of other vehicles like a
human driver and respond with different decision-making styles, thereby
improving the intelligence and diversity of the surrounding vehicles in the
driving scenario. By introducing the Level-k behavioral game theory, the paper
models the decision-making process of human drivers and employs deep
reinforcement learning to train the models with diverse decision styles,
simulating different reasoning approaches and behavioral characteristics.
Building on the Poisson cognitive hierarchy theory, this paper also presents a
novel driving scenario generation method. The method controls the proportion of
vehicles with different driving styles in the scenario using Poisson and
binomial distributions, thus generating controllable and diverse driving
environments. Experimental results demonstrate that CHARMS not only exhibits
superior decision-making capabilities as ego vehicles, but also generates more
complex and diverse driving scenarios as surrounding vehicles. We will release
code for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.",http://arxiv.org/pdf/2504.02450v1,,False
EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling,03/04/2025,"Hao Yin, Shi Guo, Xu Jia, Xudong XU, Lu Zhang, Si Liu, Dong Wang, Huchuan Lu, Tianfan Xue","When sound waves hit an object, they induce vibrations that produce
high-frequency and subtle visual changes, which can be used for recovering the
sound. Early studies always encounter trade-offs related to sampling rate,
bandwidth, field of view, and the simplicity of the optical path. Recent
advances in event camera hardware show good potential for its application in
visual sound recovery, because of its superior ability in capturing
high-frequency signals. However, existing event-based vibration recovery
methods are still sub-optimal for sound recovery. In this work, we propose a
novel pipeline for non-contact sound recovery, fully utilizing spatial-temporal
information from the event stream. We first generate a large training set using
a novel simulation pipeline. Then we designed a network that leverages the
sparsity of events to capture spatial information and uses Mamba to model
long-term temporal information. Lastly, we train a spatial aggregation block to
aggregate information from different locations to further improve signal
quality. To capture event signals caused by sound waves, we also designed an
imaging system using a laser matrix to enhance the gradient and collected
multiple data sequences for testing. Experimental results on synthetic and
real-world data demonstrate the effectiveness of our method.",http://arxiv.org/pdf/2504.02402v1,,False
Benchmark of Segmentation Techniques for Pelvic Fracture in CT and X-ray: Summary of the PENGWIN 2024 Challenge,03/04/2025,"Yudi Sang, Yanzhen Liu, Sutuke Yibulayimu, Yunning Wang, Benjamin D. Killeen, Mingxu Liu, Ping-Cheng Ku, Ole Johannsen, Karol Gotkowski, Maximilian Zenk, Klaus Maier-Hein, Fabian Isensee, Peiyan Yue, Yi Wang, Haidong Yu, Zhaohong Pan, Yutong He, Xiaokun Liang, Daiqi Liu, Fuxin Fan, Artur Jurgas, Andrzej Skalski, Yuxi Ma, Jing Yang, Szymon Płotka, Rafał Litka, Gang Zhu, Yingchun Song, Mathias Unberath, Mehran Armand, Dan Ruan, S. Kevin Zhou, Qiyong Cao, Chunpeng Zhao, Xinbao Wu, Yu Wang","The segmentation of pelvic fracture fragments in CT and X-ray images is
crucial for trauma diagnosis, surgical planning, and intraoperative guidance.
However, accurately and efficiently delineating the bone fragments remains a
significant challenge due to complex anatomy and imaging limitations. The
PENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance
automated fracture segmentation by benchmarking state-of-the-art algorithms on
these complex tasks. A diverse dataset of 150 CT scans was collected from
multiple clinical centers, and a large set of simulated X-ray images was
generated using the DeepDRR method. Final submissions from 16 teams worldwide
were evaluated under a rigorous multi-metric testing scheme. The top-performing
CT algorithm achieved an average fragment-wise intersection over union (IoU) of
0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the
best algorithm attained an IoU of 0.774, highlighting the greater challenges
posed by overlapping anatomical structures. Beyond the quantitative evaluation,
the challenge revealed methodological diversity in algorithm design. Variations
in instance representation, such as primary-secondary classification versus
boundary-core separation, led to differing segmentation strategies. Despite
promising results, the challenge also exposed inherent uncertainties in
fragment definition, particularly in cases of incomplete fractures. These
findings suggest that interactive segmentation approaches, integrating human
decision-making with task-relevant information, may be essential for improving
model reliability and clinical applicability.",http://arxiv.org/pdf/2504.02382v1,,False
OmniCam: Unified Multimodal Video Generation via Camera Control,03/04/2025,"Xiaoda Yang, Jiayang Xu, Kaixuan Luan, Xinyu Zhan, Hongshun Qiu, Shijun Shi, Hao Li, Shuai Yang, Li Zhang, Checheng Yu, Cewu Lu, Lixin Yang","Camera control, which achieves diverse visual effects by changing camera
position and pose, has attracted widespread attention. However, existing
methods face challenges such as complex interaction and limited control
capabilities. To address these issues, we present OmniCam, a unified multimodal
camera control framework. Leveraging large language models and video diffusion
models, OmniCam generates spatio-temporally consistent videos. It supports
various combinations of input modalities: the user can provide text or video
with expected trajectory as camera path guidance, and image or video as content
reference, enabling precise control over camera motion. To facilitate the
training of OmniCam, we introduce the OmniTr dataset, which contains a large
collection of high-quality long-sequence trajectories, videos, and
corresponding descriptions. Experimental results demonstrate that our model
achieves state-of-the-art performance in high-quality camera-controlled video
generation across various metrics.",http://arxiv.org/pdf/2504.02312v1,,False
Causal Self-supervised Pretrained Frontend with Predictive Code for Speech Separation,03/04/2025,"Wupeng Wang, Zexu Pan, Xinke Li, Shuai Wang, Haizhou Li","Speech separation (SS) seeks to disentangle a multi-talker speech mixture
into single-talker speech streams. Although SS can be generally achieved using
offline methods, such a processing paradigm is not suitable for real-time
streaming applications. Causal separation models, which rely only on past and
present information, offer a promising solution for real-time streaming.
However, these models typically suffer from notable performance degradation due
to the absence of future context. In this paper, we introduce a novel frontend
that is designed to mitigate the mismatch between training and run-time
inference by implicitly incorporating future information into causal models
through predictive patterns. The pretrained frontend employs a transformer
decoder network with a causal convolutional encoder as the backbone and is
pretrained in a self-supervised manner with two innovative pretext tasks:
autoregressive hybrid prediction and contextual knowledge distillation. These
tasks enable the model to capture predictive patterns directly from mixtures in
a self-supervised manner. The pretrained frontend subsequently serves as a
feature extractor to generate high-quality predictive patterns. Comprehensive
evaluations on synthetic and real-world datasets validated the effectiveness of
the proposed pretrained frontend.",http://arxiv.org/pdf/2504.02302v1,,False
State-of-the-Art Translation of Text-to-Gloss using mBART : A case study of Bangla,03/04/2025,"Sharif Md. Abdullah, Abhijit Paul, Shebuti Rayana, Ahmedul Kabir, Zarif Masud","Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language
(BdSL) remains a understudied domain. Specifically, there are no works on
Bangla text-to-gloss translation task. To address this gap, we begin by
addressing the dataset problem. We take inspiration from grammatical rule based
gloss generation used in Germany and American sign langauage (ASL) and adapt it
for BdSL. We also leverage LLM to generate synthetic data and use
back-translation, text generation for data augmentation. With dataset prepared,
we started experimentation. We fine-tuned pretrained mBART-50 and
mBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a
novel seq-to-seq model with multi-head attention. We observe significant high
performance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual
model from Facebook. We then explored why we observe such high performance with
mBART. We soon notice an interesting property of mBART -- it was trained on
shuffled and masked text data. And as we know, gloss form has shuffling
property. So we hypothesize that mBART is inherently good at text-to-gloss
tasks. To find support against this hypothesis, we trained mBART-50 on
PHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50
finetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,
far outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =
55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on
the results, this study proposes a new paradigm for text-to-gloss task using
mBART models. Additionally, our results show that BdSL text-to-gloss task can
greatly benefit from rule-based synthetic dataset.",http://arxiv.org/pdf/2504.02293v1,,False
