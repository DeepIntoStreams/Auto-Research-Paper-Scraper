Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
DANCE: Deep Learning-Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images,10/09/2024,"Taslim Murad, Prakash Chourasia, Sarwan Ali, Murray Patterson","Cancer is a complex disease characterized by uncontrolled cell growth. T cell
receptors (TCRs), crucial proteins in the immune system, play a key role in
recognizing antigens, including those associated with cancer. Recent
advancements in sequencing technologies have facilitated comprehensive
profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity
and enabling TCR-based immunotherapies. However, analyzing these intricate
biomolecules necessitates efficient representations that capture their
structural and functional information. T-cell protein sequences pose unique
challenges due to their relatively smaller lengths compared to other
biomolecules. An image-based representation approach becomes a preferred choice
for efficient embeddings, allowing for the preservation of essential details
and enabling comprehensive analysis of T-cell protein sequences. In this paper,
we propose to generate images from the protein sequences using the idea of
Chaos Game Representation (CGR) using the Kaleidoscopic images approach. This
Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced
Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein
sequences by recursively applying chaos game rules around a central seed point.
we perform the classification of the T cell receptors (TCRs) protein sequences
in terms of their respective target cancer cells, as TCRs are known for their
immune response against cancer disease. The TCR sequences are converted into
images using the DANCE method. We employ deep-learning vision models to perform
the classification to obtain insights into the relationship between the visual
patterns observed in the generated kaleidoscopic images and the underlying
protein properties. By combining CGR-based image generation with deep learning
classification, this study opens novel possibilities in the protein analysis
domain.",http://arxiv.org/pdf/2409.06694v1,,False
LLaMA-Omni: Seamless Speech Interaction with Large Language Models,10/09/2024,"Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng","Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.",http://arxiv.org/pdf/2409.06666v1,,False
Estimation and Inference for Causal Functions with Multiway Clustered Data,10/09/2024,"Nan Liu, Yanbo Liu, Yuya Sasaki","This paper proposes methods of estimation and uniform inference for a general
class of causal functions, such as the conditional average treatment effects
and the continuous treatment effects, under multiway clustering. The causal
function is identified as a conditional expectation of an adjusted
(Neyman-orthogonal) signal that depends on high-dimensional nuisance
parameters. We propose a two-step procedure where the first step uses machine
learning to estimate the high-dimensional nuisance parameters. The second step
projects the estimated Neyman-orthogonal signal onto a dictionary of basis
functions whose dimension grows with the sample size. For this two-step
procedure, we propose both the full-sample and the multiway cross-fitting
estimation approaches. A functional limit theory is derived for these
estimators. To construct the uniform confidence bands, we develop a novel
resampling procedure, called the multiway cluster-robust sieve score bootstrap,
that extends the sieve score bootstrap (Chen and Christensen, 2018) to the
novel setting with multiway clustering. Extensive numerical simulations
showcase that our methods achieve desirable finite-sample behaviors. We apply
the proposed methods to analyze the causal relationship between mistrust levels
in Africa and the historical slave trade. Our analysis rejects the null
hypothesis of uniformly zero effects and reveals heterogeneous treatment
effects, with significant impacts at higher levels of trade volumes.",http://arxiv.org/pdf/2409.06654v1,,False
DemoStart: Demonstration-led auto-curriculum applied to sim-to-real with multi-fingered robots,10/09/2024,"Maria Bauza, Jose Enrique Chen, Valentin Dalibard, Nimrod Gileadi, Roland Hafner, Murilo F. Martins, Joss Moore, Rugile Pevceviciute, Antoine Laurens, Dushyant Rao, Martina Zambelli, Martin Riedmiller, Jon Scholz, Konstantinos Bousmalis, Francesco Nori, Nicolas Heess","We present DemoStart, a novel auto-curriculum reinforcement learning method
capable of learning complex manipulation behaviors on an arm equipped with a
three-fingered robotic hand, from only a sparse reward and a handful of
demonstrations in simulation. Learning from simulation drastically reduces the
development cycle of behavior generation, and domain randomization techniques
are leveraged to achieve successful zero-shot sim-to-real transfer. Transferred
policies are learned directly from raw pixels from multiple cameras and robot
proprioception. Our approach outperforms policies learned from demonstrations
on the real robot and requires 100 times fewer demonstrations, collected in
simulation. More details and videos in https://sites.google.com/view/demostart.",http://arxiv.org/pdf/2409.06613v1,,False
Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy,10/09/2024,"Hambisa Keno, Nicholas J. Pioch, Christopher Guagliano, Timothy H. Chung","Application of Unmanned Aerial Vehicles (UAVs) in search and rescue,
emergency management, and law enforcement has gained traction with the advent
of low-cost platforms and sensor payloads. The emergence of hybrid neural and
symbolic AI approaches for complex reasoning is expected to further push the
boundaries of these applications with decreasing levels of human intervention.
However, current UAV simulation environments lack semantic context suited to
this hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission
Environment for RapId Training and Testing) provides a simulation-based
autonomy software framework that supports the training, testing and assurance
of neuro-symbolic algorithms for autonomous maneuver and perception reasoning.
HAMERITT includes scenario generation capabilities that offer mission-relevant
contextual symbolic information in addition to raw sensor data. Scenarios
include symbolic descriptions for entities of interest and their relations to
scene elements, as well as spatial-temporal constraints in the form of
time-bounded areas of interest with prior probabilities and restricted zones
within those areas. HAMERITT also features support for training distinct
algorithm threads for maneuver vs. perception within an end-to-end mission run.
Future work includes improving scenario realism and scaling symbolic context
generation through automated workflow.",http://arxiv.org/pdf/2409.06608v1,,False
Limit Order Book Simulation and Trade Evaluation with $K$-Nearest-Neighbor Resampling,10/09/2024,"Michael Giegrich, Roel Oomen, Christoph Reisinger","In this paper, we show how $K$-nearest neighbor ($K$-NN) resampling, an
off-policy evaluation method proposed in \cite{giegrich2023k}, can be applied
to simulate limit order book (LOB) markets and how it can be used to evaluate
and calibrate trading strategies. Using historical LOB data, we demonstrate
that our simulation method is capable of recreating realistic LOB dynamics and
that synthetic trading within the simulation leads to a market impact in line
with the corresponding literature. Compared to other statistical LOB simulation
methods, our algorithm has theoretical convergence guarantees under general
conditions, does not require optimization, is easy to implement and
computationally efficient. Furthermore, we show that in a benchmark comparison
our method outperforms a deep learning-based algorithm for several key
statistics. In the context of a LOB with pro-rata type matching, we demonstrate
how our algorithm can calibrate the size of limit orders for a liquidation
strategy. Finally, we describe how $K$-NN resampling can be modified for
choices of higher dimensional state spaces.",http://arxiv.org/pdf/2409.06514v1,,False
Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles,10/09/2024,"Qiujing Lu, Xuanhan Wang, Yiwei Jiang, Guangming Zhao, Mingyue Ma, Shuo Feng","The generation of corner cases has become increasingly crucial for
efficiently testing autonomous vehicles prior to road deployment. However,
existing methods struggle to accommodate diverse testing requirements and often
lack the ability to generalize to unseen situations, thereby reducing the
convenience and usability of the generated scenarios. A method that facilitates
easily controllable scenario generation for efficient autonomous vehicles (AV)
testing with realistic and challenging situations is greatly needed. To address
this, we proposed OmniTester: a multimodal Large Language Model (LLM) based
framework that fully leverages the extensive world knowledge and reasoning
capabilities of LLMs. OmniTester is designed to generate realistic and diverse
scenarios within a simulation environment, offering a robust solution for
testing and evaluating AVs. In addition to prompt engineering, we employ tools
from Simulation of Urban Mobility to simplify the complexity of codes generated
by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a
self-improvement mechanism to enhance the LLM's understanding of scenarios,
thereby increasing its ability to produce more realistic scenes. In the
experiments, we demonstrated the controllability and realism of our approaches
in generating three types of challenging and complex scenarios. Additionally,
we showcased its effectiveness in reconstructing new scenarios described in
crash report, driven by the generalization capability of LLMs.",http://arxiv.org/pdf/2409.06450v1,,False
Learning Generative Interactive Environments By Trained Agent Exploration,10/09/2024,"Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool","World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .",http://arxiv.org/pdf/2409.06445v1,,False
GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning,10/09/2024,"Kento Kawaharazuka, Kei Okada, Masayuki Inaba","Humans can autonomously learn the relationship between sensation and motion
in their own bodies, estimate and control their own body states, and move while
continuously adapting to the current environment. On the other hand, current
robots control their bodies by learning the network structure described by
humans from their experiences, making certain assumptions on the relationship
between sensors and actuators. In addition, the network model does not adapt to
changes in the robot's body, the tools that are grasped, or the environment,
and there is no unified theory, not only for control but also for state
estimation, anomaly detection, simulation, and so on. In this study, we propose
a Generalized Multisensory Correlational Model (GeMuCo), in which the robot
itself acquires a body schema describing the correlation between sensors and
actuators from its own experience, including model structures such as network
input/output. The robot adapts to the current environment by updating this body
schema model online, estimates and controls its body state, and even performs
anomaly detection and simulation. We demonstrate the effectiveness of this
method by applying it to tool-use considering changes in grasping state for an
axis-driven robot, to joint-muscle mapping learning for a musculoskeletal
robot, and to full-body tool manipulation for a low-rigidity plastic-made
humanoid.",http://arxiv.org/pdf/2409.06427v1,,False
An End-to-End Approach for Chord-Conditioned Song Generation,10/09/2024,"Shuochen Gao, Shun Lei, Fan Zhuo, Hangyu Liu, Feng Liu, Boshi Tang, Qiaochu Huang, Shiyin Kang, Zhiyong Wu","The Song Generation task aims to synthesize music composed of vocals and
accompaniment from given lyrics. While the existing method, Jukebox, has
explored this task, its constrained control over the generations often leads to
deficiency in music performance. To mitigate the issue, we introduce an
important concept from music composition, namely chords, to song generation
networks. Chords form the foundation of accompaniment and provide vocal melody
with associated harmony. Given the inaccuracy of automatic chord extractors, we
devise a robust cross-attention mechanism augmented with dynamic weight
sequence to integrate extracted chord information into song generations and
reduce frame-level flaws, and propose a novel model termed Chord-Conditioned
Song Generator (CSG) based on it. Experimental evidence demonstrates our
proposed method outperforms other approaches in terms of musical performance
and control precision of generated songs.",http://arxiv.org/pdf/2409.06307v1,,False
User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study,10/09/2024,"Julien Albert, Martin Balfroid, Miriam Doh, Jeremie Bogaert, Luca La Fisca, Liesbet De Vos, Bryan Renard, Vincent Stragier, Emmanuel Jean","Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.",http://arxiv.org/pdf/2409.06297v1,,False
Learning Augmentation Policies from A Model Zoo for Time Series Forecasting,10/09/2024,"Haochen Yuan, Xuelin Li, Yunbo Wang, Xiaokang Yang","Time series forecasting models typically rely on a fixed-size training set
and treat all data uniformly, which may not effectively capture the specific
patterns present in more challenging training samples. To address this issue,
we introduce AutoTSAug, a learnable data augmentation method based on
reinforcement learning. Our approach begins with an empirical analysis to
determine which parts of the training data should be augmented. Specifically,
we identify the so-called marginal samples by considering the prediction
diversity across a set of pretrained forecasting models. Next, we propose using
variational masked autoencoders as the augmentation model and applying the
REINFORCE algorithm to transform the marginal samples into new data. The goal
of this generative model is not only to mimic the distribution of real data but
also to reduce the variance of prediction errors across the model zoo. By
augmenting the marginal samples with a learnable policy, AutoTSAug
substantially improves forecasting performance, advancing the prior art in this
field with minimal additional computational cost.",http://arxiv.org/pdf/2409.06282v1,,False
Recurrent Neural Networks for Still Images,10/09/2024,"Dmitri, Lvov, Yair Smadar, Ran Bezen","In this paper, we explore the application of Recurrent Neural Network (RNN)
for still images. Typically, Convolutional Neural Networks (CNNs) are the
prevalent method applied for this type of data, and more recently, transformers
have gained popularity, although they often require large models. Unlike these
methods, RNNs are generally associated with processing sequences over time
rather than single images. We argue that RNNs can effectively handle still
images by interpreting the pixels as a sequence. This approach could be
particularly advantageous for compact models designed for embedded systems,
where resources are limited. Additionally, we introduce a novel RNN design
tailored for two-dimensional inputs, such as images, and a custom version of
BiDirectional RNN (BiRNN) that is more memory-efficient than traditional
implementations. In our research, we have tested these layers in Convolutional
Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers,
with RNN layers at or close to the end. Experiments on the COCO and CIFAR100
datasets show better results, particularly for small networks.",http://arxiv.org/pdf/2409.06235v1,,False
VE: Modeling Multivariate Time Series Correlation with Variate Embedding,10/09/2024,"Shangjiong Wang, Zhihong Man, Zhengwei Cao, Jinchuan Zheng, Zhikang Ge","Multivariate time series forecasting relies on accurately capturing the
correlations among variates. Current channel-independent (CI) models and models
with a CI final projection layer are unable to capture these dependencies. In
this paper, we present the variate embedding (VE) pipeline, which learns a
unique and consistent embedding for each variate and combines it with Mixture
of Experts (MoE) and Low-Rank Adaptation (LoRA) techniques to enhance
forecasting performance while controlling parameter size. The VE pipeline can
be integrated into any model with a CI final projection layer to improve
multivariate forecasting. The learned VE effectively groups variates with
similar temporal patterns and separates those with low correlations. The
effectiveness of the VE pipeline is demonstrated through extensive experiments
on four widely-used datasets. The code is available at:
\url{https://github.com/swang-song/VE}.",http://arxiv.org/pdf/2409.06169v1,,False
Variational Search Distributions,10/09/2024,"Daniel M. Steinberg, Rafael Oliveira, Cheng Soon Ong, Edwin V. Bonilla","We develop variational search distributions (VSD), a method for finding
discrete, combinatorial designs of a rare desired class in a batch sequential
manner with a fixed experimental budget. We formalize the requirements and
desiderata for this problem and formulate a solution via variational inference
that fulfill these. In particular, VSD uses off-the-shelf gradient based
optimization routines, and can take advantage of scalable predictive models. We
show that VSD can outperform existing baseline methods on a set of real
sequence-design problems in various biological systems.",http://arxiv.org/pdf/2409.06142v1,,False
Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science,10/09/2024,"E. Wes Bethel, Vianna Cramer, Alexander del Rio, Lothar Narins, Chris Pestano, Satvik Verma, Erick Arias, Nicola Bertelli, Talita Perciano, Syun'ichi Shiraiwa, Álvaro Sánchez Villar, Greg Wallace, John C. Wright","This work presents a detailed case study on using Generative AI (GenAI) to
develop AI surrogates for simulation models in fusion energy research. The
scope includes the methodology, implementation, and results of using GenAI to
assist in model development and optimization, comparing these results with
previous manually developed models.",http://arxiv.org/pdf/2409.06122v1,,False
