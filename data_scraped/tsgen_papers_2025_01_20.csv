Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems,17/01/2025,"Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang","Personalized learning represents a promising educational strategy within
intelligent educational systems, aiming to enhance learners' practice
efficiency. However, the discrepancy between offline metrics and online
performance significantly impedes their progress. To address this challenge, we
introduce Agent4Edu, a novel personalized learning simulator leveraging recent
advancements in human intelligence through large language models (LLMs).
Agent4Edu features LLM-powered generative agents equipped with learner profile,
memory, and action modules tailored to personalized learning algorithms. The
learner profiles are initialized using real-world response data, capturing
practice styles and cognitive factors. Inspired by human psychology theory, the
memory module records practice facts and high-level summaries, integrating
reflection mechanisms. The action module supports various behaviors, including
exercise understanding, analysis, and response generation. Each agent can
interact with personalized learning algorithms, such as computerized adaptive
testing, enabling a multifaceted evaluation and enhancement of customized
services. Through a comprehensive assessment, we explore the strengths and
weaknesses of Agent4Edu, emphasizing the consistency and discrepancies in
responses between agents and human learners. The code, data, and appendix are
publicly available at https://github.com/bigdata-ustc/Agent4Edu.",http://arxiv.org/pdf/2501.10332v1,,False
"Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models",17/01/2025,"Pit Neitemeier, Björn Deiseroth, Constantin Eichenberg, Lukas Balles","Tokenization is a fundamental step in natural language processing, breaking
text into units that computational models can process. While learned subword
tokenizers have become the de-facto standard, they present challenges such as
large vocabularies, limited adaptability to new domains or languages, and
sensitivity to spelling errors and variations. To overcome these limitations,
we investigate a hierarchical architecture for autoregressive language
modelling that combines character-level and word-level processing. It employs a
lightweight character-level encoder to convert character sequences into word
embeddings, which are then processed by a word-level backbone model and decoded
back into characters via a compact character-level decoder. This method retains
the sequence compression benefits of word-level tokenization without relying on
a rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion
parameters, that hierarchical transformers match the downstream task
performance of subword-tokenizer-based models while exhibiting significantly
greater robustness to input perturbations. Additionally, during continued
pretraining on an out-of-domain language, our model trains almost twice as
fast, achieves superior performance on the target language, and retains more of
its previously learned knowledge. Hierarchical transformers pave the way for
NLP systems that are more robust, flexible, and generalizable across languages
and domains.",http://arxiv.org/pdf/2501.10322v1,,False
Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling,17/01/2025,"Bruno Salezze Vieira, Eduardo Machado Silva, Antonio Augusto Chaves","Efficient surgery room scheduling is essential for hospital efficiency,
patient satisfaction, and resource utilization. This study addresses this
challenge by introducing a novel concept of Random-Key Optimizer (RKO),
rigorously tested on literature and new, real-world inspired instances. Our
combinatorial optimization problem incorporates multi-room scheduling,
equipment scheduling, and complex availability constraints for rooms, patients,
and surgeons, facilitating rescheduling and enhancing operational flexibility.
The RKO approach represents solutions as points in a continuous space, which
are then mapped in the problem solution space via a deterministic function
known as a decoder. The core idea is to operate metaheuristics and heuristics
in the random-key space, unaware of the original solution space. We design the
Biased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and
Iterated Local Search for use within an RKO framework, employing a single
decoder function. The proposed metaheuristics are complemented by lower-bound
formulations, providing optimal gaps for evaluating the effectiveness of the
heuristic results. Our results demonstrate significant lower and upper bounds
improvements for the literature instances, notably proving one optimal result.
Furthermore, the best-proposed metaheuristic efficiently generates schedules
for the newly introduced instances, even in highly constrained scenarios. This
research offers valuable insights and practical solutions for improving surgery
scheduling processes, offering tangible benefits to hospitals by optimising
resource allocation, reducing patient wait times, and enhancing overall
operational efficiency.",http://arxiv.org/pdf/2501.10243v1,,False
Amortized Bayesian Mixture Models,17/01/2025,"Šimon Kucharský, Paul Christian Bürkner","Finite mixtures are a broad class of models useful in scenarios where
observed data is generated by multiple distinct processes but without explicit
information about the responsible process for each data point. Estimating
Bayesian mixture models is computationally challenging due to issues such as
high-dimensional posterior inference and label switching. Furthermore,
traditional methods such as MCMC are applicable only if the likelihoods for
each mixture component are analytically tractable.
  Amortized Bayesian Inference (ABI) is a simulation-based framework for
estimating Bayesian models using generative neural networks. This allows the
fitting of models without explicit likelihoods, and provides fast inference.
ABI is therefore an attractive framework for estimating mixture models. This
paper introduces a novel extension of ABI tailored to mixture models. We
factorize the posterior into a distribution of the parameters and a
distribution of (categorical) mixture indicators, which allows us to use a
combination of generative neural networks for parameter inference, and
classification networks for mixture membership identification. The proposed
framework accommodates both independent and dependent mixture models, enabling
filtering and smoothing. We validate and demonstrate our approach through
synthetic and real-world datasets.",http://arxiv.org/pdf/2501.10229v1,,False
Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education,17/01/2025,William Hersh,"Generative AI has had a profound impact on biomedicine and health, both in
professional work and in education. Based on large language models (LLMs),
generative AI has been found to perform as well as humans in simulated
situations taking medical board exams, answering clinical questions, solving
clinical cases, applying clinical reasoning, and summarizing information.
Generative AI is also being used widely in education, performing well in
academic courses and their assessments. This review summarizes the successes of
LLMs and highlights some of their challenges in the context of education, most
notably aspects that may undermines the acquisition of knowledge and skills for
professional work. It then provides recommendations for best practices
overcoming shortcomings for LLM use in education. Although there are challenges
for use of generative AI in education, all students and faculty, in biomedicine
and health and beyond, must have understanding and be competent in its use.",http://arxiv.org/pdf/2501.10186v1,,False
LLM Reasoner and Automated Planner: A new NPC approach,17/01/2025,"Israel Puerta-Merino, Jordi Sabater-Mir","In domains requiring intelligent agents to emulate plausible human-like
behaviour, such as formative simulations, traditional techniques like behaviour
trees encounter significant challenges. Large Language Models (LLMs), despite
not always yielding optimal solutions, usually offer plausible and human-like
responses to a given problem. In this paper, we exploit this capability and
propose a novel architecture that integrates an LLM for decision-making with a
classical automated planner that can generate sound plans for that decision.
The combination aims to equip an agent with the ability to make decisions in
various situations, even if they were not anticipated during the design phase.",http://arxiv.org/pdf/2501.10106v1,10.3233/FAIA240443,False
Universal Actions for Enhanced Embodied Foundation Models,17/01/2025,"Jinliang Zheng, Jianxiong Li, Dongxiu Liu, Yinan Zheng, Zhihao Wang, Zhonghong Ou, Yu Liu, Jingjing Liu, Ya-Qin Zhang, Xianyuan Zhan","Training on diverse, internet-scale data is a key factor in the success of
recent large foundation models. Yet, using the same recipe for building
embodied agents has faced noticeable difficulties. Despite the availability of
many crowd-sourced embodied datasets, their action spaces often exhibit
significant heterogeneity due to distinct physical embodiment and control
interfaces for different robots, causing substantial challenges in developing
embodied foundation models using cross-domain data. In this paper, we introduce
UniAct, a new embodied foundation modeling framework operating in a tokenized
Universal Action Space. Our learned universal actions capture the generic
atomic behaviors across diverse robots by exploiting their shared structural
features, and enable enhanced cross-domain data utilization and
cross-embodiment generalizations by eliminating the notorious heterogeneity.
The universal actions can be efficiently translated back to heterogeneous
actionable commands by simply adding embodiment-specific details, from which
fast adaptation to new robots becomes simple and straightforward. Our 0.5B
instantiation of UniAct outperforms 14X larger SOTA embodied foundation models
in extensive evaluations on various real-world and simulation robots,
showcasing exceptional cross-embodiment control and adaptation capability,
highlighting the crucial benefit of adopting universal actions. Project page:
https://github.com/2toinf/UniAct",http://arxiv.org/pdf/2501.10105v1,,False
Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics,17/01/2025,"Chenhao Li, Andreas Krause, Marco Hutter","Learning robust and generalizable world models is crucial for enabling
efficient and scalable robotic control in real-world environments. In this
work, we introduce a novel framework for learning world models that accurately
capture complex, partially observable, and stochastic dynamics. The proposed
method employs a dual-autoregressive mechanism and self-supervised training to
achieve reliable long-horizon predictions without relying on domain-specific
inductive biases, ensuring adaptability across diverse robotic tasks. We
further propose a policy optimization framework that leverages world models for
efficient training in imagined environments and seamless deployment in
real-world systems. Through extensive experiments, our approach consistently
outperforms state-of-the-art methods, demonstrating superior autoregressive
prediction accuracy, robustness to noise, and generalization across
manipulation and locomotion tasks. Notably, policies trained with our method
are successfully deployed on ANYmal D hardware in a zero-shot transfer,
achieving robust performance with minimal sim-to-real performance loss. This
work advances model-based reinforcement learning by addressing the challenges
of long-horizon prediction, error accumulation, and sim-to-real transfer. By
providing a scalable and robust framework, the introduced methods pave the way
for adaptive and efficient robotic systems in real-world applications.",http://arxiv.org/pdf/2501.10100v1,,False
A recursive Bayesian neural network for constitutive modeling of sands under monotonic loading,17/01/2025,"Toiba Noor, Soban Nasir Lone, G. V. Ramana, Rajdip Nayek","In geotechnical engineering, constitutive models play a crucial role in
describing soil behavior under varying loading conditions. Data-driven deep
learning (DL) models offer a promising alternative for developing predictive
constitutive models. When prediction is the primary focus, quantifying the
predictive uncertainty of a trained DL model and communicating this uncertainty
to end users is crucial for informed decision-making.
  This study proposes a recursive Bayesian neural network (rBNN) framework,
which builds upon recursive feedforward neural networks (rFFNNs) by introducing
generalized Bayesian inference for uncertainty quantification. A significant
contribution of this work is the incorporation of a sliding window approach in
rFFNNs, allowing the models to effectively capture temporal dependencies across
load steps. The rBNN extends this framework by treating model parameters as
random variables, with their posterior distributions inferred using generalized
variational inference.
  The proposed framework is validated on two datasets: (i) a numerically
simulated consolidated drained (CD) triaxial dataset employing a hardening soil
model and (ii) an experimental dataset comprising 28 CD triaxial tests on
Baskarp sand. Comparative analyses with LSTM, Bi-LSTM, and GRU models
demonstrate that the deterministic rFFNN achieves superior predictive accuracy,
attributed to its transparent structure and sliding window design. While the
rBNN marginally trails in accuracy for the experimental case, it provides
robust confidence intervals, addressing data sparsity and measurement noise in
experimental conditions. The study underscores the trade-offs between
deterministic and probabilistic approaches and the potential of rBNNs for
uncertainty-aware constitutive modeling.",http://arxiv.org/pdf/2501.10088v1,,False
Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks,17/01/2025,"Junlan Chen, Yiqun Li, Chenyu Ling, Ziyuan Pu, Xiucheng Guo","Data imbalance is a common issue in analyzing and predicting sudden traffic
events. Secondary crashes constitute only a small proportion of all crashes.
These secondary crashes, triggered by primary crashes, significantly exacerbate
traffic congestion and increase the severity of incidents. However, the severe
imbalance of secondary crash data poses significant challenges for prediction
models, affecting their generalization ability and prediction accuracy.
Existing methods fail to fully address the complexity of traffic crash data,
particularly the coexistence of dynamic and static features, and often struggle
to effectively handle data samples of varying lengths. Furthermore, most
current studies predict the occurrence probability and spatiotemporal
distribution of secondary crashes separately, lacking an integrated solution.
To address these challenges, this study proposes a hybrid model named
VarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data
generation and jointly predicting the occurrence and spatiotemporal
distribution of secondary crashes. The VarFusiGAN-Transformer model employs
Long Short-Term Memory (LSTM) networks to enhance the generation of
multivariate long-time series data, incorporating a static data generator and
an auxiliary discriminator to model the joint distribution of dynamic and
static features. In addition, the model's prediction module achieves
simultaneous prediction of both the occurrence and spatiotemporal distribution
of secondary crashes. Compared to existing methods, the proposed model
demonstrates superior performance in generating high-fidelity data and
improving prediction accuracy.",http://arxiv.org/pdf/2501.10041v1,,False
Sparse Binary Representation Learning for Knowledge Tracing,17/01/2025,"Yahya Badran, Christine Preisach","Knowledge tracing (KT) models aim to predict students' future performance
based on their historical interactions. Most existing KT models rely
exclusively on human-defined knowledge concepts (KCs) associated with
exercises. As a result, the effectiveness of these models is highly dependent
on the quality and completeness of the predefined KCs. Human errors in labeling
and the cost of covering all potential underlying KCs can limit model
performance.
  In this paper, we propose a KT model, Sparse Binary Representation KT
(SBRKT), that generates new KC labels, referred to as auxiliary KCs, which can
augment the predefined KCs to address the limitations of relying solely on
human-defined KCs. These are learned through a binary vector representation,
where each bit indicates the presence (one) or absence (zero) of an auxiliary
KC. The resulting discrete representation allows these auxiliary KCs to be
utilized in training any KT model that incorporates KCs. Unlike pre-trained
dense embeddings, which are limited to models designed to accept such vectors,
our discrete representations are compatible with both classical models, such as
Bayesian Knowledge Tracing (BKT), and modern deep learning approaches.
  To generate this discrete representation, SBRKT employs a binarization method
that learns a sparse representation, fully trainable via stochastic gradient
descent. Additionally, SBRKT incorporates a recurrent neural network (RNN) to
capture temporal dynamics and predict future student responses by effectively
combining the auxiliary and predefined KCs. Experimental results demonstrate
that SBRKT outperforms the tested baselines on several datasets and achieves
competitive performance on others. Furthermore, incorporating the learned
auxiliary KCs consistently enhances the performance of BKT across all tested
datasets.",http://arxiv.org/pdf/2501.09893v1,,False
