Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents,01/08/2025,"Sarah Mercer, Daniel P. Martin, Phil Swatton","Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.",http://arxiv.org/pdf/2508.00742v1,,False
Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems,01/08/2025,"Liuyun Xu, Seymour M. J. Spence","Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.",http://arxiv.org/pdf/2508.00734v1,,False
Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA,01/08/2025,"Yingxu Wang, Shiqi Fan, Mengzhu Wang, Siwei Liu","Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.",http://arxiv.org/pdf/2508.00719v1,,False
NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System,01/08/2025,"Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Ajay Varghese Thomas, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya","Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.",http://arxiv.org/pdf/2508.00709v1,,False
Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies,01/08/2025,"Chakattrai Sookkongwaree, Tattep Lakmuang, Chainarong Amornbunchornvej","Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.",http://arxiv.org/pdf/2508.00658v1,,False
Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides,01/08/2025,"Marlen Neubert, Patrick Reiser, Frauke Gräter, Pascal Friederich","Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.",http://arxiv.org/pdf/2508.00578v1,,False
When Relevance Meets Novelty: Dual-Stable Periodic Optimization for Exploratory Recommendation,01/08/2025,"Hongxiang Lin, Hao Guo, Zeshun Li, Erpeng Xue, Yongqian He, Xiangyu Hou, Zhaoyu Hu, Lei Wang, Sheng Chen","Traditional recommendation systems tend to trap users in strong feedback
loops by excessively pushing content aligned with their historical preferences,
thereby limiting exploration opportunities and causing content fatigue.
Although large language models (LLMs) demonstrate potential with their diverse
content generation capabilities, existing LLM-enhanced dual-model frameworks
face two major limitations: first, they overlook long-term preferences driven
by group identity, leading to biased interest modeling; second, they suffer
from static optimization flaws, as a one-time alignment process fails to
leverage incremental user data for closed-loop optimization. To address these
challenges, we propose the Co-Evolutionary Alignment (CoEA) method. For
interest modeling bias, we introduce Dual-Stable Interest Exploration (DSIE)
module, jointly modeling long-term group identity and short-term individual
interests through parallel processing of behavioral sequences. For static
optimization limitations, we design a Periodic Collaborative Optimization (PCO)
mechanism. This mechanism regularly conducts preference verification on
incremental data using the Relevance LLM, then guides the Novelty LLM to
perform fine-tuning based on the verification results, and subsequently feeds
back the output of the incrementally fine-tuned Novelty LLM to the Relevance
LLM for re-evaluation, thereby achieving a dynamic closed-loop optimization.
Extensive online and offline experiments verify the effectiveness of the CoEA
model in exploratory recommendation.",http://arxiv.org/pdf/2508.00450v1,,False
Reducing the gap between general purpose data and aerial images in concentrated solar power plants,01/08/2025,"M. A. Pérez-Cutiño, J. Valverde, J. Capitán, J. M. Díaz-Báñez","In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.",http://arxiv.org/pdf/2508.00440v1,,False
Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation,01/08/2025,"Riddhi J. Pitliya, Ozan Catal, Toon Van de Maele, Corrado Pezzato, Tim Verbelen","We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.",http://arxiv.org/pdf/2508.00401v1,,False
EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices,01/08/2025,"Jiyu Chen, Poh Seng Lim, Shuang Peng, Daxiong Luo, JungHau Foo, Yap Deep, Timothy Lee Jun Jie, Kelvin Teh Kae Wen, Fan Yang, Danyu Feng, Hao-Yun Chen, Peng-Wen Chen, Fangyuan Li, Xiaoxin Chen, Wong Wai Mun","Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.",http://arxiv.org/pdf/2508.00370v1,,False
Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence,01/08/2025,"Danzhen Fu, Jiagao Hu, Daiguo Zhou, Fei Wang, Zepeng Wang, Wenhua Liao","Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.",http://arxiv.org/pdf/2508.00299v1,,False
Mind the Gap: The Divergence Between Human and LLM-Generated Tasks,01/08/2025,"Yi-Long Lu, Jiajun Song, Chunhui Zhang, Wei Wang","Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.",http://arxiv.org/pdf/2508.00282v1,,False
"Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study",01/08/2025,"Chuang Zhang, Geng Sun, Jiacheng Wang, Yijing Lin, Weijie Yuan, Sinem Coleri, Dusit Niyato, Tony Q. S. Quek","Low-altitude wireless networks (LAWNs) have the potential to revolutionize
communications by supporting a range of applications, including urban parcel
delivery, aerial inspections and air taxis. However, compared with traditional
wireless networks, LAWNs face unique security challenges due to low-altitude
operations, frequent mobility and reliance on unlicensed spectrum, making it
more vulnerable to some malicious attacks. In this paper, we investigate some
large artificial intelligence model (LAM)-enabled solutions for secure
communications in LAWNs. Specifically, we first explore the amplified security
risks and important limitations of traditional AI methods in LAWNs. Then, we
introduce the basic concepts of LAMs and delve into the role of LAMs in
addressing these challenges. To demonstrate the practical benefits of LAMs for
secure communications in LAWNs, we propose a novel LAM-based optimization
framework that leverages large language models (LLMs) to generate enhanced
state features on top of handcrafted representations, and to design intrinsic
rewards accordingly, thereby improving reinforcement learning performance for
secure communication tasks. Through a typical case study, simulation results
validate the effectiveness of the proposed framework. Finally, we outline
future directions for integrating LAMs into secure LAWN applications.",http://arxiv.org/pdf/2508.00256v1,,False
Jet Image Generation in High Energy Physics Using Diffusion Models,01/08/2025,"Victor D. Martinez, Vidya Manian, Sudhir Malik","This article presents, for the first time, the application of diffusion
models for generating jet images corresponding to proton-proton collision
events at the Large Hadron Collider (LHC). The kinematic variables of quark,
gluon, W-boson, Z-boson, and top quark jets from the JetNet simulation dataset
are mapped to two-dimensional image representations. Diffusion models are
trained on these images to learn the spatial distribution of jet constituents.
We compare the performance of score-based diffusion models and consistency
models in accurately generating class-conditional jet images. Unlike approaches
based on latent distributions, our method operates directly in image space. The
fidelity of the generated images is evaluated using several metrics, including
the Fr\'echet Inception Distance (FID), which demonstrates that consistency
models achieve higher fidelity and generation stability compared to score-based
diffusion models. These advancements offer significant improvements in
computational efficiency and generation accuracy, providing valuable tools for
High Energy Physics (HEP) research.",http://arxiv.org/pdf/2508.00250v1,,False
