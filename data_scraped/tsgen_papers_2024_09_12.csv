Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Riemannian Federated Learning via Averaging Gradient Stream,11/09/2024,"Zhenwei Huang, Wen Huang, Pratik Jawanpuria, Bamdev Mishra","In recent years, federated learning has garnered significant attention as an
efficient and privacy-preserving distributed learning paradigm. In the
Euclidean setting, Federated Averaging (FedAvg) and its variants are a class of
efficient algorithms for expected (empirical) risk minimization. This paper
develops and analyzes a Riemannian Federated Averaging Gradient Stream
(RFedAGS) algorithm, which is a generalization of FedAvg, to problems defined
on a Riemannian manifold. Under standard assumptions, the convergence rate of
RFedAGS with fixed step sizes is proven to be sublinear for an approximate
stationary solution. If decaying step sizes are used, the global convergence is
established. Furthermore, assuming that the objective obeys the Riemannian
Polyak-{\L}ojasiewicz property, the optimal gaps generated by RFedAGS with
fixed step size are linearly decreasing up to a tiny upper bound, meanwhile, if
decaying step sizes are used, then the gaps sublinearly vanish.
  Numerical simulations conducted on synthetic and real-world data demonstrate
the performance of the proposed RFedAGS.",http://arxiv.org/pdf/2409.07223v1,,False
A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems,11/09/2024,"Mohamed Dhouioui, Jonathan Barnoud, Rhoslyn Roebuck Williams, Harry J. Stroud, Phil Bates, David R. Glowacki","Molecular dynamics simulations are a crucial computational tool for
researchers to understand and engineer molecular structure and function in
areas such as drug discovery, protein engineering, and material design. Despite
their utility, MD simulations are expensive, owing to the high dimensionality
of molecular systems. Interactive molecular dynamics in virtual reality
(iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which
leverages high-performance computing to accelerate the researcher's ability to
solve the hyperdimensional sampling problem. By providing an immersive 3D
environment that enables visualization and manipulation of real-time molecular
motion, iMD-VR enables researchers and students to efficiently and intuitively
explore and navigate these complex, high-dimensional systems. iMD-VR platforms
offer a unique opportunity to quickly generate rich datasets that capture human
experts' spatial insight regarding molecular structure and function. This paper
explores the possibility of employing user-generated iMD-VR datasets to train
AI agents via imitation learning (IL). IL is an important technique in robotics
that enables agents to mimic complex behaviors from expert demonstrations, thus
circumventing the need for explicit programming or intricate reward design. We
review the utilization of IL for manipulation tasks in robotics and discuss how
iMD-VR recordings could be used to train IL models for solving specific
molecular 'tasks'. We then investigate how such approaches could be applied to
the data captured from iMD-VR recordings. Finally, we outline the future
research directions and potential challenges of using AI agents to augment
human expertise to efficiently navigate conformational spaces, highlighting how
this approach could provide valuable insight across domains such as materials
science, protein engineering, and computer-aided drug design.",http://arxiv.org/pdf/2409.07189v1,,False
Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering,11/09/2024,"Zehao Wang, Han Zhou, Matthew B. Blaschko, Tinne Tuytelaars, Minye Wu","Novel view synthesis of indoor scenes can be achieved by capturing a
monocular video sequence of the environment. However, redundant information
caused by artificial movements in the input video data reduces the efficiency
of scene modeling. In this work, we tackle this challenge from the perspective
of camera selection. We begin by constructing a similarity matrix that
incorporates both the spatial diversity of the cameras and the semantic
variation of the images. Based on this matrix, we use the Intra-List Diversity
(ILD) metric to assess camera redundancy, formulating the camera selection task
as an optimization problem. Then we apply a diversity-based sampling algorithm
to optimize the camera selection. We also develop a new dataset, IndoorTraj,
which includes long and complex camera movements captured by humans in virtual
indoor environments, closely mimicking real-world scenarios. Experimental
results demonstrate that our strategy outperforms other approaches under time
and memory constraints. Remarkably, our method achieves performance comparable
to models trained on the full dataset, while using only an average of 15% of
the frames and 75% of the allotted time.",http://arxiv.org/pdf/2409.07098v1,,False
TrialSynth: Generation of Synthetic Sequential Clinical Trial Data,11/09/2024,"Chufan Gao, Mandis Beigi, Afrah Shafquat, Jacob Aptekar, Jimeng Sun","Analyzing data from past clinical trials is part of the ongoing effort to
optimize the design, implementation, and execution of new clinical trials and
more efficiently bring life-saving interventions to market. While there have
been recent advances in the generation of static context synthetic clinical
trial data, due to both limited patient availability and constraints imposed by
patient privacy needs, the generation of fine-grained synthetic time-sequential
clinical trial data has been challenging. Given that patient trajectories over
an entire clinical trial are of high importance for optimizing trial design and
efforts to prevent harmful adverse events, there is a significant need for the
generation of high-fidelity time-sequence clinical trial data. Here we
introduce TrialSynth, a Variational Autoencoder (VAE) designed to address the
specific challenges of generating synthetic time-sequence clinical trial data.
Distinct from related clinical data VAE methods, the core of our method
leverages Hawkes Processes (HP), which are particularly well-suited for
modeling event-type and time gap prediction needed to capture the structure of
sequential clinical trial data. Our experiments demonstrate that TrialSynth
surpasses the performance of other comparable methods that can generate
sequential clinical trial data, in terms of both fidelity and in enabling the
generation of highly accurate event sequences across multiple real-world
sequential event datasets with small patient source populations when using
minimal external information. Notably, our empirical findings highlight that
TrialSynth not only outperforms existing clinical sequence-generating methods
but also produces data with superior utility while empirically preserving
patient privacy.",http://arxiv.org/pdf/2409.07089v1,,False
Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records,11/09/2024,"Daeun Kyung, Junu Kim, Tackeun Kim, Edward Choi","Chest X-ray imaging (CXR) is an important diagnostic tool used in hospitals
to assess patient conditions and monitor changes over time. Generative models,
specifically diffusion-based models, have shown promise in generating realistic
synthetic X-rays. However, these models mainly focus on conditional generation
using single-time-point data, i.e., typically CXRs taken at a specific time
with their corresponding reports, limiting their clinical utility, particularly
for capturing temporal changes. To address this limitation, we propose a novel
framework, EHRXDiff, which predicts future CXR images by integrating previous
CXRs with subsequent medical events, e.g., prescriptions, lab measures, etc.
Our framework dynamically tracks and predicts disease progression based on a
latent diffusion model, conditioned on the previous CXR image and a history of
medical events. We comprehensively evaluate the performance of our framework
across three key aspects, including clinical consistency, demographic
consistency, and visual realism. We demonstrate that our framework generates
high-quality, realistic future images that capture potential temporal changes,
suggesting its potential for further development as a clinical simulation tool.
This could offer valuable insights for patient monitoring and treatment
planning in the medical field.",http://arxiv.org/pdf/2409.07012v1,,False
Large Language Models and the Extended Church-Turing Thesis,11/09/2024,"Jiří Wiedermann, Jan van Leeuwen","The Extended Church-Turing Thesis (ECTT) posits that all effective
information processing, including unbounded and non-uniform interactive
computations, can be described in terms of interactive Turing machines with
advice. Does this assertion also apply to the abilities of contemporary large
language models (LLMs)? From a broader perspective, this question calls for an
investigation of the computational power of LLMs by the classical means of
computability and computational complexity theory, especially the theory of
automata. Along these lines, we establish a number of fundamental results.
Firstly, we argue that any fixed (non-adaptive) LLM is computationally
equivalent to a, possibly very large, deterministic finite-state transducer.
This characterizes the base level of LLMs. We extend this to a key result
concerning the simulation of space-bounded Turing machines by LLMs. Secondly,
we show that lineages of evolving LLMs are computationally equivalent to
interactive Turing machines with advice. The latter finding confirms the
validity of the ECTT for lineages of LLMs. From a computability viewpoint, it
also suggests that lineages of LLMs possess super-Turing computational power.
Consequently, in our computational model knowledge generation is in general a
non-algorithmic process realized by lineages of LLMs. Finally, we discuss the
merits of our findings in the broader context of several related disciplines
and philosophies.",http://arxiv.org/pdf/2409.06978v1,10.4204/EPTCS.407.14,False
Representation Tuning,11/09/2024,Christopher M. Ackerman,"Activation engineering is becoming increasingly popular as a means of online
control of large language models (LLMs). In this work, I extend the idea of
active steering with vectors that represent a behavioral direction of interest
to tuning those vectors directly into the model, obviating the need for online
control. First, I identify activation vectors related to honesty in an
open-source LLM (Llama- 2-13b-chat). Next, I demonstrate that model output can
be made more or less honest by adding positive or negative multiples of these
vectors to residual stream activations during generation. Then, I show that a
similar effect can be achieved by fine-tuning the vectors directly into the
model, by use of a dual loss function based on the cosine similarity of
residual stream activations to the vectors combined with a standard token-based
loss (""representation tuning""). Finally, I compare the generations in response
to honesty-probing prompts from the resulting models to those from models
fine-tuned with a token-based loss alone, and to those from the untuned model
subjected to online steering. Overall, fine-tuning the vectors into the models
using the cosine similarity plus token loss showed a stronger effect than
online steering, and generalized better than using the standard loss,
suggesting the potential utility of this approach as a safety measure. Code and
data are available at https://github.com/cma1114/representation_tuning; tuned
models are available at https://huggingface.co/collections/cackerman/
representation-tuning-66da1e5ab41cd1b824687d9f.",http://arxiv.org/pdf/2409.06927v1,,False
