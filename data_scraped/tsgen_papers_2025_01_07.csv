Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Learning DAGs and Root Causes from Time-Series Data,06/01/2025,"Panagiotis Misiakos, Markus Püschel","We introduce DAG-TFRC, a novel method for learning directed acyclic graphs
(DAGs) from time series with few root causes. By this, we mean that the data
are generated by a small number of events at certain, unknown nodes and time
points under a structural vector autoregression model. For such data, we (i)
learn the DAGs representing both the instantaneous and time-lagged dependencies
between nodes, and (ii) discover the location and time of the root causes. For
synthetic data with few root causes, DAG-TFRC shows superior performance in
accuracy and runtime over prior work, scaling up to thousands of nodes.
Experiments on simulated and real-world financial data demonstrate the
viability of our sparse root cause assumption. On S&P 500 data, DAG-TFRC
successfully clusters stocks by sectors and discovers major stock movements as
root causes.",http://arxiv.org/pdf/2501.03130v1,,False
Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation,06/01/2025,"Guy Yariv, Yuval Kirstain, Amit Zohar, Shelly Sheynin, Yaniv Taigman, Yossi Adi, Sagie Benaim, Adam Polyak","We consider the task of Image-to-Video (I2V) generation, which involves
transforming static images into realistic video sequences based on a textual
description. While recent advancements produce photorealistic outputs, they
frequently struggle to create videos with accurate and consistent object
motion, especially in multi-object scenarios. To address these limitations, we
propose a two-stage compositional framework that decomposes I2V generation
into: (i) An explicit intermediate representation generation stage, followed by
(ii) A video generation stage that is conditioned on this representation. Our
key innovation is the introduction of a mask-based motion trajectory as an
intermediate representation, that captures both semantic object information and
motion, enabling an expressive but compact representation of motion and
semantics. To incorporate the learned representation in the second stage, we
utilize object-level attention objectives. Specifically, we consider a spatial,
per-object, masked-cross attention objective, integrating object-specific
prompts into corresponding latent space regions and a masked spatio-temporal
self-attention objective, ensuring frame-to-frame consistency for each object.
We evaluate our method on challenging benchmarks with multi-object and
high-motion scenarios and empirically demonstrate that the proposed method
achieves state-of-the-art results in temporal coherence, motion realism, and
text-prompt faithfulness. Additionally, we introduce \benchmark, a new
challenging benchmark for single-object and multi-object I2V generation, and
demonstrate our method's superiority on this benchmark. Project page is
available at https://guyyariv.github.io/TTM/.",http://arxiv.org/pdf/2501.03059v1,,False
Human Gaze Boosts Object-Centered Representation Learning,06/01/2025,"Timothy Schaumlöffel, Arthur Aubret, Gemma Roig, Jochen Triesch","Recent self-supervised learning (SSL) models trained on human-like egocentric
visual inputs substantially underperform on image recognition tasks compared to
humans. These models train on raw, uniform visual inputs collected from
head-mounted cameras. This is different from humans, as the anatomical
structure of the retina and visual cortex relatively amplifies the central
visual information, i.e. around humans' gaze location. This selective
amplification in humans likely aids in forming object-centered visual
representations. Here, we investigate whether focusing on central visual
information boosts egocentric visual object learning. We simulate 5-months of
egocentric visual experience using the large-scale Ego4D dataset and generate
gaze locations with a human gaze prediction model. To account for the
importance of central vision in humans, we crop the visual area around the gaze
location. Finally, we train a time-based SSL model on these modified inputs.
Our experiments demonstrate that focusing on central vision leads to better
object-centered representations. Our analysis shows that the SSL model
leverages the temporal dynamics of the gaze movements to build stronger visual
representations. Overall, our work marks a significant step toward bio-inspired
learning of visual representations.",http://arxiv.org/pdf/2501.02966v1,,False
The Tabular Foundation Model TabPFN Outperforms Specialized Time Series Forecasting Models Based on Simple Features,06/01/2025,"Shi Bin Hoo, Samuel Müller, David Salinas, Frank Hutter","Foundation models have become popular in forecasting due to their ability to
make accurate predictions, even with minimal fine-tuning on specific datasets.
In this paper, we demonstrate how the newly released regression variant of
TabPFN, a general tabular foundation model, can be applied to time series
forecasting. We propose a straightforward approach, TabPFN-TS, which pairs
TabPFN with simple feature engineering to achieve strong forecasting
performance. Despite its simplicity and with only 11M parameters, TabPFN-TS
outperforms Chronos-Mini, a model of similar size, and matches or even slightly
outperforms Chronos-Large, which has 65-fold more parameters. A key strength of
our method lies in its reliance solely on artificial data during pre-training,
avoiding the need for large training datasets and eliminating the risk of
benchmark contamination.",http://arxiv.org/pdf/2501.02945v1,,False
Sim-to-Real Transfer for Mobile Robots with Reinforcement Learning: from NVIDIA Isaac Sim to Gazebo and Real ROS 2 Robots,06/01/2025,"Sahar Salimpour, Jorge Peña-Queralta, Diego Paez-Granados, Jukka Heikkonen, Tomi Westerlund","Unprecedented agility and dexterous manipulation have been demonstrated with
controllers based on deep reinforcement learning (RL), with a significant
impact on legged and humanoid robots. Modern tooling and simulation platforms,
such as NVIDIA Isaac Sim, have been enabling such advances. This article
focuses on demonstrating the applications of Isaac in local planning and
obstacle avoidance as one of the most fundamental ways in which a mobile robot
interacts with its environments. Although there is extensive research on
proprioception-based RL policies, the article highlights less standardized and
reproducible approaches to exteroception. At the same time, the article aims to
provide a base framework for end-to-end local navigation policies and how a
custom robot can be trained in such simulation environment. We benchmark
end-to-end policies with the state-of-the-art Nav2, navigation stack in Robot
Operating System (ROS). We also cover the sim-to-real transfer process by
demonstrating zero-shot transferability of policies trained in the Isaac
simulator to real-world robots. This is further evidenced by the tests with
different simulated robots, which show the generalization of the learned
policy. Finally, the benchmarks demonstrate comparable performance to Nav2,
opening the door to quick deployment of state-of-the-art end-to-end local
planners for custom robot platforms, but importantly furthering the
possibilities by expanding the state and action spaces or task definitions for
more complex missions. Overall, with this article we introduce the most
important steps, and aspects to consider, in deploying RL policies for local
path planning and obstacle avoidance with Isaac Sim training, Gazebo testing,
and ROS 2 for real-time inference in real robots. The code is available at
https://github.com/sahars93/RL-Navigation.",http://arxiv.org/pdf/2501.02902v1,,False
Samba-asr state-of-the-art speech recognition leveraging structured state-space models,06/01/2025,"Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi","We propose Samba ASR, the first state-of-the-art Automatic Speech Recognition
(ASR) model leveraging the novel Mamba architecture as both encoder and
decoder, built on the foundation of state-space models (SSMs). Unlike
transformer-based ASR models, which rely on self-attention mechanisms to
capture dependencies, Samba ASR effectively models both local and global
temporal dependencies using efficient state-space dynamics, achieving
remarkable performance gains. By addressing the limitations of transformers,
such as quadratic scaling with input length and difficulty in handling
long-range dependencies, Samba ASR achieves superior accuracy and efficiency.
  Experimental results demonstrate that Samba ASR surpasses existing
open-source transformer-based ASR models across various standard benchmarks,
establishing it as the new state of the art in ASR. Extensive evaluations on
benchmark datasets show significant improvements in Word Error Rate (WER), with
competitive performance even in low-resource scenarios. Furthermore, the
computational efficiency and parameter optimization of the Mamba architecture
make Samba ASR a scalable and robust solution for diverse ASR tasks.
  Our contributions include:
  A new Samba ASR architecture demonstrating the superiority of SSMs over
transformer-based models for speech sequence processing. A comprehensive
evaluation on public benchmarks showcasing state-of-the-art performance. An
analysis of computational efficiency, robustness to noise, and sequence
generalization. This work highlights the viability of Mamba SSMs as a
transformer-free alternative for efficient and accurate ASR. By leveraging
state-space modeling advancements, Samba ASR sets a new benchmark for ASR
performance and future research.",http://arxiv.org/pdf/2501.02832v1,,False
A Stable Measure for Conditional Periodicity of Time Series using Persistent Homology,06/01/2025,"Bala Krishnamoorthy, Elizabeth P. Thompson","Given a pair of time series, we study how the periodicity of one influences
the periodicity of the other. There are several known methods to measure the
similarity between a pair of time series, such as cross-correlation, coherence,
cross-recurrence, and dynamic time warping. But we have yet to find any
measures with theoretical stability results.
  Persistence homology has been utilized to construct a scoring function with
theoretical guarantees of stability that quantifies the periodicity of a single
univariate time series f1, denoted score(f1). Building on this concept, we
propose a conditional periodicity score that quantifies the periodicity of one
univariate time series f1 given another f2, denoted score(f1|f2), and derive
theoretical stability results for the same. With the use of dimension reduction
in mind, we prove a new stability result for score(f1|f2) under principal
component analysis (PCA) when we use the projections of the time series
embeddings onto their respective first K principal components. We show that the
change in our score is bounded by a function of the eigenvalues corresponding
to the remaining (unused) N-K principal components and hence is small when the
first K principal components capture most of the variation in the time series
embeddings. Finally we derive a lower bound on the minimum embedding dimension
to use in our pipeline which guarantees that any two such embeddings give
scores that are within a given epsilon of each other.
  We present a procedure for computing conditional periodicity scores and
implement it on several pairs of synthetic signals. We experimentally compare
our similarity measure to the most-similar statistical measure of
cross-recurrence, and show the increased accuracy and stability of our score
when predicting and measuring whether or not the periodicities of two time
series are similar.",http://arxiv.org/pdf/2501.02817v1,,False
InpDiffusion: Image Inpainting Localization via Conditional Diffusion Models,06/01/2025,"Kai Wang, Shaozhang Niu, Qixian Hao, Jiwei Zhang","As artificial intelligence advances rapidly, particularly with the advent of
GANs and diffusion models, the accuracy of Image Inpainting Localization (IIL)
has become increasingly challenging. Current IIL methods face two main
challenges: a tendency towards overconfidence, leading to incorrect
predictions; and difficulty in detecting subtle tampering boundaries in
inpainted images. In response, we propose a new paradigm that treats IIL as a
conditional mask generation task utilizing diffusion models. Our method,
InpDiffusion, utilizes the denoising process enhanced by the integration of
image semantic conditions to progressively refine predictions. During
denoising, we employ edge conditions and introduce a novel edge supervision
strategy to enhance the model's perception of edge details in inpainted
objects. Balancing the diffusion model's stochastic sampling with edge
supervision of tampered image regions mitigates the risk of incorrect
predictions from overconfidence and prevents the loss of subtle boundaries that
can result from overly stochastic processes. Furthermore, we propose an
innovative Dual-stream Multi-scale Feature Extractor (DMFE) for extracting
multi-scale features, enhancing feature representation by considering both
semantic and edge conditions of the inpainted images. Extensive experiments
across challenging datasets demonstrate that the InpDiffusion significantly
outperforms existing state-of-the-art methods in IIL tasks, while also
showcasing excellent generalization capabilities and robustness.",http://arxiv.org/pdf/2501.02816v1,,False
Segmenting Text and Learning Their Rewards for Improved RLHF in Language Model,06/01/2025,"Yueqin Yin, Shentao Yang, Yujia Xie, Ziyi Yang, Yuting Sun, Hany Awadalla, Weizhu Chen, Mingyuan Zhou","Reinforcement learning from human feedback (RLHF) has been widely adopted to
align language models (LMs) with human preference. Prior RLHF works typically
take a bandit formulation, which, though intuitive, ignores the sequential
nature of LM generation and can suffer from the sparse reward issue. While
recent works propose dense token-level RLHF, treating each token as an action
may be oversubtle to proper reward assignment. In this paper, we seek to get
the best of both by training and utilizing a segment-level reward model, which
assigns a reward to each semantically complete text segment that spans over a
short sequence of tokens. For reward learning, our method allows dynamic text
segmentation and compatibility with standard sequence-preference datasets. For
effective RL-based LM training against segment reward, we generalize the
classical scalar bandit reward normalizers into location-aware normalizer
functions and interpolate the segment reward for further densification. With
these designs, our method performs competitively on three popular RLHF
benchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation
studies are conducted to further demonstrate our method.",http://arxiv.org/pdf/2501.02790v1,,False
From Dense to Sparse: Event Response for Enhanced Residential Load Forecasting,06/01/2025,"Xin Cao, Qinghua Tao, Yingjie Zhou, Lu Zhang, Le Zhang, Dongjin Song, Dapeng Oliver Wu, Ce Zhu","Residential load forecasting (RLF) is crucial for resource scheduling in
power systems. Most existing methods utilize all given load records (dense
data) to indiscriminately extract the dependencies between historical and
future time series. However, there exist important regular patterns residing in
the event-related associations among different appliances (sparse knowledge),
which have yet been ignored.In this paper, we propose an Event-Response
Knowledge Guided approach (ERKG) for RLF by incorporating the estimation of
electricity usage events for different appliances, mining event-related sparse
knowledge from the load series. With ERKG, the event-response estimation
enables portraying the electricity consumption behaviors of residents,
revealing regular variations in appliance operational states.To be specific,
ERKG consists of knowledge extraction and guidance: i) a forecasting model is
designed for the electricity usage events by estimating appliance operational
states, aiming to extract the event-related sparse knowledge; ii) a novel
knowledge-guided mechanism is established by fusing such state estimates of the
appliance events into the RLF model, which can give particular focuses on the
patterns of users' electricity consumption behaviors.Notably, ERKG can flexibly
serve as a plug-in module to boost the capability of existing forecasting
models by leveraging event response. In numerical experiments, extensive
comparisons and ablation studies have verified the effectiveness of our ERKG,
e.g., over 8% MAE can be reduced on the tested state-of-the-art forecasting
models. The source code will be available at https://github.com/ergoucao/ERKG.",http://arxiv.org/pdf/2501.02781v1,,False
CHAT: Beyond Contrastive Graph Transformer for Link Prediction in Heterogeneous Networks,06/01/2025,"Shengming Zhang, Le Zhang, Jingbo Zhou, Hui Xiong","Link prediction in heterogeneous networks is crucial for understanding the
intricacies of network structures and forecasting their future developments.
Traditional methodologies often face significant obstacles, including
over-smoothing-wherein the excessive aggregation of node features leads to the
loss of critical structural details-and a dependency on human-defined
meta-paths, which necessitate extensive domain knowledge and can be inherently
restrictive. These limitations hinder the effective prediction and analysis of
complex heterogeneous networks. In response to these challenges, we propose the
Contrastive Heterogeneous grAph Transformer (CHAT). CHAT introduces a novel
sampling-based graph transformer technique that selectively retains nodes of
interest, thereby obviating the need for predefined meta-paths. The method
employs an innovative connection-aware transformer to encode node sequences and
their interconnections with high fidelity, guided by a dual-faceted loss
function specifically designed for heterogeneous network link prediction.
Additionally, CHAT incorporates an ensemble link predictor that synthesizes
multiple samplings to achieve enhanced prediction accuracy. We conducted
comprehensive evaluations of CHAT using three distinct drug-target interaction
(DTI) datasets. The empirical results underscore CHAT's superior performance,
outperforming both general-task approaches and models specialized in DTI
prediction. These findings substantiate the efficacy of CHAT in addressing the
complex problem of link prediction in heterogeneous networks.",http://arxiv.org/pdf/2501.02760v1,,False
Improved Data Encoding for Emerging Computing Paradigms: From Stochastic to Hyperdimensional Computing,06/01/2025,"Mehran Shoushtari Moghadam, Sercan Aygun, M. Hassan Najafi","Data encoding is a fundamental step in emerging computing paradigms,
particularly in stochastic computing (SC) and hyperdimensional computing (HDC),
where it plays a crucial role in determining the overall system performance and
hardware cost efficiency. This study presents an advanced encoding strategy
that leverages a hardware-friendly class of low-discrepancy (LD) sequences,
specifically powers-of-2 bases of Van der Corput (VDC) sequences (VDC-2^n), as
sources for random number generation. Our approach significantly enhances the
accuracy and efficiency of SC and HDC systems by addressing challenges
associated with randomness. By employing LD sequences, we improve correlation
properties and reduce hardware complexity. Experimental results demonstrate
significant improvements in accuracy and energy savings for SC and HDC systems.
Our solution provides a robust framework for integrating SC and HDC in
resource-constrained environments, paving the way for efficient and scalable AI
implementations.",http://arxiv.org/pdf/2501.02715v1,,False
Transformers Simulate MLE for Sequence Generation in Bayesian Networks,05/01/2025,"Yuan Cao, Yihan He, Dennis Wu, Hong-Yu Chen, Jianqing Fan, Han Liu","Transformers have achieved significant success in various fields, notably
excelling in tasks involving sequential data like natural language processing.
Despite these achievements, the theoretical understanding of transformers'
capabilities remains limited. In this paper, we investigate the theoretical
capabilities of transformers to autoregressively generate sequences in Bayesian
networks based on in-context maximum likelihood estimation (MLE). Specifically,
we consider a setting where a context is formed by a set of independent
sequences generated according to a Bayesian network. We demonstrate that there
exists a simple transformer model that can (i) estimate the conditional
probabilities of the Bayesian network according to the context, and (ii)
autoregressively generate a new sample according to the Bayesian network with
estimated conditional probabilities. We further demonstrate in extensive
experiments that such a transformer does not only exist in theory, but can also
be effectively obtained through training. Our analysis highlights the potential
of transformers to learn complex probabilistic models and contributes to a
better understanding of large language models as a powerful class of sequence
generators.",http://arxiv.org/pdf/2501.02547v1,,False
IRIS: A Bayesian Approach for Image Reconstruction in Radio Interferometry with expressive Score-Based priors,05/01/2025,"Noé Dia, M. J. Yantovski-Barth, Alexandre Adam, Micah Bowles, Laurence Perreault-Levasseur, Yashar Hezaveh, Anna Scaife","Inferring sky surface brightness distributions from noisy interferometric
data in a principled statistical framework has been a key challenge in radio
astronomy. In this work, we introduce Imaging for Radio Interferometry with
Score-based models (IRIS). We use score-based models trained on optical images
of galaxies as an expressive prior in combination with a Gaussian likelihood in
the uv-space to infer images of protoplanetary disks from visibility data of
the DSHARP survey conducted by ALMA. We demonstrate the advantages of this
framework compared with traditional radio interferometry imaging algorithms,
showing that it produces plausible posterior samples despite the use of a
misspecified galaxy prior. Through coverage testing on simulations, we
empirically evaluate the accuracy of this approach to generate calibrated
posterior samples.",http://arxiv.org/pdf/2501.02473v1,,False
