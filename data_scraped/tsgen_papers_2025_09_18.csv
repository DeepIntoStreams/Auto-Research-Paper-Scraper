Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting,17/09/2025,"Yifan Hu, Jie Yang, Tian Zhou, Peiyuan Liu, Yujin Tang, Rong Jin, Liang Sun","Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.",http://arxiv.org/pdf/2509.14181v1,,False
Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework,17/09/2025,"Md Rezwan Jaher, Abul Mukid Mohammad Mukaddes, A. B. M. Abdul Malek","Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.",http://arxiv.org/pdf/2509.14167v1,,False
"Machines are more productive than humans until they aren't, and vice versa",17/09/2025,Riccardo Zanardelli,"With the growth of artificial skills, organizations may increasingly confront
with the problem of optimizing skill policy decisions guided by economic
principles. This paper addresses the underlying complexity of this challenge by
developing an in-silico framework based on Monte Carlo simulations grounded in
empirical realism to analyze the economic impact of human and machine skills,
individually or jointly deployed, in the execution of tasks presenting varying
levels of complexity. Our results provide quantitative support for the
established notions that automation tends to be the most economically-effective
strategy for tasks characterized by low-to-medium generalization difficulty,
while automation struggles to match the economic utility of human skills in
more complex scenarios. Critically, our simulations highlight that combining
human and machine skills can be the most effective strategy when a high level
of generalization is required, but only if genuine augmentation is achieved. In
contrast, when failing to realize this synergy, the human-machine policy is
severely penalized by the inherent costs of its dual skill structure, causing
it to destroy value and becoming the worst choice from an economic perspective.
The takeaway for decision-makers is unambiguous: simply allocating human and
machine skills to a task is insufficient, and a human-machine skill policy is
neither a silver-bullet solution nor a low-risk compromise. Rather, it is a
critical opportunity to boost competitiveness that demands a strong
organizational commitment to enabling augmentation. Also, our findings show
that improving the cost-effectiveness of machine skills over time, while
useful, does not replace the fundamental need to focus on achieving
augmentation.",http://arxiv.org/pdf/2509.14057v1,,False
Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning,17/09/2025,"Zewen Yang, Xiaobing Dai, Dongfa Zhang, Yu Li, Ziyang Meng, Bingkun Huang, Hamid Sadeghian, Sami Haddadin","Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io",http://arxiv.org/pdf/2509.14040v1,,False
Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks,17/09/2025,"Jiun-Cheng Jiang, Morris Yu-Chao Huang, Tianlong Chen, Hsi-Sheng Goan","Variational quantum circuits (VQCs) are central to quantum machine learning,
while recent progress in Kolmogorov-Arnold networks (KANs) highlights the power
of learnable activation functions. We unify these directions by introducing
quantum variational activation functions (QVAFs), realized through single-qubit
data re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We
show that DARUAN with trainable weights in data pre-processing possesses an
exponentially growing frequency spectrum with data repetitions, enabling an
exponential reduction in parameter size compared with Fourier-based activations
without loss of expressivity. Embedding DARUAN into KANs yields
quantum-inspired KANs (QKANs), which retain the interpretability of KANs while
improving their parameter efficiency, expressivity, and generalization. We
further introduce two novel techniques to enhance scalability, feasibility and
computational efficiency, such as layer extension and hybrid QKANs (HQKANs) as
drop-in replacements of multi-layer perceptrons (MLPs) for feed-forward
networks in large-scale models. We provide theoretical analysis and extensive
experiments on function regression, image classification, and autoregressive
generative language modeling, demonstrating the efficiency and scalability of
QKANs. DARUANs and QKANs offer a promising direction for advancing quantum
machine learning on both noisy intermediate-scale quantum (NISQ) hardware and
classical quantum simulators.",http://arxiv.org/pdf/2509.14026v1,,False
Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection,17/09/2025,"Zhixion Chen, Jiangzhou Wang, and Hyundong Shin, Arumugam Nallanathan","The deployment of unmanned aerial vehicles (UAVs) for reliable and
energy-efficient data collection from spatially distributed devices holds great
promise in supporting diverse Internet of Things (IoT) applications.
Nevertheless, the limited endurance and communication range of UAVs necessitate
intelligent trajectory planning. While reinforcement learning (RL) has been
extensively explored for UAV trajectory optimization, its interactive nature
entails high costs and risks in real-world environments. Offline RL mitigates
these issues but remains susceptible to unstable training and heavily rely on
expert-quality datasets. To address these challenges, we formulate a joint UAV
trajectory planning and resource allocation problem to maximize energy
efficiency of data collection. The resource allocation subproblem is first
transformed into an equivalent linear programming formulation and solved
optimally with polynomial-time complexity. Then, we propose a large language
model (LLM)-empowered critic-regularized decision transformer (DT) framework,
termed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we
incorporate critic networks to regularize the DT model training, thereby
integrating the sequence modeling capabilities of DT with critic-based value
guidance to enable learning effective policies from suboptimal datasets.
Furthermore, to mitigate the data-hungry nature of transformer models, we
employ a pre-trained LLM as the transformer backbone of the DT model and adopt
a parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid
adaptation to UAV control tasks with small-scale dataset and low computational
overhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark
online and offline RL methods, achieving up to 36.7\% higher energy efficiency
than the current state-of-the-art DT approaches.",http://arxiv.org/pdf/2509.13934v1,,False
Holdout cross-validation for large non-Gaussian covariance matrix estimation using Weingarten calculus,17/09/2025,"Lamia Lamrani, Benoît Collins, Jean-Philippe Bouchaud","Cross-validation is one of the most widely used methods for model selection
and evaluation; its efficiency for large covariance matrix estimation appears
robust in practice, but little is known about the theoretical behavior of its
error. In this paper, we derive the expected Frobenius error of the holdout
method, a particular cross-validation procedure that involves a single train
and test split, for a generic rotationally invariant multiplicative noise
model, therefore extending previous results to non-Gaussian data distributions.
Our approach involves using the Weingarten calculus and the Ledoit-P\'ech\'e
formula to derive the oracle eigenvalues in the high-dimensional limit. When
the population covariance matrix follows an inverse Wishart distribution, we
approximate the expected holdout error, first with a linear shrinkage, then
with a quadratic shrinkage to approximate the oracle eigenvalues. Under the
linear approximation, we find that the optimal train-test split ratio is
proportional to the square root of the matrix dimension. Then we compute Monte
Carlo simulations of the holdout error for different distributions of the norm
of the noise, such as the Gaussian, Student, and Laplace distributions and
observe that the quadratic approximation yields a substantial improvement,
especially around the optimal train-test split ratio. We also observe that a
higher fourth-order moment of the Euclidean norm of the noise vector sharpens
the holdout error curve near the optimal split and lowers the ideal train-test
ratio, making the choice of the train-test ratio more important when performing
the holdout method.",http://arxiv.org/pdf/2509.13923v1,,False
TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates,17/09/2025,"Afrin Dange, Sunita Sarawagi","Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.",http://arxiv.org/pdf/2509.13906v1,10.1145/3746252.3761272,False
Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator,17/09/2025,"Frederik Møller, Gabriel Fernández-Fernández, Thomas Schweigler, Paulin de Schoulepnikoff, Jörg Schmiedmayer, Gorka Muñoz-Gil","Analog quantum simulators provide access to many-body dynamics beyond the
reach of classical computation. However, extracting physical insights from
experimental data is often hindered by measurement noise, limited observables,
and incomplete knowledge of the underlying microscopic model. Here, we develop
a machine learning approach based on a variational autoencoder (VAE) to analyze
interference measurements of tunnel-coupled one-dimensional Bose gases, which
realize the sine-Gordon quantum field theory. Trained in an unsupervised
manner, the VAE learns a minimal latent representation that strongly correlates
with the equilibrium control parameter of the system. Applied to
non-equilibrium protocols, the latent space uncovers signatures of frozen-in
solitons following rapid cooling, and reveals anomalous post-quench dynamics
not captured by conventional correlation-based methods. These results
demonstrate that generative models can extract physically interpretable
variables directly from noisy and sparse experimental data, providing
complementary probes of equilibrium and non-equilibrium physics in quantum
simulators. More broadly, our work highlights how machine learning can
supplement established field-theoretical techniques, paving the way for
scalable, data-driven discovery in quantum many-body systems.",http://arxiv.org/pdf/2509.13821v1,,False
Towards a Physics Foundation Model,17/09/2025,"Florian Wiesner, Matthias Wessling, Stephen Baek","Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.",http://arxiv.org/pdf/2509.13805v1,,False
AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation,17/09/2025,"Xinxu Zhou, Jiaqi Bai, Zhenqi Sun, Fanxiang Zeng, Yue Liu","Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.",http://arxiv.org/pdf/2509.13677v1,,False
Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation,17/09/2025,"Xiaobo Yang, Xiaojin Gong","Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify ""visual words"" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.",http://arxiv.org/pdf/2509.13676v1,,False
CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction,17/09/2025,"Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao Shan, Zhixing Li, Hong-Gee Kim","The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.",http://arxiv.org/pdf/2509.13672v1,,False
Sequential Data Augmentation for Generative Recommendation,17/09/2025,"Geon Lee, Bhuvesh Kumar, Clark Mingxuan Ju, Tong Zhao, Kijung Shin, Neil Shah, Liam Collins","Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.",http://arxiv.org/pdf/2509.13648v1,,False
Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs,17/09/2025,"Md Bokhtiar Al Zami, Md Raihan Uddin, Dinh C. Nguyen","Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.",http://arxiv.org/pdf/2509.13634v1,,False
