Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation,27/09/2024,"Shaowei Liu, Zhongzheng Ren, Saurabh Gupta, Shenlong Wang","We present PhysGen, a novel image-to-video generation method that converts a
single image and an input condition (e.g., force and torque applied to an
object in the image) to produce a realistic, physically plausible, and
temporally consistent video. Our key insight is to integrate model-based
physical simulation with a data-driven video generation process, enabling
plausible image-space dynamics. At the heart of our system are three core
components: (i) an image understanding module that effectively captures the
geometry, materials, and physical parameters of the image; (ii) an image-space
dynamics simulation model that utilizes rigid-body physics and inferred
parameters to simulate realistic behaviors; and (iii) an image-based rendering
and refinement module that leverages generative video diffusion to produce
realistic video footage featuring the simulated motion. The resulting videos
are realistic in both physics and appearance and are even precisely
controllable, showcasing superior results over existing data-driven
image-to-video generation works through quantitative comparison and
comprehensive user study. PhysGen's resulting videos can be used for various
downstream applications, such as turning an image into a realistic animation or
allowing users to interact with the image and create various dynamics. Project
page: https://stevenlsw.github.io/physgen/",http://arxiv.org/pdf/2409.18964v1,,False
Unconditional stability of a recurrent neural circuit implementing divisive normalization,27/09/2024,"Shivang Rawat, David J. Heeger, Stefano Martiniani","Stability in recurrent neural models poses a significant challenge,
particularly in developing biologically plausible neurodynamical models that
can be seamlessly trained. Traditional cortical circuit models are notoriously
difficult to train due to expansive nonlinearities in the dynamical system,
leading to an optimization problem with nonlinear stability constraints that
are difficult to impose. Conversely, recurrent neural networks (RNNs) excel in
tasks involving sequential data but lack biological plausibility and
interpretability. In this work, we address these challenges by linking dynamic
divisive normalization (DN) to the stability of ORGaNICs, a biologically
plausible recurrent cortical circuit model that dynamically achieves DN and has
been shown to simulate a wide range of neurophysiological phenomena. By using
the indirect method of Lyapunov, we prove the remarkable property of
unconditional local stability for an arbitrary-dimensional ORGaNICs circuit
when the recurrent weight matrix is the identity. We thus connect ORGaNICs to a
system of coupled damped harmonic oscillators, which enables us to derive the
circuit's energy function, providing a normative principle of what the circuit,
and individual neurons, aim to accomplish. Further, for a generic recurrent
weight matrix, we prove the stability of the 2D model and demonstrate
empirically that stability holds in higher dimensions. Finally, we show that
ORGaNICs can be trained by backpropagation through time without gradient
clipping/scaling, thanks to its intrinsic stability property and adaptive time
constants, which address the problems of exploding, vanishing, and oscillating
gradients. By evaluating the model's performance on RNN benchmarks, we find
that ORGaNICs outperform alternative neurodynamical models on static image
classification tasks and perform comparably to LSTMs on sequential tasks.",http://arxiv.org/pdf/2409.18946v1,,False
AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow,27/09/2024,"Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan","Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value
0.782, p<0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.",http://arxiv.org/pdf/2409.18924v1,,False
Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks,27/09/2024,"Richard Osuala, Smriti Joshi, Apostolia Tsirikoglou, Lidia Garrucho, Walter H. L. Pinaya, Daniel M. Lang, Julia A. Schnabel, Oliver Diaz, Karim Lekadir","This paper presents a method for virtual contrast enhancement in breast MRI,
offering a promising non-invasive alternative to traditional contrast
agent-based DCE-MRI acquisition. Using a conditional generative adversarial
network, we predict DCE-MRI images, including jointly-generated sequences of
multiple corresponding DCE-MRI timepoints, from non-contrast-enhanced MRIs,
enabling tumor localization and characterization without the associated health
risks. Furthermore, we qualitatively and quantitatively evaluate the synthetic
DCE-MRI images, proposing a multi-metric Scaled Aggregate Measure (SAMe),
assessing their utility in a tumor segmentation downstream task, and conclude
with an analysis of the temporal patterns in multi-sequence DCE-MRI generation.
Our approach demonstrates promising results in generating realistic and useful
DCE-MRI sequences, highlighting the potential of virtual contrast enhancement
for improving breast cancer diagnosis and treatment, particularly for patients
where contrast agent administration is contraindicated.",http://arxiv.org/pdf/2409.18872v1,,False
Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments,27/09/2024,"Yesukhei Jagvaral, Francois Lanusse, Rachel Mandelbaum","Forthcoming cosmological imaging surveys, such as the Rubin Observatory LSST,
require large-scale simulations encompassing realistic galaxy populations for a
variety of scientific applications. Of particular concern is the phenomenon of
intrinsic alignments (IA), whereby galaxies orient themselves towards
overdensities, potentially introducing significant systematic biases in weak
gravitational lensing analyses if they are not properly modeled. Due to
computational constraints, simulating the intricate details of galaxy formation
and evolution relevant to IA across vast volumes is impractical. As an
alternative, we propose a Deep Generative Model trained on the IllustrisTNG-100
simulation to sample 3D galaxy shapes and orientations to accurately reproduce
intrinsic alignments along with correlated scalar features. We model the cosmic
web as a set of graphs, each graph representing a halo with nodes representing
the subhalos/galaxies. The architecture consists of a SO(3) $\times$
$\mathbb{R}^n$ diffusion generative model, for galaxy orientations and $n$
scalars, implemented with E(3) equivariant Graph Neural Networks that
explicitly respect the Euclidean symmetries of our Universe. The model is able
to learn and predict features such as galaxy orientations that are
statistically consistent with the reference simulation. Notably, our model
demonstrates the ability to jointly model Euclidean-valued scalars (galaxy
sizes, shapes, and colors) along with non-Euclidean valued SO(3) quantities
(galaxy orientations) that are governed by highly complex galactic physics at
non-linear scales.",http://arxiv.org/pdf/2409.18761v1,,False
Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning,27/09/2024,"Sheikh Salman Hassan, Yu Min Park, Yan Kyaw Tun, Walid Saad, Zhu Han, Choong Seon Hong","In this paper, a novel generative adversarial imitation learning
(GAIL)-powered policy learning approach is proposed for optimizing beamforming,
spectrum allocation, and remote user equipment (RUE) association in NTNs.
Traditional reinforcement learning (RL) methods for wireless network
optimization often rely on manually designed reward functions, which can
require extensive parameter tuning. To overcome these limitations, we employ
inverse RL (IRL), specifically leveraging the GAIL framework, to automatically
learn reward functions without manual design. We augment this framework with an
asynchronous federated learning approach, enabling decentralized
multi-satellite systems to collaboratively derive optimal policies. The
proposed method aims to maximize spectrum efficiency (SE) while meeting minimum
information rate requirements for RUEs. To address the non-convex, NP-hard
nature of this problem, we combine the many-to-one matching theory with a
multi-agent asynchronous federated IRL (MA-AFIRL) framework. This allows agents
to learn through asynchronous environmental interactions, improving training
efficiency and scalability. The expert policy is generated using the Whale
optimization algorithm (WOA), providing data to train the automatic reward
function within GAIL. Simulation results show that the proposed MA-AFIRL method
outperforms traditional RL approaches, achieving a $14.6\%$ improvement in
convergence and reward value. The novel GAIL-driven policy learning establishes
a novel benchmark for 6G NTN optimization.",http://arxiv.org/pdf/2409.18718v1,,False
MG-Net: Learn to Customize QAOA with Circuit Depth Awareness,27/09/2024,"Yang Qian, Xinbiao Wang, Yuxuan Du, Yong Luo, Dacheng Tao","Quantum Approximate Optimization Algorithm (QAOA) and its variants exhibit
immense potential in tackling combinatorial optimization challenges. However,
their practical realization confronts a dilemma: the requisite circuit depth
for satisfactory performance is problem-specific and often exceeds the maximum
capability of current quantum devices. To address this dilemma, here we first
analyze the convergence behavior of QAOA, uncovering the origins of this
dilemma and elucidating the intricate relationship between the employed mixer
Hamiltonian, the specific problem at hand, and the permissible maximum circuit
depth. Harnessing this understanding, we introduce the Mixer Generator Network
(MG-Net), a unified deep learning framework adept at dynamically formulating
optimal mixer Hamiltonians tailored to distinct tasks and circuit depths.
Systematic simulations, encompassing Ising models and weighted Max-Cut
instances with up to 64 qubits, substantiate our theoretical findings,
highlighting MG-Net's superior performance in terms of both approximation ratio
and efficiency.",http://arxiv.org/pdf/2409.18692v1,,False
Using Deep Autoregressive Models as Causal Inference Engines,27/09/2024,"Daniel Jiwoong Im, Kevin Zhang, Nakul Verma, Kyunghyun Cho","Existing causal inference (CI) models are limited to primarily handling
low-dimensional confounders and singleton actions. We propose an autoregressive
(AR) CI framework capable of handling complex confounders and sequential
actions common in modern applications. We accomplish this by {\em
sequencification}, transforming data from an underlying causal diagram into a
sequence of tokens. This approach not only enables training with data generated
from any DAG but also extends existing CI capabilities to accommodate
estimating several statistical quantities using a {\em single} model. We can
directly predict interventional probabilities, simplifying inference and
enhancing outcome prediction accuracy. We demonstrate that an AR model adapted
for CI is efficient and effective in various complex applications such as
navigating mazes, playing chess endgames, and evaluating the impact of certain
keywords on paper acceptance rates.",http://arxiv.org/pdf/2409.18581v1,,False
Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architecture,27/09/2024,"Nurul Ain Nabilah Mohd Isa, Siti Nuraishah Agos Jawaddi, Azlan Ismail","Integrating machine learning (ML) into customer service chatbots enhances
their ability to understand and respond to user queries, ultimately improving
service performance. However, they may appear artificial to some users and
affecting customer experience. Hence, meticulous evaluation of ML models for
each pipeline component is crucial for optimizing performance, though
differences in functionalities can lead to unfair comparisons. In this paper,
we present a tailored experimental evaluation approach for goal-oriented
customer service chatbots with pipeline architecture, focusing on three key
components: Natural Language Understanding (NLU), dialogue management (DM), and
Natural Language Generation (NLG). Our methodology emphasizes individual
assessment to determine optimal ML models. Specifically, we focus on optimizing
hyperparameters and evaluating candidate models for NLU (utilizing BERT and
LSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT).
The results show that for the NLU component, BERT excelled in intent detection
whereas LSTM was superior for slot filling. For the DM component, the DDQN
model outperformed DQN by achieving fewer turns, higher rewards, as well as
greater success rates. For NLG, the large language model GPT-2 surpassed
DialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a
benchmark for future research in developing and optimizing customer service
chatbots, offering valuable insights into model performance and optimal
hyperparameters.",http://arxiv.org/pdf/2409.18568v1,,False
MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System,27/09/2024,"Harsh Purohit, Tomoya Nishida, Kota Dohi, Takashi Endo, Yohei Kawaguchi","Insufficient recordings and the scarcity of anomalies present significant
challenges in developing and validating robust anomaly detection systems for
machine sounds. To address these limitations, we propose a novel approach for
generating diverse anomalies in machine sound using a latent diffusion-based
model that integrates an encoder-decoder framework. Our method utilizes the
Flan-T5 model to encode captions derived from audio file metadata, enabling
conditional generation through a carefully designed U-Net architecture. This
approach aids our model in generating audio signals within the EnCodec latent
space, ensuring high contextual relevance and quality. We objectively evaluated
the quality of our generated sounds using the Fr\'echet Audio Distance (FAD)
score and other metrics, demonstrating that our approach surpasses existing
models in generating reliable machine audio that closely resembles actual
abnormal conditions. The evaluation of the anomaly detection system using our
generated data revealed a strong correlation, with the area under the curve
(AUC) score differing by 4.8\% from the original, validating the effectiveness
of our generated data. These results demonstrate the potential of our approach
to enhance the evaluation and robustness of anomaly detection systems across
varied and previously unseen conditions. Audio samples can be found at
\url{https://hpworkhub.github.io/MIMII-Gen.github.io/}.",http://arxiv.org/pdf/2409.18542v1,,False
Treating Brain-inspired Memories as Priors for Diffusion Model to Forecast Multivariate Time Series,27/09/2024,"Muyao Wang, Wenchao Chen, Zhibin Duan, Bo Chen","Forecasting Multivariate Time Series (MTS) involves significant challenges in
various application domains. One immediate challenge is modeling temporal
patterns with the finite length of the input. These temporal patterns usually
involve periodic and sudden events that recur across different channels. To
better capture temporal patterns, we get inspiration from humans' memory
mechanisms and propose a channel-shared, brain-inspired memory module for MTS.
Specifically, brain-inspired memory comprises semantic and episodic memory,
where the former is used to capture general patterns, such as periodic events,
and the latter is employed to capture special patterns, such as sudden events,
respectively. Meanwhile, we design corresponding recall and update mechanisms
to better utilize these patterns. Furthermore, acknowledging the capacity of
diffusion models to leverage memory as a prior, we present a brain-inspired
memory-augmented diffusion model. This innovative model retrieves relevant
memories for different channels, utilizing them as distinct priors for MTS
predictions. This incorporation significantly enhances the accuracy and
robustness of predictions. Experimental results on eight datasets consistently
validate the superiority of our approach in capturing and leveraging diverse
recurrent temporal patterns across different channels.",http://arxiv.org/pdf/2409.18491v1,,False
HSTFL: A Heterogeneous Federated Learning Framework for Misaligned Spatiotemporal Forecasting,27/09/2024,"Shuowei Cai, Hao Liu","Spatiotemporal forecasting has emerged as an indispensable building block of
diverse smart city applications, such as intelligent transportation and smart
energy management. Recent advancements have uncovered that the performance of
spatiotemporal forecasting can be significantly improved by integrating
knowledge in geo-distributed time series data from different domains, \eg
enhancing real-estate appraisal with human mobility data; joint taxi and bike
demand predictions. While effective, existing approaches assume a centralized
data collection and exploitation environment, overlooking the privacy and
commercial interest concerns associated with data owned by different parties.
In this paper, we investigate multi-party collaborative spatiotemporal
forecasting without direct access to multi-source private data. However, this
task is challenging due to 1) cross-domain feature heterogeneity and 2)
cross-client geographical heterogeneity, where standard horizontal or vertical
federated learning is inapplicable. To this end, we propose a Heterogeneous
SpatioTemporal Federated Learning (HSTFL) framework to enable multiple clients
to collaboratively harness geo-distributed time series data from different
domains while preserving privacy. Specifically, we first devise vertical
federated spatiotemporal representation learning to locally preserve
spatiotemporal dependencies among individual participants and generate
effective representations for heterogeneous data. Then we propose a
cross-client virtual node alignment block to incorporate cross-client
spatiotemporal dependencies via a multi-level knowledge fusion scheme.
Extensive privacy analysis and experimental evaluations demonstrate that HSTFL
not only effectively resists inference attacks but also provides a significant
improvement against various baselines.",http://arxiv.org/pdf/2409.18482v1,,False
A TextGCN-Based Decoding Approach for Improving Remote Sensing Image Captioning,27/09/2024,"Swadhin Das, Raksha Sharma","Remote sensing images are highly valued for their ability to address complex
real-world issues such as risk management, security, and meteorology. However,
manually captioning these images is challenging and requires specialized
knowledge across various domains. This letter presents an approach for
automatically describing (captioning) remote sensing images. We propose a novel
encoder-decoder setup that deploys a Text Graph Convolutional Network (TextGCN)
and multi-layer LSTMs. The embeddings generated by TextGCN enhance the
decoder's understanding by capturing the semantic relationships among words at
both the sentence and corpus levels. Furthermore, we advance our approach with
a comparison-based beam search method to ensure fairness in the search strategy
for generating the final caption. We present an extensive evaluation of our
approach against various other state-of-the-art encoder-decoder frameworks. We
evaluated our method across three datasets using seven metrics: BLEU-1 to
BLEU-4, METEOR, ROUGE-L, and CIDEr. The results demonstrate that our approach
significantly outperforms other state-of-the-art encoder-decoder methods.",http://arxiv.org/pdf/2409.18467v1,,False
Physics Augmented Tuple Transformer for Autism Severity Level Detection,27/09/2024,"Chinthaka Ranasingha, Harshala Gammulle, Tharindu Fernando, Sridha Sridharan, Clinton Fookes","Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and
favorable step towards enhancing the health and well-being of children with
ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to
human error due to several factors contaminating the results. This paper
proposes a novel framework that exploits the laws of physics for ASD severity
recognition. The proposed physics-informed neural network architecture encodes
the behaviour of the subject extracted by observing a part of the
skeleton-based motion trajectory in a higher dimensional latent space. Two
decoders, namely physics-based and non-physics-based decoder, use this latent
embedding and predict the future motion patterns. The physics branch leverages
the laws of physics that apply to a skeleton sequence in the prediction process
while the non-physics-based branch is optimised to minimise the difference
between the predicted and actual motion of the subject. A classifier also
leverages the same latent space embeddings to recognise the ASD severity. This
dual generative objective explicitly forces the network to compare the actual
behaviour of the subject with the general normal behaviour of children that are
governed by the laws of physics, aiding the ASD recognition task. The proposed
method attains state-of-the-art performance on multiple ASD diagnosis
benchmarks. To illustrate the utility of the proposed framework beyond the task
ASD diagnosis, we conduct a third experiment using a publicly available
benchmark for the task of fall prediction and demonstrate the superiority of
our model.",http://arxiv.org/pdf/2409.18438v1,,False
SciDFM: A Large Language Model with Mixture-of-Experts for Science,27/09/2024,"Liangtai Sun, Danyu Luo, Da Ma, Zihan Zhao, Baocai Chen, Zhennan Shen, Su Zhu, Lu Chen, Xin Chen, Kai Yu","Recently, there has been a significant upsurge of interest in leveraging
large language models (LLMs) to assist scientific discovery. However, most LLMs
only focus on general science, while they lack domain-specific knowledge, such
as chemical molecules and amino acid sequences. To bridge these gaps, we
introduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and
is able to conduct college-level scientific reasoning and understand molecules
and amino acid sequences. We collect a large-scale training corpus containing
numerous scientific papers and books from different disciplines as well as data
from domain-specific databases. We further fine-tune the pre-trained model on
lots of instruction data to improve performances on downstream benchmarks. From
experiment results, we show that SciDFM achieves strong performance on general
scientific benchmarks such as SciEval and SciQ, and it reaches a SOTA
performance on domain-specific benchmarks among models of similar size. We
further analyze the expert layers and show that the results of expert selection
vary with data from different disciplines. To benefit the broader research
community, we open-source SciDFM at
https://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.",http://arxiv.org/pdf/2409.18412v1,,False
Embed and Emulate: Contrastive representations for simulation-based inference,27/09/2024,"Ruoxi Jiang, Peter Y. Lu, Rebecca Willett","Scientific modeling and engineering applications rely heavily on parameter
estimation methods to fit physical models and calibrate numerical simulations
using real-world measurements. In the absence of analytic statistical models
with tractable likelihoods, modern simulation-based inference (SBI) methods
first use a numerical simulator to generate a dataset of parameters and
simulated outputs. This dataset is then used to approximate the likelihood and
estimate the system parameters given observation data. Several SBI methods
employ machine learning emulators to accelerate data generation and parameter
estimation. However, applying these approaches to high-dimensional physical
systems remains challenging due to the cost and complexity of training
high-dimensional emulators. This paper introduces Embed and Emulate (E&E): a
new SBI method based on contrastive learning that efficiently handles
high-dimensional data and complex, multimodal parameter posteriors. E&E learns
a low-dimensional latent embedding of the data (i.e., a summary statistic) and
a corresponding fast emulator in the latent space, eliminating the need to run
expensive simulations or a high dimensional emulator during inference. We
illustrate the theoretical properties of the learned latent space through a
synthetic experiment and demonstrate superior performance over existing methods
in a realistic, non-identifiable parameter estimation task using the
high-dimensional, chaotic Lorenz 96 system.",http://arxiv.org/pdf/2409.18402v1,,False
"Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly",27/09/2024,"Alexander Htet Kyaw, Se Hwan Jeon, Miana Smith, Neil Gershenfeld","We present a system that transforms speech into physical objects by combining
3D generative Artificial Intelligence with robotic assembly. The system
leverages natural language input to make design and manufacturing more
accessible, enabling individuals without expertise in 3D modeling or robotic
programming to create physical objects. We propose utilizing discrete robotic
assembly of lattice-based voxel components to address the challenges of using
generative AI outputs in physical production, such as design variability,
fabrication speed, structural integrity, and material waste. The system
interprets speech to generate 3D objects, discretizes them into voxel
components, computes an optimized assembly sequence, and generates a robotic
toolpath. The results are demonstrated through the assembly of various objects,
ranging from chairs to shelves, which are prompted via speech and realized
within 5 minutes using a 6-axis robotic arm.",http://arxiv.org/pdf/2409.18390v1,,False
CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models,27/09/2024,"Kanghyun Ryu, Qiayuan Liao, Zhongyu Li, Koushil Sreenath, Negar Mehr","Curriculum learning is a training mechanism in reinforcement learning (RL)
that facilitates the achievement of complex policies by progressively
increasing the task difficulty during training. However, designing effective
curricula for a specific task often requires extensive domain knowledge and
human intervention, which limits its applicability across various domains. Our
core idea is that large language models (LLMs), with their extensive training
on diverse language data and ability to encapsulate world knowledge, present
significant potential for efficiently breaking down tasks and decomposing
skills across various robotics environments. Additionally, the demonstrated
success of LLMs in translating natural language into executable code for RL
agents strengthens their role in generating task curricula. In this work, we
propose CurricuLLM, which leverages the high-level planning and programming
capabilities of LLMs for curriculum design, thereby enhancing the efficient
learning of complex target tasks. CurricuLLM consists of: (Step 1) Generating
sequence of subtasks that aid target task learning in natural language form,
(Step 2) Translating natural language description of subtasks in executable
task code, including the reward code and goal distribution code, and (Step 3)
Evaluating trained policies based on trajectory rollout and subtask
description. We evaluate CurricuLLM in various robotics simulation
environments, ranging from manipulation, navigation, and locomotion, to show
that CurricuLLM can aid learning complex robot control tasks. In addition, we
validate humanoid locomotion policy learned through CurricuLLM in real-world.
The code is provided in https://github.com/labicon/CurricuLLM",http://arxiv.org/pdf/2409.18382v1,,False
