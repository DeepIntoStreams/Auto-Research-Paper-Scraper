Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation,18/02/2025,"Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He, Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi","Spatial intelligence is a critical component of embodied AI, promoting robots
to understand and interact with their environments. While recent advances have
enhanced the ability of VLMs to perceive object locations and positional
relationships, they still lack the capability to precisely understand object
orientations-a key requirement for tasks involving fine-grained manipulations.
Addressing this limitation not only requires geometric reasoning but also an
expressive and intuitive way to represent orientation. In this context, we
propose that natural language offers a more flexible representation space than
canonical frames, making it particularly suitable for instruction-following
robotic systems. In this paper, we introduce the concept of semantic
orientation, which defines object orientations using natural language in a
reference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the
''handle'' direction of a knife). To support this, we construct OrienText300K,
a large-scale dataset of 3D models annotated with semantic orientations that
link geometric understanding to functional semantics. By integrating semantic
orientation into a VLM system, we enable robots to generate manipulation
actions with both positional and orientational constraints. Extensive
experiments in simulation and real world demonstrate that our approach
significantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy
on Open6DOR and 74.9% accuracy on SIMPLER.",http://arxiv.org/pdf/2502.13143v1,,False
"Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions",18/02/2025,"Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja Matarić","We present an end-to-end framework for generating synthetic users for
evaluating interactive agents designed to encourage positive behavior changes,
such as in health and lifestyle coaching. The synthetic users are grounded in
health and lifestyle conditions, specifically sleep and diabetes management in
this study, to ensure realistic interactions with the health coaching agent.
Synthetic users are created in two stages: first, structured data are generated
grounded in real-world health and lifestyle factors in addition to basic
demographics and behavioral attributes; second, full profiles of the synthetic
users are developed conditioned on the structured data. Interactions between
synthetic users and the coaching agent are simulated using generative
agent-based models such as Concordia, or directly by prompting a language
model. Using two independently-developed agents for sleep and diabetes coaching
as case studies, the validity of this framework is demonstrated by analyzing
the coaching agent's understanding of the synthetic users' needs and
challenges. Finally, through multiple blinded evaluations of user-coach
interactions by human experts, we demonstrate that our synthetic users with
health and behavioral attributes more accurately portray real human users with
the same attributes, compared to generic synthetic users not grounded in such
attributes. The proposed framework lays the foundation for efficient
development of conversational agents through extensive, realistic, and grounded
simulated interactions.",http://arxiv.org/pdf/2502.13135v1,,False
Natural Language Generation from Visual Sequences: Challenges and Future Directions,18/02/2025,"Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle","The ability to use natural language to talk about visual content is at the
core of human intelligence and a crucial feature of any artificial intelligence
system. Various studies have focused on generating text for single images. In
contrast, comparatively little attention has been paid to exhaustively
analyzing and advancing work on multiple-image vision-to-text settings. In this
position paper, we claim that any task dealing with temporally ordered
sequences of multiple images or frames is an instance of a broader, more
general problem involving the understanding of intricate relationships between
the visual content and the corresponding text. We comprehensively analyze five
tasks that are instances of this problem and argue that they pose a common set
of challenges and share similarities in terms of modeling and evaluation
approaches. Based on the insights from these various aspects and stages of
multi-image-to-text generation, we highlight several open questions and suggest
future research directions. We believe that these directions can advance the
understanding of complex phenomena in this domain and the development of better
models.",http://arxiv.org/pdf/2502.13034v1,,False
You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations,18/02/2025,"Frederic Kirstein, Muneeb Khan, Jan Philip Wahle, Terry Ruas, Bela Gipp","Meeting summarization suffers from limited high-quality data, mainly due to
privacy restrictions and expensive collection processes. We address this gap
with FAME, a dataset of 500 meetings in English and 300 in German produced by
MIMIC, our new multi-agent meeting synthesis framework that generates meeting
transcripts on a given knowledge source by defining psychologically grounded
participant profiles, outlining the conversation, and orchestrating a large
language model (LLM) debate. A modular post-processing step refines these
outputs, mitigating potential repetitiveness and overly formal tones, ensuring
coherent, credible dialogues at scale. We also propose a psychologically
grounded evaluation framework assessing naturalness, social behavior
authenticity, and transcript difficulties. Human assessments show that FAME
approximates real-meeting spontaneity (4.5/5 in naturalness), preserves
speaker-centric challenges (3/5 in spoken language), and introduces richer
information-oriented difficulty (4/5 in difficulty). These findings highlight
that FAME is a good and scalable proxy for real-world meeting conditions. It
enables new test scenarios for meeting summarization research and other
conversation-centric applications in tasks requiring conversation data or
simulating social scenarios under behavioral constraints.",http://arxiv.org/pdf/2502.13001v1,,False
PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization,18/02/2025,"Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Doruk Oner, Pascal Fua","Accurate 3D shape representation is essential in engineering applications
such as design, optimization, and simulation. In practice, engineering
workflows require structured, part-aware representations, as objects are
inherently designed as assemblies of distinct components. However, most
existing methods either model shapes holistically or decompose them without
predefined part structures, limiting their applicability in real-world design
tasks. We propose PartSDF, a supervised implicit representation framework that
explicitly models composite shapes with independent, controllable parts while
maintaining shape consistency. Despite its simple single-decoder architecture,
PartSDF outperforms both supervised and unsupervised baselines in
reconstruction and generation tasks. We further demonstrate its effectiveness
as a structured shape prior for engineering applications, enabling precise
control over individual components while preserving overall coherence. Code
available at https://github.com/cvlab-epfl/PartSDF.",http://arxiv.org/pdf/2502.12985v1,,False
Electron flow matching for generative reaction mechanism prediction obeying conservation laws,18/02/2025,"Joonyoung F. Joung, Mun Hong Fong, Nicholas Casetti, Jordan P. Liles, Ne S. Dassanayake, Connor W. Coley","Central to our understanding of chemical reactivity is the principle of mass
conservation, which is fundamental for ensuring physical consistency, balancing
equations, and guiding reaction design. However, data-driven computational
models for tasks such as reaction product prediction rarely abide by this most
basic constraint. In this work, we recast the problem of reaction prediction as
a problem of electron redistribution using the modern deep generative framework
of flow matching. Our model, FlowER, overcomes limitations inherent in previous
approaches by enforcing exact mass conservation, thereby resolving
hallucinatory failure modes, recovering mechanistic reaction sequences for
unseen substrate scaffolds, and generalizing effectively to out-of-domain
reaction classes with extremely data-efficient fine-tuning. FlowER additionally
enables estimation of thermodynamic or kinetic feasibility and manifests a
degree of chemical intuition in reaction prediction tasks. This inherently
interpretable framework represents a significant step in bridging the gap
between predictive accuracy and mechanistic understanding in data-driven
reaction outcome prediction.",http://arxiv.org/pdf/2502.12979v1,,False
Guaranteed Conditional Diffusion: 3D Block-based Models for Scientific Data Compression,18/02/2025,"Jaemoon Lee, Xiao Li, Liangji Zhu, Sanjay Ranka, Anand Rangarajan","This paper proposes a new compression paradigm -- Guaranteed Conditional
Diffusion with Tensor Correction (GCDTC) -- for lossy scientific data
compression. The framework is based on recent conditional diffusion (CD)
generative models, and it consists of a conditional diffusion model, tensor
correction, and error guarantee. Our diffusion model is a mixture of 3D
conditioning and 2D denoising U-Net. The approach leverages a 3D block-based
compressing module to address spatiotemporal correlations in structured
scientific data. Then, the reverse diffusion process for 2D spatial data is
conditioned on the ``slices'' of content latent variables produced by the
compressing module. After training, the denoising decoder reconstructs the data
with zero noise and content latent variables, and thus it is entirely
deterministic. The reconstructed outputs of the CD model are further
post-processed by our tensor correction and error guarantee steps to control
and ensure a maximum error distortion, which is an inevitable requirement in
lossy scientific data compression. Our experiments involving two datasets
generated by climate and chemical combustion simulations show that our
framework outperforms standard convolutional autoencoders and yields
competitive compression quality with an existing scientific data compression
algorithm.",http://arxiv.org/pdf/2502.12951v1,,False
Performance of Zero-Shot Time Series Foundation Models on Cloud Data,18/02/2025,"William Toner, Thomas L. Lee, Artjom Joosen, Rajkarn Singh, Martin Asenov","Time series foundation models (FMs) have emerged as a popular paradigm for
zero-shot multi-domain forecasting. FMs are trained on numerous diverse
datasets and claim to be effective forecasters across multiple different time
series domains, including cloud data. In this work we investigate this claim,
exploring the effectiveness of FMs on cloud data. We demonstrate that many
well-known FMs fail to generate meaningful or accurate zero-shot forecasts in
this setting. We support this claim empirically, showing that FMs are
outperformed consistently by simple linear baselines. We also illustrate a
number of interesting pathologies, including instances where FMs suddenly
output seemingly erratic, random-looking forecasts. Our results suggest a
widespread failure of FMs to model cloud data.",http://arxiv.org/pdf/2502.12944v1,,False
A Smooth Transition Between Induction and Deduction: Fast Abductive Learning Based on Probabilistic Symbol Perception,18/02/2025,"Lin-Han Jia, Si-Yu Han, Lan-Zhe Guo, Zhi Zhou, Zhao-Long Li, Yu-Feng Li, Zhi-Hua Zhou","Abductive learning (ABL) that integrates strengths of machine learning and
logical reasoning to improve the learning generalization, has been recently
shown effective. However, its efficiency is affected by the transition between
numerical induction and symbolical deduction, leading to high computational
costs in the worst-case scenario. Efforts on this issue remain to be limited.
In this paper, we identified three reasons why previous optimization algorithms
for ABL were not effective: insufficient utilization of prediction, symbol
relationships, and accumulated experience in successful abductive processes,
resulting in redundant calculations to the knowledge base. To address these
challenges, we introduce an optimization algorithm named as Probabilistic
Symbol Perception (PSP), which makes a smooth transition between induction and
deduction and keeps the correctness of ABL unchanged. We leverage probability
as a bridge and present an efficient data structure, achieving the transfer
from a continuous probability sequence to discrete Boolean sequences with low
computational complexity. Experiments demonstrate the promising results.",http://arxiv.org/pdf/2502.12919v1,,False
Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning,18/02/2025,"Nandakishor M, Anjali M","Creating personalized and adaptable conversational AI remains a key
challenge. This paper introduces a Continuous Learning Conversational AI (CLCA)
approach, implemented using A2C reinforcement learning, to move beyond static
Large Language Models (LLMs). We use simulated sales dialogues, generated by
LLMs, to train an A2C agent. This agent learns to optimize conversation
strategies for personalization, focusing on engagement and delivering value.
Our system architecture integrates reinforcement learning with LLMs for both
data creation and response selection. This method offers a practical way to
build personalized AI companions that evolve through continuous learning,
advancing beyond traditional static LLM techniques.",http://arxiv.org/pdf/2502.12876v1,,False
PPGF: Probability Pattern-Guided Time Series Forecasting,18/02/2025,"Yanru Sun, Zongxia Xie, Haoyu Xing, Hualong Yu, Qinghua Hu","Time series forecasting (TSF) is an essential branch of machine learning with
various applications. Most methods for TSF focus on constructing different
networks to extract better information and improve performance. However,
practical application data contain different internal mechanisms, resulting in
a mixture of multiple patterns. That is, the model's ability to fit different
patterns is different and generates different errors. In order to solve this
problem, we propose an end-to-end framework, namely probability pattern-guided
time series forecasting (PPGF). PPGF reformulates the TSF problem as a
forecasting task guided by probabilistic pattern classification. Firstly, we
propose the grouping strategy to approach forecasting problems as
classification and alleviate the impact of data imbalance on classification.
Secondly, we predict in the corresponding class interval to guarantee the
consistency of classification and forecasting. In addition, True Class
Probability (TCP) is introduced to pay more attention to the difficult samples
to improve the classification accuracy. Detailedly, PPGF classifies the
different patterns to determine which one the target value may belong to and
estimates it accurately in the corresponding interval. To demonstrate the
effectiveness of the proposed framework, we conduct extensive experiments on
real-world datasets, and PPGF achieves significant performance improvements
over several baseline methods. Furthermore, the effectiveness of TCP and the
necessity of consistency between classification and forecasting are proved in
the experiments. All data and codes are available online:
https://github.com/syrGitHub/PPGF.",http://arxiv.org/pdf/2502.12802v1,,False
Envious Explore and Exploit,18/02/2025,"Omer Ben-Porat, Yotam Gafni, Or Markovetzki","Explore-and-exploit tradeoffs play a key role in recommendation systems
(RSs), aiming at serving users better by learning from previous interactions.
Despite their commercial success, the societal effects of explore-and-exploit
mechanisms are not well understood, especially regarding the utility
discrepancy they generate between different users. In this work, we measure
such discrepancy using the economic notion of envy. We present a multi-armed
bandit-like model in which every round consists of several sessions, and
rewards are realized once per round. We call the latter property reward
consistency, and show that the RS can leverage this property for better
societal outcomes. On the downside, doing so also generates envy, as
late-to-arrive users enjoy the information gathered by early-to-arrive users.
We examine the generated envy under several arrival order mechanisms and
virtually any anonymous algorithm, i.e., any algorithm that treats all similar
users similarly without leveraging their identities. We provide tight envy
bounds on uniform arrival and upper bound the envy for nudged arrival, in which
the RS can affect the order of arrival by nudging its users. Furthermore, we
study the efficiency-fairness trade-off by devising an algorithm that allows
constant envy and approximates the optimal welfare in restricted settings.
Finally, we validate our theoretical results empirically using simulations.",http://arxiv.org/pdf/2502.12798v1,,False
Composition and Control with Distilled Energy Diffusion Models and Sequential Monte Carlo,18/02/2025,"James Thornton, Louis Bethune, Ruixiang Zhang, Arwen Bradley, Preetum Nakkiran, Shuangfei Zhai","Diffusion models may be formulated as a time-indexed sequence of energy-based
models, where the score corresponds to the negative gradient of an energy
function. As opposed to learning the score directly, an energy parameterization
is attractive as the energy itself can be used to control generation via Monte
Carlo samplers. Architectural constraints and training instability in energy
parameterized models have so far yielded inferior performance compared to
directly approximating the score or denoiser. We address these deficiencies by
introducing a novel training regime for the energy function through
distillation of pre-trained diffusion models, resembling a Helmholtz
decomposition of the score vector field. We further showcase the synergies
between energy and score by casting the diffusion sampling procedure as a
Feynman Kac model where sampling is controlled using potentials from the learnt
energy functions. The Feynman Kac model formalism enables composition and low
temperature sampling through sequential Monte Carlo.",http://arxiv.org/pdf/2502.12786v1,,False
TREND: A Whitespace Replacement Information Hiding Method,18/02/2025,"Malte Hellmeier, Hendrik Norkowski, Ernst-Christoph Schrewe, Haydar Qarawlus, Falk Howar","Large Language Models (LLMs) have gained significant popularity in recent
years. Differentiating between a text written by a human and a text generated
by an LLM has become almost impossible. Information hiding techniques such as
digital watermarking or steganography can help by embedding information inside
text without being noticed. However, existing techniques, such as
linguistic-based or format-based methods, change the semantics or do not work
on pure, unformatted text. In this paper, we introduce a novel method for
information hiding termed TREND, which is able to conceal any byte-encoded
sequence within a cover text. The proposed method is implemented as a
multi-platform library using the Kotlin programming language, accompanied by a
command-line tool and a web interface provided as examples of usage. By
substituting conventional whitespace characters with visually similar Unicode
whitespace characters, our proposed scheme preserves the semantics of the cover
text without increasing the number of characters. Furthermore, we propose a
specified structure for secret messages that enables configurable compression,
encryption, hashing, and error correction. Our experimental benchmark
comparison on a dataset of one million Wikipedia articles compares ten
algorithms from literature and practice. It proves the robustness of our
proposed method in various applications while remaining imperceptible to
humans. We discuss the limitations of limited embedding capacity and further
robustness, which guide implications for future work.",http://arxiv.org/pdf/2502.12710v1,,False
CausalMan: A physics-based simulator for large-scale causality,18/02/2025,"Nicholas Tagliapietra, Juergen Luettin, Lavdim Halilaj, Moritz Willig, Tim Pychynski, Kristian Kersting","A comprehensive understanding of causality is critical for navigating and
operating within today's complex real-world systems. The absence of realistic
causal models with known data generating processes complicates fair
benchmarking. In this paper, we present the CausalMan simulator, modeled after
a real-world production line. The simulator features a diverse range of linear
and non-linear mechanisms and challenging-to-predict behaviors, such as
discrete mode changes. We demonstrate the inadequacy of many state-of-the-art
approaches and analyze the significant differences in their performance and
tractability, both in terms of runtime and memory complexity. As a
contribution, we will release the CausalMan large-scale simulator. We present
two derived datasets, and perform an extensive evaluation of both.",http://arxiv.org/pdf/2502.12707v1,,False
Federated Variational Inference for Bayesian Mixture Models,18/02/2025,"Jackie Rao, Francesca L. Crowe, Tom Marshall, Sylvia Richardson, Paul D. W. Kirk","We present a federated learning approach for Bayesian model-based clustering
of large-scale binary and categorical datasets. We introduce a principled
'divide and conquer' inference procedure using variational inference with local
merge and delete moves within batches of the data in parallel, followed by
'global' merge moves across batches to find global clustering structures. We
show that these merge moves require only summaries of the data in each batch,
enabling federated learning across local nodes without requiring the full
dataset to be shared. Empirical results on simulated and benchmark datasets
demonstrate that our method performs well in comparison to existing clustering
algorithms. We validate the practical utility of the method by applying it to
large scale electronic health record (EHR) data.",http://arxiv.org/pdf/2502.12684v1,,False
A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem,18/02/2025,Vatsal Maru,"The Aircraft Landing Problem (ALP) is one of the challenging problems in
aircraft transportation and management. The challenge is to schedule the
arriving aircraft in a sequence so that the cost and delays are optimized.
There are various solution approaches to solving this problem, most of which
are based on operations research algorithms and meta-heuristics. Although
traditional methods perform better on one or the other factors, there remains a
problem of solving real-time rescheduling and computational scalability
altogether. This paper presents a novel deep reinforcement learning (DRL)
framework that combines graph neural networks with actor-critic architectures
to address the ALP. This paper introduces three key contributions: A
graph-based state representation that efficiently captures temporal and spatial
relationships between aircraft, a specialized actor-critic architecture
designed to handle multiple competing objectives in landing scheduling, and a
runway balance strategy that ensures efficient resource utilization while
maintaining safety constraints. The results show that the trained algorithm can
be tested on different problem sets and the results are competitive to
operation research algorithms. The experimental results on standard benchmark
data sets demonstrate a 99.95 reduction in computational time compared to Mixed
Integer Programming (MIP) and 38 higher runway throughput over First Come First
Serve (FCFS) approaches. Therefore, the proposed solution is competitive to
traditional approaches and achieves substantial advancements. Notably, it does
not require retraining, making it particularly suitable for industrial
deployment. The frameworks capability to generate solutions within 1 second
enables real-time rescheduling, addressing critical requirements of air traffic
management.",http://arxiv.org/pdf/2502.12617v1,,False
Disentangling Long-Short Term State Under Unknown Interventions for Online Time Series Forecasting,18/02/2025,"Ruichu Cai, Haiqin Huang, Zhifang Jiang, Zijian Li, Changze Zhou, Yuequn Liu, Yuming Liu, Zhifeng Hao","Current methods for time series forecasting struggle in the online scenario,
since it is difficult to preserve long-term dependency while adapting
short-term changes when data are arriving sequentially. Although some recent
methods solve this problem by controlling the updates of latent states, they
cannot disentangle the long/short-term states, leading to the inability to
effectively adapt to nonstationary. To tackle this challenge, we propose a
general framework to disentangle long/short-term states for online time series
forecasting. Our idea is inspired by the observations where short-term changes
can be led by unknown interventions like abrupt policies in the stock market.
Based on this insight, we formalize a data generation process with unknown
interventions on short-term states. Under mild assumptions, we further leverage
the independence of short-term states led by unknown interventions to establish
the identification theory to achieve the disentanglement of long/short-term
states. Built on this theory, we develop a long short-term disentanglement
model (LSTD) to extract the long/short-term states with long/short-term
encoders, respectively. Furthermore, the LSTD model incorporates a smooth
constraint to preserve the long-term dependencies and an interrupted dependency
constraint to enforce the forgetting of short-term dependencies, together
boosting the disentanglement of long/short-term states. Experimental results on
several benchmark datasets show that our \textbf{LSTD} model outperforms
existing methods for online time series forecasting, validating its efficacy in
real-world applications.",http://arxiv.org/pdf/2502.12603v1,,False
HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading,18/02/2025,"Cheng Luo, Zefan Cai, Hanshi Sun, Jinqi Xiao, Bo Yuan, Wen Xiao, Junjie Hu, Jiawei Zhao, Beidi Chen, Anima Anandkumar","Transformer-based large language models (LLMs) demonstrate impressive
performance in long context generation. Extending the context length has
disproportionately shifted the memory footprint of LLMs during inference to the
key-value cache (KV cache). In this paper, we propose HEADINFER, which offloads
the KV cache to CPU RAM while avoiding the need to fully store the KV cache for
any transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise
offloading strategy, maintaining only selective attention heads KV cache on the
GPU while computing attention output dynamically. Through roofline analysis, we
demonstrate that HEADINFER maintains computational efficiency while
significantly reducing memory footprint. We evaluate HEADINFER on the
Llama-3-8B model with a 1-million-token sequence, reducing the GPU memory
footprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage
from 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline
inference. Notably, HEADINFER enables 4-million-token inference with an 8B
model on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without
approximation methods.",http://arxiv.org/pdf/2502.12574v1,,False
Improving the Stability of GNN Force Field Models by Reducing Feature Correlation,18/02/2025,"Yujie Zeng, Wenlong He, Ihor Vasyltsov, Jiaxin Wei, Ying Zhang, Lin Chen, Yuehua Dai","Recently, Graph Neural Network based Force Field (GNNFF) models are widely
used in Molecular Dynamics (MD) simulation, which is one of the most
cost-effective means in semiconductor material research. However, even such
models provide high accuracy in energy and force Mean Absolute Error (MAE) over
trained (in-distribution) datasets, they often become unstable during long-time
MD simulation when used for out-of-distribution datasets. In this paper, we
propose a feature correlation based method for GNNFF models to enhance the
stability of MD simulation. We reveal the negative relationship between feature
correlation and the stability of GNNFF models, and design a loss function with
a dynamic loss coefficient scheduler to reduce edge feature correlation that
can be applied in general GNNFF training. We also propose an empirical metric
to evaluate the stability in MD simulation. Experiments show our method can
significantly improve stability for GNNFF models especially in
out-of-distribution data with less than 3% computational overhead. For example,
we can ensure the stable MD simulation time from 0.03ps to 10ps for Allegro
model.",http://arxiv.org/pdf/2502.12548v1,,False
Predicate Hierarchies Improve Few-Shot State Classification,18/02/2025,"Emily Jin, Joy Hsu, Jiajun Wu","State classification of objects and their relations is core to many
long-horizon tasks, particularly in robot planning and manipulation. However,
the combinatorial explosion of possible object-predicate combinations, coupled
with the need to adapt to novel real-world environments, makes it a desideratum
for state classification models to generalize to novel queries with few
examples. To this end, we propose PHIER, which leverages predicate hierarchies
to generalize effectively in few-shot scenarios. PHIER uses an object-centric
scene encoder, self-supervised losses that infer semantic relations between
predicates, and a hyperbolic distance metric that captures hierarchical
structure; it learns a structured latent space of image-predicate pairs that
guides reasoning over state classification queries. We evaluate PHIER in the
CALVIN and BEHAVIOR robotic environments and show that PHIER significantly
outperforms existing methods in few-shot, out-of-distribution state
classification, and demonstrates strong zero- and few-shot generalization from
simulated to real-world tasks. Our results demonstrate that leveraging
predicate hierarchies improves performance on state classification tasks with
limited data.",http://arxiv.org/pdf/2502.12481v1,,False
Computational-Statistical Tradeoffs at the Next-Token Prediction Barrier: Autoregressive and Imitation Learning under Misspecification,18/02/2025,"Dhruv Rohatgi, Adam Block, Audrey Huang, Akshay Krishnamurthy, Dylan J. Foster","Next-token prediction with the logarithmic loss is a cornerstone of
autoregressive sequence modeling, but, in practice, suffers from error
amplification, where errors in the model compound and generation quality
degrades as sequence length $H$ increases. From a theoretical perspective, this
phenomenon should not appear in well-specified settings, and, indeed, a growing
body of empirical work hypothesizes that misspecification, where the learner is
not sufficiently expressive to represent the target distribution, may be the
root cause. Under misspecification -- where the goal is to learn as well as the
best-in-class model up to a multiplicative approximation factor $C\geq 1$ -- we
confirm that $C$ indeed grows with $H$ for next-token prediction, lending
theoretical support to this empirical hypothesis. We then ask whether this mode
of error amplification is avoidable algorithmically, computationally, or
information-theoretically, and uncover inherent computational-statistical
tradeoffs. We show:
  (1) Information-theoretically, one can avoid error amplification and achieve
$C=O(1)$.
  (2) Next-token prediction can be made robust so as to achieve $C=\tilde
O(H)$, representing moderate error amplification, but this is an inherent
barrier: any next-token prediction-style objective must suffer $C=\Omega(H)$.
  (3) For the natural testbed of autoregressive linear models, no
computationally efficient algorithm can achieve sub-polynomial approximation
factor $C=e^{(\log H)^{1-\Omega(1)}}$; however, at least for binary token
spaces, one can smoothly trade compute for statistical power and improve on
$C=\Omega(H)$ in sub-exponential time.
  Our results have consequences in the more general setting of imitation
learning, where the widely-used behavior cloning algorithm generalizes
next-token prediction.",http://arxiv.org/pdf/2502.12465v1,,False
Scientific Machine Learning of Flow Resistance Using Universal Shallow Water Equations with Differentiable Programming,18/02/2025,"Xiaofeng Liu, Yalan Song","Shallow water equations (SWEs) are the backbone of most hydrodynamics models
for flood prediction, river engineering, and many other water resources
applications. The estimation of flow resistance, i.e., the Manning's roughness
coefficient $n$, is crucial for ensuring model accuracy, and has been
previously determined using empirical formulas or tables. To better account for
temporal and spatial variability in channel roughness, inverse modeling of $n$
using observed flow data is more reliable and adaptable; however, it is
challenging when using traditional SWE solvers. Based on the concept of
universal differential equation (UDE), which combines physics-based
differential equations with neural networks (NNs), we developed a universal
SWEs (USWEs) solver, Hydrograd, for hybrid hydrodynamics modeling. It can do
accurate forward simulations, support automatic differentiation (AD) for
gradient-based sensitivity analysis and parameter inversion, and perform
scientific machine learning for physics discovery. In this work, we first
validated the accuracy of its forward modeling, then applied a real-world case
to demonstrate the ability of USWEs to capture model sensitivity (gradients)
and perform inverse modeling of Manning's $n$. Furthermore, we used a NN to
learn a universal relationship between $n$, hydraulic parameters, and flow in a
real river channel. Unlike inverse modeling using surrogate models, Hydrograd
uses a two-dimensional SWEs solver as its physics backbone, which eliminates
the need for data-intensive pretraining and resolves the generalization problem
when applied to out-of-sample scenarios. This differentiable modeling approach,
with seamless integration with NNs, provides a new pathway for solving complex
inverse problems and discovering new physics in hydrodynamics.",http://arxiv.org/pdf/2502.12396v1,,False
