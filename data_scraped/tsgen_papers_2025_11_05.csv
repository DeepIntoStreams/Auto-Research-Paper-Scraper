Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Agentic World Modeling for 6G: Near-Real-Time Generative State-Space Reasoning,04/11/2025,"Farhad Rezazadeh, Hatim Chergui, Merouane Debbah, Houbing Song, Dusit Niyato, Lingjia Liu","We argue that sixth-generation (6G) intelligence is not fluent token
prediction but the capacity to imagine and choose -- to simulate future
scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe
open radio access network (O-RAN) near-real-time (Near-RT) control via
counterfactual dynamics and a world modeling (WM) paradigm that learns an
action-conditioned generative state space. This enables quantitative ""what-if""
forecasting beyond large language models (LLMs) as the primary modeling
primitive. Actions such as physical resource blocks (PRBs) are treated as
first-class control inputs in a causal world model, and both aleatoric and
epistemic uncertainty are modeled for prediction and what-if analysis. An
agentic, model predictive control (MPC)-based cross-entropy method (CEM)
planner operates over short horizons, using prior-mean rollouts within
data-driven PRB bounds to maximize a deterministic reward. The model couples
multi-scale structured state-space mixtures (MS3M) with a compact stochastic
latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories
and predicting next-step KPIs under hypothetical PRB sequences. On realistic
O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with
32% fewer parameters and similar latency, and achieves 35-80% lower root mean
squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster
inference, enabling rare-event simulation and offline policy screening.",http://arxiv.org/pdf/2511.02748v1,,False
RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication Trade-offs,04/11/2025,"Adam Umra, Aya M. Ahmed, Aydin Sezgin","This paper proposes a reinforcement learning (RL)-aided cognitive framework
for massive MIMO-based integrated sensing and communication (ISAC) systems
employing a uniform planar array (UPA). The focus is on enhancing radar sensing
performance in environments with unknown and dynamic disturbance
characteristics. A Wald-type detector is employed for robust target detection
under non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive
estimation of target positions without prior environmental knowledge. Based on
the RL-derived sensing information, a joint waveform optimization strategy is
formulated to balance radar sensing accuracy and downlink communication
throughput. The resulting design provides an adaptive trade-off between
detection performance and achievable sum rate through an analytically derived
closed-form solution. Monte Carlo simulations demonstrate that the proposed
cognitive ISAC framework achieves significantly improved detection probability
compared to orthogonal and non-learning adaptive baselines, while maintaining
competitive communication performance. These results underline the potential of
RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation
wireless networks.",http://arxiv.org/pdf/2511.02672v1,,False
Natural-gas storage modelling by deep reinforcement learning,04/11/2025,"Tiziano Balaconi, Aldo Glielmo, Marco Taboga","We introduce GasRL, a simulator that couples a calibrated representation of
the natural gas market with a model of storage-operator policies trained with
deep reinforcement learning (RL). We use it to analyse how optimal stockpile
management affects equilibrium prices and the dynamics of demand and supply. We
test various RL algorithms and find that Soft Actor Critic (SAC) exhibits
superior performance in the GasRL environment: multiple objectives of storage
operators - including profitability, robust market clearing and price
stabilisation - are successfully achieved. Moreover, the equilibrium price
dynamics induced by SAC-derived optimal policies have characteristics, such as
volatility and seasonality, that closely match those of real-world prices.
Remarkably, this adherence to the historical distribution of prices is obtained
without explicitly calibrating the model to price data. We show how the
simulator can be used to assess the effects of EU-mandated minimum storage
thresholds. We find that such thresholds have a positive effect on market
resilience against unanticipated shifts in the distribution of supply shocks.
For example, with unusually large shocks, market disruptions are averted more
often if a threshold is in place.",http://arxiv.org/pdf/2511.02646v1,10.1145/3768292.3770348,False
A Multi-Agent Psychological Simulation System for Human Behavior Modeling,04/11/2025,"Xiangen Hu, Jiarui Tong, Sheng Xu","Training and education in human-centered fields require authentic practice,
yet realistic simulations of human behavior have remained limited. We present a
multi-agent psychological simulation system that models internal
cognitive-affective processes to generate believable human behaviors. In
contrast to black-box neural models, this system is grounded in established
psychological theories (e.g., self-efficacy, mindset, social constructivism)
and explicitly simulates an ``inner parliament'' of agents corresponding to key
psychological factors. These agents deliberate and interact to determine the
system's output behavior, enabling unprecedented transparency and alignment
with human psychology. We describe the system's architecture and theoretical
foundations, illustrate its use in teacher training and research, and discuss
how it embodies principles of social learning, cognitive apprenticeship,
deliberate practice, and meta-cognition.",http://arxiv.org/pdf/2511.02606v1,,False
A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding,04/11/2025,"Jingyu Lu, Haonan Wang, Qixiang Zhang, Xiaomeng Li","Subject-agnostic brain decoding, which aims to reconstruct continuous visual
experiences from fMRI without subject-specific training, holds great potential
for clinical applications. However, this direction remains underexplored due to
challenges in cross-subject generalization and the complex nature of brain
signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a
novel hierarchical decoding framework that explicitly models the ventral-dorsal
architecture of the human visual system to learn multi-dimensional
representations. By disentangling and leveraging features from early visual
cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary
cognitive information essential for visual reconstruction. Furthermore, we
introduce a feature-level contrastive learning strategy to enhance the
extraction of subject-invariant semantic representations, thereby enhancing
subject-agnostic applicability to previously unseen subjects. Unlike
conventional pipelines that need more than 12 hours of per-subject data and
heavy computation, VCFlow sacrifices only 7\% accuracy on average yet generates
each reconstructed video in 10 seconds without any retraining, offering a fast
and clinically scalable solution. The source code will be released upon
acceptance of the paper.",http://arxiv.org/pdf/2511.02565v1,,False
Theoretical Guarantees for Causal Discovery on Large Random Graphs,04/11/2025,"Mathieu Chevalley, Arash Mehrjou, Patrick Schwab","We investigate theoretical guarantees for the false-negative rate (FNR) --
the fraction of true causal edges whose orientation is not recovered, under
single-variable random interventions and an $\epsilon$-interventional
faithfulness assumption that accommodates latent confounding. For sparse
Erd\H{o}s--R\'enyi directed acyclic graphs, where the edge probability scales
as $p_e = \Theta(1/d)$, we show that the FNR concentrates around its mean at
rate $O(\frac{\log d}{\sqrt d})$, implying that large deviations above the
expected error become exponentially unlikely as dimensionality increases. This
concentration ensures that derived upper bounds hold with high probability in
large-scale settings. Extending the analysis to generalized Barab\'asi--Albert
graphs reveals an even stronger phenomenon: when the degree exponent satisfies
$\gamma > 3$, the deviation width scales as $O(d^{\beta - \frac{1}{2}})$ with
$\beta = 1/(\gamma - 1) < \frac{1}{2}$, and hence vanishes in the limit. This
demonstrates that realistic scale-free topologies intrinsically regularize
causal discovery, reducing variability in orientation error. These
finite-dimension results provide the first dimension-adaptive,
faithfulness-robust guarantees for causal structure recovery, and challenge the
intuition that high dimensionality and network heterogeneity necessarily hinder
accurate discovery. Our simulation results corroborate these theoretical
predictions, showing that the FNR indeed concentrates and often vanishes in
practice as dimensionality grows.",http://arxiv.org/pdf/2511.02536v1,,False
Agentic AI for Mobile Network RAN Management and Optimization,04/11/2025,"Jorge Pellejero, Luis A. Hernández Gómez, Luis Mendo Tomás, Zoraida Frias Barroso","Agentic AI represents a new paradigm for automating complex systems by using
Large AI Models (LAMs) to provide human-level cognitive abilities with
multimodal perception, planning, memory, and reasoning capabilities. This will
lead to a new generation of AI systems that autonomously decompose goals,
retain context over time, learn continuously, operate across tools and
environments, and adapt dynamically. The complexity of 5G and upcoming 6G
networks renders manual optimization ineffective, pointing to Agentic AI as a
method for automating decisions in dynamic RAN environments. However, despite
its rapid advances, there is no established framework outlining the
foundational components and operational principles of Agentic AI systems nor a
universally accepted definition.
  This paper contributes to ongoing research on Agentic AI in 5G and 6G
networks by outlining its core concepts and then proposing a practical use case
that applies Agentic principles to RAN optimization. We first introduce Agentic
AI, tracing its evolution from classical agents and discussing the progress
from workflows and simple AI agents to Agentic AI. Core design
patterns-reflection, planning, tool use, and multi-agent collaboration-are then
described to illustrate how intelligent behaviors are orchestrated. These
theorical concepts are grounded in the context of mobile networks, with a focus
on RAN management and optimization. A practical 5G RAN case study shows how
time-series analytics and LAM-driven agents collaborate for KPI-based
autonomous decision-making.",http://arxiv.org/pdf/2511.02532v1,,False
Many-vs-Many Missile Guidance via Virtual Targets,04/11/2025,"Marc Schneider, Walter Fichter","This paper presents a novel approach to many-vs-many missile guidance using
virtual targets (VTs) generated by a Normalizing Flows-based trajectory
predictor. Rather than assigning n interceptors directly to m physical targets
through conventional weapon target assignment algorithms, we propose a
centralized strategy that constructs n VT trajectories representing
probabilistic predictions of maneuvering target behavior. Each interceptor is
guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse
flight, transitioning to Proportional Navigation guidance for terminal
interception. This approach treats many-vs-many engagements as
many-vs-distribution scenarios, exploiting numerical superiority (n > m) by
distributing interceptors across diverse trajectory hypotheses rather than
pursuing identical deterministic predictions. Monte Carlo simulations across
various target-interceptor configurations (1-6 targets, 1-8 interceptors)
demonstrate that the VT method matches or exceeds baseline straight-line
prediction performance by 0-4.1% when n = m, with improvements increasing to
5.8-14.4% when n > m. The results confirm that probabilistic VTs enable
effective exploitation of numerical superiority, significantly increasing
interception probability in many-vs-many scenarios.",http://arxiv.org/pdf/2511.02526v1,,False
"Efficient Solvers for SLOPE in R, Python, Julia, and C++",04/11/2025,"Johan Larsson, Malgorzata Bogdan, Krystyna Grzesiak, Mathurin Massias, Jonas Wallin","We present a suite of packages in R, Python, Julia, and C++ that efficiently
solve the Sorted L-One Penalized Estimation (SLOPE) problem. The packages
feature a highly efficient hybrid coordinate descent algorithm that fits
generalized linear models (GLMs) and supports a variety of loss functions,
including Gaussian, binomial, Poisson, and multinomial logistic regression. Our
implementation is designed to be fast, memory-efficient, and flexible. The
packages support a variety of data structures (dense, sparse, and out-of-memory
matrices) and are designed to efficiently fit the full SLOPE path as well as
handle cross-validation of SLOPE models, including the relaxed SLOPE. We
present examples of how to use the packages and benchmarks that demonstrate the
performance of the packages on both real and simulated data and show that our
packages outperform existing implementations of SLOPE in terms of speed.",http://arxiv.org/pdf/2511.02430v1,,False
H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart Sound Recordings,04/11/2025,"Rohith Shinoj Kumar, Rushdeep Dinda, Aditya Tyagi, Annappa B., Naveen Kumar M. R","Early detection of heart arrhythmia can prevent severe future complications
in cardiac patients. While manual diagnosis still remains the clinical
standard, it relies heavily on visual interpretation and is inherently
subjective. In recent years, deep learning has emerged as a powerful tool to
automate arrhythmia detection, offering improved accuracy, consistency, and
efficiency. Several variants of convolutional and recurrent neural network
architectures have been widely explored to capture spatial and temporal
patterns in physiological signals. However, despite these advancements, current
models often struggle to generalize well in real-world scenarios, especially
when dealing with small or noisy datasets, which are common challenges in
biomedical applications. In this paper, a novel CNN-H-Infinity-LSTM
architecture is proposed to identify arrhythmic heart signals from heart sound
recordings. This architecture introduces trainable parameters inspired by the
H-Infinity filter from control theory, enhancing robustness and generalization.
Extensive experimentation on the PhysioNet CinC Challenge 2016 dataset, a
public benchmark of heart audio recordings, demonstrates that the proposed
model achieves stable convergence and outperforms existing benchmarks, with a
test accuracy of 99.42% and an F1 score of 98.85%.",http://arxiv.org/pdf/2511.02379v1,,False
LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment,04/11/2025,"Rohan Wandre, Yash Gajewar, Namrata Patel, Vivek Dhalkari","Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for
grounding large language model outputs in verifiable evidence. However, as
modern AI agents transition from static knowledge bases to continuous
multimodal streams encompassing text, images, video, and audio, two critical
challenges arise: maintaining index freshness without prohibitive re-indexing
costs, and preserving cross-modal semantic consistency across heterogeneous
embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture
featuring three key innovations: (i) a streaming, multi-tier memory system that
dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier
under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that
maintains cross-modal consistency through incremental orthogonal Procrustes
updates; and (iii) stability-aware retrieval telemetry providing Safe@k
guarantees by jointly bounding alignment drift and quantization error.
Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94),
graceful performance degradation under product quantization offloading, and
provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG
as a practical framework for production multimodal RAG systems.",http://arxiv.org/pdf/2511.02371v1,,False
A Stable Lasso,04/11/2025,"Mahdi Nouraie, Houying Zhu, Samuel Muller","The Lasso has been widely used as a method for variable selection, valued for
its simplicity and empirical performance. However, Lasso's selection stability
deteriorates in the presence of correlated predictors. Several approaches have
been developed to mitigate this limitation. In this paper, we provide a brief
review of existing approaches, highlighting their limitations. We then propose
a simple technique to improve the selection stability of Lasso by integrating a
weighting scheme into the Lasso penalty function, where the weights are defined
as an increasing function of a correlation-adjusted ranking that reflects the
predictive power of predictors. Empirical evaluations on both simulated and
real-world datasets demonstrate the efficacy of the proposed method. Additional
numerical results demonstrate the effectiveness of the proposed approach in
stabilizing other regularization-based selection methods, indicating its
potential as a general-purpose solution.",http://arxiv.org/pdf/2511.02306v1,,False
Federated Quantum Kernel Learning for Anomaly Detection in Multivariate IoT Time-Series,04/11/2025,"Kuan-Cheng Chen, Samuel Yen-Chi Chen, Chen-Yu Liu, Kin K. Leung","The rapid growth of industrial Internet of Things (IIoT) systems has created
new challenges for anomaly detection in high-dimensional, multivariate
time-series, where privacy, scalability, and communication efficiency are
critical. Classical federated learning approaches mitigate privacy concerns by
enabling decentralized training, but they often struggle with highly non-linear
decision boundaries and imbalanced anomaly distributions. To address this gap,
we propose a Federated Quantum Kernel Learning (FQKL) framework that integrates
quantum feature maps with federated aggregation to enable distributed,
privacy-preserving anomaly detection across heterogeneous IoT networks. In our
design, quantum edge nodes locally compute compressed kernel statistics using
parameterized quantum circuits and share only these summaries with a central
server, which constructs a global Gram matrix and trains a decision function
(e.g., Fed-QSVM). Experimental results on synthetic IIoT benchmarks demonstrate
that FQKL achieves superior generalization in capturing complex temporal
correlations compared to classical federated baselines, while significantly
reducing communication overhead. This work highlights the promise of quantum
kernels in federated settings, advancing the path toward scalable, robust, and
quantum-enhanced intelligence for next-generation IoT infrastructures.",http://arxiv.org/pdf/2511.02301v1,,False
From Models to Operators: Rethinking Autoscaling Granularity for Large Generative Models,04/11/2025,"Xingqi Cui, Chieh-Jan Mike Liang, Jiarong Xing, Haoran Qiu","Serving large generative models such as LLMs and multi- modal transformers
requires balancing user-facing SLOs (e.g., time-to-first-token,
time-between-tokens) with provider goals of efficiency and cost reduction.
Existing solutions rely on static provisioning or model-level autoscaling, both
of which treat the model as a monolith. This coarse-grained resource management
leads to degraded performance or significant resource underutilization due to
poor adaptability to dynamic inference traffic that is common online.
  The root cause of this inefficiency lies in the internal structure of
generative models: they are executed as graphs of interconnected operators.
Through detailed characterization and systematic analysis, we find that
operators are heterogeneous in their compute and memory footprints and exhibit
diverse sensitivity to workload and resource factors such as batch size,
sequence length, and traffic rate. This heterogeneity suggests that the
operator, rather than the entire model, is the right granularity for scaling
decisions.
  We propose an operator-level autoscaling framework, which allocates resources
at finer (operator)-granularity, optimizing the scaling, batching, and
placement based on individual operator profiles. Evaluated on production-scale
traces, our approach preserves SLOs with up to 40% fewer GPUs and 35% less
energy, or under fixed resources achieves 1.6x higher throughput with 5% less
energy. These results show that the operator, rather than the model, is
fundamentally a more effective unit for scaling large generative workloads.",http://arxiv.org/pdf/2511.02248v1,,False
LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation,04/11/2025,"Youngjin Hong, Houjian Yu, Mingen Li, Changhyun Choi","Learning generalizable policies for robotic manipulation increasingly relies
on large-scale models that map language instructions to actions (L2A). However,
this one-way paradigm often produces policies that execute tasks without deeper
contextual understanding, limiting their ability to generalize or explain their
behavior. We argue that the complementary skill of mapping actions back to
language (A2L) is essential for developing more holistic grounding. An agent
capable of both acting and explaining its actions can form richer internal
representations and unlock new paradigms for self-supervised learning. We
introduce LACY (Language-Action Cycle), a unified framework that learns such
bidirectional mappings within a single vision-language model. LACY is jointly
trained on three synergistic tasks: generating parameterized actions from
language (L2A), explaining observed actions in language (A2L), and verifying
semantic consistency between two language descriptions (L2C). This enables a
self-improving cycle that autonomously generates and filters new training data
through an active augmentation strategy targeting low-confidence cases, thereby
improving the model without additional human labels. Experiments on
pick-and-place tasks in both simulation and the real world show that LACY
improves task success rates by 56.46% on average and yields more robust
language-action grounding for robotic manipulation. Project page:
https://vla2026.github.io/LACY/",http://arxiv.org/pdf/2511.02239v1,,False
Learning Interactive World Model for Object-Centric Reinforcement Learning,04/11/2025,"Fan Feng, Phillip Lippe, Sara Magliacane","Agents that understand objects and their interactions can learn policies that
are more robust and transferable. However, most object-centric RL methods
factor state by individual objects while leaving interactions implicit. We
introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a
unified framework that learns structured representations of both objects and
their interactions within a world model. FIOC-WM captures environment dynamics
with disentangled and modular representations of object interactions, improving
sample efficiency and generalization for policy learning. Concretely, FIOC-WM
first learns object-centric latents and an interaction structure directly from
pixels, leveraging pre-trained vision encoders. The learned world model then
decomposes tasks into composable interaction primitives, and a hierarchical
policy is trained on top: a high level selects the type and order of
interactions, while a low level executes them. On simulated robotic and
embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and
generalization over world-model baselines, indicating that explicit, modular
interaction learning is crucial for robust control.",http://arxiv.org/pdf/2511.02225v1,,False
Adaptive Cooperative Transmission Design for Ultra-Reliable Low-Latency Communications via Deep Reinforcement Learning,04/11/2025,"Hyemin Yu, Hong-Chuan Yang","Next-generation wireless communication systems must support ultra-reliable
low-latency communication (URLLC) service for mission-critical applications.
Meeting stringent URLLC requirements is challenging, especially for two-hop
cooperative communication. In this paper, we develop an adaptive transmission
design for a two-hop relaying communication system. Each hop transmission
adaptively configures its transmission parameters separately, including
numerology, mini-slot size, and modulation and coding scheme, for reliable
packet transmission within a strict latency constraint. We formulate the
hop-specific transceiver configuration as a Markov decision process (MDP) and
propose a dual-agent reinforcement learning-based cooperative latency-aware
transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies
in a distributed manner. Simulation results verify that the proposed algorithm
achieves the near-optimal reliability while satisfying strict latency
requirements.",http://arxiv.org/pdf/2511.02216v1,,False
Estimation of Segmental Longitudinal Strain in Transesophageal Echocardiography by Deep Learning,04/11/2025,"Anders Austlid Taskén, Thierry Judge, Erik Andreas Rye Berg, Jinyang Yu, Bjørnar Grenne, Frank Lindseth, Svend Aakhus, Pierre-Marc Jodoin, Nicolas Duchateau, Olivier Bernard, Gabriel Kiss","Segmental longitudinal strain (SLS) of the left ventricle (LV) is an
important prognostic indicator for evaluating regional LV dysfunction, in
particular for diagnosing and managing myocardial ischemia. Current techniques
for strain estimation require significant manual intervention and expertise,
limiting their efficiency and making them too resource-intensive for monitoring
purposes. This study introduces the first automated pipeline, autoStrain, for
SLS estimation in transesophageal echocardiography (TEE) using deep learning
(DL) methods for motion estimation. We present a comparative analysis of two DL
approaches: TeeFlow, based on the RAFT optical flow model for dense
frame-to-frame predictions, and TeeTracker, based on the CoTracker point
trajectory model for sparse long-sequence predictions.
  As ground truth motion data from real echocardiographic sequences are hardly
accessible, we took advantage of a unique simulation pipeline (SIMUS) to
generate a highly realistic synthetic TEE (synTEE) dataset of 80 patients with
ground truth myocardial motion to train and evaluate both models. Our
evaluation shows that TeeTracker outperforms TeeFlow in accuracy, achieving a
mean distance error in motion estimation of 0.65 mm on a synTEE test dataset.
  Clinical validation on 16 patients further demonstrated that SLS estimation
with our autoStrain pipeline aligned with clinical references, achieving a mean
difference (95\% limits of agreement) of 1.09% (-8.90% to 11.09%).
Incorporation of simulated ischemia in the synTEE data improved the accuracy of
the models in quantifying abnormal deformation. Our findings indicate that
integrating AI-driven motion estimation with TEE can significantly enhance the
precision and efficiency of cardiac function assessment in clinical settings.",http://arxiv.org/pdf/2511.02210v1,10.1109/JBHI.2025.3605793,False
Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction and Phenotyping,04/11/2025,"Jiajia Li, Keyi Zhu, Qianwen Zhang, Dong Chen, Qi Sun, Zhaojian Li","Strawberries are among the most economically significant fruits in the United
States, generating over $2 billion in annual farm-gate sales and accounting for
approximately 13% of the total fruit production value. Plant phenotyping plays
a vital role in selecting superior cultivars by characterizing plant traits
such as morphology, canopy structure, and growth dynamics. However, traditional
plant phenotyping methods are time-consuming, labor-intensive, and often
destructive. Recently, neural rendering techniques, notably Neural Radiance
Fields (NeRF) and 3D Gaussian Splatting (3DGS), have emerged as powerful
frameworks for high-fidelity 3D reconstruction. By capturing a sequence of
multi-view images or videos around a target plant, these methods enable
non-destructive reconstruction of complex plant architectures. Despite their
promise, most current applications of 3DGS in agricultural domains reconstruct
the entire scene, including background elements, which introduces noise,
increases computational costs, and complicates downstream trait analysis. To
address this limitation, we propose a novel object-centric 3D reconstruction
framework incorporating a preprocessing pipeline that leverages the Segment
Anything Model v2 (SAM-2) and alpha channel background masking to achieve clean
strawberry plant reconstructions. This approach produces more accurate
geometric representations while substantially reducing computational time. With
a background-free reconstruction, our algorithm can automatically estimate
important plant traits, such as plant height and canopy width, using DBSCAN
clustering and Principal Component Analysis (PCA). Experimental results show
that our method outperforms conventional pipelines in both accuracy and
efficiency, offering a scalable and non-destructive solution for strawberry
plant phenotyping.",http://arxiv.org/pdf/2511.02207v1,,False
DoFlow: Causal Generative Flows for Interventional and Counterfactual Time-Series Prediction,04/11/2025,"Dongze Wu, Feng Qiu, Yao Xie","Time-series forecasting increasingly demands not only accurate observational
predictions but also causal forecasting under interventional and counterfactual
queries in multivariate systems. We present DoFlow, a flow based generative
model defined over a causal DAG that delivers coherent observational and
interventional predictions, as well as counterfactuals through the natural
encoding and decoding mechanism of continuous normalizing flows (CNFs). We also
provide a supporting counterfactual recovery result under certain assumptions.
Beyond forecasting, DoFlow provides explicit likelihoods of future
trajectories, enabling principled anomaly detection. Experiments on synthetic
datasets with various causal DAG and real world hydropower and cancer treatment
time series show that DoFlow achieves accurate system-wide observational
forecasting, enables causal forecasting over interventional and counterfactual
queries, and effectively detects anomalies. This work contributes to the
broader goal of unifying causal reasoning and generative modeling for complex
dynamical systems.",http://arxiv.org/pdf/2511.02137v1,,False
InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance,03/11/2025,"Ziheng Geng, Jiachen Liu, Ran Cao, Lu Cheng, Dan M. Frangopol, Minghui Cheng","Flood insurance is an effective strategy for individuals to mitigate
disaster-related losses. However, participation rates among at-risk populations
in the United States remain strikingly low. This gap underscores the need to
understand and model the behavioral mechanisms underlying insurance decisions.
Large language models (LLMs) have recently exhibited human-like intelligence
across wide-ranging tasks, offering promising tools for simulating human
decision-making. This study constructs a benchmark dataset to capture insurance
purchase probabilities across factors. Using this dataset, the capacity of LLMs
is evaluated: while LLMs exhibit a qualitative understanding of factors, they
fall short in estimating quantitative probabilities. To address this
limitation, InsurAgent, an LLM-empowered agent comprising five modules
including perception, retrieval, reasoning, action, and memory, is proposed.
The retrieval module leverages retrieval-augmented generation (RAG) to ground
decisions in empirical survey data, achieving accurate estimation of marginal
and bivariate probabilities. The reasoning module leverages LLM common sense to
extrapolate beyond survey data, capturing contextual information that is
intractable for traditional models. The memory module supports the simulation
of temporal decision evolutions, illustrated through a roller coaster life
trajectory. Overall, InsurAgent provides a valuable tool for behavioral
modeling and policy analysis.",http://arxiv.org/pdf/2511.02119v1,,False
Uncertainty Guided Online Ensemble for Non-stationary Data Streams in Fusion Science,03/11/2025,"Kishansingh Rajput, Malachi Schram, Brian Sammuli, Sen Lin","Machine Learning (ML) is poised to play a pivotal role in the development and
operation of next-generation fusion devices. Fusion data shows non-stationary
behavior with distribution drifts, resulted by both experimental evolution and
machine wear-and-tear. ML models assume stationary distribution and fail to
maintain performance when encountered with such non-stationary data streams.
Online learning techniques have been leveraged in other domains, however it has
been largely unexplored for fusion applications. In this paper, we present an
application of online learning to continuously adapt to drifting data stream
for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion
facility. The results demonstrate that online learning is critical to maintain
ML model performance and reduces error by 80% compared to a static model.
Moreover, traditional online learning can suffer from short-term performance
degradation as ground truth is not available before making the predictions. As
such, we propose an uncertainty guided online ensemble method to further
improve the performance. The Deep Gaussian Process Approximation (DGPA)
technique is leveraged for calibrated uncertainty estimation and the
uncertainty values are then used to guide a meta-algorithm that produces
predictions based on an ensemble of learners trained on different horizon of
historical data. The DGPA also provides uncertainty estimation along with the
predictions for decision makers. The online ensemble and the proposed
uncertainty guided online ensemble reduces predictions error by about 6%, and
10% respectively over standard single model based online learning.",http://arxiv.org/pdf/2511.02092v1,,False
Watermarking Discrete Diffusion Language Models,03/11/2025,"Avi Bagchi, Akhil Bhimaraju, Moulik Choraria, Daniel Alabi, Lav R. Varshney","Watermarking has emerged as a promising technique to track AI-generated
content and differentiate it from authentic human creations. While prior work
extensively studies watermarking for autoregressive large language models
(LLMs) and image diffusion models, none address discrete diffusion language
models, which are becoming popular due to their high inference throughput. In
this paper, we introduce the first watermarking method for discrete diffusion
models by applying the distribution-preserving Gumbel-max trick at every
diffusion step and seeding the randomness with the sequence index to enable
reliable detection. We experimentally demonstrate that our scheme is reliably
detectable on state-of-the-art diffusion language models and analytically prove
that it is distortion-free with an exponentially decaying probability of false
detection in the token sequence length.",http://arxiv.org/pdf/2511.02083v1,,False
Beyond Static Cutoffs: One-Shot Dynamic Thresholding for Diffusion Language Models,03/11/2025,"Jucheng Shen, Yeonju Ro","Masked diffusion language models (MDLMs) are becoming competitive with their
autoregressive counterparts but typically decode with fixed steps and
sequential unmasking. To accelerate decoding, recent work such as Fast-dLLM
enables parallel decoding via a static global confidence threshold, yet we
observe strong block- and step-wise confidence fluctuations and, within a
dataset, near-identical confidence trajectories across inputs as measured by
cosine similarity. Motivated by these observations, we introduce One-Shot
Dynamic Thresholding (OSDT), which calibrates thresholds on a single sequence
and applies them to subsequent inputs with negligible overhead. On GPQA, GSM8K,
and HumanEval, OSDT attains superior accuracy-throughput trade-offs (+24%
tokens/s on GSM8K at the best accuracy, +45% on GPQA with comparable accuracy,
and +50% on HumanEval with a modest accuracy gap). Beyond these results, our
findings suggest broader opportunities to leverage reusable task-level
confidence signatures for more general-purpose algorithmic and systems
innovations in diffusion decoding.",http://arxiv.org/pdf/2511.02077v1,,False
Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning,03/11/2025,"Vivswan Shah, Randy Cogill, Hanwei Yue, Gopinath Chennupati, Rinat Khaziev","Fine-tuning LLMs for classification typically maps inputs directly to labels.
We ask whether attaching brief explanations to each label during fine-tuning
yields better models. We evaluate conversational response quality along three
axes: naturalness, comprehensiveness, and on-topic adherence, each rated on
5-point scales. Using ensemble-generated data from multiple LLMs, we fine-tune
a 7B-parameter model and test across six diverse conversational datasets.
Across 18 dataset, task settings, label-plus-explanation training outperforms
label-only baselines.
  A central and unexpected result concerns random tokens. We replace
human-written explanations with text that is syntactically incoherent yet
vocabulary-aligned with the originals (e.g., shuffled or bag-of-words
variants). Despite lacking semantics, these pseudo-explanations still improve
accuracy over label-only training and often narrow much of the gap to true
explanations. The effect persists across datasets and training seeds,
indicating that gains arise less from meaning than from structure: the extra
token budget encourages richer intermediate computation and acts as a
regularizer that reduces over-confident shortcuts.
  Internal analyses support this view: explanation-augmented models exhibit
higher activation entropy in intermediate layers alongside sharper predictive
mass at the output layer, consistent with increased deliberation before
decision. Overall, explanation-augmented fine-tuning, whether with genuine
rationales or carefully constructed random token sequences, improves accuracy
and reliability for LLM classification while clarifying how token-level
scaffolding shapes computation during inference.",http://arxiv.org/pdf/2511.02044v1,,False
Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure,03/11/2025,"Zhi Wang, Chicheng Zhang, Ramya Korlakai Vinayak","In lifelong learning, a learner faces a sequence of tasks with shared
structure and aims to identify and leverage it to accelerate learning. We study
the setting where such structure is captured by a common representation of
data. Unlike multi-task learning or learning-to-learn, where tasks are
available upfront to learn the representation, lifelong learning requires the
learner to make use of its existing knowledge while continually gathering
partial information in an online fashion. In this paper, we consider a
generalized framework of lifelong representation learning. We propose a simple
algorithm that uses multi-task empirical risk minimization as a subroutine and
establish a sample complexity bound based on a new notion we introduce--the
task-eluder dimension. Our result applies to a wide range of learning problems
involving general function classes. As concrete examples, we instantiate our
result on classification and regression tasks under noise.",http://arxiv.org/pdf/2511.01847v1,,False
Towards Multi-Fidelity Scaling Laws of Neural Surrogates in CFD,03/11/2025,"Paul Setinek, Gianluca Galletti, Johannes Brandstetter","Scaling laws describe how model performance grows with data, parameters and
compute. While large datasets can usually be collected at relatively low cost
in domains such as language or vision, scientific machine learning is often
limited by the high expense of generating training data through numerical
simulations. However, by adjusting modeling assumptions and approximations,
simulation fidelity can be traded for computational cost, an aspect absent in
other domains. We investigate this trade-off between data fidelity and cost in
neural surrogates using low- and high-fidelity Reynolds-Averaged Navier-Stokes
(RANS) simulations. Reformulating classical scaling laws, we decompose the
dataset axis into compute budget and dataset composition. Our experiments
reveal compute-performance scaling behavior and exhibit budget-dependent
optimal fidelity mixes for the given dataset configuration. These findings
provide the first study of empirical scaling laws for multi-fidelity neural
surrogate datasets and offer practical considerations for compute-efficient
dataset generation in scientific machine learning.",http://arxiv.org/pdf/2511.01830v1,,False
GenDexHand: Generative Simulation for Dexterous Hands,03/11/2025,"Feng Chen, Zhuxiu Xu, Tianzhe Chu, Xunzhe Zhou, Li Sun, Zewen Wu, Shenghua Gao, Zhongyu Li, Yanchao Yang, Yi Ma","Data scarcity remains a fundamental bottleneck for embodied intelligence.
Existing approaches use large language models (LLMs) to automate gripper-based
simulation generation, but they transfer poorly to dexterous manipulation,
which demands more specialized environment design. Meanwhile, dexterous
manipulation tasks are inherently more difficult due to their higher degrees of
freedom. Massively generating feasible and trainable dexterous hand tasks
remains an open challenge. To this end, we present GenDexHand, a generative
simulation pipeline that autonomously produces diverse robotic tasks and
environments for dexterous manipulation. GenDexHand introduces a closed-loop
refinement process that adjusts object placements and scales based on
vision-language model (VLM) feedback, substantially improving the average
quality of generated environments. Each task is further decomposed into
sub-tasks to enable sequential reinforcement learning, reducing training time
and increasing success rates. Our work provides a viable path toward scalable
training of diverse dexterous hand behaviors in embodied intelligence by
offering a simulation-based solution to synthetic data generation. Our website:
https://winniechen2002.github.io/GenDexHand/.",http://arxiv.org/pdf/2511.01791v1,,False
How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment,03/11/2025,"Zhen Chen, Qing Xu, Jinlin Wu, Biao Yang, Yuhao Zhai, Geng Guo, Jing Zhang, Yinlu Ding, Nassir Navab, Jiebo Luo","Foundation models in video generation are demonstrating remarkable
capabilities as potential world models for simulating the physical world.
However, their application in high-stakes domains like surgery, which demand
deep, specialized causal knowledge rather than general physical rules, remains
a critical unexplored gap. To systematically address this challenge, we present
SurgVeo, the first expert-curated benchmark for video generation model
evaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel,
four-tiered framework tailored to assess model outputs from basic appearance to
complex surgical strategy. On the basis of the SurgVeo benchmark, we task the
advanced Veo-3 model with a zero-shot prediction task on surgical clips from
laparoscopic and neurosurgical procedures. A panel of four board-certified
surgeons evaluates the generated videos according to the SPP. Our results
reveal a distinct ""plausibility gap"": while Veo-3 achieves exceptional Visual
Perceptual Plausibility, it fails critically at higher levels of the SPP,
including Instrument Operation Plausibility, Environment Feedback Plausibility,
and Surgical Intent Plausibility. This work provides the first quantitative
evidence of the chasm between visually convincing mimicry and causal
understanding in surgical AI. Our findings from SurgVeo and the SPP establish a
crucial foundation and roadmap for developing future models capable of
navigating the complexities of specialized, real-world healthcare domains.",http://arxiv.org/pdf/2511.01775v1,,False
Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement,03/11/2025,"Sekh Mainul Islam, Pepa Atanasova, Isabelle Augenstein","Natural Language Explanations (NLEs) describe how Large Language Models
(LLMs) make decisions, drawing on both external Context Knowledge (CK) and
Parametric Knowledge (PK) stored in model weights. Understanding their
interaction is key to assessing the grounding of NLEs, yet it remains
underexplored. Prior work has largely examined only single-step generation,
typically the final answer, and has modelled PK and CK interaction only as a
binary choice in a rank-1 subspace. This overlooks richer forms of interaction,
such as complementary or supportive knowledge. We propose a novel rank-2
projection subspace that disentangles PK and CK contributions more accurately
and use it for the first multi-step analysis of knowledge interactions across
longer NLE sequences. Experiments on four QA datasets and three open-weight
instruction-tuned LLMs show that diverse knowledge interactions are poorly
represented in a rank-1 subspace but are effectively captured in our rank-2
formulation. Our multi-step analysis reveals that hallucinated NLEs align
strongly with the PK direction, context-faithful ones balance PK and CK, and
Chain-of-Thought prompting for NLEs shifts generated NLEs toward CK by reducing
PK reliance. This work provides the first framework for systematic studies of
multi-step knowledge interactions in LLMs through a richer rank-2 subspace
disentanglement. Code and data:
https://github.com/copenlu/pk-ck-knowledge-disentanglement.",http://arxiv.org/pdf/2511.01706v1,,False
Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding,03/11/2025,"Jungyeon Koh, Hyun Jong Yang","The growing demand for on-device large language model (LLM) inference
highlights the need for efficient mobile edge computing (MEC) solutions,
especially in resource-constrained settings. Speculative decoding offers a
promising solution by partitioning token generation between a lightweight draft
model on mobile devices and a powerful target model on edge servers, but
suffers from communication overhead and asynchronous delays. This paper is the
first to propose a unified framework that jointly optimizes user association
and resource allocation (UARA) to support efficient parallel speculative
decoding. We solve the UARA problem using a multi-agent deep reinforcement
learning algorithm. To evaluate our approach under realistic conditions, we
conduct experiments using the Sionna simulator. Results show that our method
achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency
without compromising inference accuracy, enabling scalable and low-latency LLM
services in MEC systems.",http://arxiv.org/pdf/2511.01695v2,,False
Driving scenario generation and evaluation using a structured layer representation and foundational models,03/11/2025,"Arthur Hubert, Gamal Elghazaly, Raphaël Frank","Rare and challenging driving scenarios are critical for autonomous vehicle
development. Since they are difficult to encounter, simulating or generating
them using generative models is a popular approach. Following previous efforts
to structure driving scenario representations in a layer model, we propose a
structured five-layer model to improve the evaluation and generation of rare
scenarios. We use this model alongside large foundational models to generate
new driving scenarios using a data augmentation strategy. Unlike previous
representations, our structure introduces subclasses and characteristics for
every agent of the scenario, allowing us to compare them using an embedding
specific to our layer-model. We study and adapt two metrics to evaluate the
relevance of a synthetic dataset in the context of a structured representation:
the diversity score estimates how different the scenarios of a dataset are from
one another, while the originality score calculates how similar a synthetic
dataset is from a real reference set. This paper showcases both metrics in
different generation setup, as well as a qualitative evaluation of synthetic
videos generated from structured scenario descriptions. The code and extended
results can be found at https://github.com/Valgiz/5LMSG.",http://arxiv.org/pdf/2511.01541v1,,False
NeuroClean: A Generalized Machine-Learning Approach to Neural Time-Series Conditioning,03/11/2025,"Manuel A. Hernandez Alonso, Michael Depass, Stephan Quessy, Numa Dancause, Ignasi Cos","Electroencephalography (EEG) and local field potentials (LFP) are two widely
used techniques to record electrical activity from the brain. These signals are
used in both the clinical and research domains for multiple applications.
However, most brain data recordings suffer from a myriad of artifacts and noise
sources other than the brain itself. Thus, a major requirement for their use is
proper and, given current volumes of data, a fully automatized conditioning. As
a means to this end, here we introduce an unsupervised, multipurpose EEG/LFP
preprocessing method, the NeuroClean pipeline. In addition to its completeness
and reliability, NeuroClean is an unsupervised series of algorithms intended to
mitigate reproducibility issues and biases caused by human intervention. The
pipeline is designed as a five-step process, including the common bandpass and
line noise filtering, and bad channel rejection. However, it incorporates an
efficient independent component analysis with an automatic component rejection
based on a clustering algorithm. This machine learning classifier is used to
ensure that task-relevant information is preserved after each step of the
cleaning process. We used several data sets to validate the pipeline.
NeuroClean removed several common types of artifacts from the signal. Moreover,
in the context of motor tasks of varying complexity, it yielded more than 97%
accuracy (vs. a chance-level of 33.3%) in an optimized Multinomial Logistic
Regression model after cleaning the data, compared to the raw data, which
performed at 74% accuracy. These results show that NeuroClean is a promising
pipeline and workflow that can be applied to future work and studies to achieve
better generalization and performance on machine learning pipelines.",http://arxiv.org/pdf/2511.01951v1,,False
MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments,03/11/2025,"Cankut Bora Tuncer, Marc Toussaint, Ozgur S. Oguz","In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided
Manipulation planner for highly constrained rearrangement problems. MO-SeGMan
generates object placement sequences that minimize both replanning per object
and robot travel distance while preserving critical dependency structures with
a lazy evaluation method. To address highly cluttered, non-monotone scenarios,
we propose a Selective Guided Forward Search (SGFS) that efficiently relocates
only critical obstacles and to feasible relocation points. Furthermore, we
adopt a refinement method for adaptive subgoal selection to eliminate
unnecessary pick-and-place actions, thereby improving overall solution quality.
Extensive evaluations on nine benchmark rearrangement tasks demonstrate that
MO-SeGMan generates feasible motion plans in all cases, consistently achieving
faster solution times and superior solution quality compared to the baselines.
These results highlight the robustness and scalability of the proposed
framework for complex rearrangement planning problems.",http://arxiv.org/pdf/2511.01476v1,,False
Split-Flows: Measure Transport and Information Loss Across Molecular Resolutions,03/11/2025,"Sander Hummerich, Tristan Bereau, Ullrich Köthe","By reducing resolution, coarse-grained models greatly accelerate molecular
simulations, unlocking access to long-timescale phenomena, though at the
expense of microscopic information. Recovering this fine-grained detail is
essential for tasks that depend on atomistic accuracy, making backmapping a
central challenge in molecular modeling. We introduce split-flows, a novel
flow-based approach that reinterprets backmapping as a continuous-time measure
transport across resolutions. Unlike existing generative strategies,
split-flows establish a direct probabilistic link between resolutions, enabling
expressive conditional sampling of atomistic structures and -- for the first
time -- a tractable route to computing mapping entropies, an
information-theoretic measure of the irreducible detail lost in
coarse-graining. We demonstrate these capabilities on diverse molecular
systems, including chignolin, a lipid bilayer, and alanine dipeptide,
highlighting split-flows as a principled framework for accurate backmapping and
systematic evaluation of coarse-grained models.",http://arxiv.org/pdf/2511.01464v1,,False
Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm,03/11/2025,"Amrapali Pednekar, Álvaro Garrido-Pérez, Yara Khaluf, Pieter Simoens","This study explores the interference in temporal processing within a
dual-task paradigm from an artificial intelligence (AI) perspective. In this
context, the dual-task setup is implemented as a simplified version of the
Overcooked environment with two variations, single task (T) and dual task
(T+N). Both variations involve an embedded time production task, but the dual
task (T+N) additionally involves a concurrent number comparison task. Two deep
reinforcement learning (DRL) agents were separately trained for each of these
tasks. These agents exhibited emergent behavior consistent with human timing
research. Specifically, the dual task (T+N) agent exhibited significant
overproduction of time relative to its single task (T) counterpart. This result
was consistent across four target durations. Preliminary analysis of neural
dynamics in the agents' LSTM layers did not reveal any clear evidence of a
dedicated or intrinsic timer. Hence, further investigation is needed to better
understand the underlying time-keeping mechanisms of the agents and to provide
insights into the observed behavioral patterns. This study is a small step
towards exploring parallels between emergent DRL behavior and behavior observed
in biological systems in order to facilitate a better understanding of both.",http://arxiv.org/pdf/2511.01415v1,,False
FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths,03/11/2025,"Paolo Rabino, Gabriele Tiboni, Tatiana Tommasi","Object-Centric Motion Generation (OCMG) is instrumental in advancing
automated manufacturing processes, particularly in domains requiring
high-precision expert robotic motions, such as spray painting and welding. To
realize effective automation, robust algorithms are essential for generating
extended, object-aware trajectories across intricate 3D geometries. However,
contemporary OCMG techniques are either based on ad-hoc heuristics or employ
learning-based pipelines that are still reliant on sensitive post-processing
steps to generate executable paths. We introduce FoldPath, a novel, end-to-end,
neural field based method for OCMG. Unlike prior deep learning approaches that
predict discrete sequences of end-effector waypoints, FoldPath learns the robot
motion as a continuous function, thus implicitly encoding smooth output paths.
This paradigm shift eliminates the need for brittle post-processing steps that
concatenate and order the predicted discrete waypoints. Particularly, our
approach demonstrates superior predictive performance compared to recently
proposed learning-based methods, and attains generalization capabilities even
in real industrial settings, where only a limited amount of 70 expert samples
are provided. We validate FoldPath through comprehensive experiments in a
realistic simulation environment and introduce new, rigorous metrics designed
to comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG
task towards practical maturity.",http://arxiv.org/pdf/2511.01407v1,,False
Beyond Permissions: Investigating Mobile Personalization with Simulated Personas,03/11/2025,"Ibrahim Khalilov, Chaoran Chen, Ziang Xiao, Tianshi Li, Toby Jia-Jun Li, Yaxing Yao","Mobile applications increasingly rely on sensor data to infer user context
and deliver personalized experiences. Yet the mechanisms behind this
personalization remain opaque to users and researchers alike. This paper
presents a sandbox system that uses sensor spoofing and persona simulation to
audit and visualize how mobile apps respond to inferred behaviors. Rather than
treating spoofing as adversarial, we demonstrate its use as a tool for
behavioral transparency and user empowerment. Our system injects multi-sensor
profiles - generated from structured, lifestyle-based personas - into Android
devices in real time, enabling users to observe app responses to contexts such
as high activity, location shifts, or time-of-day changes. With automated
screenshot capture and GPT-4 Vision-based UI summarization, our pipeline helps
document subtle personalization cues. Preliminary findings show measurable app
adaptations across fitness, e-commerce, and everyday service apps such as
weather and navigation. We offer this toolkit as a foundation for
privacy-enhancing technologies and user-facing transparency interventions.",http://arxiv.org/pdf/2511.01336v1,10.1145/3733816.3760758,False
"Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models",03/11/2025,"Tae-Young Lee, Juwon Seo, Jong Hwan Ko, Gyeong-Moon Park","Recent advances in diffusion models have enabled high-quality synthesis of
specific subjects, such as identities or objects. This capability, while
unlocking new possibilities in content creation, also introduces significant
privacy risks, as personalization techniques can be misused by malicious users
to generate unauthorized content. Although several studies have attempted to
counter this by generating adversarially perturbed samples designed to disrupt
personalization, they rely on unrealistic assumptions and become ineffective in
the presence of even a few clean images or under simple image transformations.
To address these challenges, we shift the protection target from the images to
the diffusion model itself to hinder the personalization of specific subjects,
through our novel framework called Anti-Personalized Diffusion Models (APDM).
We first provide a theoretical analysis demonstrating that a naive approach of
existing loss functions to diffusion models is inherently incapable of ensuring
convergence for robust anti-personalization. Motivated by this finding, we
introduce Direct Protective Optimization (DPO), a novel loss function that
effectively disrupts subject personalization in the target model without
compromising generative quality. Moreover, we propose a new dual-path
optimization strategy, coined Learning to Protect (L2P). By alternating between
personalization and protection paths, L2P simulates future personalization
trajectories and adaptively reinforces protection at each step. Experimental
results demonstrate that our framework outperforms existing methods, achieving
state-of-the-art performance in preventing unauthorized personalization. The
code is available at https://github.com/KU-VGI/APDM.",http://arxiv.org/pdf/2511.01307v1,,False
Optimal Attention Temperature Enhances In-Context Learning under Distribution Shift,03/11/2025,"Samet Demir, Zafer Dogan","Pretrained Transformers excel at in-context learning (ICL), inferring new
tasks from only a handful of examples. Yet, their ICL performance can degrade
sharply under distribution shift between pretraining and test data, a regime
increasingly common in real-world deployments. While recent empirical work
hints that adjusting the attention temperature in the softmax can enhance
Transformer performance, the attention temperature's role in ICL under
distribution shift remains unexplored. This paper provides the first
theoretical and empirical study of attention temperature for ICL under
distribution shift. Using a simplified but expressive ""linearized softmax""
framework, we derive closed-form generalization error expressions and prove
that shifts in input covariance or label noise substantially impair ICL, but
that an optimal attention temperature exists which minimizes this error. We
then validate our predictions through extensive simulations on linear
regression tasks and large-scale experiments with GPT-2 and LLaMA2-7B on
question-answering benchmarks. Our results establish attention temperature as a
principled and powerful mechanism for improving the robustness of ICL in
pretrained Transformers, advancing theoretical understanding and providing
actionable guidance for selecting attention temperature in practice.",http://arxiv.org/pdf/2511.01292v1,,False
Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting,03/11/2025,"Zan Li, Kyongmin Yeo, Wesley Gifford, Lara Marcuse, Madeline Fields, Bülent Yener","Forecasting epileptic seizures from multivariate EEG signals represents a
critical challenge in healthcare time series prediction, requiring high
sensitivity, low false alarm rates, and subject-specific adaptability. We
present STAN, an Adversarial Spatio-Temporal Attention Network that jointly
models spatial brain connectivity and temporal neural dynamics through cascaded
attention blocks with alternating spatial and temporal modules. Unlike existing
approaches that assume fixed preictal durations or separately process spatial
and temporal features, STAN captures bidirectional dependencies between spatial
and temporal patterns through a unified cascaded architecture. Adversarial
training with gradient penalty enables robust discrimination between interictal
and preictal states learned from clearly defined 15-minute preictal windows.
Continuous 90-minute pre-seizure monitoring reveals that the learned
spatio-temporal attention patterns enable early detection: reliable alarms
trigger at subject-specific times (typically 15-45 minutes before onset),
reflecting the model's capacity to capture subtle preictal dynamics without
requiring individualized training. Experiments on two benchmark EEG datasets
(CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14
events) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011
false detections per hour and 94.2% sensitivity with 0.063 false detections per
hour, respectively, while maintaining computational efficiency (2.3M
parameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond
epilepsy, the proposed framework provides a general paradigm for
spatio-temporal forecasting in healthcare and other time series domains where
individual heterogeneity and interpretability are crucial.",http://arxiv.org/pdf/2511.01275v1,,False
MotionStream: Real-Time Video Generation with Interactive Motion Controls,03/11/2025,"Joonghyuk Shin, Zhengqi Li, Richard Zhang, Jun-Yan Zhu, Jaesik Park, Eli Schechtman, Xun Huang","Current motion-conditioned video generation methods suffer from prohibitive
latency (minutes per video) and non-causal processing that prevents real-time
interaction. We present MotionStream, enabling sub-second latency with up to 29
FPS streaming generation on a single GPU. Our approach begins by augmenting a
text-to-video model with motion control, which generates high-quality videos
that adhere to the global text prompt and local motion guidance, but does not
perform inference on the fly. As such, we distill this bidirectional teacher
into a causal student through Self Forcing with Distribution Matching
Distillation, enabling real-time streaming inference. Several key challenges
arise when generating videos of long, potentially infinite time-horizons: (1)
bridging the domain gap from training on finite length and extrapolating to
infinite horizons, (2) sustaining high quality by preventing error
accumulation, and (3) maintaining fast inference, without incurring growth in
computational cost due to increasing context windows. A key to our approach is
introducing carefully designed sliding-window causal attention, combined with
attention sinks. By incorporating self-rollout with attention sinks and KV
cache rolling during training, we properly simulate inference-time
extrapolations with a fixed context window, enabling constant-speed generation
of arbitrarily long videos. Our models achieve state-of-the-art results in
motion following and video quality while being two orders of magnitude faster,
uniquely enabling infinite-length streaming. With MotionStream, users can paint
trajectories, control cameras, or transfer motion, and see results unfold in
real-time, delivering a truly interactive experience.",http://arxiv.org/pdf/2511.01266v1,,False
WindMiL: Equivariant Graph Learning for Wind Loading Prediction,03/11/2025,"Themistoklis Vargiemezis, Charilaos Kanatsoulis, Catherine Gorlé","Accurate prediction of wind loading on buildings is crucial for structural
safety and sustainable design, yet conventional approaches such as wind tunnel
testing and large-eddy simulation (LES) are prohibitively expensive for
large-scale exploration. Each LES case typically requires at least 24 hours of
computation, making comprehensive parametric studies infeasible. We introduce
WindMiL, a new machine learning framework that combines systematic dataset
generation with symmetry-aware graph neural networks (GNNs). First, we
introduce a large-scale dataset of wind loads on low-rise buildings by applying
signed distance function interpolation to roof geometries and simulating 462
cases with LES across varying shapes and wind directions. Second, we develop a
reflection-equivariant GNN that guarantees physically consistent predictions
under mirrored geometries. Across interpolation and extrapolation evaluations,
WindMiL achieves high accuracy for both the mean and the standard deviation of
surface pressure coefficients (e.g., RMSE $\leq 0.02$ for mean $C_p$) and
remains accurate under reflected-test evaluation, maintaining hit rates above
$96\%$ where the non-equivariant baseline model drops by more than $10\%$. By
pairing a systematic dataset with an equivariant surrogate, WindMiL enables
efficient, scalable, and accurate predictions of wind loads on buildings.",http://arxiv.org/pdf/2511.01226v1,,False
An Interdisciplinary and Cross-Task Review on Missing Data Imputation,03/11/2025,Jicong Fan,"Missing data is a fundamental challenge in data science, significantly
hindering analysis and decision-making across a wide range of disciplines,
including healthcare, bioinformatics, social science, e-commerce, and
industrial monitoring. Despite decades of research and numerous imputation
methods, the literature remains fragmented across fields, creating a critical
need for a comprehensive synthesis that connects statistical foundations with
modern machine learning advances. This work systematically reviews core
concepts-including missingness mechanisms, single versus multiple imputation,
and different imputation goals-and examines problem characteristics across
various domains. It provides a thorough categorization of imputation methods,
spanning classical techniques (e.g., regression, the EM algorithm) to modern
approaches like low-rank and high-rank matrix completion, deep learning models
(autoencoders, GANs, diffusion models, graph neural networks), and large
language models. Special attention is given to methods for complex data types,
such as tensors, time series, streaming data, graph-structured data,
categorical data, and multimodal data. Beyond methodology, we investigate the
crucial integration of imputation with downstream tasks like classification,
clustering, and anomaly detection, examining both sequential pipelines and
joint optimization frameworks. The review also assesses theoretical guarantees,
benchmarking resources, and evaluation metrics. Finally, we identify critical
challenges and future directions, emphasizing model selection and
hyperparameter optimization, the growing importance of privacy-preserving
imputation via federated learning, and the pursuit of generalizable models that
can adapt across domains and data types, thereby outlining a roadmap for future
research.",http://arxiv.org/pdf/2511.01196v1,,False
ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction,03/11/2025,"Lvhua Wu, Xuefeng Jiang, Sheng Sun, Tian Wen, Yuwei Wang, Min Liu","The rapid spread of fake news threatens social stability and public trust,
rendering its detection an imperative research priority. Although large
language models (LLMs) excel at numerous natural language processing tasks with
their remarkable contextual understanding and extensive prior knowledge, the
time-bounded knowledge coverage and tendency for generating hallucination
content reduce their reliability when handling fast-evolving news streams.
Furthermore, models trained on existing static datasets also often lack the
generalization needed for emerging news topics. To address these challenges, we
propose ZoFia, a novel two-stage zero-shot fake news detection framework.
First, we introduce Hierarchical Salience to quantify the importance of
entities in the news content, and propose the SC-MMR algorithm to effectively
select an informative and diverse set of keywords that serve as queries for
retrieving up-to-date external evidence. Subsequently, a multi LLM interactive
system, in which each agent assumes a distinct role, performs multi-view
collaborative analysis and adversarial debate over the news text and its
related information, and finally produces an interpretable and robust judgment.
Comprehensive experiments on two public datasets demonstrate that ZoFia
obviously outperforms existing zero-shot baselines and most of few-shot
methods. Our codes will be open-sourced to facilitate related communities.",http://arxiv.org/pdf/2511.01188v1,,False
