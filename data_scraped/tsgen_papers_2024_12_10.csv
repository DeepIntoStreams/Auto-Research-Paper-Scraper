Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
AnyBimanual: Transferring Unimanual Policy for General Bimanual Manipulation,09/12/2024,"Guanxing Lu, Tengbo Yu, Haoyuan Deng, Season Si Chen, Yansong Tang, Ziwei Wang","Performing general language-conditioned bimanual manipulation tasks is of
great importance for many applications ranging from household service to
industrial assembly. However, collecting bimanual manipulation data is
expensive due to the high-dimensional action space, which poses challenges for
conventional methods to handle general bimanual manipulation tasks. In
contrast, unimanual policy has recently demonstrated impressive
generalizability across a wide range of tasks because of scaled model
parameters and training data, which can provide sharable manipulation knowledge
for bimanual systems. To this end, we propose a plug-and-play method named
AnyBimanual, which transfers pre-trained unimanual policy to general bimanual
manipulation policy with few bimanual demonstrations. Specifically, we first
introduce a skill manager to dynamically schedule the skill representations
discovered from pre-trained unimanual policy for bimanual manipulation tasks,
which linearly combines skill primitives with task-oriented compensation to
represent the bimanual manipulation instruction. To mitigate the observation
discrepancy between unimanual and bimanual systems, we present a visual aligner
to generate soft masks for visual embedding of the workspace, which aims to
align visual input of unimanual policy model for each arm with those during
pretraining stage. AnyBimanual shows superiority on 12 simulated tasks from
RLBench2 with a sizable 12.67% improvement in success rate over previous
methods. Experiments on 9 real-world tasks further verify its practicality with
an average success rate of 84.62%.",http://arxiv.org/pdf/2412.06779v1,,False
Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework,09/12/2024,"Tianming Liu, Jirong Yang, Yafeng Yin","In transportation system demand modeling and simulation, agent-based models
and microsimulations are current state-of-the-art approaches. However, existing
agent-based models still have some limitations on behavioral realism and
resource demand that limit their applicability. In this study, leveraging the
emerging technology of large language models (LLMs) and LLM-based agents, we
propose a general LLM-agent-based modeling framework for transportation
systems. We argue that LLM agents not only possess the essential capabilities
to function as agents but also offer promising solutions to overcome some
limitations of existing agent-based models. Our conceptual framework design
closely replicates the decision-making and interaction processes and traits of
human travelers within transportation networks, and we demonstrate that the
proposed systems can meet critical behavioral criteria for decision-making and
learning behaviors using related studies and a demonstrative example of LLM
agents' learning and adjustment in the bottleneck setting. Although further
refinement of the LLM-agent-based modeling framework is necessary, we believe
that this approach has the potential to improve transportation system modeling
and simulation.",http://arxiv.org/pdf/2412.06681v1,,False
The Narrow Gate: Localized Image-Text Communication in Vision-Language Models,09/12/2024,"Alessandro Serra, Francesco Ortu, Emanuele Panizon, Lucrezia Valeriani, Lorenzo Basile, Alessio Ansuini, Diego Doimo, Alberto Cazzaniga","Recent advances in multimodal training have significantly improved the
integration of image understanding and generation within a unified model. This
study investigates how vision-language models (VLMs) handle image-understanding
tasks, specifically focusing on how visual information is processed and
transferred to the textual domain. We compare VLMs that generate both images
and text with those that output only text, highlighting key differences in
information flow. We find that in models with multimodal outputs, image and
text embeddings are more separated within the residual stream. Additionally,
models vary in how information is exchanged from visual to textual tokens. VLMs
that only output text exhibit a distributed communication pattern, where
information is exchanged through multiple image tokens. In contrast, models
trained for image and text generation rely on a single token that acts as a
narrow gate for the visual information. We demonstrate that ablating this
single token significantly deteriorates performance on image understanding
tasks. Furthermore, modifying this token enables effective steering of the
image semantics, showing that targeted, local interventions can reliably
control the model's global behavior.",http://arxiv.org/pdf/2412.06646v1,,False
SimuDICE: Offline Policy Optimization Through World Model Updates and DICE Estimation,09/12/2024,"Catalin E. Brita, Stephan Bongers, Frans A. Oliehoek","In offline reinforcement learning, deriving an effective policy from a
pre-collected set of experiences is challenging due to the distribution
mismatch between the target policy and the behavioral policy used to collect
the data, as well as the limited sample size. Model-based reinforcement
learning improves sample efficiency by generating simulated experiences using a
learned dynamic model of the environment. However, these synthetic experiences
often suffer from the same distribution mismatch. To address these challenges,
we introduce SimuDICE, a framework that iteratively refines the initial policy
derived from offline data using synthetically generated experiences from the
world model. SimuDICE enhances the quality of these simulated experiences by
adjusting the sampling probabilities of state-action pairs based on stationary
DIstribution Correction Estimation (DICE) and the estimated confidence in the
model's predictions. This approach guides policy improvement by balancing
experiences similar to those frequently encountered with ones that have a
distribution mismatch. Our experiments show that SimuDICE achieves performance
comparable to existing algorithms while requiring fewer pre-collected
experiences and planning steps, and it remains robust across varying data
collection policies.",http://arxiv.org/pdf/2412.06486v1,,False
An inferential measure of dependence between two systems using Bayesian model comparison,09/12/2024,"Guillaume Marrelec, Alain Giron","We propose to quantify dependence between two systems $X$ and $Y$ in a
dataset $D$ based on the Bayesian comparison of two models: one, $H_0$, of
statistical independence and another one, $H_1$, of dependence. In this
framework, dependence between $X$ and $Y$ in $D$, denoted $B(X,Y|D)$, is
quantified as $P(H_1|D)$, the posterior probability for the model of dependence
given $D$, or any strictly increasing function thereof. It is therefore a
measure of the evidence for dependence between $X$ and $Y$ as modeled by $H_1$
and observed in $D$. We review several statistical models and reconsider
standard results in the light of $B(X,Y|D)$ as a measure of dependence. Using
simulations, we focus on two specific issues: the effect of noise and the
behavior of $B(X,Y|D)$ when $H_1$ has a parameter coding for the intensity of
dependence. We then derive some general properties of $B(X,Y|D)$, showing that
it quantifies the information contained in $D$ in favor of $H_1$ versus $H_0$.
While some of these properties are typical of what is expected from a valid
measure of dependence, others are novel and naturally appear as desired
features for specific measures of dependence, which we call inferential. We
finally put these results in perspective; in particular, we discuss the
consequences of using the Bayesian framework as well as the similarities and
differences between $B(X,Y|D)$ and mutual information.",http://arxiv.org/pdf/2412.06478v1,,False
Echocardiography to Cardiac MRI View Transformation for Real-Time Blind Restoration,09/12/2024,"Ilke Adalioglu, Serkan Kiranyaz, Mete Ahishali, Aysen Degerli, Tahir Hamid, Rahmat Ghaffar, Ridha Hamila, Moncef Gabbouj","Echocardiography is the most widely used imaging to monitor cardiac
functions, serving as the first line in early detection of myocardial ischemia
and infarction. However, echocardiography often suffers from several artifacts
including sensor noise, lack of contrast, severe saturation, and missing
myocardial segments which severely limit its usage in clinical diagnosis. In
recent years, several machine learning methods have been proposed to improve
echocardiography views. Yet, these methods usually address only a specific
problem (e.g. denoising) and thus cannot provide a robust and reliable
restoration in general. On the other hand, cardiac MRI provides a clean view of
the heart without suffering such severe issues. However, due to its
significantly higher cost, it is often only afforded by a few major hospitals,
hence hindering its use and accessibility. In this pilot study, we propose a
novel approach to transform echocardiography into the cardiac MRI view. For
this purpose, Echo2MRI dataset, consisting of echocardiography and real cardiac
MRI image pairs, is composed and will be shared publicly. A dedicated
Cycle-consistent Generative Adversarial Network (Cycle-GAN) is trained to learn
the transformation from echocardiography frames to cardiac MRI views. An
extensive set of qualitative evaluations shows that the proposed transformer
can synthesize high-quality artifact-free synthetic cardiac MRI views from a
given sequence of echocardiography frames. Medical evaluations performed by a
group of cardiologists further demonstrate that synthetic MRI views are
indistinguishable from their original counterparts and are preferred over their
initial sequence of echocardiography frames for diagnosis in 78.9% of the
cases.",http://arxiv.org/pdf/2412.06445v1,,False
Simulating Human-like Daily Activities with Desire-driven Autonomy,09/12/2024,"Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang","Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.",http://arxiv.org/pdf/2412.06435v1,,False
Systematic comparison of deep generative models applied to multivariate financial time series,09/12/2024,"Howard Caulfield, James P. Gleeson","Financial time series (FTS) generation models are a core pillar to
applications in finance. Risk management and portfolio optimization rely on
realistic multivariate price generation models. Accordingly, there is a strong
modelling literature dating back to Bachelier's Theory of Speculation in 1901.
Generating FTS using deep generative models (DGMs) is still in its infancy. In
this work, we systematically compare DGMs against state-of-the-art parametric
alternatives for multivariate FTS generation. We initially compare both DGMs
and parametric models over increasingly complex synthetic datasets. The models
are evaluated through distance measures for varying distribution moments of
both the full and rolling FTS. We then apply the best performing DGM models to
empirical data, demonstrating the benefit of DGMs through a implied volatility
trading task.",http://arxiv.org/pdf/2412.06417v1,,False
Exploring the Impact of Synthetic Data on Human Gesture Recognition Tasks Using GANs,09/12/2024,"George Kontogiannis, Pantelis Tzamalis, Sotiris Nikoletseas","In the evolving domain of Human Activity Recognition (HAR) using Internet of
Things (IoT) devices, there is an emerging interest in employing Deep
Generative Models (DGMs) to address data scarcity, enhance data quality, and
improve classification metrics scores. Among these types of models, Generative
Adversarial Networks (GANs) have arisen as a powerful tool for generating
synthetic data that mimic real-world scenarios with high fidelity. However,
Human Gesture Recognition (HGR), a subset of HAR, particularly in healthcare
applications, using time series data such as allergic gestures, remains highly
unexplored.
  In this paper, we examine and evaluate the performance of two GANs in the
generation of synthetic gesture motion data that compose a part of an
open-source benchmark dataset. The data is related to the disease
identification domain and healthcare, specifically to allergic rhinitis. We
also focus on these AI models' performance in terms of fidelity, diversity, and
privacy. Furthermore, we examine the scenario if the synthetic data can
substitute real data, in training scenarios and how well models trained on
synthetic data can be generalized for the allergic rhinitis gestures. In our
work, these gestures are related to 6-axes accelerometer and gyroscope data,
serving as multi-variate time series instances, and retrieved from smart
wearable devices. To the best of our knowledge, this study is the first to
explore the feasibility of synthesizing motion gestures for allergic rhinitis
from wearable IoT device data using Generative Adversarial Networks (GANs) and
testing their impact on the generalization of gesture recognition systems. It
is worth noting that, even if our method has been applied to a specific
category of gestures, it is designed to be generalized and can be deployed also
to other motion data in the HGR domain.",http://arxiv.org/pdf/2412.06389v1,10.1109/DCOSS-IoT61029.2024.00064,False
Measuring Pre-training Data Quality without Labels for Time Series Foundation Models,09/12/2024,"Songkang Wen, Vasilii Feofanov, Jianfeng Zhang","Recently, there has been a growing interest in time series foundation models
that generalize across different downstream tasks. A key to strong foundation
models is a diverse pre-training dataset, which is particularly challenging to
collect for time series classification. In this work, we explore the
performance of a contrastive-learning-based foundation model as a function of
the data used for pre-training. We introduce contrastive accuracy, a new
measure to evaluate the quality of the representation space learned by the
foundation model. Our experiments reveal the positive correlation between the
proposed measure and the accuracy of the model on a collection of downstream
tasks. This suggests that the contrastive accuracy can serve as a criterion to
search for time series datasets that can enhance the pre-training and improve
thereby the foundation model's generalization.",http://arxiv.org/pdf/2412.06368v1,,False
Tracking control of latent dynamic systems with application to spacecraft attitude control,09/12/2024,"Congxi Zhang, Yongchun Xie","When intelligent spacecraft or space robots perform tasks in a complex
environment, the controllable variables are usually not directly available and
have to be inferred from high-dimensional observable variables, such as outputs
of neural networks or images. While the dynamics of these observations are
highly complex, the mechanisms behind them may be simple, which makes it
possible to regard them as latent dynamic systems. For control of latent
dynamic systems, methods based on reinforcement learning suffer from sample
inefficiency and generalization problems. In this work, we propose an
asymptotic tracking controller for latent dynamic systems. The latent variables
are related to the high-dimensional observations through an unknown nonlinear
function. The dynamics are unknown but assumed to be affine nonlinear. To
realize asymptotic tracking, an identifiable latent dynamic model is learned to
recover the latents and estimate the dynamics. This training process does not
depend on the goals or reference trajectories. Based on the learned model, we
use a manually designed feedback linearization controller to ensure the
asymptotic tracking property of the closed-loop system. After considering fully
controllable systems, the results are extended to the case that uncontrollable
environmental latents exist. As an application, simulation experiments on a
latent spacecraft attitude dynamic model are conducted to verify the proposed
methods, and the observation noise and control deviation are taken into
consideration.",http://arxiv.org/pdf/2412.06342v1,,False
Optimizing Multi-Task Learning for Enhanced Performance in Large Language Models,09/12/2024,"Zhen Qi, Jiajing Chen, Shuo Wang, Bingying Liu, Hongye Zheng, Chihang Wang","This study aims to explore the performance improvement method of large
language models based on GPT-4 under the multi-task learning framework and
conducts experiments on two tasks: text classification and automatic summary
generation. Through the combined design of shared feature extractors and
task-specific modules, we achieve knowledge-sharing and optimization of
multiple tasks in the same model. The experiment uses multiple subtasks of the
GLUE dataset to compare the performance of the multi-task model with the
single-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and
the classic Bi-LSTM with Attention model. The results show that the proposed
multi-task learning model outperforms other comparison models in terms of text
classification accuracy and ROUGE value of summary generation, demonstrating
the advantages of multi-task learning in improving model generalization ability
and collaborative learning between tasks. The model maintains a stable loss
convergence rate during training, showing good learning efficiency and
adaptability to the test set. This study verifies the applicability of the
multi-task learning framework in large language models, especially in improving
the model's ability to balance different tasks. In the future, with the
combination of large language models and multimodal data and the application of
dynamic task adjustment technology, the framework based on multi-task learning
is expected to play a greater role in practical applications across fields and
provide new ideas for the development of general artificial intelligence.",http://arxiv.org/pdf/2412.06249v1,,False
Query-Efficient Planning with Language Models,09/12/2024,"Gonzalo Gonzalez-Pumariega, Wayne Chen, Kushal Kedia, Sanjiban Choudhury","Planning in complex environments requires an agent to efficiently query a
world model to find a feasible sequence of actions from start to goal. Recent
work has shown that Large Language Models (LLMs), with their rich prior
knowledge and reasoning capabilities, can potentially help with planning by
searching over promising states and adapting to feedback from the world. In
this paper, we propose and study two fundamentally competing frameworks that
leverage LLMs for query-efficient planning. The first uses LLMs as a heuristic
within a search-based planner to select promising nodes to expand and propose
promising actions. The second uses LLMs as a generative planner to propose an
entire sequence of actions from start to goal, query a world model, and adapt
based on feedback. We show that while both approaches improve upon comparable
baselines, using an LLM as a generative planner results in significantly fewer
interactions. Our key finding is that the LLM as a planner can more rapidly
adapt its planning strategies based on immediate feedback than LLM as a
heuristic. We present evaluations and ablations on Robotouille and PDDL
planning benchmarks and discuss connections to existing theory on
query-efficient planning algorithms. Code is available at
https://github.com/portal-cornell/llms-for-planning",http://arxiv.org/pdf/2412.06162v1,,False
PowerMamba: A Deep State Space Model and Comprehensive Benchmark for Time Series Prediction in Electric Power Systems,09/12/2024,"Ali Menati, Fatemeh Doudi, Dileep Kalathil, Le Xie","The electricity sector is undergoing substantial transformations due to the
rising electrification of demand, enhanced integration of renewable energy
resources, and the emergence of new technologies. These changes are rendering
the electric grid more volatile and unpredictable, making it difficult to
maintain reliable operations. In order to address these issues, advanced time
series prediction models are needed for closing the gap between the forecasted
and actual grid outcomes. In this paper, we introduce a multivariate time
series prediction model that combines traditional state space models with deep
learning methods to simultaneously capture and predict the underlying dynamics
of multiple time series. Additionally, we design a time series processing
module that incorporates high-resolution external forecasts into
sequence-to-sequence prediction models, achieving this with negligible
increases in size and no loss of accuracy. We also release an extended dataset
spanning five years of load, electricity price, ancillary service price, and
renewable generation. To complement this dataset, we provide an open-access
toolbox that includes our proposed model, the dataset itself, and several
state-of-the-art prediction models, thereby creating a unified framework for
benchmarking advanced machine learning approaches. Our findings indicate that
the proposed model outperforms existing models across various prediction tasks,
improving state-of-the-art prediction error by an average of 7% and decreasing
model parameters by 43%.",http://arxiv.org/pdf/2412.06112v1,,False
