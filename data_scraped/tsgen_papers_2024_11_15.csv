Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
One-Shot Manipulation Strategy Learning by Making Contact Analogies,14/11/2024,"Yuyao Liu, Jiayuan Mao, Joshua Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling","We present a novel approach, MAGIC (manipulation analogies for generalizable
intelligent contacts), for one-shot learning of manipulation strategies with
fast and extensive generalization to novel objects. By leveraging a reference
action trajectory, MAGIC effectively identifies similar contact points and
sequences of actions on novel objects to replicate a demonstrated strategy,
such as using different hooks to retrieve distant objects of different shapes
and sizes. Our method is based on a two-stage contact-point matching process
that combines global shape matching using pretrained neural features with local
curvature analysis to ensure precise and physically plausible contact points.
We experiment with three tasks including scooping, hanging, and hooking
objects. MAGIC demonstrates superior performance over existing methods,
achieving significant improvements in runtime speed and generalization to
different object categories. Website: https://magic-2024.github.io/ .",http://arxiv.org/pdf/2411.09627v1,,False
Local deployment of large-scale music AI models on commodity hardware,14/11/2024,"Xun Zhou, Charlie Ruan, Zihe Zhao, Tianqi Chen, Chris Donahue","We present the MIDInfinite, a web application capable of generating symbolic
music using a large-scale generative AI model locally on commodity hardware.
Creating this demo involved porting the Anticipatory Music Transformer, a large
language model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine
Learning Compilation (MLC) framework. Once the model is ported, MLC facilitates
inference on a variety of runtimes including C++, mobile, and the browser. We
envision that MLC has the potential to bridge the gap between the landscape of
increasingly capable music AI models and technology more familiar to music
software developers. As a proof of concept, we build a web application that
allows users to generate endless streams of multi-instrumental MIDI in the
browser, either from scratch or conditioned on a prompt. On commodity hardware
(an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster
than real-time playback for 72.9% of generations, and increases to 86.3% with 2
seconds of upfront buffering.",http://arxiv.org/pdf/2411.09625v1,,False
Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control,14/11/2024,"Qianqian Zhang, Ye Hu, Minchae Jung","The rapid advancement of low Earth orbit (LEO) satellite communication
systems has significantly enhanced global connectivity, offering high-capacity,
low-latency services crucial for next-generation applications. However, the
dense configuration of LEO constellations poses challenges in resource
allocation optimization and interference management, complicating coexistence
with other communication systems. To address these limitations, this paper
proposes a novel framework for optimizing the beam scheduling and resource
allocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic
demand, a hybrid beam pattern is employed to enhance the downlink quality of
service and minimize the transmission latency from LEO satellites to ground
user terminals. Additionally, a dynamic co-channel interference (CCI) control
mechanism is developed to mitigate inter-beam interference within the LEO
constellation and limit cross-system interference affecting protected users
from other networks. The problem of user-beam-frequency allocation with power
optimization is formulated as a mixed-integer dynamic programming model and
solved using a low-complexity neural network-based graph generation algorithm.
Simulation results show that the proposed approach outperforms the baseline
methods of full frequency reuse and single-channel transmission, and highlights
the potential for further performance improvement with multi-user
transmissions.",http://arxiv.org/pdf/2411.09600v1,,False
DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing,14/11/2024,"Junjie Zhou, Lin Wang, Qiang Meng, Xiaofan Wang","Generating realistic and diverse road scenarios is essential for autonomous
vehicle testing and validation. Nevertheless, owing to the complexity and
variability of real-world road environments, creating authentic and varied
scenarios for intelligent driving testing is challenging. In this paper, we
propose DiffRoad, a novel diffusion model designed to produce controllable and
high-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities
of diffusion models to synthesize road layouts from white noise through an
inverse denoising process, preserving real-world spatial features. To enhance
the quality of generated scenarios, we design the Road-UNet architecture,
optimizing the balance between backbone and skip connections for high-realism
scenario generation. Furthermore, we introduce a road scenario evaluation
module that screens adequate and reasonable scenarios for intelligent driving
testing using two critical metrics: road continuity and road reasonableness.
Experimental results on multiple real-world datasets demonstrate DiffRoad's
ability to generate realistic and smooth road structures while maintaining the
original distribution. Additionally, the generated scenarios can be fully
automated into the OpenDRIVE format, facilitating generalized autonomous
vehicle simulation testing. DiffRoad provides a rich and diverse scenario
library for large-scale autonomous vehicle testing and offers valuable insights
for future infrastructure designs that are better suited for autonomous
vehicles.",http://arxiv.org/pdf/2411.09451v1,,False
A survey of probabilistic generative frameworks for molecular simulations,14/11/2024,"Richard John, Lukas Herron, Pratyush Tiwary","Generative artificial intelligence is now a widely used tool in molecular
science. Despite the popularity of probabilistic generative models, numerical
experiments benchmarking their performance on molecular data are lacking. In
this work, we introduce and explain several classes of generative models,
broadly sorted into two categories: flow-based models and diffusion models. We
select three representative models: Neural Spline Flows, Conditional Flow
Matching, and Denoising Diffusion Probabilistic Models, and examine their
accuracy, computational cost, and generation speed across datasets with tunable
dimensionality, complexity, and modal asymmetry. Our findings are varied, with
no one framework being the best for all purposes. In a nutshell, (i) Neural
Spline Flows do best at capturing mode asymmetry present in low-dimensional
data, (ii) Conditional Flow Matching outperforms other models for
high-dimensional data with low complexity, and (iii) Denoising Diffusion
Probabilistic Models appears the best for low-dimensional data with high
complexity. Our datasets include a Gaussian mixture model and the dihedral
torsion angle distribution of the Aib\textsubscript{9} peptide, generated via a
molecular dynamics simulation. We hope our taxonomy of probabilistic generative
frameworks and numerical results may guide model selection for a wide range of
molecular tasks.",http://arxiv.org/pdf/2411.09388v1,,False
Approximate Probabilistic Inference forTime-Series Data A Robust Latent Gaussian Model With Temporal Awareness,14/11/2024,"Anton Johansson, Arunselvan Ramaswamy","The development of robust generative models for highly varied non-stationary
time series data is a complex yet important problem. Traditional models for
time series data prediction, such as Long Short-Term Memory (LSTM), are
inefficient and generalize poorly as they cannot capture complex temporal
relationships. In this paper, we present a probabilistic generative model that
can be trained to capture temporal information, and that is robust to data
errors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel
architecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is
trained to minimize a loss function based on the negative log loss. One
contributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is
our regularizer, which accounts for data trends. Experiments conducted show
that tDLGM is able to reconstruct and generate complex time series data, and
that it is robust against to noise and faulty data.",http://arxiv.org/pdf/2411.09312v1,,False
Enhancing generalization in high energy physics using white-box adversarial attacks,14/11/2024,"Franck Rothen, Samuel Klein, Matthew Leigh, Tobias Golling","Machine learning is becoming increasingly popular in the context of particle
physics. Supervised learning, which uses labeled Monte Carlo (MC) simulations,
remains one of the most widely used methods for discriminating signals beyond
the Standard Model. However, this paper suggests that supervised models may
depend excessively on artifacts and approximations from Monte Carlo
simulations, potentially limiting their ability to generalize well to real
data. This study aims to enhance the generalization properties of supervised
models by reducing the sharpness of local minima. It reviews the application of
four distinct white-box adversarial attacks in the context of classifying Higgs
boson decay signals. The attacks are divided into weight space attacks, and
feature space attacks. To study and quantify the sharpness of different local
minima this paper presents two analysis methods: gradient ascent and reduced
Hessian eigenvalue analysis. The results show that white-box adversarial
attacks significantly improve generalization performance, albeit with increased
computational complexity.",http://arxiv.org/pdf/2411.09296v1,,False
StreamAdapter: Efficient Test Time Adaptation from Contextual Streams,14/11/2024,"Dilxat Muhtar, Yelong Shen, Yaming Yang, Xiaodong Liu, Yadong Lu, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Xueliang Zhang, Jianfeng Gao, Weizhu Chen, Qi Zhang","In-context learning (ICL) allows large language models (LLMs) to adapt to new
tasks directly from the given demonstrations without requiring gradient
updates. While recent advances have expanded context windows to accommodate
more demonstrations, this approach increases inference costs without
necessarily improving performance. To mitigate these issues, We propose
StreamAdapter, a novel approach that directly updates model parameters from
context at test time, eliminating the need for explicit in-context
demonstrations. StreamAdapter employs context mapping and weight absorption
mechanisms to dynamically transform ICL demonstrations into parameter updates
with minimal additional parameters. By reducing reliance on numerous in-context
examples, StreamAdapter significantly reduce inference costs and allows for
efficient inference with constant time complexity, regardless of demonstration
count. Extensive experiments across diverse tasks and model architectures
demonstrate that StreamAdapter achieves comparable or superior adaptation
capability to ICL while requiring significantly fewer demonstrations. The
superior task adaptation and context encoding capabilities of StreamAdapter on
both language understanding and generation tasks provides a new perspective for
adapting LLMs at test time using context, allowing for more efficient
adaptation across scenarios and more cost-effective inference",http://arxiv.org/pdf/2411.09289v1,,False
Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging,14/11/2024,"Bo Wang, Dingwei Tan, Yen-Ling Kuo, Zhaowei Sun, Jeremy M. Wolfe, Tat-Jen Cham, Mengmi Zhang","Imagine searching a collection of coins for quarters ($0.25$), dimes
($0.10$), nickels ($0.05$), and pennies ($0.01$)-a hybrid foraging task where
observers look for multiple instances of multiple target types. In such tasks,
how do target values and their prevalence influence foraging and eye movement
behaviors (e.g., should you prioritize rare quarters or common nickels)? To
explore this, we conducted human psychophysics experiments, revealing that
humans are proficient reward foragers. Their eye fixations are drawn to regions
with higher average rewards, fixation durations are longer on more valuable
targets, and their cumulative rewards exceed chance, approaching the upper
bound of optimal foragers. To probe these decision-making processes of humans,
we developed a transformer-based Visual Forager (VF) model trained via
reinforcement learning. Our VF model takes a series of targets, their
corresponding values, and the search image as inputs, processes the images
using foveated vision, and produces a sequence of eye movements along with
decisions on whether to collect each fixated item. Our model outperforms all
baselines, achieves cumulative rewards comparable to those of humans, and
approximates human foraging behavior in eye movements and foraging biases
within time-limited environments. Furthermore, stress tests on
out-of-distribution tasks with novel targets, unseen values, and varying set
sizes demonstrate the VF model's effective generalization. Our work offers
valuable insights into the relationship between eye movements and
decision-making, with our model serving as a powerful tool for further
exploration of this connection. All data, code, and models will be made
publicly available.",http://arxiv.org/pdf/2411.09176v1,,False
Hybrid deep additive neural networks,14/11/2024,"Gyu Min Kim, Jeong Min Jeon","Traditional neural networks (multi-layer perceptrons) have become an
important tool in data science due to their success across a wide range of
tasks. However, their performance is sometimes unsatisfactory, and they often
require a large number of parameters, primarily due to their reliance on the
linear combination structure. Meanwhile, additive regression has been a popular
alternative to linear regression in statistics. In this work, we introduce
novel deep neural networks that incorporate the idea of additive regression.
Our neural networks share architectural similarities with Kolmogorov-Arnold
networks but are based on simpler yet flexible activation and basis functions.
Additionally, we introduce several hybrid neural networks that combine this
architecture with that of traditional neural networks. We derive their
universal approximation properties and demonstrate their effectiveness through
simulation studies and a real-data application. The numerical results indicate
that our neural networks generally achieve better performance than traditional
neural networks while using fewer parameters.",http://arxiv.org/pdf/2411.09175v1,,False
GRAINRec: Graph and Attention Integrated Approach for Real-Time Session-Based Item Recommendations,14/11/2024,"Bhavtosh Rath, Pushkar Chennu, David Relyea, Prathyusha Kanmanth Reddy, Amit Pande","Recent advancements in session-based recommendation models using deep
learning techniques have demonstrated significant performance improvements.
While they can enhance model sophistication and improve the relevance of
recommendations, they also make it challenging to implement a scalable
real-time solution. To addressing this challenge, we propose GRAINRec- a Graph
and Attention Integrated session-based recommendation model that generates
recommendations in real-time. Our scope of work is item recommendations in
online retail where a session is defined as an ordered sequence of digital
guest actions, such as page views or adds to cart. The proposed model generates
recommendations by considering the importance of all items in the session
together, letting us predict relevant recommendations dynamically as the
session evolves. We also propose a heuristic approach to implement real-time
inferencing that meets Target platform's service level agreement (SLA). The
proposed architecture lets us predict relevant recommendations dynamically as
the session evolves, rather than relying on pre-computed recommendations for
each item. Evaluation results of the proposed model show an average improvement
of 1.5% across all offline evaluation metrics. A/B tests done over a 2 week
duration showed an increase of 10% in click through rate and 9% increase in
attributable demand. Extensive ablation studies are also done to understand our
model performance for different parameters.",http://arxiv.org/pdf/2411.09152v1,,False
