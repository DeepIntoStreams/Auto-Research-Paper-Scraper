Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
V-HOP: Visuo-Haptic 6D Object Pose Tracking,24/02/2025,"Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar","Humans naturally integrate vision and haptics for robust object perception
during manipulation. The loss of either modality significantly degrades
performance. Inspired by this multisensory integration, prior object pose
estimation research has attempted to combine visual and haptic/tactile
feedback. Although these works demonstrate improvements in controlled
environments or synthetic datasets, they often underperform vision-only
approaches in real-world settings due to poor generalization across diverse
grippers, sensor layouts, or sim-to-real environments. Furthermore, they
typically estimate the object pose for each frame independently, resulting in
less coherent tracking over sequences in real-world deployments. To address
these limitations, we introduce a novel unified haptic representation that
effectively handles multiple gripper embodiments. Building on this
representation, we introduce a new visuo-haptic transformer-based object pose
tracker that seamlessly integrates visual and haptic input. We validate our
framework in our dataset and the Feelsight dataset, demonstrating significant
performance improvement on challenging sequences. Notably, our method achieves
superior generalization and robustness across novel embodiments, objects, and
sensor types (both taxel-based and vision-based tactile sensors). In real-world
experiments, we demonstrate that our approach outperforms state-of-the-art
visual trackers by a large margin. We further show that we can achieve precise
manipulation tasks by incorporating our real-time object tracking result into
motion plans, underscoring the advantages of visuo-haptic perception. Our model
and dataset will be made open source upon acceptance of the paper. Project
website: https://lhy.xyz/projects/v-hop/",http://arxiv.org/pdf/2502.17434v1,,False
Reasoning with Latent Thoughts: On the Power of Looped Transformers,24/02/2025,"Nikunj Saunshi, Nishanth Dikkala, Zhiyuan Li, Sanjiv Kumar, Sashank J. Reddi","Large language models have shown remarkable reasoning abilities and scaling
laws suggest that large parameter count, especially along the depth axis, is
the primary driver. In this work, we make a stronger claim -- many reasoning
problems require a large depth but not necessarily many parameters. This
unlocks a novel application of looped models for reasoning. Firstly, we show
that for many synthetic reasoning problems like addition, $p$-hop induction,
and math problems, a $k$-layer transformer looped $L$ times nearly matches the
performance of a $kL$-layer non-looped model, and is significantly better than
a $k$-layer model. This is further corroborated by theoretical results showing
that many such reasoning problems can be solved via iterative algorithms, and
thus, can be solved effectively using looped models with nearly optimal depth.
Perhaps surprisingly, these benefits also translate to practical settings of
language modeling -- on many downstream reasoning tasks, a language model with
$k$-layers looped $L$ times can be competitive to, if not better than, a
$kL$-layer language model. In fact, our empirical analysis reveals an
intriguing phenomenon: looped and non-looped models exhibit scaling behavior
that depends on their effective depth, akin to the inference-time scaling of
chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT
reasoning by proving that looped models implicitly generate latent thoughts and
can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we
also present an interesting dichotomy between reasoning and memorization, and
design a looping-based regularization that is effective on both fronts.",http://arxiv.org/pdf/2502.17416v1,,False
Sustainable Greenhouse Management: A Comparative Analysis of Recurrent and Graph Neural Networks,24/02/2025,"Emiliano Seri, Marcello Petitta, Cristina Cornaro","The integration of photovoltaic (PV) systems into greenhouses not only
optimizes land use but also enhances sustainable agricultural practices by
enabling dual benefits of food production and renewable energy generation.
However, accurate prediction of internal environmental conditions is crucial to
ensure optimal crop growth while maximizing energy production. This study
introduces a novel application of Spatio-Temporal Graph Neural Networks
(STGNNs) to greenhouse microclimate modeling, comparing their performance with
traditional Recurrent Neural Networks (RNNs). While RNNs excel at temporal
pattern recognition, they cannot explicitly model the directional relationships
between environmental variables. Our STGNN approach addresses this limitation
by representing these relationships as directed graphs, enabling the model to
capture both spatial dependencies and their directionality. Using
high-frequency data collected at 15-minute intervals from a greenhouse in
Volos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winter
conditions (R^2 = 0.985) but show limitations during summer cooling system
operation. Though STGNNs currently show lower performance (winter R^2 = 0.947),
their architecture offers greater potential for integrating additional
variables such as PV generation and crop growth indicators.",http://arxiv.org/pdf/2502.17371v1,,False
Overconfident Oracles: Limitations of In Silico Sequence Design Benchmarking,24/02/2025,"Shikha Surana, Nathan Grinsztajn, Timothy Atkinson, Paul Duckworth, Thomas D. Barrett","Machine learning methods can automate the in silico design of biological
sequences, aiming to reduce costs and accelerate medical research. Given the
limited access to wet labs, in silico design methods commonly use an oracle
model to evaluate de novo generated sequences. However, the use of different
oracle models across methods makes it challenging to compare them reliably,
motivating the question: are in silico sequence design benchmarks reliable? In
this work, we examine 12 sequence design methods that utilise ML oracles common
in the literature and find that there are significant challenges with their
cross-consistency and reproducibility. Indeed, oracles differing by
architecture, or even just training seed, are shown to yield conflicting
relative performance with our analysis suggesting poor out-of-distribution
generalisation as a key issue. To address these challenges, we propose
supplementing the evaluation with a suite of biophysical measures to assess the
viability of generated sequences and limit out-of-distribution sequences the
oracle is required to score, thereby improving the robustness of the design
procedure. Our work aims to highlight potential pitfalls in the current
evaluation process and contribute to the development of robust benchmarks,
ultimately driving the improvement of in silico design methods.",http://arxiv.org/pdf/2502.17246v1,,False
Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being,24/02/2025,"Bin Yin, Chong-Yi Liu, Liya Fu, Jinkun Zhang","Affective computing has made significant strides in emotion recognition and
generation, yet current approaches mainly focus on short-term pattern
recognition and lack a comprehensive framework to guide affective agents toward
long-term human well-being. To address this, we propose a teleology-driven
affective computing framework that unifies major emotion theories (basic
emotion, appraisal, and constructivist approaches) under the premise that
affect is an adaptive, goal-directed process that facilitates survival and
development. Our framework emphasizes aligning agent responses with both
personal/individual and group/collective well-being over extended timescales.
We advocate for creating a ""dataverse"" of personal affective events, capturing
the interplay between beliefs, goals, actions, and outcomes through real-world
experience sampling and immersive virtual reality. By leveraging causal
modeling, this ""dataverse"" enables AI systems to infer individuals' unique
affective concerns and provide tailored interventions for sustained well-being.
Additionally, we introduce a meta-reinforcement learning paradigm to train
agents in simulated environments, allowing them to adapt to evolving affective
concerns and balance hierarchical goals - from immediate emotional needs to
long-term self-actualization. This framework shifts the focus from statistical
correlations to causal reasoning, enhancing agents' ability to predict and
respond proactively to emotional challenges, and offers a foundation for
developing personalized, ethically aligned affective systems that promote
meaningful human-AI interactions and societal well-being.",http://arxiv.org/pdf/2502.17172v1,,False
CodeSwift: Accelerating LLM Inference for Efficient Code Generation,24/02/2025,"Qianhui Zhao, Li Zhang, Fang Liu, Xiaoli Lian, Qiaoyuanhe Meng, Ziqian Jiao, Zetong Zhou, Borui Zhang, Runlin Guo, Jia Li","Code generation is a latency-sensitive task that demands high timeliness, but
the autoregressive decoding mechanism of Large Language Models (LLMs) leads to
poor inference efficiency. Existing LLM inference acceleration methods mainly
focus on standalone functions using only built-in components. Moreover, they
treat code like natural language sequences, ignoring its unique syntax and
semantic characteristics. As a result, the effectiveness of these approaches in
code generation tasks remains limited and fails to align with real-world
programming scenarios. To alleviate this issue, we propose CodeSwift, a simple
yet highly efficient inference acceleration approach specifically designed for
code generation, without comprising the quality of the output. CodeSwift
constructs a multi-source datastore, providing access to both general and
project-specific knowledge, facilitating the retrieval of high-quality draft
sequences. Moreover, CodeSwift reduces retrieval cost by controlling retrieval
timing, and enhances efficiency through parallel retrieval and a context- and
LLM preference-aware cache. Experimental results show that CodeSwift can reach
up to 2.53x and 2.54x speedup compared to autoregressive decoding in
repository-level and standalone code generation tasks, respectively,
outperforming state-of-the-art inference acceleration approaches by up to 88%.",http://arxiv.org/pdf/2502.17139v1,,False
"Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions",24/02/2025,"Zhong Li, Qi Huang, Lincen Yang, Jiayang Shi, Zhao Yang, Niki van Stein, Thomas BÃ¤ck, Matthijs van Leeuwen","In recent years, generative models have achieved remarkable performance
across diverse applications, including image generation, text synthesis, audio
creation, video generation, and data augmentation. Diffusion models have
emerged as superior alternatives to Generative Adversarial Networks (GANs) and
Variational Autoencoders (VAEs) by addressing their limitations, such as
training instability, mode collapse, and poor representation of multimodal
distributions. This success has spurred widespread research interest. In the
domain of tabular data, diffusion models have begun to showcase similar
advantages over GANs and VAEs, achieving significant performance breakthroughs
and demonstrating their potential for addressing unique challenges in tabular
data modeling. However, while domains like images and time series have numerous
surveys summarizing advancements in diffusion models, there remains a notable
gap in the literature for tabular data. Despite the increasing interest in
diffusion models for tabular data, there has been little effort to
systematically review and summarize these developments. This lack of a
dedicated survey limits a clear understanding of the challenges, progress, and
future directions in this critical area. This survey addresses this gap by
providing a comprehensive review of diffusion models for tabular data. Covering
works from June 2015, when diffusion models emerged, to December 2024, we
analyze nearly all relevant studies, with updates maintained in a
\href{https://github.com/Diffusion-Model-Leiden/awesome-diffusion-models-for-tabular-data}{GitHub
repository}. Assuming readers possess foundational knowledge of statistics and
diffusion models, we employ mathematical formulations to deliver a rigorous and
detailed review, aiming to promote developments in this emerging and exciting
area.",http://arxiv.org/pdf/2502.17119v1,,False
Decoding Financial Health in Kenyas' Medical Insurance Sector: A Data-Driven Cluster Analysis,24/02/2025,"Evans Kiptoo Korir, Zsolt Vizi","This study examines insurance companies' financial performance and reporting
trends within the medical sector using advanced clustering techniques to
identify distinct patterns. Four clusters were identified by analyzing
financial ratios and time series data, each representing unique financial
performance and reporting consistency combinations. Dynamic Time Warping (DTW)
and KMeans clustering were employed to capture temporal variations and uncover
key insights into company behaviors. The findings reveal that resilient
performers consistently report and have financial stability, making them
reliable options for policyholders. In contrast, clusters of underperforming
companies and those with reporting gaps highlight operational challenges and
issues related to data consistency. These insights emphasize the importance of
transparency and timely reporting to ensure the sector's resilience. This study
contributes to the literature by integrating time series analysis into
financial clustering, offering practical recommendations for improving data
governance and financial stability in the insurance sector. Future research
could further investigate non-financial indicators and explore alternative
clustering methods to provide a deeper understanding of performance dynamics.",http://arxiv.org/pdf/2502.17072v1,,False
Towards Auto-Regressive Next-Token Prediction: In-Context Learning Emerges from Generalization,24/02/2025,"Zixuan Gong, Xiaolin Hu, Huayi Tang, Yong Liu","Large language models (LLMs) have demonstrated remarkable in-context learning
(ICL) abilities. However, existing theoretical analysis of ICL primarily
exhibits two limitations: (a) Limited i.i.d. Setting. Most studies focus on
supervised function learning tasks where prompts are constructed with i.i.d.
input-label pairs. This i.i.d. assumption diverges significantly from real
language learning scenarios where prompt tokens are interdependent. (b) Lack of
Emergence Explanation. Most literature answers what ICL does from an implicit
optimization perspective but falls short in elucidating how ICL emerges and the
impact of pre-training phase on ICL. In our paper, to extend (a), we adopt a
more practical paradigm, auto-regressive next-token prediction (AR-NTP), which
closely aligns with the actual training of language models. Specifically,
within AR-NTP, we emphasize prompt token-dependency, which involves predicting
each subsequent token based on the preceding sequence. To address (b), we
formalize a systematic pre-training and ICL framework, highlighting the
layer-wise structure of sequences and topics, alongside a two-level
expectation. In conclusion, we present data-dependent, topic-dependent and
optimization-dependent PAC-Bayesian generalization bounds for pre-trained LLMs,
investigating that ICL emerges from the generalization of sequences and topics.
Our theory is supported by experiments on numerical linear dynamic systems,
synthetic GINC and real-world language datasets.",http://arxiv.org/pdf/2502.17024v1,,False
Active Learning for Conditional Inverse Design with Crystal Generation and Foundation Atomic Models,24/02/2025,"Zhuoyuan Li, Siyu Liu, Beilin Ye, David J. Srolovitz, Tongqi Wen","Artificial intelligence (AI) is transforming materials science, enabling both
theoretical advancements and accelerated materials discovery. Recent progress
in crystal generation models, which design crystal structures for targeted
properties, and foundation atomic models (FAMs), which capture interatomic
interactions across the periodic table, has significantly improved inverse
materials design. However, an efficient integration of these two approaches
remains an open challenge. Here, we present an active learning framework that
combines crystal generation models and foundation atomic models to enhance the
accuracy and efficiency of inverse design. As a case study, we employ Con-CDVAE
to generate candidate crystal structures and MACE-MP-0 FAM as one of the
high-throughput screeners for bulk modulus evaluation. Through iterative active
learning, we demonstrate that Con-CDVAE progressively improves its accuracy in
generating crystals with target properties, highlighting the effectiveness of a
property-driven fine-tuning process. Our framework is general to accommodate
different crystal generation and foundation atomic models, and establishes a
scalable approach for AI-driven materials discovery. By bridging generative
modeling with atomic-scale simulations, this work paves the way for more
accurate and efficient inverse materials design.",http://arxiv.org/pdf/2502.16984v1,,False
LongSafety: Evaluating Long-Context Safety of Large Language Models,24/02/2025,"Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang","As Large Language Models (LLMs) continue to advance in understanding and
generating long sequences, new safety concerns have been introduced through the
long context. However, the safety of LLMs in long-context tasks remains
under-explored, leaving a significant gap in both evaluation and improvement of
their safety. To address this, we introduce LongSafety, the first comprehensive
benchmark specifically designed to evaluate LLM safety in open-ended
long-context tasks. LongSafety encompasses 7 categories of safety issues and 6
user-oriented long-context tasks, with a total of 1,543 test cases, averaging
5,424 words per context. Our evaluation towards 16 representative LLMs reveals
significant safety vulnerabilities, with most models achieving safety rates
below 55%. Our findings also indicate that strong safety performance in
short-context scenarios does not necessarily correlate with safety in
long-context tasks, emphasizing the unique challenges and urgency of improving
long-context safety. Moreover, through extensive analysis, we identify
challenging safety issues and task types for long-context models. Furthermore,
we find that relevant context and extended input sequences can exacerbate
safety risks in long-context scenarios, highlighting the critical need for
ongoing attention to long-context safety challenges. Our code and data are
available at https://github.com/thu-coai/LongSafety.",http://arxiv.org/pdf/2502.16971v1,,False
Zero-shot Load Forecasting for Integrated Energy Systems: A Large Language Model-based Framework with Multi-task Learning,24/02/2025,"Jiaheng Li, Donghe Li, Ye Yang, Huan Xi, Yu Xiao, Li Sun, Dou An, Qingyu Yang","The growing penetration of renewable energy sources in power systems has
increased the complexity and uncertainty of load forecasting, especially for
integrated energy systems with multiple energy carriers. Traditional
forecasting methods heavily rely on historical data and exhibit limited
transferability across different scenarios, posing significant challenges for
emerging applications in smart grids and energy internet. This paper proposes
the TSLLM-Load Forecasting Mechanism, a novel zero-shot load forecasting
framework based on large language models (LLMs) to address these challenges.
The framework consists of three key components: a data preprocessing module
that handles multi-source energy load data, a time series prompt generation
module that bridges the semantic gap between energy data and LLMs through
multi-task learning and similarity alignment, and a prediction module that
leverages pre-trained LLMs for accurate forecasting. The framework's
effectiveness was validated on a real-world dataset comprising load profiles
from 20 Australian solar-powered households, demonstrating superior performance
in both conventional and zero-shot scenarios. In conventional testing, our
method achieved a Mean Squared Error (MSE) of 0.4163 and a Mean Absolute Error
(MAE) of 0.3760, outperforming existing approaches by at least 8\%. In
zero-shot prediction experiments across 19 households, the framework maintained
consistent accuracy with a total MSE of 11.2712 and MAE of 7.6709, showing at
least 12\% improvement over current methods. The results validate the
framework's potential for accurate and transferable load forecasting in
integrated energy systems, particularly beneficial for renewable energy
integration and smart grid applications.",http://arxiv.org/pdf/2502.16896v1,,False
A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis,24/02/2025,"Yuzhi Hao, Danyang Xie","This paper pioneers a novel approach to economic and public policy analysis
by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial
economic agents. We first evaluate five LLMs' economic decision-making
capabilities in solving two-period consumption allocation problems under two
distinct scenarios: with explicit utility functions and based on intuitive
reasoning. While previous research has often simulated heterogeneity by solely
varying prompts, our approach harnesses the inherent variations in analytical
capabilities across different LLMs to model agents with diverse cognitive
traits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB)
framework by mapping these LLMs to specific educational groups and
corresponding income brackets. Using interest-income taxation as a case study,
we demonstrate how the MLAB framework can simulate policy impacts across
heterogeneous agents, offering a promising new direction for economic and
public policy analysis by leveraging LLMs' human-like reasoning capabilities
and computational power.",http://arxiv.org/pdf/2502.16879v1,,False
Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment,24/02/2025,"Kartik Nagpal, Dayi Dong, Jean-Baptiste Bouvier, Negar Mehr","Recent work, spanning from autonomous vehicle coordination to in-space
assembly, has shown the importance of learning collaborative behavior for
enabling robots to achieve shared goals. A common approach for learning this
cooperative behavior is to utilize the centralized-training
decentralized-execution paradigm. However, this approach also introduces a new
challenge: how do we evaluate the contributions of each agent's actions to the
overall success or failure of the team. This credit assignment problem has
remained open, and has been extensively studied in the Multi-Agent
Reinforcement Learning literature. In fact, humans manually inspecting agent
behavior often generate better credit evaluations than existing methods. We
combine this observation with recent works which show Large Language Models
demonstrate human-level performance at many pattern recognition tasks. Our key
idea is to reformulate credit assignment to the two pattern recognition
problems of sequence improvement and attribution, which motivates our novel
LLM-MCA method. Our approach utilizes a centralized LLM reward-critic which
numerically decomposes the environment reward based on the individualized
contribution of each agent in the scenario. We then update the agents' policy
networks based on this feedback. We also propose an extension LLM-TACA where
our LLM critic performs explicit task assignment by passing an intermediary
goal directly to each agent policy in the scenario. Both our methods far
outperform the state-of-the-art on a variety of benchmarks, including
Level-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark which
incorporates collision-related safety constraints. As an artifact of our
methods, we generate large trajectory datasets with each timestep annotated
with per-agent reward information, as sampled from our LLM critics.",http://arxiv.org/pdf/2502.16863v1,,False
