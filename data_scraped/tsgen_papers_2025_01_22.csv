Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Parallel Sequence Modeling via Generalized Spatial Propagation Network,21/01/2025,"Hongjun Wang, Wonmin Byeon, Jiarui Xu, Jinwei Gu, Ka Chun Cheung, Xiaolong Wang, Kai Han, Jan Kautz, Sifei Liu","We present the Generalized Spatial Propagation Network (GSPN), a new
attention mechanism optimized for vision tasks that inherently captures 2D
spatial structures. Existing attention models, including transformers, linear
attention, and state-space models like Mamba, process multi-dimensional data as
1D sequences, compromising spatial coherence and efficiency. GSPN overcomes
these limitations by directly operating on spatially coherent image data and
forming dense pairwise connections through a line-scan approach. Central to
GSPN is the Stability-Context Condition, which ensures stable, context-aware
propagation across 2D sequences and reduces the effective sequence length to
$\sqrt{N}$ for a square map with N elements, significantly enhancing
computational efficiency. With learnable, input-dependent weights and no
reliance on positional embeddings, GSPN achieves superior spatial fidelity and
state-of-the-art performance in vision tasks, including ImageNet
classification, class-guided image generation, and text-to-image generation.
Notably, GSPN accelerates SD-XL with softmax-attention by over $84\times$ when
generating 16K images.",http://arxiv.org/pdf/2501.12381v1,,False
Budget-constrained Collaborative Renewable Energy Forecasting Market,21/01/2025,"Carla Goncalves, Ricardo J. Bessa, Tiago Teixeira, Joao Vinagre","Accurate power forecasting from renewable energy sources (RES) is crucial for
integrating additional RES capacity into the power system and realizing
sustainability goals. This work emphasizes the importance of integrating
decentralized spatio-temporal data into forecasting models. However,
decentralized data ownership presents a critical obstacle to the success of
such spatio-temporal models, and incentive mechanisms to foster data-sharing
need to be considered. The main contributions are a) a comparative analysis of
the forecasting models, advocating for efficient and interpretable spline LASSO
regression models, and b) a bidding mechanism within the data/analytics market
to ensure fair compensation for data providers and enable both buyers and
sellers to express their data price requirements. Furthermore, an incentive
mechanism for time series forecasting is proposed, effectively incorporating
price constraints and preventing redundant feature allocation. Results show
significant accuracy improvements and potential monetary gains for data
sellers. For wind power data, an average root mean squared error improvement of
over 10% was achieved by comparing forecasts generated by the proposal with
locally generated ones.",http://arxiv.org/pdf/2501.12367v1,0.1109/TSTE.2025.3532835,False
Efficient Algorithm for Sparse Fourier Transform of Generalized q-ary Functions,21/01/2025,"Darin Tsui, Kunal Talreja, Amirali Aghazadeh","Computing the Fourier transform of a $q$-ary function
$f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to
real numbers, is an important problem in mathematics with wide-ranging
applications in biology, signal processing, and machine learning. Previous
studies have shown that, under the sparsity assumption, the Fourier transform
can be computed efficiently using fast and sample-efficient algorithms.
However, in many practical settings, the function is defined over a more
general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1}
\times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each
$\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. A naive approach
involves setting $q=\max_i{q_i}$ and treating the function as $q$-ary, which
results in heavy computational overheads. Herein, we develop GFast, an
algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample
complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a
failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow
\infty$ with $S = N^\delta$ for some $0 \leq \delta < 1$. In the presence of
noise, we further demonstrate that a robust version of GFast computes the
transform with a sample complexity of $O(Sn^2)$ and computational complexity of
$O(Sn^2 \log N)$ under the same high probability guarantees. Using large-scale
synthetic experiments, we demonstrate that GFast computes the sparse Fourier
transform of generalized $q$-ary functions using $16\times$ fewer samples and
running $8\times$ faster than existing algorithms. In real-world protein
fitness datasets, GFast explains the predictive interactions of a neural
network with $>25\%$ smaller normalized mean-squared error compared to existing
algorithms.",http://arxiv.org/pdf/2501.12365v1,,False
Test-time regression: a unifying framework for designing sequence models with associative memory,21/01/2025,"Ke Alexander Wang, Jiaxin Shi, Emily B. Fox","Sequences provide a remarkably general way to represent and process
information. This powerful abstraction has placed sequence modeling at the
center of modern deep learning applications, inspiring numerous architectures
from transformers to recurrent networks. While this fragmented development has
yielded powerful models, it has left us without a unified framework to
understand their fundamental similarities and explain their effectiveness. We
present a unifying framework motivated by an empirical observation: effective
sequence models must be able to perform associative recall. Our key insight is
that memorizing input tokens through an associative memory is equivalent to
performing regression at test-time. This regression-memory correspondence
provides a framework for deriving sequence models that can perform associative
recall, offering a systematic lens to understand seemingly ad-hoc architectural
choices. We show numerous recent architectures -- including linear attention
models, their gated variants, state-space models, online learners, and softmax
attention -- emerge naturally as specific approaches to test-time regression.
Each architecture corresponds to three design choices: the relative importance
of each association, the regressor function class, and the optimization
algorithm. This connection leads to new understanding: we provide theoretical
justification for QKNorm in softmax attention, and we motivate higher-order
generalizations of softmax attention. Beyond unification, our work unlocks
decades of rich statistical tools that can guide future development of more
powerful yet principled sequence models.",http://arxiv.org/pdf/2501.12352v1,,False
With Great Backbones Comes Great Adversarial Transferability,21/01/2025,"Erik Arakelyan, Karen Hambardzumyan, Davit Papikyan, Pasquale Minervini, Albert Gordo, Isabelle Augenstein, Aram H. Markosyan","Advances in self-supervised learning (SSL) for machine vision have improved
representation robustness and model performance, giving rise to pre-trained
backbones like \emph{ResNet} and \emph{ViT} models tuned with SSL methods such
as \emph{SimCLR}. Due to the computational and data demands of pre-training,
the utilization of such backbones becomes a strenuous necessity. However,
employing these backbones may inherit vulnerabilities to adversarial attacks.
While adversarial robustness has been studied under \emph{white-box} and
\emph{black-box} settings, the robustness of models tuned on pre-trained
backbones remains largely unexplored. Additionally, the role of tuning
meta-information in mitigating exploitation risks is unclear. This work
systematically evaluates the adversarial robustness of such models across
$20,000$ combinations of tuning meta-information, including fine-tuning
techniques, backbone families, datasets, and attack types. We propose using
proxy models to transfer attacks, simulating varying levels of target knowledge
by fine-tuning these proxies with diverse configurations. Our findings reveal
that proxy-based attacks approach the effectiveness of \emph{white-box}
methods, even with minimal tuning knowledge. We also introduce a naive
""backbone attack,"" leveraging only the backbone to generate adversarial
samples, which outperforms \emph{black-box} attacks and rivals \emph{white-box}
methods, highlighting critical risks in model-sharing practices. Finally, our
ablations reveal how increasing tuning meta-information impacts attack
transferability, measuring each meta-information combination.",http://arxiv.org/pdf/2501.12275v1,,False
InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models,21/01/2025,"Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min","The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.",http://arxiv.org/pdf/2501.12231v1,,False
GLAM: Global-Local Variation Awareness in Mamba-based World Model,21/01/2025,"Qian He, Wenqi Liang, Chunhui Hao, Gan Sun, Jiandong Tian","Mimicking the real interaction trajectory in the inference of the world model
has been shown to improve the sample efficiency of model-based reinforcement
learning (MBRL) algorithms. Many methods directly use known state sequences for
reasoning. However, this approach fails to enhance the quality of reasoning by
capturing the subtle variation between states. Much like how humans infer
trends in event development from this variation, in this work, we introduce
Global-Local variation Awareness Mamba-based world model (GLAM) that improves
reasoning quality by perceiving and predicting variation between states. GLAM
comprises two Mambabased parallel reasoning modules, GMamba and LMamba, which
focus on perceiving variation from global and local perspectives, respectively,
during the reasoning process. GMamba focuses on identifying patterns of
variation between states in the input sequence and leverages these patterns to
enhance the prediction of future state variation. LMamba emphasizes reasoning
about unknown information, such as rewards, termination signals, and visual
representations, by perceiving variation in adjacent states. By integrating the
strengths of the two modules, GLAM accounts for highervalue variation in
environmental changes, providing the agent with more efficient
imagination-based training. We demonstrate that our method outperforms existing
methods in normalized human scores on the Atari 100k benchmark.",http://arxiv.org/pdf/2501.11949v1,,False
A Lightweight and Interpretable Deepfakes Detection Framework,21/01/2025,"Muhammad Umar Farooq, Ali Javed, Khalid Mahmood Malik, Muhammad Anas Raza","The recent realistic creation and dissemination of so-called deepfakes poses
a serious threat to social life, civil rest, and law. Celebrity defaming,
election manipulation, and deepfakes as evidence in court of law are few
potential consequences of deepfakes. The availability of open source trained
models based on modern frameworks such as PyTorch or TensorFlow, video
manipulations Apps such as FaceApp and REFACE, and economical computing
infrastructure has easen the creation of deepfakes. Most of the existing
detectors focus on detecting either face-swap, lip-sync, or puppet master
deepfakes, but a unified framework to detect all three types of deepfakes is
hardly explored. This paper presents a unified framework that exploits the
power of proposed feature fusion of hybrid facial landmarks and our novel heart
rate features for detection of all types of deepfakes. We propose novel heart
rate features and fused them with the facial landmark features to better
extract the facial artifacts of fake videos and natural variations available in
the original videos. We used these features to train a light-weight XGBoost to
classify between the deepfake and bonafide videos. We evaluated the performance
of our framework on the world leaders dataset (WLDR) that contains all types of
deepfakes. Experimental results illustrate that the proposed framework offers
superior detection performance over the comparative deepfakes detection
methods. Performance comparison of our framework against the LSTM-FCN, a
candidate of deep learning model, shows that proposed model achieves similar
results, however, it is more interpretable.",http://arxiv.org/pdf/2501.11927v1,,False
Hybrid Adaptive Modeling using Neural Networks Trained with Nonlinear Dynamics Based Features,21/01/2025,"Zihan Liu, Prashant N. Kambali, C. Nataraj","Accurate models are essential for design, performance prediction, control,
and diagnostics in complex engineering systems. Physics-based models excel
during the design phase but often become outdated during system deployment due
to changing operational conditions, unknown interactions, excitations, and
parametric drift. While data-based models can capture the current state of
complex systems, they face significant challenges, including excessive data
dependence, limited generalizability to changing conditions, and inability to
predict parametric dependence. This has led to combining physics and data in
modeling, termed physics-infused machine learning, often using numerical
simulations from physics-based models. This paper introduces a novel approach
that departs from standard techniques by uncovering information from nonlinear
dynamical modeling and embedding it in data-based models. The goal is to create
a hybrid adaptive modeling framework that integrates data-based modeling with
newly measured data and analytical nonlinear dynamical models for enhanced
accuracy, parametric dependence, and improved generalizability. By explicitly
incorporating nonlinear dynamic phenomena through perturbation methods, the
predictive capabilities are more realistic and insightful compared to knowledge
obtained from brute-force numerical simulations. In particular, perturbation
methods are utilized to derive asymptotic solutions which are parameterized to
generate frequency responses. Frequency responses provide comprehensive
insights into dynamics and nonlinearity which are quantified and extracted as
high-quality features. A machine-learning model, trained by these features,
tracks parameter variations and updates the mismatched model. The results
demonstrate that this adaptive modeling method outperforms numerical gray box
models in prediction accuracy and computational efficiency.",http://arxiv.org/pdf/2501.11835v1,,False
Glinthawk: A Two-Tiered Architecture for High-Throughput LLM Inference,20/01/2025,"Pouya Hamadanian, Sadjad Fouladi","Large Language Models (LLM) have revolutionized natural language processing,
but their inference demands substantial resources, while under-utilizing
high-end accelerators like GPUs. A major bottleneck arises from the attention
mechanism, which requires storing large key-value caches, limiting the maximum
achievable throughput way below the available computing resources. Current
approaches attempt to mitigate this issue through memory-efficient attention
and paging mechanisms, but remained constrained by the assumption that all
operations must be performed on high-end accelerators.
  In this work, we propose Glinthawk, a two-tiered architecture that decouples
the attention mechanism from the rest of the Transformer model. This approach
allows the memory requirements for attention to scale independently, enabling
larger batch sizes and more efficient use of the high-end accelerators. We
prototype Glinthawk with NVIDIA T4 GPUs as one tier and standard CPU VMs as the
other. Compared to a traditional single-tier setup, it improves throughput by
$5.9\times$ and reduces cost of generation by $2.8\times$. For longer sequence
lengths, it achieves $16.3\times$ throughput improvement at $2.4\times$ less
cost. Our evaluation shows that this architecture can tolerate moderate network
latency with minimal performance degradation, making it highly effective for
latency-tolerant, throughput-oriented applications such as batch processing. We
shared our prototype publicly at \url{https://github.com/microsoft/glinthawk}.",http://arxiv.org/pdf/2501.11779v1,,False
Hypergraph Representations of scRNA-seq Data for Improved Clustering with Random Walks,20/01/2025,"Wan He, Daniel I. Bolnick, Samuel V. Scarpino, Tina Eliassi-Rad","Analysis of single-cell RNA sequencing data is often conducted through
network projections such as coexpression networks, primarily due to the
abundant availability of network analysis tools for downstream tasks. However,
this approach has several limitations: loss of higher-order information,
inefficient data representation caused by converting a sparse dataset to a
fully connected network, and overestimation of coexpression due to
zero-inflation. To address these limitations, we propose conceptualizing
scRNA-seq expression data as hypergraphs, which are generalized graphs in which
the hyperedges can connect more than two vertices. In the context of scRNA-seq
data, the hypergraph nodes represent cells and the edges represent genes. Each
hyperedge connects all cells where its corresponding gene is actively expressed
and records the expression of the gene across different cells. This hypergraph
conceptualization enables us to explore multi-way relationships beyond the
pairwise interactions in coexpression networks without loss of information. We
propose two novel clustering methods: (1) the Dual-Importance Preference
Hypergraph Walk (DIPHW) and (2) the Coexpression and Memory-Integrated
Dual-Importance Preference Hypergraph Walk (CoMem-DIPHW). They outperform
established methods on both simulated and real scRNA-seq datasets. The
improvement brought by our proposed methods is especially significant when data
modularity is weak. Furthermore, CoMem-DIPHW incorporates the gene coexpression
network, cell coexpression network, and the cell-gene expression hypergraph
from the single-cell abundance counts data altogether for embedding
computation. This approach accounts for both the local level information from
single-cell level gene expression and the global level information from the
pairwise similarity in the two coexpression networks.",http://arxiv.org/pdf/2501.11760v1,,False
SeRpEnt: Selective Resampling for Expressive State Space Models,20/01/2025,"Stefano Rando, Luca Romani, Matteo Migliarini, Luca Franco, Denis Gudovskiy, Fabio Galasso","State Space Models (SSMs) have recently enjoyed a rise to prominence in the
field of deep learning for sequence modeling, especially as an alternative to
Transformers. Their success stems from avoiding two well-known drawbacks of
attention-based models: quadratic complexity with respect to the sequence
length and inability to model long-range dependencies. The SSM variant Mamba
has demonstrated performance comparable to Transformers without any form of
attention, thanks to the use of a selective mechanism for the state parameters.
Selectivity, however, is only evaluated empirically and the reasons of its
effectiveness remain unclear. In this work, we show how selectivity is related
to the sequence processing. Our analysis shows that selective time intervals in
Mamba act as linear approximators of information. Then, we propose our SeRpEnt
architecture, a SSM that further exploits selectivity to compress sequences in
an information-aware fashion. It employs a resampling mechanism that aggregates
elements based on their information content. Our empirical results in the Long
Range Arena benchmark and other language modeling tasks show benefits of the
SeRpEnt's resampling mechanism.",http://arxiv.org/pdf/2501.11729v1,,False
KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning,20/01/2025,"M. Umar B. Niazi, John Cao, Matthieu Barreau, Karl Henrik Johansson","This paper proposes a novel learning approach for designing
Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems.
The design of a KKL observer involves finding an injective map that transforms
the system state into a higher-dimensional observer state, whose dynamics is
linear and stable. The observer's state is then mapped back to the original
system coordinates via the inverse map to obtain the state estimate. However,
finding this transformation and its inverse is quite challenging. We propose to
sequentially approximate these maps by neural networks that are trained using
physics-informed learning. We generate synthetic data for training by
numerically solving the system and observer dynamics. Theoretical guarantees
for the robustness of state estimation against approximation error and system
uncertainties are provided. Additionally, a systematic method for optimizing
observer performance through parameter selection is presented. The
effectiveness of the proposed approach is demonstrated through numerical
simulations on benchmark examples and its application to sensor fault detection
and isolation in a network of Kuramoto oscillators using learned KKL observers.",http://arxiv.org/pdf/2501.11655v1,,False
Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation,20/01/2025,"M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo","Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.",http://arxiv.org/pdf/2501.11560v1,,False
DLinear-based Prediction of Remaining Useful Life of Lithium-Ion Batteries: Feature Engineering through Explainable Artificial Intelligence,20/01/2025,"Minsu Kim, Jaehyun Oh, Sang-Young Lee, Junghwan Kim","Accurate prediction of the Remaining Useful Life (RUL) of lithium-ion
batteries is essential for ensuring safety, reducing maintenance costs, and
optimizing usage. However, predicting RUL is challenging due to the nonlinear
characteristics of the degradation caused by complex chemical reactions.
Machine learning allows precise predictions by learning the latent functions of
degradation relationships based on cycling behavior. This study introduces an
accurate RUL prediction approach based on feature engineering and DLinear,
applied to the dataset from NASA's Prognostics Center of Excellence. Among the
20 features generated from current, voltage, temperature, and time provided in
this dataset, key features contributing to degradation are selected using
Pearson correlation coefficient and Shapley values. Shapley value-based feature
selection effectively reflects cell-to-cell variability, showing similar
importance rankings across all cells. The DLinear-based RUL prediction using
key features efficiently captures the time-series trend, demonstrating
significantly better performance compared to Long Short-Term Memory and
Transformer models.",http://arxiv.org/pdf/2501.11542v1,,False
A Survey on Diffusion Models for Anomaly Detection,20/01/2025,"Jing Liu, Zhenchao Ma, Zepu Wang, Yang Liu, Zehua Wang, Peng Sun, Liang Song, Bo Hu, Azzedine Boukerche, Victor C. M. Leung","Diffusion models (DMs) have emerged as a powerful class of generative AI
models, showing remarkable potential in anomaly detection (AD) tasks across
various domains, such as cybersecurity, fraud detection, healthcare, and
manufacturing. The intersection of these two fields, termed diffusion models
for anomaly detection (DMAD), offers promising solutions for identifying
deviations in increasingly complex and high-dimensional data. In this survey,
we systematically review recent advances in DMAD research and investigate their
capabilities. We begin by presenting the fundamental concepts of AD and DMs,
followed by a comprehensive analysis of classic DM architectures including
DDPMs, DDIMs, and Score SDEs. We further categorize existing DMAD methods into
reconstruction-based, density-based, and hybrid approaches, providing detailed
examinations of their methodological innovations. We also explore the diverse
tasks across different data modalities, encompassing image, time series, video,
and multimodal data analysis. Furthermore, we discuss critical challenges and
emerging research directions, including computational efficiency, model
interpretability, robustness enhancement, edge-cloud collaboration, and
integration with large language models. The collection of DMAD research papers
and resources is available at https://github.com/fdjingliu/DMAD.",http://arxiv.org/pdf/2501.11430v1,,False
Neural Contextual Reinforcement Framework for Logical Structure Language Generation,20/01/2025,"Marcus Irvin, William Cooper, Edward Hughes, Jessica Morgan, Christopher Hamilton","The Neural Contextual Reinforcement Framework introduces an innovative
approach to enhancing the logical coherence and structural consistency of text
generated by large language models. Leveraging reinforcement learning
principles, the framework integrates custom reward functions and dynamic
context alignment mechanisms to address challenges inherent in maintaining
long-range dependencies across extended sequences. The architecture
incorporates multi-head attention layers and hierarchical encoding modules,
enabling the model to produce outputs that align closely with human
expectations of logical structure and semantic flow. Quantitative evaluations
across diverse datasets demonstrate substantial improvements in coherence
metrics, perplexity reduction, and semantic alignment, showcasing the
framework's ability to outperform baseline models in both general and
domain-specific tasks. Qualitative analyses further highlight the framework's
capacity to generate text with improved narrative clarity and reduced
redundancy, reflecting its effectiveness in balancing fluency with structural
precision. In addition to its performance gains, the framework exhibits
robustness in handling noisy input data and scalability across varying model
sizes, reinforcing its versatility in practical applications. Experimental
results reveal that optimal context window sizes significantly influence
coherence outcomes, showing the importance of architectural flexibility in
adapting to diverse linguistic structures. Cross-lingual performance
evaluations affirm the framework's adaptability to multiple languages,
extending its utility beyond monolingual contexts. Resource efficiency analyses
indicate a reduction in computational overhead compared to traditional
approaches, emphasizing the practicality of the framework for large-scale
deployment.",http://arxiv.org/pdf/2501.11417v1,,False
A Truly Sparse and General Implementation of Gradient-Based Synaptic Plasticity,20/01/2025,"Jamie Lohoff, Anil Kaya, Florian Assmuth, Emre Neftci","Online synaptic plasticity rules derived from gradient descent achieve high
accuracy on a wide range of practical tasks. However, their software
implementation often requires tediously hand-derived gradients or using
gradient backpropagation which sacrifices the online capability of the rules.
In this work, we present a custom automatic differentiation (AD) pipeline for
sparse and online implementation of gradient-based synaptic plasticity rules
that generalizes to arbitrary neuron models. Our work combines the programming
ease of backpropagation-type methods for forward AD while being
memory-efficient. To achieve this, we exploit the advantageous compute and
memory scaling of online synaptic plasticity by providing an inherently sparse
implementation of AD where expensive tensor contractions are replaced with
simple element-wise multiplications if the tensors are diagonal. Gradient-based
synaptic plasticity rules such as eligibility propagation (e-prop) have exactly
this property and thus profit immensely from this feature. We demonstrate the
alignment of our gradients with respect to gradient backpropagation on an
synthetic task where e-prop gradients are exact, as well as audio speech
classification benchmarks. We demonstrate how memory utilization scales with
network size without dependence on the sequence length, as expected from
forward AD methods.",http://arxiv.org/pdf/2501.11407v1,,False
