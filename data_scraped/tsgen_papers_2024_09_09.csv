Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Approximating Metric Magnitude of Point Sets,06/09/2024,"Rayna Andreeva, James Ward, Primoz Skraba, Jie Gao, Rik Sarkar","Metric magnitude is a measure of the ""size"" of point clouds with many
desirable geometric properties. It has been adapted to various mathematical
contexts and recent work suggests that it can enhance machine learning and
optimization algorithms. But its usability is limited due to the computational
cost when the dataset is large or when the computation must be carried out
repeatedly (e.g. in model training). In this paper, we study the magnitude
computation problem, and show efficient ways of approximating it. We show that
it can be cast as a convex optimization problem, but not as a submodular
optimization. The paper describes two new algorithms - an iterative
approximation algorithm that converges fast and is accurate, and a subset
selection method that makes the computation even faster. It has been previously
proposed that magnitude of model sequences generated during stochastic gradient
descent is correlated to generalization gap. Extension of this result using our
more scalable algorithms shows that longer sequences in fact bear higher
correlations. We also describe new applications of magnitude in machine
learning - as an effective regularizer for neural network training, and as a
novel clustering criterion.",http://arxiv.org/pdf/2409.04411v1,,False
HiSC4D: Human-centered interaction and 4D Scene Capture in Large-scale Space Using Wearable IMUs and LiDAR,06/09/2024,"Yudi Dai, Zhiyong Wang, Xiping Lin, Chenglu Wen, Lan Xu, Siqi Shen, Yuexin Ma, Cheng Wang","We introduce HiSC4D, a novel Human-centered interaction and 4D Scene Capture
method, aimed at accurately and efficiently creating a dynamic digital world,
containing large-scale indoor-outdoor scenes, diverse human motions, rich
human-human interactions, and human-environment interactions. By utilizing
body-mounted IMUs and a head-mounted LiDAR, HiSC4D can capture egocentric human
motions in unconstrained space without the need for external devices and
pre-built maps. This affords great flexibility and accessibility for
human-centered interaction and 4D scene capturing in various environments.
Taking into account that IMUs can capture human spatially unrestricted poses
but are prone to drifting for long-period using, and while LiDAR is stable for
global localization but rough for local positions and orientations, HiSC4D
employs a joint optimization method, harmonizing all sensors and utilizing
environment cues, yielding promising results for long-term capture in large
scenes. To promote research of egocentric human interaction in large scenes and
facilitate downstream tasks, we also present a dataset, containing 8 sequences
in 4 large scenes (200 to 5,000 $m^2$), providing 36k frames of accurate 4D
human motions with SMPL annotations and dynamic scenes, 31k frames of cropped
human point clouds, and scene mesh of the environment. A variety of scenarios,
such as the basketball gym and commercial street, alongside challenging human
motions, such as daily greeting, one-on-one basketball playing, and tour
guiding, demonstrate the effectiveness and the generalization ability of
HiSC4D. The dataset and code will be publicated on
www.lidarhumanmotion.net/hisc4d available for research purposes.",http://arxiv.org/pdf/2409.04398v1,,False
Provable Hyperparameter Tuning for Structured Pfaffian Settings,06/09/2024,"Maria-Florina Balcan, Anh Tuan Nguyen, Dravyansh Sharma","Data-driven algorithm design automatically adapts algorithms to specific
application domains, achieving better performance. In the context of
parameterized algorithms, this approach involves tuning the algorithm
parameters using problem instances drawn from the problem distribution of the
target application domain. While empirical evidence supports the effectiveness
of data-driven algorithm design, providing theoretical guarantees for several
parameterized families remains challenging. This is due to the intricate
behaviors of their corresponding utility functions, which typically admit
piece-wise and discontinuity structures. In this work, we present refined
frameworks for providing learning guarantees for parameterized data-driven
algorithm design problems in both distributional and online learning settings.
For the distributional learning setting, we introduce the Pfaffian GJ
framework, an extension of the classical GJ framework, capable of providing
learning guarantees for function classes for which the computation involves
Pfaffian functions. Unlike the GJ framework, which is limited to function
classes with computation characterized by rational functions, our proposed
framework can deal with function classes involving Pfaffian functions, which
are much more general and widely applicable. We then show that for many
parameterized algorithms of interest, their utility function possesses a
refined piece-wise structure, which automatically translates to learning
guarantees using our proposed framework. For the online learning setting, we
provide a new tool for verifying dispersion property of a sequence of loss
functions. This sufficient condition allows no-regret learning for sequences of
piece-wise structured loss functions where the piece-wise structure involves
Pfaffian transition boundaries.",http://arxiv.org/pdf/2409.04367v1,,False
Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets,06/09/2024,"Desiree Heim, Christian Jilek, Adrian Ulges, Andreas Dengel","Current publicly available knowledge work data collections lack diversity,
extensive annotations, and contextual information about the users and their
documents. These issues hinder objective and comparable data-driven evaluations
and optimizations of knowledge work assistance systems. Due to the considerable
resources needed to collect such data in real-life settings and the necessity
of data censorship, collecting such a dataset appears nearly impossible. For
this reason, we propose a configurable, multi-agent knowledge work dataset
generator. This system simulates collaborative knowledge work among agents
producing Large Language Model-generated documents and accompanying data
traces. Additionally, the generator captures all background information, given
in its configuration or created during the simulation process, in a knowledge
graph. Finally, the resulting dataset can be utilized and shared without
privacy or confidentiality concerns.
  This paper introduces our approach's design and vision and focuses on
generating authentic knowledge work documents using Large Language Models. Our
study involving human raters who assessed 53% of the generated and 74% of the
real documents as realistic demonstrates the potential of our approach.
Furthermore, we analyze the authenticity criteria mentioned in the
participants' comments and elaborate on potential improvements for identified
common issues.",http://arxiv.org/pdf/2409.04286v1,,False
Unmasking Covert Intrusions: Detection of Fault-Masking Cyberattacks on Differential Protection Systems,06/09/2024,"Ahmad Mohammad Saber, Amr Youssef, Davor Svetinovic, Hatem Zeineldin, Ehab F. El-Saadany","Line Current Differential Relays (LCDRs) are high-speed relays progressively
used to protect critical transmission lines. However, LCDRs are vulnerable to
cyberattacks. Fault-Masking Attacks (FMAs) are stealthy cyberattacks performed
by manipulating the remote measurements of the targeted LCDR to disguise faults
on the protected line. Hence, they remain undetected by this LCDR. In this
paper, we propose a two-module framework to detect FMAs. The first module is a
Mismatch Index (MI) developed from the protected transmission line's equivalent
physical model. The MI is triggered only if there is a significant mismatch in
the LCDR's local and remote measurements while the LCDR itself is untriggered,
which indicates an FMA. After the MI is triggered, the second module, a neural
network-based classifier, promptly confirms that the triggering event is a
physical fault that lies on the line protected by the LCDR before declaring the
occurrence of an FMA. The proposed framework is tested using the IEEE 39-bus
benchmark system. Our simulation results confirm that the proposed framework
can accurately detect FMAs on LCDRs and is not affected by normal system
disturbances, variations, or measurement noise. Our experimental results using
OPAL-RT's real-time simulator confirm the proposed solution's real-time
performance capability.",http://arxiv.org/pdf/2409.04242v1,,False
SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation,06/09/2024,"Yi Tian, Juan Andrade-Cetto","Event cameras generate asynchronous and sparse event streams capturing
changes in light intensity. They offer significant advantages over conventional
frame-based cameras, such as a higher dynamic range and an extremely faster
data rate, making them particularly useful in scenarios involving fast motion
or challenging lighting conditions. Spiking neural networks (SNNs) share
similar asynchronous and sparse characteristics and are well-suited for
processing data from event cameras. Inspired by the potential of transformers
and spike-driven transformers (spikeformers) in other computer vision tasks, we
propose two solutions for fast and robust optical flow estimation for event
cameras: STTFlowNet and SDformerFlow. STTFlowNet adopts a U-shaped artificial
neural network (ANN) architecture with spatiotemporal shifted window
self-attention (swin) transformer encoders, while SDformerFlow presents its
fully spiking counterpart, incorporating swin spikeformer encoders.
Furthermore, we present two variants of the spiking version with different
neuron models. Our work is the first to make use of spikeformers for dense
optical flow estimation. We conduct end-to-end training for all models using
supervised learning. Our results yield state-of-the-art performance among
SNN-based event optical flow methods on both the DSEC and MVSEC datasets, and
show significant reduction in power consumption compared to the equivalent
ANNs.",http://arxiv.org/pdf/2409.04082v1,,False
UI-JEPA: Towards Active Perception of User Intent through Onscreen User Activity,06/09/2024,"Yicheng Fu, Raviteja Anantha, Prabal Vashisht, Jianpeng Cheng, Etai Littwin","Generating user intent from a sequence of user interface (UI) actions is a
core challenge in comprehensive UI understanding. Recent advancements in
multimodal large language models (MLLMs) have led to substantial progress in
this area, but their demands for extensive model parameters, computing power,
and high latency makes them impractical for scenarios requiring lightweight,
on-device solutions with low latency or heightened privacy. Additionally, the
lack of high-quality datasets has hindered the development of such lightweight
models. To address these challenges, we propose UI-JEPA, a novel framework that
employs masking strategies to learn abstract UI embeddings from unlabeled data
through self-supervised learning, combined with an LLM decoder fine-tuned for
user intent prediction. We also introduce two new UI-grounded multimodal
datasets, ""Intent in the Wild"" (IIW) and ""Intent in the Tame"" (IIT), designed
for few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos
across 219 intent categories, while IIT contains 914 videos across 10
categories. We establish the first baselines for these datasets, showing that
representations learned using a JEPA-style objective, combined with an LLM
decoder, can achieve user intent predictions that match the performance of
state-of-the-art large MLLMs, but with significantly reduced annotation and
deployment resources. Measured by intent similarity scores, UI-JEPA outperforms
GPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged
across two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x
reduction in computational cost and a 6.6x improvement in latency in the IIW
dataset. These results underscore the effectiveness of UI-JEPA, highlighting
its potential for lightweight, high-performance UI understanding.",http://arxiv.org/pdf/2409.04081v1,,False
An Efficient and Generalizable Symbolic Regression Method for Time Series Analysis,06/09/2024,"Yi Xie, Tianyu Qiu, Yun Xiong, Xiuqi Huang, Xiaofeng Gao, Chao Chen","Time series analysis and prediction methods currently excel in quantitative
analysis, offering accurate future predictions and diverse statistical
indicators, but generally falling short in elucidating the underlying evolution
patterns of time series. To gain a more comprehensive understanding and provide
insightful explanations, we utilize symbolic regression techniques to derive
explicit expressions for the non-linear dynamics in the evolution of time
series variables. However, these techniques face challenges in computational
efficiency and generalizability across diverse real-world time series data. To
overcome these challenges, we propose \textbf{N}eural-\textbf{E}nhanced
\textbf{Mo}nte-Carlo \textbf{T}ree \textbf{S}earch (NEMoTS) for time series.
NEMoTS leverages the exploration-exploitation balance of Monte-Carlo Tree
Search (MCTS), significantly reducing the search space in symbolic regression
and improving expression quality. Furthermore, by integrating neural networks
with MCTS, NEMoTS not only capitalizes on their superior fitting capabilities
to concentrate on more pertinent operations post-search space reduction, but
also replaces the complex and time-consuming simulation process, thereby
substantially improving computational efficiency and generalizability in time
series analysis. NEMoTS offers an efficient and comprehensive approach to time
series analysis. Experiments with three real-world datasets demonstrate
NEMoTS's significant superiority in performance, efficiency, reliability, and
interpretability, making it well-suited for large-scale real-world time series
data.",http://arxiv.org/pdf/2409.03986v1,,False
