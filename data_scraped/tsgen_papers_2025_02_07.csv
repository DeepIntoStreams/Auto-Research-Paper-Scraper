Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Targeted Learning for Data Fairness,06/02/2025,"Alexander Asemota, Giles Hooker","Data and algorithms have the potential to produce and perpetuate
discrimination and disparate treatment. As such, significant effort has been
invested in developing approaches to defining, detecting, and eliminating
unfair outcomes in algorithms. In this paper, we focus on performing
statistical inference for fairness. Prior work in fairness inference has
largely focused on inferring the fairness properties of a given predictive
algorithm. Here, we expand fairness inference by evaluating fairness in the
data generating process itself, referred to here as data fairness. We perform
inference on data fairness using targeted learning, a flexible framework for
nonparametric inference. We derive estimators demographic parity, equal
opportunity, and conditional mutual information. Additionally, we find that our
estimators for probabilistic metrics exploit double robustness. To validate our
approach, we perform several simulations and apply our estimators to real data.",http://arxiv.org/pdf/2502.04309v1,,False
DexterityGen: Foundation Controller for Unprecedented Dexterity,06/02/2025,"Zhao-Heng Yin, Changhao Wang, Luis Pineda, Francois Hogan, Krishna Bodduluri, Akash Sharma, Patrick Lancaster, Ishita Prasad, Mrinal Kalakrishnan, Jitendra Malik, Mike Lambeta, Tingfan Wu, Pieter Abbeel, Mustafa Mukadam","Teaching robots dexterous manipulation skills, such as tool use, presents a
significant challenge. Current approaches can be broadly categorized into two
strategies: human teleoperation (for imitation learning) and sim-to-real
reinforcement learning. The first approach is difficult as it is hard for
humans to produce safe and dexterous motions on a different embodiment without
touch feedback. The second RL-based approach struggles with the domain gap and
involves highly task-specific reward engineering on complex tasks. Our key
insight is that RL is effective at learning low-level motion primitives, while
humans excel at providing coarse motion commands for complex, long-horizon
tasks. Therefore, the optimal solution might be a combination of both
approaches. In this paper, we introduce DexterityGen (DexGen), which uses RL to
pretrain large-scale dexterous motion primitives, such as in-hand rotation or
translation. We then leverage this learned dataset to train a dexterous
foundational controller. In the real world, we use human teleoperation as a
prompt to the controller to produce highly dexterous behavior. We evaluate the
effectiveness of DexGen in both simulation and real world, demonstrating that
it is a general-purpose controller that can realize input dexterous
manipulation commands and significantly improves stability by 10-100x measured
as duration of holding objects across diverse tasks. Notably, with DexGen we
demonstrate unprecedented dexterous skills including diverse object
reorientation and dexterous tool use such as pen, syringe, and screwdriver for
the first time.",http://arxiv.org/pdf/2502.04307v1,,False
Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression,06/02/2025,"Lirui Wang, Kevin Zhao, Chaoqi Liu, Xinlei Chen","We propose Heterogeneous Masked Autoregression (HMA) for modeling
action-video dynamics to generate high-quality data and evaluation in scaling
robot learning. Building interactive video world models and policies for
robotics is difficult due to the challenge of handling diverse settings while
maintaining computational efficiency to run in real time. HMA uses
heterogeneous pre-training from observations and action sequences across
different robotic embodiments, domains, and tasks. HMA uses masked
autoregression to generate quantized or soft tokens for video predictions.
\ourshort achieves better visual fidelity and controllability than the previous
robotic video generation models with 15 times faster speed in the real world.
After post-training, this model can be used as a video simulator from low-level
action inputs for evaluating policies and generating synthetic data. See this
link https://liruiw.github.io/hma for more information.",http://arxiv.org/pdf/2502.04296v1,,False
Variational decision diagrams for quantum-inspired machine learning applications,06/02/2025,"Santiago Acevedo-Mancera, Vladimir Vargas-Calderón, Herbert Vinck-Posada","Decision diagrams (DDs) have emerged as an efficient tool for simulating
quantum circuits due to their capacity to exploit data redundancies in quantum
states and quantum operations, enabling the efficient computation of
probability amplitudes. However, their application in quantum machine learning
(QML) has remained unexplored. This paper introduces variational decision
diagrams (VDDs), a novel graph structure that combines the structural benefits
of DDs with the adaptability of variational methods for efficiently
representing quantum states. We investigate the trainability of VDDs by
applying them to the ground state estimation problem for transverse-field Ising
and Heisenberg Hamiltonians. Analysis of gradient variance suggests that
training VDDs is possible, as no signs of vanishing gradients--also known as
barren plateaus--are observed. This work provides new insights into the use of
decision diagrams in QML as an alternative to design and train variational
ans\""atze.",http://arxiv.org/pdf/2502.04271v1,,False
On the importance of structural identifiability for machine learning with partially observed dynamical systems,06/02/2025,"Janis Norden, Elisa Oostwal, Michael Chappell, Peter Tino, Kerstin Bunte","The successful application of modern machine learning for time series
classification is often hampered by limitations in quality and quantity of
available training data. To overcome these limitations, available domain expert
knowledge in the form of parametrised mechanistic dynamical models can be used
whenever it is available and time series observations may be represented as an
element from a given class of parametrised dynamical models. This makes the
learning process interpretable and allows the modeller to deal with sparsely
and irregularly sampled data in a natural way. However, the internal processes
of a dynamical model are often only partially observed. This can lead to
ambiguity regarding which particular model realization best explains a given
time series observation. This problem is well-known in the literature, and a
dynamical model with this issue is referred to as structurally unidentifiable.
Training a classifier that incorporates knowledge about a structurally
unidentifiable dynamical model can negatively influence classification
performance. To address this issue, we employ structural identifiability
analysis to explicitly relate parameter configurations that are associated with
identical system outputs. Using the derived relations in classifier training,
we demonstrate that this method significantly improves the classifier's ability
to generalize to unseen data on a number of example models from the biomedical
domain. This effect is especially pronounced when the number of training
instances is limited. Our results demonstrate the importance of accounting for
structural identifiability, a topic that has received relatively little
attention from the machine learning community.",http://arxiv.org/pdf/2502.04131v1,,False
Evaluating Inter-Column Logical Relationships in Synthetic Tabular Data Generation,06/02/2025,"Yunbo Long, Liming Xu, Alexandra Brintrup","Current evaluations of synthetic tabular data mainly focus on how well joint
distributions are modeled, often overlooking the assessment of their
effectiveness in preserving realistic event sequences and coherent entity
relationships across columns.This paper proposes three evaluation metrics
designed to assess the preservation of logical relationships among columns in
synthetic tabular data. We validate these metrics by assessing the performance
of both classical and state-of-the-art generation methods on a real-world
industrial dataset.Experimental results reveal that existing methods often fail
to rigorously maintain logical consistency (e.g., hierarchical relationships in
geography or organization) and dependencies (e.g., temporal sequences or
mathematical relationships), which are crucial for preserving the fine-grained
realism of real-world tabular data. Building on these insights, this study also
discusses possible pathways to better capture logical relationships while
modeling the distribution of synthetic tabular data.",http://arxiv.org/pdf/2502.04055v1,,False
Decision Trees That Remember: Gradient-Based Learning of Recurrent Decision Trees with Memory,06/02/2025,"Sascha Marton, Moritz Schneider","Neural architectures such as Recurrent Neural Networks (RNNs), Transformers,
and State-Space Models have shown great success in handling sequential data by
learning temporal dependencies. Decision Trees (DTs), on the other hand, remain
a widely used class of models for structured tabular data but are typically not
designed to capture sequential patterns directly. Instead, DT-based approaches
for time-series data often rely on feature engineering, such as manually
incorporating lag features, which can be suboptimal for capturing complex
temporal dependencies. To address this limitation, we introduce ReMeDe Trees, a
novel recurrent DT architecture that integrates an internal memory mechanism,
similar to RNNs, to learn long-term dependencies in sequential data. Our model
learns hard, axis-aligned decision rules for both output generation and state
updates, optimizing them efficiently via gradient descent. We provide a
proof-of-concept study on synthetic benchmarks to demonstrate the effectiveness
of our approach.",http://arxiv.org/pdf/2502.04052v1,,False
PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data,06/02/2025,"Keon Vin Park, Jisu Kim, Jaemin Seo","This paper introduces PINT (Physics-Informed Neural Time Series Models), a
framework that integrates physical constraints into neural time series models
to improve their ability to capture complex dynamics. We apply PINT to the ERA5
WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data.
PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informed
prior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures.
This equation's analytical solutions (sine and cosine functions) facilitate
rigorous evaluation of the benefits of incorporating physics-informed
constraints. By benchmarking against a linear regression baseline derived from
its exact solutions, we quantify the impact of embedding physical principles in
data-driven models. Unlike traditional time series models that rely on future
observations, PINT is designed for practical forecasting. Using only the first
90 days of observed data, it iteratively predicts the next two years,
addressing challenges posed by limited real-time updates. Experiments on the
WeatherBench dataset demonstrate PINT's ability to generalize, capture periodic
trends, and align with physical principles. This study highlights the potential
of physics-informed neural models in bridging machine learning and
interpretable climate applications.
  Our models and datasets are publicly available on GitHub:
https://github.com/KV-Park.",http://arxiv.org/pdf/2502.04018v1,,False
MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation,06/02/2025,"YoonJe Kang, Yonghoon Jung, Wonseop Shin, Bumsoo Kim, Sanghyun Seo","In this paper, we present synthetic data generation framework for flood
hazard detection system. For high fidelity and quality, we characterize several
real-world properties into virtual world and simulate the flood situation by
controlling them. For the sake of efficiency, recent generative models in
image-to-3D and urban city synthesis are leveraged to easily composite flood
environments so that we avoid data bias due to the hand-crafted manner. Based
on our framework, we build the flood synthetic dataset with 5 levels, dubbed
MultiFloodSynth which contains rich annotation types like normal map,
segmentation, 3D bounding box for a variety of downstream task. In experiments,
our dataset demonstrate the enhanced performance of flood hazard detection with
on-par realism compared with real dataset.",http://arxiv.org/pdf/2502.03966v1,,False
Innovative Framework for Early Estimation of Mental Disorder Scores to Enable Timely Interventions,06/02/2025,"Himanshi Singh, Sadhana Tiwari, Sonali Agarwal, Ritesh Chandra, Sanjay Kumar Sonbhadra, Vrijendra Singh","Individual's general well-being is greatly impacted by mental health
conditions including depression and Post-Traumatic Stress Disorder (PTSD),
underscoring the importance of early detection and precise diagnosis in order
to facilitate prompt clinical intervention. An advanced multimodal deep
learning system for the automated classification of PTSD and depression is
presented in this paper. Utilizing textual and audio data from clinical
interview datasets, the method combines features taken from both modalities by
combining the architectures of LSTM (Long Short Term Memory) and BiLSTM
(Bidirectional Long Short-Term Memory).Although text features focus on speech's
semantic and grammatical components; audio features capture vocal traits
including rhythm, tone, and pitch. This combination of modalities enhances the
model's capacity to identify minute patterns connected to mental health
conditions. Using test datasets, the proposed method achieves classification
accuracies of 92% for depression and 93% for PTSD, outperforming traditional
unimodal approaches and demonstrating its accuracy and robustness.",http://arxiv.org/pdf/2502.03965v1,,False
MAQInstruct: Instruction-based Unified Event Relation Extraction,06/02/2025,"Jun Xu, Mengshu Sun, Zhiqiang Zhang, Jun Zhou","Extracting event relations that deviate from known schemas has proven
challenging for previous methods based on multi-class classification, MASK
prediction, or prototype matching. Recent advancements in large language models
have shown impressive performance through instruction tuning. Nevertheless, in
the task of event relation extraction, instruction-based methods face several
challenges: there are a vast number of inference samples, and the relations
between events are non-sequential. To tackle these challenges, we present an
improved instruction-based event relation extraction framework named
MAQInstruct. Firstly, we transform the task from extracting event relations
using given event-event instructions to selecting events using given
event-relation instructions, which reduces the number of samples required for
inference. Then, by incorporating a bipartite matching loss, we reduce the
dependency of the instruction-based method on the generation sequence. Our
experimental results demonstrate that MAQInstruct significantly improves the
performance of event relation extraction across multiple LLMs.",http://arxiv.org/pdf/2502.03954v1,,False
CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning,06/02/2025,"Yousef Koka, David Selby, Gerrit Großmann, Sebastian Vollmer","Data preprocessing is a critical yet frequently neglected aspect of machine
learning, often paid little attention despite its potentially significant
impact on model performance. While automated machine learning pipelines are
starting to recognize and integrate data preprocessing into their solutions for
classification and regression tasks, this integration is lacking for more
specialized tasks like survival or time-to-event models. As a result, survival
analysis not only faces the general challenges of data preprocessing but also
suffers from the lack of tailored, automated solutions in this area.
  To address this gap, this paper presents 'CleanSurvival', a
reinforcement-learning-based solution for optimizing preprocessing pipelines,
extended specifically for survival analysis. The framework can handle
continuous and categorical variables, using Q-learning to select which
combination of data imputation, outlier detection and feature extraction
techniques achieves optimal performance for a Cox, random forest, neural
network or user-supplied time-to-event model. The package is available on
GitHub: https://github.com/datasciapps/CleanSurvival
  Experimental benchmarks on real-world datasets show that the Q-learning-based
data preprocessing results in superior predictive performance to standard
approaches, finding such a model up to 10 times faster than undirected random
grid search. Furthermore, a simulation study demonstrates the effectiveness in
different types and levels of missingness and noise in the data.",http://arxiv.org/pdf/2502.03946v1,,False
Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software,06/02/2025,"Andreas Baumann, Peter Eberhard","Large Language Models (LLMs) are increasingly helpful in text generation,
even writing code in programming languages based on user prompts written in
natural language. They are even applied to generate simulation models for
multibody systems from natural language. Research results suggest that LLMs
surpass the mere replication of existing code examples, where some LLMs have
been trained on an open-source multibody simulation code. However, for
closed-source simulation software, such results are not to be expected as their
ideas and concepts might differ from other publicly available ones. LLMs can
hallucinate for knowledge-intensive tasks, such as model creation, which can
lead to wrong responses. This is especially the case for the LLM unknown
closed-source simulation software. The same applies to other internal knowledge
kept private to protect intellectual property or data privacy. The
Retrieval-Augmented Generation (RAG) approach might yield a solution for these
knowledge-intensive tasks. This paper explores the application of RAG to
closed-source simulation software and presents first experiments. After a brief
introduction to LLMs, the RAG approach, and the simulation method applied by
the close-source simulation software, several examples are provided to test
LLMs' knowledge of the simulation software and the creation of simulation
models using two RAG systems. The examples show promising results indicating
the benefits of applying RAG systems to closed-source simulation software,
helping to access their knowledge. Nevertheless, they also reveal gaps in the
applied information and open questions for further research.",http://arxiv.org/pdf/2502.03916v1,,False
Technical Report: Generating the WEB-IDS23 Dataset,06/02/2025,"Eric Lanfer, Dominik Brockmann, Nils Aschenbruck","Anomaly-based Network Intrusion Detection Systems (NIDS) require correctly
labelled, representative and diverse datasets for an accurate evaluation and
development. However, several widely used datasets do not include labels which
are fine-grained enough and, together with small sample sizes, can lead to
overfitting issues that also remain undetected when using test data.
Additionally, the cybersecurity sector is evolving fast, and new attack
mechanisms require the continuous creation of up-to-date datasets. To address
these limitations, we developed a modular traffic generator that can simulate a
wide variety of benign and malicious traffic. It incorporates multiple
protocols, variability through randomization techniques and can produce attacks
along corresponding benign traffic, as it occurs in real-world scenarios. Using
the traffic generator, we create a dataset capturing over 12 million samples
with 82 flow-level features and 21 fine-grained labels. Additionally, we
include several web attack types which are often underrepresented in other
datasets.",http://arxiv.org/pdf/2502.03909v1,,False
PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations,06/02/2025,"Sanghyeon Lee, Sangjun Bae, Yisak Park, Seungyul Han","Meta-reinforcement learning (Meta-RL) facilitates rapid adaptation to unseen
tasks but faces challenges in long-horizon environments. Skill-based approaches
tackle this by decomposing state-action sequences into reusable skills and
employing hierarchical decision-making. However, these methods are highly
susceptible to noisy offline demonstrations, resulting in unstable skill
learning and degraded performance. To overcome this, we propose Prioritized
Refinement for Skill-Based Meta-RL (PRISM), a robust framework that integrates
exploration near noisy data to generate online trajectories and combines them
with offline data. Through prioritization, PRISM extracts high-quality data to
learn task-relevant skills effectively. By addressing the impact of noise, our
method ensures stable skill learning and achieves superior performance in
long-horizon tasks, even with noisy and sub-optimal data.",http://arxiv.org/pdf/2502.03752v1,,False
Principal Curvatures Estimation with Applications to Single Cell Data,06/02/2025,"Yanlei Zhang, Lydia Mezrag, Xingzhi Sun, Charles Xu, Kincaid Macdonald, Dhananjay Bhaskar, Smita Krishnaswamy, Guy Wolf, Bastian Rieck","The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)
presents challenges for data analysis due to its massive datasets. A common
method in manifold learning consists in hypothesizing that datasets lie on a
lower dimensional manifold. This allows to study the geometry of point clouds
by extracting meaningful descriptors like curvature. In this work, we will
present Adaptive Local PCA (AdaL-PCA), a data-driven method for accurately
estimating various notions of intrinsic curvature on data manifolds, in
particular principal curvatures for surfaces. The model relies on local PCA to
estimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfaces
shows state-of-the-art results. Combined with a PHATE embedding, the model
applied to single-cell RNA sequencing data allows us to identify key variations
in the cellular differentiation.",http://arxiv.org/pdf/2502.03750v1,,False
Controlled LLM Decoding via Discrete Auto-regressive Biasing,06/02/2025,"Patrick Pynadath, Ruqi Zhang","Controlled text generation allows for enforcing user-defined constraints on
large language model outputs, an increasingly important field as LLMs become
more prevalent in everyday life. One common approach uses energy-based
decoding, which defines a target distribution through an energy function that
combines multiple constraints into a weighted average. However, these methods
often struggle to balance fluency with constraint satisfaction, even with
extensive tuning of the energy function's coefficients. In this paper, we
identify that this suboptimal balance arises from sampling in continuous space
rather than the natural discrete space of text tokens. To address this, we
propose Discrete Auto-regressive Biasing, a controlled decoding algorithm that
leverages gradients while operating entirely in the discrete text domain.
Specifically, we introduce a new formulation for controlled text generation by
defining a joint distribution over the generated sequence and an auxiliary bias
sequence. To efficiently sample from this joint distribution, we propose a
Langevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC.
Our method significantly improves constraint satisfaction while maintaining
comparable or better fluency, all with even lower computational costs. We
demonstrate the advantages of our controlled decoding method on sentiment
control, language detoxification, and keyword-guided generation.",http://arxiv.org/pdf/2502.03685v1,,False
