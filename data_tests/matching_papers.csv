Title,Author(s),Publication Date,Proposed Model,Category,Loss,Application Domain,Datasets,Evaluation Metrics,Abstract,Link Paper,Link Code,Arxiv Code
Bidirectional Recurrent Neural Networks as Generative Models - Reconstructing Gaps in Time Series,"Mathias Berglund, Tapani Raiko, Mikko Honkala, Leo Kärkkäinen, Akos Vetek, Juha Karhunen",02/11/2015,BRNN,Methodology,Likelihood,Time series categorial prediction,English text from Wikipedia,1) Mean log-likelihood,"Bidirectional recurrent neural networks (RNN) are trained to predict both in the positive and negative time directions simultaneously. They have not been used commonly in unsupervised tasks, because a probabilistic interpretation of the model has been difficult. Recently, two different frameworks, GSN and NADE, provide a connection between reconstruction and probabilistic modeling, which makes the interpretation possible. As far as we know, neither GSN or NADE have been studied in the context of time series before. As an example of an unsupervised task, we study the problem of filling in gaps in high-dimensional time series with complex dynamics. Although unidirectional RNNs have recently been trained successfully to model such time series, inference in the negative time direction is non-trivial. We propose two probabilistic interpretations of bidirectional RNNs that can be used to reconstruct missing gaps efficiently. Our experiments on text data show that both proposed methods are much more accurate than unidirectional reconstructions, although a bit less accurate than a computationally complex bidirectional Bayesian inference on the unidirectional RNN. We also provide results on music data for which the Bayesian inference is computationally infeasible, demonstrating the scalability of the proposed methods.",https://doi.org/10.48550/arXiv.1504.01575,,1504.01575
C-RNN-GAN: Continuous recurrent neural networks with adversarial training,Olof Mogren,29/11/2016,C-RNN-GAN,Application,GAN Loss (Min-Max),Music creation,music of classical music,"Polyphone
Scale consistency
Repetitions
Tone Span","Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs",https://doi.org/10.48550/arXiv.1611.09904,https://github.com/olofmogren/c-rnn-gan,1611.09904
Feature-driven time series generation,"Lars Kegel, M. Hahmann, Wolfgang Lehner",30/05/2017,"Trend, season, residual model",Methodology,,Synthetic time series generation,M-3 competition,1) Time series visualization,"Time series data are an ubiquitous and important data source in many domains. Most companies and organizations rely on this data for critical tasks like decision-making, planning, and analytics in general. Usually, all these tasks focus on actual data representing organization and business processes. In order to assess the robustness of current systems and methods, it is also desirable to focus on time-series scenarios which represent specific time-series features. This work presents a generally applicable and easy-to-use method for the feature-driven generation of time series data. Our approach extracts descriptive features of a data set and allows the construction of a specific version by means of the modification of these features.
",http://ceur-ws.org/Vol-1858/paper11.pdf,,
Real-Valued (Medical) Time Series Generation With Recurrent Conditional GANs,"Cristóbal Esteban, Stephanie L. Hyland, Gunnar Rätsch",04/12/2017,"RGAN
 RCGAN",Application,,Medical time series generation,"Sine waves
 Sequential MNIST
 Gaussian process
 Philips eICU data","1) MAXIMUM MEAN DISCREPANCY
 2) TSTR
 3) TRTS","Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.",https://doi.org/10.48550/arXiv.1706.02633,,1706.02633
Biosignal Data Augmentation Based on Generative Adversarial Networks,"Shota Harada, Hideaki Hayashi, Seeichi Uchida",01/07/2018,,Application,GAN Loss (Min-Max),"synthetic biosignals using the electrocar-
diogram and electroencephalogram datasets","ECG 200 
Epileptic Seizure Recognition Data Set",," In this paper, we propose a synthetic generation method for time-series data based on generative adversarial networks (GANs) and apply it to data augmentation for biosignal classification. GANs are a recently proposed framework for learning a generative model, where two neural networks, one generating synthetic data and the other discriminating synthetic and real data, are trained while competing with each other. In the proposed method, each neural network in GANs is developed based on a recurrent neural network using long short-term memories, thereby allowing the adaptation of the GANs framework to time-series data generation. In the experiments, we confirmed the capability of the proposed method for generating synthetic biosignals using the electrocardiogram and electroencephalogram datasets. We also showed the effectiveness of the proposed method for data augmentation in the biosignal classification problem.",https://doi.org/10.1109/EMBC.2018.8512396,,
Hierarchical Deep Generative Models For Multi-Rate Multivariate Time Series,"Zhengping Che, Sanjay Purushotham, Guangyu Li, Bo Jiang, Yan Liu",10/07/2018,Multi-Rate Hierarchical Deep Markov Model,Methodology,ELBO,Multi-Rate Multivariate Time Series generation,"MIMIC-III dataset 
 USHCN climate dataset","1) Forecasting
 2) Interpolation","Multi-Rate Multivariate Time Series (MR-MTS) are the multivariate time series observations which come with various sampling rates and encode multiple temporal dependencies. State-space models such as Kalman filters and deep learning models such as deep Markov models are mainly designed for time series data with the same sampling rate and cannot capture all the dependencies present in the MR-MTS data. To address this challenge, we propose the Multi-Rate Hierarchical Deep Markov Model (MR-HDMM), a novel deep generative model which uses the latent hierarchical structure with a learnable switch mechanism to capture the temporal dependencies of MR-MTS. Experimental results on two real-world datasets demonstrate that our MR-HDMM model outperforms the existing state-of-the-art deep learning and state-space models on forecasting and interpolation tasks. In addition, the latent hierarchies in our model provide a way to show and interpret the multiple temporal dependencies.",http://proceedings.mlr.press/v80/che18a/che18a.pdf,,
T-CGAN: Conditional Generative Adversarial Network for Data Augmentation in Noisy Time Series with Irregular Sampling,"Giorgia Ramponi, Pavlos Protopapas, Marco Brambilla, Ryan Janssen",20/11/2018,T-CGAN,Methodology,,,,,"In this paper we propose a data augmentation method for time series with irregular sampling, Time-Conditional Generative Adversarial Network (T-CGAN). Our approach is based on Conditional Generative Adversarial Networks (CGAN), where the generative step is implemented by a deconvolutional NN and the discriminative step by a convolutional NN. Both the generator and the discriminator are conditioned on the sampling timestamps, to learn the hidden relationship between data and timestamps, and consequently to generate new time series. We evaluate our model with synthetic and real-world datasets. For the synthetic data, we compare the performance of a classifier trained with T-CGAN-generated data, against the performance of the same classifier trained on the original data. Results show that classifiers trained on T-CGAN-generated data perform the same as classifiers trained on real data, even with very short time series and small training sets. For the real world datasets, we compare our method with other techniques of data augmentation for time series, such as time slicing and time warping, over a classification problem with unbalanced datasets. Results show that our method always outperforms the other approaches, both in case of regularly sampled and irregularly sampled time series. We achieve particularly good performance in case with a small training set and short, noisy, irregularly-sampled time series. ",https://doi.org/10.48550/arXiv.1811.08295,,1811.08295
Stock Price Manipulation Detection using Generative Adversarial Networks,Teema Leangarun; Poj Tangamchit; Suttipong Thajchayapong,21/11/2018,,Application,,Financial Markets,,,"We implemented Generative Adversarial Networks (GANs) for detecting abnormal trading behaviors caused by stock price manipulations. Long short-term memory (LSTM) was used as a base structure of our GANs, which learned normal market behaviors in an unsupervised way. After the training, the discriminator network of GANs was used as a detector to discriminate between normal and manipulative trading. Our work is different from the previous work in that we did not use manipulation cases to train the neural networks. Instead, we used normal data to train them, and simulated manipulation cases were only used for testing purposes. The detection system was tested with the trading data from the Stock Exchange of Thailand (SET). It can achieve 68.1% accuracy in detecting pump-and-dump manipulations in unseen market data.",https://doi.org/10.1109/SSCI.2018.8628777,,
STCN: Stochastic Temporal Convolutional Networks,"Emre Aksan, Otmar Hilliges",18/02/2019,STCN,Methodology,,Handwritten texts and speech modelling.,"IAM-OnDB 
Deepwriting
TIMIT
Blizzard",,"Convolutional architectures have recently been shown to be competitive on many sequence modelling tasks when compared to the de-facto standard of recurrent neural networks (RNNs), while providing computational and modeling advantages due to inherent parallelism. However, currently there remains a performance gap to more expressive stochastic RNN variants, especially those with several layers of dependent random variables. In this work, we propose stochastic temporal convolutional networks (STCNs), a novel architecture that combines the computational advantages of temporal convolutional networks (TCN) with the representational power and robustness of stochastic latent spaces. In particular, we propose a hierarchy of stochastic latent variables that captures temporal dependencies at different time-scales. The architecture is modular and flexible due to the decoupling of the deterministic and stochastic layers. We show that the proposed architecture achieves state of the art log-likelihoods across several tasks. Finally, the model is capable of predicting high-quality synthetic samples over a long-range temporal horizon in modeling of handwritten text. ",https://doi.org/10.48550/arXiv.1902.06568,https://github.com/emreaksan/stcn,1902.06568
Modeling Financial Time-Series With Generative Adversarial Networks,"Shuntaro Takahashi, Yu Chen, Kumiko Tanaka-Ishii",01/08/2019,GAN,Application,GAN Loss,Finantial market data generation,Stock prices of S&P 500 firms,"1) Linear unpredictability
 2) Fat-tailed distribution
 3) Volatility Clustering
 4) Leverage effects
 5) Coarse-fine volatility correlation
 6) Gain/Loss asymmetry","Financial time-series modeling is a challenging problem as it retains various complex statistical properties and the mechanism behind the process is unrevealed to a large extent. In this paper, a deep neural networks based approach, generative adversarial networks (GANs) for financial time-series modeling is presented. GANs learn the properties of data and generate realistic data in a data-driven manner. The GAN model produces a time-series that recovers the statistical properties of financial time-series such as the linear unpredictability, the heavy-tailed price return distribution, volatility clustering, leverage effects, the coarse-fine volatility correlation, and the gain/loss asymmetry",https://doi.org/10.1016/j.physa.2019.121261,https://github.com/stakahashy/fingan,
Quick And Easy Time Series Generation With Established Image-Based GANs,"Eoin Brophy, Zhengwei Wang, Tomas E. Ward",29/10/2019,WGAN,Methodology,,Synthetic time series generation,"Sine
 Photoplethysmograp (PPG)
 Electrocardiograph (ECG)","1) FID score
 2) MMD","In the recent years Generative Adversarial Networks (GANs) have demonstrated significant progress in generating authentic looking data. In this work we introduce our simple method to exploit the advancements in well established image-based GANs to synthesise single channel time series data. We implement Wasserstein GANs (WGANs) with gradient penalty due to their stability in training to synthesise three different types of data; sinusoidal data, photoplethysmograph (PPG) data and electrocardiograph (ECG) data. The length of the returned time series data is limited only by the image resolution, we use an image size of 64x64 pixels which yields 4096 data points. We present both visual and quantitative evidence that our novel method can successfully generate time series data using image-based GANs.",https://doi.org/10.48550/arXiv.1902.05624,,1902.05624
Time-Series Generative Adversarial Networks,"Jinsung Yoon, Daniel Jarrett, Mihaela van der Schaar",08/12/2019,Time-GAN,Methodology,"Reconstruction Loss
 Unsupervised Loss: GAN loss
 Supervised Loss: ML loss",Synthetic time series generation,"Synthetic AR Gaussian process
 Multivariate sinusoidal sequence
 Google stock data
 UCI Appliances energy prediction dataset
 Lung cancer pathways datase","1) Diversity: t-SNE, PCA visualization
 2) Fidelity: Discriminative score
 3) Usefulness: Predictive score","A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction—which allow finer control over network dynamics—are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability",https://proceedings.neurips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf,https://github.com/jsyoon0823/TimeGAN,
Quant Gans: Deep Generation Of Financial Time Series,"Magnus Wiese, Robert Knobloch, Ralf Korn, Peter Kretschmer",06/04/2020,Quant GAN,Methodology,,Finantial market data generation,S&P 500 index,"1) W1 metric
 2) DY metric
 3) ACF score
 4) Leverage effect score","Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity.",https://doi.org/10.1080/14697688.2020.1730426,https://github.com/JamesSullivan/temporalCN,1907.06673
A Data-driven Market Simulator For Small Data Environments,"Hans Buhler, Blanka Horvath, Terry Lyons, Imanol Perez Arribas, Ben Wood",21/06/2020,,Methodology,,,,,"Neural network based data-driven market simulation unveils a new and flexible way of modelling financial time series without imposing assumptions on the underlying stochastic dynamics. Though in this sense generative market simulation is model-free, the concrete modelling choices are nevertheless decisive for the features of the simulated paths. We give a brief overview of currently used generative modelling approaches and performance evaluation metrics for financial time series, and address some of the challenges to achieve good results in the latter. We also contrast some classical approaches of market simulation with simulation based on generative modelling and highlight some advantages and pitfalls of the new approach. While most generative models tend to rely on large amounts of training data, we present here a generative model that works reliably in environments where the amount of available training data is notoriously small. Furthermore, we show how a rough paths perspective combined with a parsimonious Variational Autoencoder framework provides a powerful way for encoding and evaluating financial time series in such environments where available training data is scarce. Finally, we also propose a suitable performance evaluation metric for financial time series and discuss some connections of our Market Generator to deep hedging. ",https://arxiv.org/abs/2006.14498,https://github.com/imanolperez/market_simulator,2006.14498
MTSS-GAN: Multivariate Time Series Simulation Generative Adversarial Networks,Derek Snow,26/06/2020,MTSS-GAN,Methodology,,Multivariate synthetic time series generation,Google stock data,"1) Autocorrelation
 2) Correlation matrix
 3) Predictive score
 4) t-SNE, PCA plots","MTSS-GAN is a new generative adversarial network (GAN) developed to simulate diverse multivariate time series (MTS) data with finance applications in mind. The purpose of this synthesiser is two-fold, we both want to generate data that accurately represents the original data, while also having the flexibility to generate data with novel and unique relationships that could help with model testing and robustness checks. The method is inspired by stacked GANs originally designed for image generation. Stacked GANs have produced some of the best quality images, for that reason MTSS-GAN is expected to be a leading contender in multivariate time series generation.",https://dx.doi.org/10.2139/ssrn.3616557,https://github.com/firmai/mtss-gan,
Conditional GAN for timeseries generation,"Kaleb E Smith, Anthony O Smith",30/06/2020,TSGAN,Methodology,,,,,"It is abundantly clear that time dependent data is a vital source of information in the world. The challenge has been for applications in machine learning to gain access to a considerable amount of quality data needed for algorithm development and analysis. Modeling synthetic data using a Generative Adversarial Network (GAN) has been at the heart of providing a viable solution. Our work focuses on one dimensional times series and explores the few shot approach, which is the ability of an algorithm to perform well with limited data. This work attempts to ease the frustration by proposing a new architecture, Time Series GAN (TSGAN), to model realistic time series data. We evaluate TSGAN on 70 data sets from a benchmark time series database. Our results demonstrate that TSGAN performs better than the competition both quantitatively using the Frechet Inception Score (FID) metric, and qualitatively when classification is used as the evaluation criteria.",https://doi.org/10.48550/arXiv.2006.16477,https://github.com/numancelik34/TimeSeries-GAN,2006.16477
Cot-GAN: Generating Sequential Data Via Causal Optimal Transport,"Tianlin Xu, Li K. Wenliang, Michael Munn, Beatrice Acciaio",21/10/2020,COT-GAN,Methodology,,,"Multivariate AR(1)
 Noisy oscillation
 UCI Electroencephalography dataset",1) Correlation metric,"We introduce COT-GAN, an adversarial algorithm to train implicit generative models optimized for producing sequential data. The loss function of this algorithm is formulated using ideas from Causal Optimal Transport (COT), which combines classic optimal transport methods with an additional temporal causality constraint. Remarkably, we find that this causality condition provides a natural framework to parameterize the cost function that is learned by the discriminator as a robust (worst-case) distance, and an ideal mechanism for learning time dependent data distributions. Following Genevay et al. (2018), we also include an entropic penalization term which allows for the use of the Sinkhorn algorithm when computing the optimal transport cost. Our experiments show effectiveness and stability of COT-GAN when generating both low- and high-dimensional time series data. The success of the algorithm also relies on a new, improved version of the Sinkhorn divergence which demonstrates less bias in learning.",https://doi.org/10.48550/arXiv.2006.08571,https://github.com/tianlinxu312/cot-gan,2006.08571
"Using GANs For Sharing Networked Time Series Data: Challenges, Initial Promise, And Open Questions","Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, Vyas Sekar",27/10/2020,DoppelGANger,Methodology,,Synthetic time series generation,"Wikipedia Web Traffic
 Measuring Broadband America 
 Google Cluster Usage Traces","1) Temporal and spatial autocorrelation
 2) W1-distance
 3) Resource costs","Limited data access is a longstanding barrier to data-driven research and development in the networked systems community. In this work, we explore if and how generative adversarial networks (GANs) can be used to incentivize data sharing by enabling a generic framework for sharing synthetic datasets with minimal expert knowledge. As a specific target, our focus in this paper is on time series datasets with metadata (e.g., packet loss rate measurements with corresponding ISPs). We identify key challenges of existing GAN approaches for such workloads with respect to fidelity (e.g., long-term dependencies, complex multidimensional relationships, mode collapse) and privacy (i.e., existing guarantees are poorly understood and can sacrifice fidelity). To improve fidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate that across diverse real-world datasets (e.g., bandwidth measurements, cluster requests, web sessions) and use cases (e.g., structural characterization, predictive modeling, algorithm comparison), DG achieves up to 43% better fidelity than baseline models. Although we do not resolve the privacy problem in this work, we identify fundamental challenges with both classical notions of privacy and recent advances to improve the privacy properties of GANs, and suggest a potential roadmap for addressing these challenges. By shedding light on the promise and challenges, we hope our work can rekindle the conversation on workflows for data sharing",https://doi.org/10.1145/3419394.3423643,https://github.com/fjxmlzn/DoppelGANger,1909.13403
A Spectral Enabled GAN for Time Series Data Generation,"Kaleb E. Smith, Anthony O. Smith",02/03/2021,uTSGAN,Methodology,,,,,"Time dependent data is a main source of information in today's data driven world. Generating this type of data though has shown its challenges and made it an interesting research area in the field of generative machine learning. One such approach was that by Smith et al. who developed Time Series Generative Adversarial Network (TSGAN) which showed promising performance in generating time dependent data and the ability of few shot generation though being flawed in certain aspects of training and learning. This paper looks to improve on the results from TSGAN and address those flaws by unifying the training of the independent networks in TSGAN and creating a dependency both in training and learning. This improvement, called unified TSGAN (uTSGAN) was tested and comapred both quantitatively and qualitatively to its predecessor on 70 benchmark time series data sets used in the community. uTSGAN showed to outperform TSGAN in 80\% of the data sets by the same number of training epochs and 60\% of the data sets in 3/4th the amount of training time or less while maintaining the few shot generation ability with better FID scores across those data sets.",https://doi.org/10.48550/arXiv.2103.01904,,2103.01904
Generative Time-Series Modeling With Fourier Flows,"Ahmed M. Alaa, Alex James Chan, Mihaela van der Schaar",18/03/2021,Fourier flow,Methodology,Likelihood,Synthetic time series generation,"Sinusoidal sequence
 Google stocks data
 UCI Energy data
 Lung cancer pathways datase","1) F-score
 2) Predictive score","Generating synthetic time-series data is crucial in various application domains, such as medical prognosis, wherein research is hamstrung by the lack of access to data due to concerns over privacy. Most of the recently proposed methods for generating synthetic time-series rely on implicit likelihood modeling using generative adversarial networks (GANs)—but such models can be difficult to train, and may jeopardize privacy by “memorizing” temporal patterns in training data. In this paper, we propose an explicit likelihood model based on a novel class of normalizing flows that view time-series data in the frequency-domain rather than the time-domain. The proposed flow, dubbed a Fourier flow, uses a discrete Fourier transform (DFT) to convert variable-length time-series with arbitrary sampling periods into fixedlength spectral representations, then applies a (data-dependent) spectral filter to the frequency-transformed time-series. We show that, by virtue of the DFT analytic properties, the Jacobian determinants and inverse mapping for the Fourier flow can be computed efficiently in linearithmic time, without imposing explicit structural constraints as in existing flows such as NICE (Dinh et al. (2014)), RealNVP (Dinh et al. (2016)) and GLOW (Kingma & Dhariwal (2018)). Experiments show that Fourier flows perform competitively compared to state-of-the-art baselines.",https://openreview.net/pdf?id=PpshD0AXfA,https://github.com/ahmedmalaa/Fourier-flows,
Multivariate Time Series Synthesis Using Generative Adversarial Networks,"Mark Leznik, Patrick Michalsky, Peter Willis, Benjamin Schanzel, Per-Olov Östberg, Jörg Domaschka",19/04/2021,,Application,,Multivariate Time series generation,Content Delivery Network data,"1) Engle-Granger test
 2) Johansen test","Collection and analysis of distributed (cloud) computing workloads allows for a deeper understanding of user and system behavior and is necessary for efficient operation of infrastructures and applications. The availability of such workload data is however often limited as most cloud infrastructures are commercially operated and monitoring data is considered proprietary or falls under GPDR regulations. This work investigates the generation of synthetic workloads using Generative Adversarial Networks and addresses a current need for more data and better tools for workload generation. Resource utilization measurements such as the utilization rates of Content Delivery Network (CDN) caches are generated and a comparative evaluation pipeline using descriptive statistics and time-series analysis is developed to assess the statistical similarity of generated and measured workloads. We use CDN data open sourced by us in a data generation pipeline as well as back-end ISP workload data to demonstrate the multivariate synthesis capability of our approach. The work contributes a generation method for multivariate time series workload generation that can provide arbitrary amounts of statistically similar data sets based on small subsets of real data. The presented technique shows promising results, in particular for heterogeneous workloads not too irregular in temporal behavior.",https://doi.org/10.1145/3427921.3450257,,
Clare-GAN: Generation Of Class-Specific Time Series,"Hiba Arnout, Johanna Bronner, Thomas Runkler",04/05/2021,ClaReGAN,Methodology,,Synthetic time series generation,"Italy Power Demand
 Two Lead ECG
 Freezer Regular Train
 Distal Phalanx TW
 Yoga","1) Diversity: t-SNE, PCA visualization
 2) Fidelity: Discriminative score
 3) Usefulness: Predictive score","Through numerous works [9], [26], [32] attempts were made to obtain generative models for time series that correctly reproduce the underlying temporal characteristics of a given training data set. However, we prove in this work that the performance of these models is limited on datasets with high-variability for example containing different classes. In such setups, it is extremely difficult for a generative model to find the right trade-off between sample fidelity i.e. their similarity to the real time series and sample diversity. Furthermore, it is essential to preserve the original classes and the variation within each class. To tackle this issue, we propose a new generative class sensitive model, Class-specific Recurrent GAN (CLaReGAN), that conditions the generator on an auxiliary information containing the class-specific and class-independent attributes. Our model relies on class specific encoders: a unique encoder for two contradictory functionalities i.e. extracting the inter- and intra-class attributes. To extract the high-level representation of the time series, we make a shared-latent space assumption [19]. At the same time, we use a class discriminator that discriminates between the latent vectors to efficiently extract the class-specific attributes. We test our approach on a set of publicly available datasets where the number of classes, the length and the number of available times series for each class varies and evaluate our approach both visually and computationally. We prove that our model outperforms the state-of-the-art generative models and leads to a significant and consistent improvement in the quality of the generated time series while preserving the classes and variation of the original dataset.",https://doi.org/10.1109/SSCI50451.2021.9660020,,
Generative Adversarial Networks in Finance: an overview,"Florian Eckerli, Joerg Osterrieder",01/06/2021,,Model assessment,,Finantial market data generation,S&P500,stylized facts,"Modelling in finance is a challenging task: the data often has complex statistical properties and its inner workings are largely unknown. Deep learning algorithms are making progress in the field of data-driven modelling, but the lack of sufficient data to train these models is currently holding back several new applications. Generative Adversarial Networks (GANs) are a neural network architecture family that has achieved good results in image generation and is being successfully applied to generate time series and other types of financial data. The purpose of this study is to present an overview of how these GANs work, their capabilities and limitations in the current state of research with financial data and present some practical applications in the industry. As a proof of concept, three known GAN architectures were tested on financial time series, and the generated data was evaluated on its statistical properties, yielding solid results. Finally, it was shown that GANs have made considerable progress in their finance applications and can be a solid additional tool for data scientists in this field.",https://doi.org/10.48550/arXiv.2106.06364,https://github.com/eckerli/BA_code ,2106.06364
Generative Adversarial Networks For Markovian Temporal Dynamics: Stochastic Continuous Data Generation,"Sung Woo Park, Dong Wook Shu, Junseok Kwon",18/07/2021,SD-GAN,Methodology,Conditional Markov W1 Distance,,"Fashion-MNIST
 Gaussian process
 Human action video data
 LPC-Sprite Animations","1) Fréchet Inception distance
 2) Kernel Inception distance","In this paper, we present a novel generative adversarial network (GAN) that can describe Markovian temporal dynamics. To generate stochastic sequential data, we introduce a novel stochastic differential equation-based conditional generator and spatial-temporal constrained discriminator networks. To stabilize the learning dynamics of the min-max type of the GAN objective function, we propose well-posed constraint terms for both networks. We also propose a novel conditional Markov Wasserstein distance to induce a pathwise Wasserstein distance. The experimental results demonstrate that our method outperforms stateof-the-art methods using several different types of data.",http://proceedings.mlr.press/v139/park21d/park21d.pdf,,
Analyzing Deep Generated Financial Time Series For Various Asset Classes,Antonio Rosolia,18/07/2021,GAN,Application,GAN Loss,Finantial market data generation,"Gold Futures
 EUR vs USD Foreign Exchange Reference Rate
 S&P 500 Volatility Index VIX Futures 
 S&P 500 Index, Continuous Contract
 Apple Inc. (AAPL) Stock Prices","1) Kurtosis
 2) ACF
 3) Histogram","Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a GAN to produce realistic realvalued time series, with an emphasis on their application to financial data. Our aim is having a GAN, applied on various financial time series for various asset classes, that can reflect all the characteristics of them, as well as the characteristics we may be unaware of, as GANs learn the underlying structure of our data, rather than just a set of features. If we are able to achieve this, the synthetic datasets we create could be used for a variety of purposes including model training and model selection. In this paper we try to train a GAN with real data, representing one asset of different asset classes such as commodities, forex, futures, index and shares.",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3898792,,
Conditional Loss And Deep Euler Scheme For Time Series Generation,"Carl Remlinger, Joseph Mikael, Romuald Elie",06/10/2021,Conditional Euler Generator,Methodology,W2 distance metric,Synthetic time series generation driven by SDE,"GBM process
 OU process
 Stocks data
 Jena Climate 
 Electric Load","1) Marginal statistics
 2) Quadratic variation
 3) Correlation structure
 4) Underlying process parameters
 5) Discriminative and predictive scores","We introduce three new generative models for time series that are based on Euler discretization of Stochastic Differential Equations (SDEs) and Wasserstein metrics. Two of these methods rely on the adaptation of generative adversarial networks (GANs) to time series. The third algorithm, called Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the transition probability distributions over all time steps. In the context of Itô processes, we provide theoretical guarantees that minimizing this criterion implies accurate estimations of the drift and volatility parameters. We demonstrate empirically that CEGEN outperforms state-of-the-art and GAN generators on both marginal and temporal dynamics metrics. Besides, it identifies accurate correlation structures in high dimension. When few data points are available, we verify the effectiveness of CEGEN, when combined with transfer learning methods on Monte Carlo simulations. Finally, we illustrate the robustness of our method on various real-world datasets.",https://doi.org/10.48550/arXiv.2102.05313,,2102.05313
Differentially Private Time Series Generation,"Hiba Arnout, Johanna Bronner, Thomas Runkler",06/10/2021,"DP-TimeGAN, DP-Clare GAN, DP-CRNN GAN",Model Assessment,,Time series generation with data privacy,"Italy Power Demand
 Two Lead ECG
 Freezer Regular Train
 Distal Phalanx TW
 Yoga","1) TRTS classification score
 2) TSTR classification score","Privacy issues prevent data owner from improving Machine Learning (ML) performance as it makes external collaborations binding. To allow data sharing without confidentiality concerns, we propose in this work methods to generate time series in a privacy preserving manner. We combine the existing Generative Adversarial Networks (GAN) models for time series namely TimeGAN [1], ClaRe-GAN [2] and C-RNN-GAN [3] with differential privacy. This is achieved by changing their original discriminator with a private discriminator that relies on the differentially private stochastic gradient method (DPSGD) [4]. Our experiments show that the developed methods - in particular TimeGAN and ClaRe-GAN outperform the existing and unique differentially private model for time series of RCGAN [5] in terms of privacy and accuracy.",https://doi.org/10.14428/esann%2F2021.es2021-20,,
Sig-Wasserstein GANs For Time Series Generation,"Hao Ni, Lukasz Szpruch, Marc Sabate-Vidales, Baoren Xiao, Magnus Wiese, Shujian Liao",01/11/2021,Sig-WGAN,Methodology,Maximum Mean Discrepancy,Synthetic time series generation,"Multi-dimensional Geometric Brownian motion
 Rough Volatility model
 S&P 500 and DJI Market Data","1) Sig-W1 metric
 2) Marginal distribution metric
 3) Correlation metric","Synthetic data is an emerging technology that can significantly accelerate the development and deployment of AI machine learning pipelines. In this work, we develop high-fidelity time-series generators, the SigWGAN, by combining continuous-time stochastic models with the newly proposed signature W1 metric. The former are the Logsig-RNN models based on the stochastic differential equations, whereas the latter originates from the universal and principled mathematical features to characterize the measure induced by time series. SigWGAN allows turning computationally challenging GAN min-max problem into supervised learning while generating high fidelity samples. We validate the proposed model on both synthetic data generated by popular quantitative risk models and empirical financial data.",https://arxiv.org/pdf/2111.01207.pdf,https://github.com/SigCGANs/Sig-WassersteinGANs.git,2111.01207
Towards Generating Real-World Time Series Data,"Hengzhi Pei, Kan Ren, Yuqing Yang, Chang Liu, Tao Qin, Dongsheng Li",16/11/2021,RTSGAN,Application,GAN Loss,Real-world time series generation,"Google stocks data
 UCI Appliances energy prediction dataset
 PhysioNet Challenge 2012 dataset
 Medical Information Mart for Intensive Care (MIMIC-III) database","1) Discriminative Score
 2) Predictive Score
 3) t-SNE, PCA","Time series data generation has drawn increasing attention in recent years. Several generative adversarial network (GAN) based methods have been proposed to tackle the problem usually with the assumption that the targeted time series data are well-formatted and complete. However, real-world time series (RTS) data are far away from this utopia, e.g., long sequences with variable lengths and informative missing data raise intractable challenges for designing powerful generation algorithms. In this paper, we propose a novel generative framework for RTS data — RTSGAN to tackle the aforementioned challenges. RTSGAN first learns an encoder-decoder module which provides a mapping between a time series instance and a fixeddimension latent vector and then learns a generation module to generate vectors in the same latent space. By combining the generator and the decoder, RTSGAN is able to generate RTS which respect the original feature distributions and the temporal dynamics. To generate time series with missing values, we further equip RTSGAN with an observation embedding layer and a decide-and-generate decoder to better utilize the informative missing patterns. Experiments on the four RTS datasets show that the proposed framework outperforms the previous generation methods in terms of synthetic data utility for downstream classification and prediction tasks. 
",https://doi.org/10.48550/arXiv.2111.08386,https://seqml.github.io/rtsgan,2111.08386
Time-Series Generation By Contrastive Imitation,"Daniel Jarrett, Ioana Bica, Mihaela van der Schaar",06/12/2021,GAN with different loss,Methodology,Expected quality difference,Synthetic time series generation,"Multivariate sinusoid
 UCI energy, gas, metro dataset
 MIMIC-III","1) Predictive Score
 2) Train-on-Synthetic, Test-on-Real","Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learned cooperatively, avoiding the instabilities typical of adversarial objectives. At inference, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a trajectory-level measure for evaluating sample quality. By expressly training a policy to imitate sequential behavior of time-series features in a dataset, this approach embodies “generation by imitation”. Theoretically, we illustrate the correctness of this formulation and the consistency of the algorithm. Empirically, we evaluate its ability to generate predictively useful samples from realworld datasets, verifying that it performs at the standard of existing benchmarks.",https://openreview.net/pdf?id=RHZs3GqLBwg,,
TimeVAE: A Variational Auto-Encoder For Multivariate Time Series Generation,"Abhyuday Desai, Cynthia Freeman, Zuhui Wang, Ian Beaver",07/12/2021,TimeVAE,Methodology,ELBO,,"Sines
 Stoke prices
  UCI Energy, Air data","1) t-SNE
 2) Discriminative score
 3) Predictive score","Recent work in synthetic data generation in the time-series domain has focused on the use of Generative Adversarial Networks. We propose a novel architecture for synthetically generating time-series data with the use of Variational AutoEncoders (VAEs). The proposed architecture has several distinct properties: interpretability, ability to encode domain knowledge, and reduced training times. We evaluate data generation quality by similarity and predictability against four multivariate datasets. We experiment with varying sizes of training data to measure the impact of data availability on generation quality for our VAE method as well as several state-of-the-art data generation methods. Our results on similarity tests show that the VAE approach is able to accurately represent the temporal attributes of the original data. On next-step prediction tasks using generated data, the proposed VAE architecture consistently meets or exceeds performance of state-ofthe-art data generation methods. While noise reduction may cause the generated data to deviate from original data, we demonstrate the resulting de-noised data can significantly improve performance for next-step prediction using generated data. Finally, the proposed architecture can incorporate domain-specific time-patterns such as polynomial trends and seasonalities to provide interpretable outputs. Such interpretability can be highly advantageous in applications requiring transparency of model outputs or where users desire to inject prior knowledge of time-series patterns into the generative model.
",https://arxiv.org/pdf/2111.08095.pdf,https://github.com/ratschlab/RGAN,2111.08095
PSA-GAN: Progressive Self Attention Gans For Synthetic Time Series,"Jeha Paul, Bohlke-Schneider Michael, Mercado Pedro, Kapoor Shubham, Singh Nirwan Rajbir, Flunkert Valentin, Gasthaus Jan, Januschowski Tim",28/03/2022,PSA-GAN,Methodology,LSGAN loss,Synthetic time series generation and forecasting,"The M4 Competition, 
 Solar, hourly solar energy collection data in Alabama State, 
 Electricity, hourly electricity consumption data, 
 Traffic: hourly occupancy rate of lanes in San Francisco","1) Context FID score,
 2) Far-forecasting
 3) Missing Value Stretches","Realistic synthetic time series data of sufficient length enables practical applications in time series modeling tasks, such as forecasting, but remains a challenge. In this paper, we present PSA-GAN, a generative adversarial network (GAN) that generates long time series samples of high quality using progressive growing of GANs and self-attention. We show that PSA-GAN can be used to reduce the error in several downstream forecasting tasks over baselines that only use real data. We also introduce a Frechet Inception distance-like score for time series, Context-FID, assessing the quality of synthetic time series samples. We find that Context-FID is indicative for downstream performance. Therefore, Context-FID could be a useful tool to develop time series GAN models.",https://doi.org/10.48550/arXiv.2108.00981,https://github.com/mbohlkeschneider/psa-gan,2108.00981
Time Series Generation With Masked Autoencoder,"Mengyue Zha, SiuTim Wong, Mengqi Liu, Tong Zhang, Kani Chen",19/05/2022,ExtraMAE,Methodology,,Synthetic time series generation,"Google stock price
 Sine
 UCI Energy data
 Wafer 
 Italy Power Demand
 Strawberry","1) PCA visualization
 2) t-SNE visualization
 3) Prediction score
 4) Classification score","This paper shows that masked autoencoder with extrapolator (ExtraMAE) is a scalable self-supervised model for time series generation. ExtraMAE randomly masks some patches of the original time series and learns temporal dynamics by recovering the masked patches. Our approach has two core designs. First, ExtraMAE is self-supervised. Supervision allows ExtraMAE to effectively and efficiently capture the temporal dynamics of the original time series. Second, ExtraMAE proposes an extrapolator to disentangle two jobs of the decoder: recovering latent representations and mapping them back into the feature space. These unique designs enable ExtraMAE to consistently and significantly outperform state-of-the-art (SoTA) benchmarks in time series generation. The lightweight architecture also makes ExtraMAE fast and scalable. ExtraMAE shows outstanding behavior in various downstream tasks such as time series classification, prediction, and imputation. As a self-supervised generative model, ExtraMAE allows explicit management of the synthetic data. We hope this paper will usher in a new era of time series generation with self-supervised models.",https://doi.org/10.48550/arXiv.2201.07006,https://github.com/Dolores2333/ExtraMAE,2201.07006
Time-Series Transformer Generative Adversarial Networks,"Padmanaba Srinivasan, William J. Knottenbelt",23/05/2022,TsT-GAN,Methodology,LS-GAN loss + moment loss,,"Sines
 Stoke prices
  UCI Energy, Air data
 UCI Hungarian Chickenpox Cases data","1) Predictive score
 2) Discriminative score
 3) t-SNE","Many real-world tasks are plagued by limitations on data: in some instances very little data is available and in others, data is protected by privacy enforcing regulations (e.g. GDPR). We consider limitations posed specifically on time-series data and present a model that can generate synthetic time-series which can be used in place of real data. A model that generates synthetic time-series data has two objectives: 1) to capture the stepwise conditional distribution of real sequences, and 2) to faithfully model the joint distribution of entire real sequences. Autoregressive models trained via maximum likelihood estimation can be used in a system where previous predictions are fed back in and used to predict future ones; in such models, errors can accrue over time. Furthermore, a plausible initial value is required making MLE based models not really generative. Many downstream tasks learn to model conditional distributions of the time-series, hence, synthetic data drawn from a generative model must satisfy 1) in addition to performing 2). We present TsT-GAN, a framework that capitalises on the Transformer architecture to satisfy the desiderata and compare its performance against five state-of-the-art models on five datasets and show that TsT-GAN achieves higher predictive performance on all datasets.",https://doi.org/10.48550/arXiv.2205.11164,https://github.com/jsyoon0823/TimeGAN,2205.11164
TTS-GAN: A Transformer-Based Time-Series Generative Adversarial Network,"Xiaomin Li, Vangelis Metsis, Huangyingrui Wang, Anne Hee Hiong Ngu",26/06/2022,TTS-GAN,Methodology,,,"Sine
UniMiB data
PTB Diagnostic ECG data","1) t-SNE, PCA visualization
 2) Cosine similarity
 3) Jensen-Shannon distance","Signal measurements appearing in the form of time series are one of the most common types of data used in medical machine learning applications. However, such datasets are often small, making the training of deep neural network architectures ineffective. For time-series, the suite of data augmentation tricks we can use to expand the size of the dataset is limited by the need to maintain the basic properties of the signal. Data generated by a Generative Adversarial Network (GAN) can be utilized as another data augmentation tool. RNN-based GANs suffer from the fact that they cannot effectively model long sequences of data points with irregular temporal relations. To tackle these problems, we introduce TTS-GAN, a transformer-based GAN which can successfully generate realistic synthetic time-series data sequences of arbitrary length, similar to the real ones. Both the generator and discriminator networks of the GAN model are built using a pure transformer encoder architecture. We use visualizations and dimensionality reduction techniques to demonstrate the similarity of real and generated time-series data. We also compare the quality of our generated data with the best existing alternative, which is an RNN-based time-series GAN.",https://doi.org/10.48550/arXiv.2202.02691,https://github.com/imics-lab/tts-gan,2202.02691
Simulating financial time series using attention,"Weilong Fu, Ali Hirsa, Jörg Osterrieder",01/07/2022,TAGAN and TTGAN,Methodology,,Financial data,S&P 500 index and option data,,"Financial time series simulation is a central topic since it extends the limited real data for training and evaluation of trading strategies. It is also challenging because of the complex statistical properties of the real financial data. We introduce two generative adversarial networks (GANs), which utilize the convolutional networks with attention and the transformers, for financial time series simulation. The GANs learn the statistical properties in a data-driven manner and the attention mechanism helps to replicate the long-range dependencies. The proposed GANs are tested on the S&P 500 index and option data, examined by scores based on the stylized facts and are compared with the pure convolutional GAN, i.e. QuantGAN. The attention-based GANs not only reproduce the stylized facts, but also smooth the autocorrelation of returns. ",https://doi.org/10.48550/arXiv.2207.00493,,2207.00493
Wasserstein generative adversarial networks for modeling marked events,"S. Haleh S. Dizaji, Saeid Pashazadeh, Javad Musevi Niya",01/08/2022,,Methodology,WGAN Loss for sequences,,,,"Marked temporal events are ubiquitous in several areas, where the events’ times and marks (types) are usually interrelated. Point processes and their non-functional variations using recurrent neural networks (RNN) model temporal events using intensity functions. However, since they usually utilize the likelihood maximization approach, they might fail. Moreover, their high simulation complexity makes them inappropriate. Since calculating the intensity function is not always necessary, generative models are utilized for modeling. Generative adversarial networks (GANs) have been successful in modeling point processes, but they still lack in modeling interdependent types and times of events. In this research, a double Wasserstein GAN (WGAN), using a conditional GAN, is proposed which generates types of events that are categorical data, dependent on their times. Experiments on synthetic and real-world data represent that WGAN methods are efficient or competitive with the compared intensity-based models. Furthermore, these methods have a faster simulation than intensity-based methods.",https://link.springer.com/article/10.1007/s11227-022-04781-0,,
Generating Synthetic Time Series for Machine-Learning-Empowered Monitoring of Electric Motor Test Benches,"Tobias Westmeier, Diego Botache, Maarten Bieshaar, Bernhard Sick",15/10/2022,,Application,,,,FITD,"The development of new electric traction machines is a time-consuming process as it involves intensive testing on motor test benches. Machine-Learning-empowered monitoring offers the opportunity to anticipate costly failures early and hence reduce development time. However, machine learning (ML) for process monitoring requires large amounts of training data, especially as the targeted fault states are scarce and yet diverse in their appearances.Therefore, we propose to use synthetic time series data to leverage the high cost of acquiring training data from experiments in real test benches. In this article, we present a novel scheme to generate synthetic data based on a sub-dimensional time series representation. We introduce a highly flexible model by mapping the data to a latent representation and approximating the latent data distribution by a Gaussian Mixture Model. In addition, we propose the Fréchet InceptionTime Distance (FITD) as a new distance measure to evaluate the generated data. It allows extracting characteristics at different scales by using multiple kernel sizes. In this way, we ensure that the synthesized data contains characteristics similar to those present in the real data. In our experiment, we train two types of fault detectors, one based on real data of a motor test bench and the other based on synthetic data. We also consider employing fault-aware conditional architectures to generate training data for different fault types explicitly. Our final results show that using synthesized data in the training process increases the performance in terms of classification accuracy score (CAS) up to 29%.",https://doi.org/10.1109/DSAA54385.2022.10032385,,
Learning the conditional law: signatures and conditional GANs in filtering and prediction of diffusion processes,"Fabian Germ, Marc Sabate-Vidales",09/12/2022,"NDE
CSigWGAN",Methodology,,Synthetic dataset,,,"We consider the filtering and prediction problem for a diffusion process. The signal and observation are modeled by stochastic differential equations (SDEs) driven by correlated Wiener processes. In classical estimation theory, measure-valued stochastic partial differential equations (SPDEs) are derived for the filtering and prediction measures. These equations can be hard to solve numerically. We provide an approximation algorithm using conditional generative adversarial networks (GANs) in combination with signatures, an object from rough path theory. The signature of a sufficiently smooth path determines the path completely. As a result, in some cases, GANs based on signatures have been shown to efficiently approximate the law of a stochastic process. For our algorithm we extend this method to sample from the conditional law, given noisy, partial observation. Our generator is constructed using neural differential equations (NDEs), relying on their universal approximator property. We show well-posedness in providing a rigorous mathematical framework. Numerical results show the efficiency of our algorithm.",https://doi.org/10.1109/CDC51059.2022.9993386,https://github.com/msabvid/SigFiltering ,
Generating multivariate time series with COmmon Source CoordInated GAN (COSCI-GAN),"Ali Seyfi, Jean-Francois Rajotte, Raymond T. Ng",15/12/2022,COSCI-GAN,Methodology,,Healthcare,,,"Generating multivariate time series is a promising approach for sharing sensitive data in many medical, financial, and IoT applications. A common type of multivariate time series originates from a single source such as the biometric measurements from a medical patient. This leads to complex dynamical patterns between individual time series that are hard to learn by typical generation models such as GANs. There is valuable information in those patterns that machine learning models can use to better classify, predict or perform other downstream tasks. We propose a novel framework that takes time series' common origin into account and favors channel/feature relationships preservation. The two key points of our method are: 1) the individual time series are generated from a common point in latent space and 2) a central discriminator favors the preservation of inter-channel/feature dynamics. We demonstrate empirically that our method helps preserve channel/feature correlations and that our synthetic data performs very well in downstream tasks with medical and financial data. ",https://doi.org/10.48550/arXiv.2205.13741,https://github.com/aliseyfi75/COSCI-GAN,2205.13741
Generative Adversarial Networks in Time Series: A Systematic Literature Review,"Eoin Brophy, Zhengwei Wang, QI She, Tomas Ward",02/02/2023,,Review,,,,,"Generative adversarial network (GAN) studies have grown exponentially in the past few years. Their impact has been seen mainly in the computer vision field with realistic image and video manipulation, especially generation, making significant advancements. Although these computer vision advances have garnered much attention, GAN applications have diversified across disciplines such as time series and sequence generation. As a relatively new niche for GANs, fieldwork is ongoing to develop high-quality, diverse, and private time series data. In this article, we review GAN variants designed for time series related applications. We propose a classification of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. Here we showcase the latest and most popular literature in this field—their architectures, results, and applications. We also provide a list of the most popular evaluation metrics and their suitability across applications. Also presented is a discussion of privacy measures for these GANs and further protections and directions for dealing with sensitive data. We aim to frame clearly and concisely the latest and state-of-the-art research in this area and their applications to real-world technologies.",https://doi.org/10.1145/3559540,,
Using Time-Series Generative Adversarial Networks to Synthesize Sensing Data for Pest Incidence Forecasting on Sustainable Agriculture,"Chen-Yu Tai, Wun-Jhe Wang, Yueh-Min Huang",17/04/2023,,Application,,Agriculture,,,"A sufficient amount of data is crucial for high-performance and accurate trend prediction. However, it is difficult and time-consuming to collect agricultural data over long periods of time; the consequence of such difficulty is datasets that are characterized by missing data. In this study we use a time-series generative adversarial network (TimeGAN) to synthesize multivariate agricultural sensing data and train RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit) neural network prediction models on the original and generated data to predict future pest populations. After our experiment, the data generated using TimeGAN and the original data have the smallest EC value in the GRU model, which is 9.86. The results show that the generative model effectively synthesizes multivariate agricultural sensing data and can be used to make up for the lack of actual data. The pest prediction model trained on synthetic data using time-series data generation yields results that are similar to that of the model trained on actual data. Accurate prediction of pest populations would represent a breakthrough in allowing for accurate and timely pest control.",https://doi.org/10.3390/su15107834,,
Non-adversarial training of Neural SDEs with signature kernel scores,"Zacharia Issa, Blanka Horvath, Maud Lemercier, Cristopher Salvi",01/05/2023,,Methodology,, irregular time series generation,"Geometric Brownian motion
Rough Bergomi volatility
Foreign exchange currency pairs
NASDAQ public exchange",,"Neural SDEs are continuous-time generative models for sequential data. Stateof-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure permits conditioning on a rich variety of market conditions and significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics.",https://arxiv.org/abs/2305.16274,https://github.com/issaz/sigker-nsdes,2305.16274
PCF-GAN: generating sequential data via the characteristic function of measures on the path space,"Hang Lou, Siran Li, Hao Ni",21/05/2023,PCF-GAN,Methodology,,,,,"Generating high-fidelity time series data using generative adversarial networks (GANs) remains a challenging task, as it is difficult to capture the temporal dependence of joint probability distributions induced by time-series data. Towards this goal, a key step is the development of an effective discriminator to distinguish between time series distributions. We propose the so-called PCF-GAN, a novel GAN that incorporates the path characteristic function (PCF) as the principled representation of time series distribution into the discriminator to enhance its generative performance. On the one hand, we establish theoretical foundations of the PCF distance by proving its characteristicity, boundedness, differentiability with respect to generator parameters, and weak continuity, which ensure the stability and feasibility of training the PCF-GAN. On the other hand, we design efficient initialisation and optimisation schemes for PCFs to strengthen the discriminative power and accelerate training efficiency. To further boost the capabilities of complex time series generation, we integrate the auto-encoder structure via sequential embedding into the PCF-GAN, which provides additional reconstruction functionality. Extensive numerical experiments on various datasets demonstrate the consistently superior performance of PCF-GAN over state-of-the-art baselines, in both generation and reconstruction quality. ",https://doi.org/10.48550/arXiv.2305.12511,https://github.com/DeepIntoStreams/PCF-GAN,2305.12511
Limit Order Book Simulation with Generative Adversarial Networks,"Rama Cont, Mihai Cucuringu, Jonathan Kochems, Felix Prenzel",24/07/2023,,Methodology,,Financial data (LOB),,,"We propose a nonparametric method for simulating the dynamics of a limit order book using Generative Adversarial Networks (GAN) to learn the conditional distribution of the future state of the order book given its current state from time series of the limit order book. Our method yields a scenario generator for limit order books which captures a range of stylized facts and salient properties of limit order book transitions. We show that the trained generator is also able to correctly reproduce some key properties observed in empirical studies on market impact. In particular, the model exhibits a decaying marginal impact of trade size, higher impact of aggressive orders, as well as a decreasing relation between impact and order book depth. ",http://dx.doi.org/10.2139/ssrn.4512356,,
Fully Embedded Time-Series Generative Adversarial Networks,"Joe Beck, Subhadeep Chakraborty",30/08/2023,FETSGAN,Methodology,custom loss,,"Sinuses synthetic dataset
historical Google stocks datase
UCI Applicances energy dataset
Traffic and weather data from UCI Metro Interstate dataset","discriminative score by training an RNN classifier
MAE prediction error","Generative Adversarial Networks (GANs) should produce synthetic data that fits the underlying distribution of the data being modeled. For real valued time-series data, this implies the need to simultaneously capture the static distribution of the data, but also the full temporal distribution of the data for any potential time horizon. This temporal element produces a more complex problem that can potentially leave current solutions under-constrained, unstable during training, or prone to varying degrees of mode collapse. In FETSGAN, entire sequences are translated directly to the generator’s sampling space using a seq2seq style adversarial autoencoder (AAE), where adversarial training is used to match the training distribution in both the feature space and the lower dimensional sampling space. This additional constraint provides a loose assurance that the temporal distribution of the synthetic samples will not collapse. In addition, the First Above Threshold (FAT) operator is introduced to supplement the reconstruction of encoded sequences, which improves training stability and the overall quality of the synthetic data being generated. These novel contributions demonstrate a significant improvement to the current state of the art for adversarial learners in qualitative measures of temporal similarity and quantitative predictive ability of data generated through FETSGAN.",https://doi.org/10.48550/arXiv.2308.15730,https://github.com/jbeck9/FETSGAN,2308.1573
Deep Learning for Time Series Forecasting: Advances and Open Problems ,"Angelo Casolaro, Vincenzo Capone,  Gennaro Iannuzzo, Francesco Camastra",26/09/2023,,Review,,,,,"A time series is a sequence of time-ordered data, and it is generally used to describe how a phenomenon evolves over time. Time series forecasting, estimating future values of time series, allows the implementation of decision-making strategies. Deep learning, the currently leading field of machine learning, applied to time series forecasting can cope with complex and high-dimensional time series that cannot be usually handled by other machine learning techniques. The aim of the work is to provide a review of state-of-the-art deep learning architectures for time series forecasting, underline recent advances and open problems, and also pay attention to benchmark data sets. Moreover, the work presents a clear distinction between deep learning architectures that are suitable for short-term and long-term forecasting. With respect to existing literature, the major advantage of the work consists in describing the most recent architectures for time series forecasting, such as Graph Neural Networks, Deep Gaussian Processes, Generative Adversarial Networks, Diffusion Models, and Transformers.",https://doi.org/10.3390/info14110598,,
Conditional Sig-Wasserstein GANs for Time Series Generation,"Shujian Liao, Hao Ni, Lukasz Szpruch, Magnus Wiese, Marc Sabate-Vidales, Baoren Xiao",11/10/2023,Sig-WCGAN framework,Methodology,,,,,"Generative adversarial networks (GANs) have been extremely successful in generating samples, from seemingly high dimensional probability measures. However, these methods struggle to capture the temporal dependence of joint probability distributions induced by time-series data. Furthermore, long time-series data streams hugely increase the dimension of the target space, which may render generative modelling infeasible. To overcome these challenges, motivated by the autoregressive models in econometric, we are interested in the conditional distribution of future time series given the past information. We propose the generic conditional Sig-WGAN framework by integrating Wasserstein-GANs (WGANs) with mathematically principled and efficient path feature extraction called the signature of a path. The signature of a path is a graded sequence of statistics that provides a universal description for a stream of data, and its expected value characterises the law of the time-series model. In particular, we develop the conditional Sig-W1 metric, that captures the conditional joint law of time series models, and use it as a discriminator. The signature feature space enables the explicit representation of the proposed discriminators which alleviates the need for expensive training. We validate our method on both synthetic and empirical dataset and observe that our method consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability. ",https://doi.org/10.48550/arXiv.2006.05421,https://github.com/SigCGANs/Conditional-Sig-Wasserstein-GANs,2006.05421
Time-series Generation by Contrastive Imitation,"Daniel Jarrett, Ioana Bica, Mihaela van der Schaar",02/11/2023,TimeGCI ,Methodology,,,"Sines
Energy
Gas
Metro
MIMIC-III",,"Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learned cooperatively, avoiding the instabilities typical of adversarial objectives. At inference, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a trajectory-level measure for evaluating sample quality. By expressly training a policy to imitate sequential behavior of time-series features in a dataset, this approach embodies ""generation by imitation"". Theoretically, we illustrate the correctness of this formulation and the consistency of the algorithm. Empirically, we evaluate its ability to generate predictively useful samples from real-world datasets, verifying that it performs at the standard of existing benchmarks. ",https://doi.org/10.48550/arXiv.2311.01388,,2311.01388
Synthetic Data Applications in Finance,"Vamsi K. Potluru, Daniel Borrajo, Andrea Coletta, Niccolò Dalmasso, Yousef El-Laham, Elizabeth Fons, Mohsen Ghassemi, Sriram Gopalakrishnan, Vikesh Gosai, Eleonora Kreačić, Ganapathy Mani, Saheed Obitayo, Deepak Paramanand, Natraj Raman, Mikhail Solonin, Srijan Sood, Svitlana Vyetrenko, Haibei Zhu, Manuela Veloso, Tucker Balch",29/12/2023,,Review,,Financial data,,,"Synthetic data has made tremendous strides in various commercial settings including finance, healthcare, and virtual reality. We present a broad overview of prototypical applications of synthetic data in the financial sector and in particular provide richer details for a few select ones. These cover a wide variety of data modalities including tabular, time-series, event-series, and unstructured arising from both markets and retail financial applications. Since finance is a highly regulated industry, synthetic data is a potential approach for dealing with issues related to privacy, fairness, and explainability. Various metrics are utilized in evaluating the quality and effectiveness of our approaches in these applications. We conclude with open directions in synthetic data in the context of the financial domain.",https://doi.org/10.48550/arXiv.2401.00081,,2401.00081
Wasserstein Learning of Deep Generative Point Process Models,"Shuai Xiao, Mehrdad Farajtabar, Xiaojing Ye, Junchi Yan, Le Song, Hongyuan Zha",23/05/2017,WGAN For TPP,Methodology,WGAN Loss for sequences,,,,"Point processes are becoming very popular in modeling asynchronous sequential data due to their sound mathematical foundation and strength in modeling a variety of real-world phenomena. Currently, they are often characterized via intensity function which limits model's expressiveness due to unrealistic assumptions on its parametric form used in practice. Furthermore, they are learned via maximum likelihood approach which is prone to failure in multi-modal distributions of sequences. In this paper, we propose an intensity-free approach for point processes modeling that transforms nuisance processes to a target one. Furthermore, we train the model using a likelihood-free leveraging Wasserstein distance between point processes. Experiments on various synthetic and real-world data substantiate the superiority of the proposed point process model over conventional ones. ",https://doi.org/10.48550/arXiv.1705.08051,https://github.com/xiaoshuai09/Wasserstein-Learning-For-Point-Process,1705.08051
Fractional SDE-Net: Generation of Time Series Data with Long-term Memory,"Kohei Hayashi, Kei Nakagawa",24/08/2022,fSDE-Net,Methodology,,,,,"In this paper, we focus on the generation of time-series data using neural networks. It is often the case that input time-series data have only one realized (and usually irregularly sampled) path, which makes it difficult to extract time-series characteristics, and its noise structure is more complicated than i.i.d. type. Time series data, especially from hydrology, telecommunications, economics, and finance, exhibit long-term memory also called long-range dependency (LRD). The main purpose of this paper is to artificially generate time series with the help of neural networks, making the LRD of paths into account. We propose fSDE-Net: neural fractional Stochastic Differential Equation Network. It generalizes the neural stochastic differential equation model by using fractional Brownian motion with a Hurst index larger than half, which exhibits the LRD property. We derive the solver of fSDE-Net and theoretically analyze the existence and uniqueness of the solution to fSDE-Net. Our experiments with artificial and real time-series data demonstrate that the fSDE-Net model can replicate distributional properties well.",https://doi.org/10.48550/arXiv.2201.05974,,2201.05974
Towards Realistic Market Simulations: a Generative Adversarial Networks Approach,"Andrea Coletta, Matteo Prata, Michele Conti, Emanuele Mercanti, Novella Bartolini, Aymeric Moulin, Svitlana Vyetrenko, Tucker Balch",25/10/2021,,Methodology,,,,,"Simulated environments are increasingly used by trading firms and investment banks to evaluate trading strategies before approaching real markets. Backtesting, a widely used approach, consists of simulating experimental strategies while replaying historical market scenarios. Unfortunately, this approach does not capture the market response to the experimental agents' actions. In contrast, multi-agent simulation presents a natural bottom-up approach to emulating agent interaction in financial markets. It allows to set up pools of traders with diverse strategies to mimic the financial market trader population, and test the performance of new experimental strategies. Since individual agent-level historical data is typically proprietary and not available for public use, it is difficult to calibrate multiple market agents to obtain the realism required for testing trading strategies. To addresses this challenge we propose a synthetic market generator based on Conditional Generative Adversarial Networks (CGANs) trained on real aggregate-level historical data. A CGAN-based ""world"" agent can generate meaningful orders in response to an experimental agent. We integrate our synthetic market generator into ABIDES, an open source simulator of financial markets. By means of extensive simulations we show that our proposal outperforms previous work in terms of stylized facts reflecting market responsiveness and realism. ",https://doi.org/10.48550/arXiv.2110.13287 ,,2110.13287
Learning to simulate realistic limit order book markets from data as a World Agent,"Andrea Coletta, Svitlana Vyetrenko, Aymeric Moulin, Tucker Balch",26/09/2022,,Methodology,,,,,"Multi-agent market simulators usually require careful calibration to emulate real markets, which includes the number and the type of agents. Poorly calibrated simulators can lead to misleading conclusions, potentially causing severe loss when employed by investment banks, hedge funds, and traders to study and evaluate trading strategies. In this paper, we propose a world model simulator that accurately emulates a limit order book market -- it requires no agent calibration but rather learns the simulated market behavior directly from historical data. Traditional approaches fail short to learn and calibrate trader population, as historical labeled data with details on each individual trader strategy is not publicly available. Our approach proposes to learn a unique ""world"" agent from historical data. It is intended to emulate the overall trader population, without the need of making assumptions about individual market agent strategies. We implement our world agent simulator models as a Conditional Generative Adversarial Network (CGAN), as well as a mixture of parametric distributions, and we compare our models against previous work. Qualitatively and quantitatively, we show that the proposed approaches consistently outperform previous work, providing more realism and responsiveness. ",,,2210.09897
"Conditional Generators for Limit Order Book Environments: Explainability, Challenges, and Robustness", Challenges, and Robustness,LOBGAN,Methodology,,,,,"Limit order books are a fundamental and widespread market mechanism. This paper investigates the use of conditional generative models for order book simulation. For developing a trading agent, this approach has drawn recent attention as an alternative to traditional backtesting due to its ability to react to the presence of the trading agent. Using a state-of-the-art CGAN (from Coletta et al. (2022)), we explore its dependence upon input features, which highlights both strengths and weaknesses. To do this, we use ""adversarial attacks"" on the model's features and its mechanism. We then show how these insights can be used to improve the CGAN, both in terms of its realism and robustness. We finish by laying out a roadmap for future work. ",,,2306.12806
Generating Realistic Stock Market Order Streams,"Junyi Li, Xitong Wang, Yaoyang Lin, Arunesh Sinha, Micheal P. Wellman",07/06/2020,,,,,,,"We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks (GANs). Our Stock-GAN model employs a conditional Wasserstein GAN to capture history dependence of orders. The generator design includes specially crafted aspects including components that approximate the market's auction mechanism, augmenting the order history with order-book constructions to improve the generation task. We perform an ablation study to verify the usefulness of aspects of our network structure. We provide a mathematical characterization of distribution learned by the generator. We also propose statistics to measure the quality of generated orders. We test our approach with synthetic and actual market data, compare to many baseline generative models, and find the generated data to be close to real data.",,,2006.04212
Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network,"Peer Nagy, Kang Li, Sascha Frey, Anisoara Calinescu, Jakob Foerster, Silvia Sapora, Stefan Zohren",23/08/2023,simplified structured state-space layers,Methodology,,,,,"Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data and we commit to open-sourcing our code to facilitate future research. ",,,2309.00638
Fin-GAN: Forecasting and Classifying Financial Time Series via Generative Adversarial Networks,"Milena Vuletic, Mihai Cucuringu, Felix Prenzel",19/01/2023,,,,,,,"We investigate the use of Generative Adversarial Networks (GANs) for probabilistic forecasting of financial time series. To this end, we introduce a novel economics-driven loss function for the generator. This newly designed loss function renders GANs more suitable for a classification task, and places them into a supervised learning setting, whilst producing full conditional probability distributions of price returns given previous historical values. Our approach moves beyond the point estimates traditionally employed in the forecasting literature, and allows for uncertainty estimates. Numerical experiments on equity data showcase the effectiveness of our proposed methodology, which achieves higher Sharpe Ratios compared to classical supervised learning models, such as LSTMs and ARIMA.",,,
Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context,"Haochong Xia, Shuo Sun, Xinrun Wang, Bo An",14/09/2023,,,,,,,"Financial simulators play an important role in enhancing forecasting accuracy, managing risks, and fostering strategic financial decision-making. Despite the development of financial market simulation methodologies, existing frameworks often struggle with adapting to specialized simulation context. We pinpoint the challenges as i) current financial datasets do not contain context labels; ii) current techniques are not designed to generate financial data with context as control, which demands greater precision compared to other modalities; iii) the inherent difficulties in generating context-aligned, high-fidelity data given the non-stationary, noisy nature of financial data. To address these challenges, our contributions are: i) we proposed the Contextual Market Dataset with market dynamics, stock ticker, and history state as context, leveraging a market dynamics modeling method that combines linear regression and Dynamic Time Warping clustering to extract market dynamics; ii) we present Market-GAN, a novel architecture incorporating a Generative Adversarial Networks (GAN) for the controllable generation with context, an autoencoder for learning low-dimension features, and supervisors for knowledge transfer; iii) we introduce a two-stage training scheme to ensure that Market-GAN captures the intrinsic market distribution with multiple objectives. In the pertaining stage, with the use of the autoencoder and supervisors, we prepare the generator with a better initialization for the adversarial training stage. We propose a set of holistic evaluation metrics that consider alignment, fidelity, data usability on downstream tasks, and market facts. We evaluate Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and showcase superior performance in comparison to 4 state-of-the-art time-series generative models. ",,,2309.07708
