Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Towards Foundation Auto-Encoders for Time-Series Anomaly Detection,02/07/2025,"Gastón García González, Pedro Casas, Emilio Martínez, Alicia Fernández","We investigate a novel approach to time-series modeling, inspired by the
successes of large pretrained foundation models. We introduce FAE (Foundation
Auto-Encoders), a foundation generative-AI model for anomaly detection in
time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we
mean a model pretrained on massive amounts of time-series data which can learn
complex temporal patterns useful for accurate modeling, forecasting, and
detection of anomalies on previously unseen datasets. FAE leverages VAEs and
Dilated Convolutional Neural Networks (DCNNs) to build a generic model for
univariate time-series modeling, which could eventually perform properly in
out-of-the-box, zero-shot anomaly detection applications. We introduce the main
concepts of FAE, and present preliminary results in different multi-dimensional
time-series datasets from various domains, including a real dataset from an
operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.",http://arxiv.org/pdf/2507.01875v1,,False
Low-Perplexity LLM-Generated Sequences and Where To Find Them,02/07/2025,"Arthur Wuhrmann, Anastasiia Kucherenko, Andrei Kucharavy","As Large Language Models (LLMs) become increasingly widespread, understanding
how specific training data shapes their outputs is crucial for transparency,
accountability, privacy, and fairness. To explore how LLMs leverage and
replicate their training data, we introduce a systematic approach centered on
analyzing low-perplexity sequences - high-probability text spans generated by
the model. Our pipeline reliably extracts such long sequences across diverse
topics while avoiding degeneration, then traces them back to their sources in
the training data. Surprisingly, we find that a substantial portion of these
low-perplexity spans cannot be mapped to the corpus. For those that do match,
we quantify the distribution of occurrences across source documents,
highlighting the scope and nature of verbatim recall and paving a way toward
better understanding of how LLMs training data impacts their behavior.",http://arxiv.org/pdf/2507.01844v1,,False
mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling,02/07/2025,"Tristan Torchet, Christian Metzner, Laura Kriener, Melika Payvand","Edge devices for temporal processing demand models that capture both short-
and long- range dynamics under tight memory constraints. While Transformers
excel at sequence modeling, their quadratic memory scaling with sequence length
makes them impractical for such settings. Recurrent Neural Networks (RNNs)
offer constant memory but train sequentially, and Temporal Convolutional
Networks (TCNs), though efficient, scale memory with kernel size. To address
this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay
Embedding), a hybrid-memory system that integrates a temporal 1D-convolution
with learnable spacings followed by a minimal gated recurrent unit (minGRU).
This design allows the convolutional layer to realize a flexible delay
embedding that captures rapid temporal variations, while the recurrent module
efficiently maintains global context with minimal memory overhead. We validate
our approach on two synthetic tasks, demonstrating that mGRADE effectively
separates and preserves multi-scale temporal features. Furthermore, on
challenging pixel-by-pixel image classification benchmarks, mGRADE consistently
outperforms both pure convolutional and pure recurrent counterparts using
approximately 20% less memory footprint, highlighting its suitability for
memory-constrained temporal processing at the edge. This highlights mGRADE's
promise as an efficient solution for memory-constrained multi-scale temporal
processing at the edge.",http://arxiv.org/pdf/2507.01829v1,,False
A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference,02/07/2025,"Trung-Dung Hoang, Alceu Bissoto, Vihangkumar V. Naik, Tim Flühmann, Artemii Shlychkov, José Garcia-Tirado, Lisa M. Koch","Accurately estimating parameters of physiological models is essential to
achieving reliable digital twins. For Type 1 Diabetes, this is particularly
challenging due to the complexity of glucose-insulin interactions. Traditional
methods based on Markov Chain Monte Carlo struggle with high-dimensional
parameter spaces and fit parameters from scratch at inference time, making them
slow and computationally expensive. In this study, we propose a
Simulation-Based Inference approach based on Neural Posterior Estimation to
efficiently capture the complex relationships between meal intake, insulin, and
glucose level, providing faster, amortized inference. Our experiments
demonstrate that SBI not only outperforms traditional methods in parameter
estimation but also generalizes better to unseen conditions, offering real-time
posterior inference with reliable uncertainty quantification.",http://arxiv.org/pdf/2507.01740v1,,False
Token Communication in the Era of Large Models: An Information Bottleneck-Based Approach,02/07/2025,"Hao Wei, Wanli Ni, Wen Wang, Wenjun Xu, Dusit Niyato, Ping Zhang","This letter proposes UniToCom, a unified token communication paradigm that
treats tokens as the fundamental units for both processing and wireless
transmission. Specifically, to enable efficient token representations, we
propose a generative information bottleneck (GenIB) principle, which
facilitates the learning of tokens that preserve essential information while
supporting reliable generation across multiple modalities. By doing this,
GenIB-based tokenization is conducive to improving the communication efficiency
and reducing computational complexity. Additionally, we develop $\sigma$-GenIB
to address the challenges of variance collapse in autoregressive modeling,
maintaining representational diversity and stability. Moreover, we employ a
causal Transformer-based multimodal large language model (MLLM) at the receiver
to unify the processing of both discrete and continuous tokens under the
next-token prediction paradigm. Simulation results validate the effectiveness
and superiority of the proposed UniToCom compared to baselines under dynamic
channel conditions. By integrating token processing with MLLMs, UniToCom
enables scalable and generalizable communication in favor of multimodal
understanding and generation, providing a potential solution for
next-generation intelligent communications.",http://arxiv.org/pdf/2507.01728v1,,False
Generative flow-based warm start of the variational quantum eigensolver,02/07/2025,"Hang Zou, Martin Rahm, Anton Frisk Kockum, Simon Olsson","Hybrid quantum-classical algorithms like the variational quantum eigensolver
(VQE) show promise for quantum simulations on near-term quantum devices, but
are often limited by complex objective functions and expensive optimization
procedures. Here, we propose Flow-VQE, a generative framework leveraging
conditional normalizing flows with parameterized quantum circuits to
efficiently generate high-quality variational parameters. By embedding a
generative model into the VQE optimization loop through preference-based
training, Flow-VQE enables quantum gradient-free optimization and offers a
systematic approach for parameter transfer, accelerating convergence across
related problems through warm-started optimization. We compare Flow-VQE to a
number of standard benchmarks through numerical simulations on molecular
systems, including hydrogen chains, water, ammonia, and benzene. We find that
Flow-VQE outperforms baseline optimization algorithms, achieving computational
accuracy with fewer circuit evaluations (improvements range from modest to more
than two orders of magnitude) and, when used to warm-start the optimization of
new systems, accelerates subsequent fine-tuning by up to 50-fold compared with
Hartree--Fock initialization. Therefore, we believe Flow-VQE can become a
pragmatic and versatile paradigm for leveraging generative modeling to reduce
the costs of variational quantum algorithms.",http://arxiv.org/pdf/2507.01726v1,,False
AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training,02/07/2025,"Zhenyu Han, Ansheng You, Haibo Wang, Kui Luo, Guang Yang, Wenqi Shi, Menglong Chen, Sicheng Zhang, Zeshun Lan, Chunshi Deng, Huazhong Ji, Wenjie Liu, Yu Huang, Yixiang Zhang, Chenyi Pan, Jing Wang, Xin Huang, Chunsheng Li, Jianping Wu","Reinforcement learning (RL) has become a pivotal technology in the
post-training phase of large language models (LLMs). Traditional task-colocated
RL frameworks suffer from significant scalability bottlenecks, while
task-separated RL frameworks face challenges in complex dataflows and the
corresponding resource idling and workload imbalance. Moreover, most existing
frameworks are tightly coupled with LLM training or inference engines, making
it difficult to support custom-designed engines. To address these challenges,
we propose AsyncFlow, an asynchronous streaming RL framework for efficient
post-training. Specifically, we introduce a distributed data storage and
transfer module that provides a unified data management and fine-grained
scheduling capability in a fully streamed manner. This architecture inherently
facilitates automated pipeline overlapping among RL tasks and dynamic load
balancing. Moreover, we propose a producer-consumer-based asynchronous workflow
engineered to minimize computational idleness by strategically deferring
parameter update process within staleness thresholds. Finally, the core
capability of AsynFlow is architecturally decoupled from underlying training
and inference engines and encapsulated by service-oriented user interfaces,
offering a modular and customizable user experience. Extensive experiments
demonstrate an average of 1.59 throughput improvement compared with
state-of-the-art baseline. The presented architecture in this work provides
actionable insights for next-generation RL training system designs.",http://arxiv.org/pdf/2507.01663v1,,False
Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective,02/07/2025,"Yuxin Mao, Zhen Qin, Jinxing Zhou, Hui Deng, Xuyang Shen, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai","Autoregressive (AR) models have garnered significant attention in image
generation for their ability to effectively capture both local and global
structures within visual data. However, prevalent AR models predominantly rely
on the transformer architectures, which are beset by quadratic computational
complexity concerning input sequence length and substantial memory overhead due
to the necessity of maintaining key-value caches. Although linear attention
mechanisms have successfully reduced this burden in language models, our
initial experiments reveal that they significantly degrade image generation
quality because of their inability to capture critical long-range dependencies
in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a
novel attention mechanism that explicitly preserves genuine 2D spatial
relationships within the flattened image sequences by computing
position-dependent decay factors based on true 2D spatial location rather than
1D sequence positions. Based on this mechanism, we present LASADGen, an
autoregressive image generator that enables selective attention to relevant
spatial contexts with linear complexity. Experiments on ImageNet show LASADGen
achieves state-of-the-art image generation performance and computational
efficiency, bridging the gap between linear attention's efficiency and spatial
understanding needed for high-quality generation.",http://arxiv.org/pdf/2507.01652v1,,False
Dance Dance ConvLSTM,02/07/2025,Miguel O'Malley,"\textit{Dance Dance Revolution} is a rhythm game consisting of songs and
accompanying choreography, referred to as charts. Players press arrows on a
device referred to as a dance pad in time with steps determined by the song's
chart. In 2017, the authors of Dance Dance Convolution (DDC) developed an
algorithm for the automatic generation of \textit{Dance Dance Revolution}
charts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM
(DDCL), a new method for the automatic generation of DDR charts using a
ConvLSTM based model, which improves upon the DDC methodology and substantially
increases the accuracy of chart generation.",http://arxiv.org/pdf/2507.01644v1,,False
Enhanced Influence-aware Group Recommendation for Online Media Propagation,02/07/2025,"Chengkun He, Xiangmin Zhou, Chen Wang, Longbing Cao, Jie Shao, Xiaodong Li, Guang Xu, Carrie Jinqiu Hu, Zahir Tari","Group recommendation over social media streams has attracted significant
attention due to its wide applications in domains such as e-commerce,
entertainment, and online news broadcasting. By leveraging social connections
and group behaviours, group recommendation (GR) aims to provide more accurate
and engaging content to a set of users rather than individuals. Recently,
influence-aware GR has emerged as a promising direction, as it considers the
impact of social influence on group decision-making. In earlier work, we
proposed Influence-aware Group Recommendation (IGR) to solve this task.
However, this task remains challenging due to three key factors: the large and
ever-growing scale of social graphs, the inherently dynamic nature of influence
propagation within user groups, and the high computational overhead of
real-time group-item matching.
  To tackle these issues, we propose an Enhanced Influence-aware Group
Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based
Sampling (GES) strategy to minimise redundancy across multiple temporal social
graphs and effectively capture the evolving dynamics of both groups and items.
Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict
how influence propagates over time across social items and user groups.
Finally, we develop a two-level hash-based User Group Index (UG-Index) to
efficiently organise user groups and enable real-time recommendation
generation. Extensive experiments on real-world datasets demonstrate that our
proposed framework, EIGR, consistently outperforms state-of-the-art baselines
in both effectiveness and efficiency.",http://arxiv.org/pdf/2507.01616v1,,False
When Less Is More: Binary Feedback Can Outperform Ordinal Comparisons in Ranking Recovery,02/07/2025,"Shirong Xu, Jingnan Zhang, Junhui Wang","Paired comparison data, where users evaluate items in pairs, play a central
role in ranking and preference learning tasks. While ordinal comparison data
intuitively offer richer information than binary comparisons, this paper
challenges that conventional wisdom. We propose a general parametric framework
for modeling ordinal paired comparisons without ties. The model adopts a
generalized additive structure, featuring a link function that quantifies the
preference difference between two items and a pattern function that governs the
distribution over ordinal response levels. This framework encompasses classical
binary comparison models as special cases, by treating binary responses as
binarized versions of ordinal data. Within this framework, we show that
binarizing ordinal data can significantly improve the accuracy of ranking
recovery. Specifically, we prove that under the counting algorithm, the ranking
error associated with binary comparisons exhibits a faster exponential
convergence rate than that of ordinal data. Furthermore, we characterize a
substantial performance gap between binary and ordinal data in terms of a
signal-to-noise ratio (SNR) determined by the pattern function. We identify the
pattern function that minimizes the SNR and maximizes the benefit of
binarization. Extensive simulations and a real application on the MovieLens
dataset further corroborate our theoretical findings.",http://arxiv.org/pdf/2507.01613v1,,False
Chargax: A JAX Accelerated EV Charging Simulator,02/07/2025,"Koen Ponse, Jan Felix Kleuker, Aske Plaat, Thomas Moerland","Deep Reinforcement Learning can play a key role in addressing sustainable
energy challenges. For instance, many grid systems are heavily congested,
highlighting the urgent need to enhance operational efficiency. However,
reinforcement learning approaches have traditionally been slow due to the high
sample complexity and expensive simulation requirements. While recent works
have effectively used GPUs to accelerate data generation by converting
environments to JAX, these works have largely focussed on classical toy
problems. This paper introduces Chargax, a JAX-based environment for realistic
simulation of electric vehicle charging stations designed for accelerated
training of RL agents. We validate our environment in a variety of scenarios
based on real data, comparing reinforcement learning agents against baselines.
Chargax delivers substantial computational performance improvements of over
100x-1000x over existing environments. Additionally, Chargax' modular
architecture enables the representation of diverse real-world charging station
configurations.",http://arxiv.org/pdf/2507.01522v1,,False
Symbolic identification of tensor equations in multidimensional physical fields,02/07/2025,"Tianyi Chen, Hao Yang, Wenjun Ma, Jun Zhang","Recently, data-driven methods have shown great promise for discovering
governing equations from simulation or experimental data. However, most
existing approaches are limited to scalar equations, with few capable of
identifying tensor relationships. In this work, we propose a general
data-driven framework for identifying tensor equations, referred to as Symbolic
Identification of Tensor Equations (SITE). The core idea of SITE--representing
tensor equations using a host-plasmid structure--is inspired by the
multidimensional gene expression programming (M-GEP) approach. To improve the
robustness of the evolutionary process, SITE adopts a genetic information
retention strategy. Moreover, SITE introduces two key innovations beyond
conventional evolutionary algorithms. First, it incorporates a dimensional
homogeneity check to restrict the search space and eliminate physically invalid
expressions. Second, it replaces traditional linear scaling with a tensor
linear regression technique, greatly enhancing the efficiency of numerical
coefficient optimization. We validate SITE using two benchmark scenarios, where
it accurately recovers target equations from synthetic data, showing robustness
to noise and small sample sizes. Furthermore, SITE is applied to identify
constitutive relations directly from molecular simulation data, which are
generated without reliance on macroscopic constitutive models. It adapts to
both compressible and incompressible flow conditions and successfully
identifies the corresponding macroscopic forms, highlighting its potential for
data-driven discovery of tensor equation.",http://arxiv.org/pdf/2507.01466v1,,False
DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal,02/07/2025,"Wenjie Liu, Bingshu Wang, Ze Wang, C. L. Philip Chen","Document shadow removal is a crucial task in the field of document image
enhancement. However, existing methods tend to remove shadows with constant
color background and ignore color shadows. In this paper, we first design a
diffusion model in latent space for document image shadow removal, called
DocShaDiffusion. It translates shadow images from pixel space to latent space,
enabling the model to more easily capture essential features. To address the
issue of color shadows, we design a shadow soft-mask generation module (SSGM).
It is able to produce accurate shadow mask and add noise into shadow regions
specially. Guided by the shadow mask, a shadow mask-aware guided diffusion
module (SMGDM) is proposed to remove shadows from document images by
supervising the diffusion and denoising process. We also propose a
shadow-robust perceptual feature loss to preserve details and structures in
document images. Moreover, we develop a large-scale synthetic document color
shadow removal dataset (SDCSRD). It simulates the distribution of realistic
color shadows and provides powerful supports for the training of models.
Experiments on three public datasets validate the proposed method's superiority
over state-of-the-art. Our code and dataset will be publicly available.",http://arxiv.org/pdf/2507.01422v1,,False
LEDOM: An Open and Fundamental Reverse Language Model,02/07/2025,"Xunjian Yin, Sitao Cheng, Yuxi Xie, Xinyu Hu, Li Lin, Xinyi Wang, Liangming Pan, William Yang Wang, Xiaojun Wan","We introduce LEDOM, the first purely reverse language model, trained
autoregressively on 435B tokens with 2B and 7B parameter variants, which
processes sequences in reverse temporal order through previous token
prediction. For the first time, we present the reverse language model as a
potential foundational model across general tasks, accompanied by a set of
intriguing examples and insights. Based on LEDOM, we further introduce a novel
application: Reverse Reward, where LEDOM-guided reranking of forward language
model outputs leads to substantial performance improvements on mathematical
reasoning tasks. This approach leverages LEDOM's unique backward reasoning
capability to refine generation quality through posterior evaluation. Our
findings suggest that LEDOM exhibits unique characteristics with broad
application potential. We will release all models, training code, and
pre-training data to facilitate future research.",http://arxiv.org/pdf/2507.01335v1,,False
Neural Hamiltonian Operator,02/07/2025,Qian Qi,"Stochastic control problems in high dimensions are notoriously difficult to
solve due to the curse of dimensionality. An alternative to traditional dynamic
programming is Pontryagin's Maximum Principle (PMP), which recasts the problem
as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In
this paper, we introduce a formal framework for solving such problems with deep
learning by defining a \textbf{Neural Hamiltonian Operator (NHO)}. This
operator parameterizes the coupled FBSDE dynamics via neural networks that
represent the feedback control and an ansatz for the value function's spatial
gradient. We show how the optimal NHO can be found by training the underlying
networks to enforce the consistency conditions dictated by the PMP. By adopting
this operator-theoretic view, we situate the deep FBSDE method within the
rigorous language of statistical inference, framing it as a problem of learning
an unknown operator from simulated data. This perspective allows us to prove
the universal approximation capabilities of NHOs under general martingale
drivers and provides a clear lens for analyzing the significant optimization
challenges inherent to this class of models.",http://arxiv.org/pdf/2507.01313v1,,False
LLM-based Realistic Safety-Critical Driving Video Generation,02/07/2025,"Yongjie Fu, Ruijian Zha, Pei Tian, Xuan Di","Designing diverse and safety-critical driving scenarios is essential for
evaluating autonomous driving systems. In this paper, we propose a novel
framework that leverages Large Language Models (LLMs) for few-shot code
generation to automatically synthesize driving scenarios within the CARLA
simulator, which has flexibility in scenario scripting, efficient code-based
control of traffic participants, and enforcement of realistic physical
dynamics. Given a few example prompts and code samples, the LLM generates
safety-critical scenario scripts that specify the behavior and placement of
traffic participants, with a particular focus on collision events. To bridge
the gap between simulation and real-world appearance, we integrate a video
generation pipeline using Cosmos-Transfer1 with ControlNet, which converts
rendered scenes into realistic driving videos. Our approach enables
controllable scenario generation and facilitates the creation of rare but
critical edge cases, such as pedestrian crossings under occlusion or sudden
vehicle cut-ins. Experimental results demonstrate the effectiveness of our
method in generating a wide range of realistic, diverse, and safety-critical
scenarios, offering a promising tool for simulation-based testing of autonomous
vehicles.",http://arxiv.org/pdf/2507.01264v1,,False
Geometry-aware 4D Video Generation for Robot Manipulation,01/07/2025,"Zeyi Liu, Shuang Li, Eric Cousineau, Siyuan Feng, Benjamin Burchfiel, Shuran Song","Understanding and predicting the dynamics of the physical world can enhance a
robot's ability to plan and interact effectively in complex environments. While
recent video generation models have shown strong potential in modeling dynamic
scenes, generating videos that are both temporally coherent and geometrically
consistent across camera views remains a significant challenge. To address
this, we propose a 4D video generation model that enforces multi-view 3D
consistency of videos by supervising the model with cross-view pointmap
alignment during training. This geometric supervision enables the model to
learn a shared 3D representation of the scene, allowing it to predict future
video sequences from novel viewpoints based solely on the given RGB-D
observations, without requiring camera poses as inputs. Compared to existing
baselines, our method produces more visually stable and spatially aligned
predictions across multiple simulated and real-world robotic datasets. We
further show that the predicted 4D videos can be used to recover robot
end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting
robust robot manipulation and generalization to novel camera viewpoints.",http://arxiv.org/pdf/2507.01099v1,,False
ZeCO: Zero Communication Overhead Sequence Parallelism for Linear Attention,01/07/2025,"Yuhong Chou, Zehao Liu, Ruijie Zhu, Xinyi Wan, Tianjian Li, Congying Chu, Qian Liu, Jibin Wu, Zejun Ma","Linear attention mechanisms deliver significant advantages for Large Language
Models (LLMs) by providing linear computational complexity, enabling efficient
processing of ultra-long sequences (e.g., 1M context). However, existing
Sequence Parallelism (SP) methods, essential for distributing these workloads
across devices, become the primary bottleneck due to substantial communication
overhead. In this paper, we introduce ZeCO (Zero Communication Overhead)
sequence parallelism for linear attention models, a new SP method designed to
overcome these limitations and achieve end-to-end near-linear scalability for
long sequence training. For example, training a model with a 1M sequence length
across 64 devices using ZeCO takes roughly the same time as training with an
16k sequence on a single device. At the heart of ZeCO lies All-Scan, a new
collective communication primitive. All-Scan provides each SP rank with
precisely the initial operator state it requires while maintaining a minimal
communication footprint, effectively eliminating communication overhead.
Theoretically, we prove the optimaity of ZeCO, showing that it introduces only
negligible time and space overhead. Empirically, we compare the communication
costs of different sequence parallelism strategies and demonstrate that
All-Scan achieves the fastest communication in SP scenarios. Specifically, on
256 GPUs with an 8M sequence length, ZeCO achieves a 60\% speedup compared to
the current state-of-the-art (SOTA) SP method. We believe ZeCO establishes a
clear path toward efficiently training next-generation LLMs on previously
intractable sequence lengths.",http://arxiv.org/pdf/2507.01004v2,,False
Box Pose and Shape Estimation and Domain Adaptation for Large-Scale Warehouse Automation,01/07/2025,"Xihang Yu, Rajat Talak, Jingnan Shi, Ulrich Viereck, Igor Gilitschenski, Luca Carlone","Modern warehouse automation systems rely on fleets of intelligent robots that
generate vast amounts of data -- most of which remains unannotated. This paper
develops a self-supervised domain adaptation pipeline that leverages
real-world, unlabeled data to improve perception models without requiring
manual annotations. Our work focuses specifically on estimating the pose and
shape of boxes and presents a correct-and-certify pipeline for self-supervised
box pose and shape estimation. We extensively evaluate our approach across a
range of simulated and real industrial settings, including adaptation to a
large-scale real-world dataset of 50,000 images. The self-supervised model
significantly outperforms models trained solely in simulation and shows
substantial improvements over a zero-shot 3D bounding box estimation baseline.",http://arxiv.org/pdf/2507.00984v1,,False
MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement,01/07/2025,"Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan","With the advent of new sequence models like Mamba and xLSTM, several studies
have shown that these models match or outperform state-of-the-art models in
single-channel speech enhancement, automatic speech recognition, and
self-supervised audio representation learning. However, prior research has
demonstrated that sequence models like LSTM and Mamba tend to overfit to the
training set. To address this issue, previous works have shown that adding
self-attention to LSTMs substantially improves generalization performance for
single-channel speech enhancement. Nevertheless, neither the concept of hybrid
Mamba and time-frequency attention models nor their generalization performance
have been explored for speech enhancement. In this paper, we propose a novel
hybrid architecture, MambAttention, which combines Mamba and shared time- and
frequency-multi-head attention modules for generalizable single-channel speech
enhancement. To train our model, we introduce VoiceBank+Demand Extended
(VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging
noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our
proposed MambAttention model significantly outperforms existing
state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar
complexity across all reported metrics on two out-of-domain datasets: DNS 2020
and EARS-WHAM_v2, while matching their performance on the in-domain dataset
VB-DemandEx. Ablation studies highlight the role of weight sharing between the
time- and frequency-multi-head attention modules for generalization
performance. Finally, we explore integrating the shared time- and
frequency-multi-head attention modules with LSTM and xLSTM, which yields a
notable performance improvement on the out-of-domain datasets. However, our
MambAttention model remains superior on both out-of-domain datasets across all
reported evaluation metrics.",http://arxiv.org/pdf/2507.00966v1,,False
From Sentences to Sequences: Rethinking Languages in Biological System,01/07/2025,"Ke Liu, Shuanke Shen, Hao Chen","The paradigm of large language models in natural language processing (NLP)
has also shown promise in modeling biological languages, including proteins,
RNA, and DNA. Both the auto-regressive generation paradigm and evaluation
metrics have been transferred from NLP to biological sequence modeling.
However, the intrinsic structural correlations in natural and biological
languages differ fundamentally. Therefore, we revisit the notion of language in
biological systems to better understand how NLP successes can be effectively
translated to biological domains. By treating the 3D structure of biomolecules
as the semantic content of a sentence and accounting for the strong
correlations between residues or bases, we highlight the importance of
structural evaluation and demonstrate the applicability of the auto-regressive
paradigm in biological language modeling. Code can be found at
\href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}",http://arxiv.org/pdf/2507.00953v1,,False
Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks,01/07/2025,"Feng Wang, Shengyu Zhang, Een-Kee Hong, Tony Q. S. Quek","Direct-satellite-to-device (DS2D) communication is emerging as a promising
solution for global mobile service extension, leveraging the deployment of
satellite constellations. However, the challenge of managing DS2D connectivity
for multi-constellations becomes outstanding, including high interference and
frequent handovers caused by multi-coverage overlap and rapid satellite
movement. Moreover, existing approaches primarily operate within
single-constellation shell, which inherently limits the ability to exploit the
vast potential of multi-constellation connectivity provision, resulting in
suboptimal DS2D service performances. To address these challenges, this article
proposes a Constellation as a Service (CaaS) framework, which treats the entire
multi-constellation infrastructure as a shared resource pool and dynamically
forms optimal sub-constellations (SCs) for each DS2D service region. The
formation of each SC integrates satellites from various orbits to provide
tailored connectivity based on user demands, guided by two innovative
strategies: predictive satellite beamforming using generative artificial
intelligence (GenAI) and pre-configured handover path for efficient satellite
access and mobility management. Simulation results demonstrate that CaaS
significantly improves satellite service rates while reducing handover
overhead, making it an efficient and continuable solution for managing DS2D
connectivity in multi-constellation environments.",http://arxiv.org/pdf/2507.00902v1,,False
"TABASCO: A Fast, Simplified Model for Molecular Generation with Improved Physical Quality",01/07/2025,"Carlos Vonessen, Charles Harris, Miruna Cretu, Pietro Liò","State-of-the-art models for 3D molecular generation are based on significant
inductive biases, SE(3), permutation equivariance to respect symmetry and graph
message-passing networks to capture local chemistry, yet the generated
molecules still struggle with physical plausibility. We introduce TABASCO which
relaxes these assumptions: The model has a standard non-equivariant transformer
architecture, treats atoms in a molecule as sequences and reconstructs bonds
deterministically after generation. The absence of equivariant layers and
message passing allows us to significantly simplify the model architecture and
scale data throughput. On the GEOM-Drugs benchmark TABASCO achieves
state-of-the-art PoseBusters validity and delivers inference roughly 10x faster
than the strongest baseline, while exhibiting emergent rotational equivariance
despite symmetry not being hard-coded. Our work offers a blueprint for training
minimalist, high-throughput generative models suited to specialised tasks such
as structure- and pharmacophore-based drug design. We provide a link to our
implementation at github.com/carlosinator/tabasco.",http://arxiv.org/pdf/2507.00899v1,,False
HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning,01/07/2025,"Zhi Jing, Siyuan Yang, Jicong Ao, Ting Xiao, Yugang Jiang, Chenjia Bai","For robotic manipulation, existing robotics datasets and simulation
benchmarks predominantly cater to robot-arm platforms. However, for humanoid
robots equipped with dual arms and dexterous hands, simulation tasks and
high-quality demonstrations are notably lacking. Bimanual dexterous
manipulation is inherently more complex, as it requires coordinated arm
movements and hand operations, making autonomous data collection challenging.
This paper presents HumanoidGen, an automated task creation and demonstration
collection framework that leverages atomic dexterous operations and LLM
reasoning to generate relational constraints. Specifically, we provide spatial
annotations for both assets and dexterous hands based on the atomic operations,
and perform an LLM planner to generate a chain of actionable spatial
constraints for arm movements based on object affordances and scenes. To
further improve planning ability, we employ a variant of Monte Carlo tree
search to enhance LLM reasoning for long-horizon tasks and insufficient
annotation. In experiments, we create a novel benchmark with augmented
scenarios to evaluate the quality of the collected data. The results show that
the performance of the 2D and 3D diffusion policies can scale with the
generated dataset. Project page is https://openhumanoidgen.github.io.",http://arxiv.org/pdf/2507.00833v1,,False
PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments,01/07/2025,"Mengyun Wang, Bo Wang, Yifeng Niu, Chang Wang","Accurate dynamics modeling is essential for quadrotors to achieve precise
trajectory tracking in various applications. Traditional physical
knowledge-driven modeling methods face substantial limitations in unknown
environments characterized by variable payloads, wind disturbances, and
external perturbations. On the other hand, data-driven modeling methods suffer
from poor generalization when handling out-of-distribution (OoD) data,
restricting their effectiveness in unknown scenarios. To address these
challenges, we introduce the Physics-Informed Wind-Adaptive Network (PI-WAN),
which combines knowledge-driven and data-driven modeling methods by embedding
physical constraints directly into the training process for robust quadrotor
dynamics learning. Specifically, PI-WAN employs a Temporal Convolutional
Network (TCN) architecture that efficiently captures temporal dependencies from
historical flight data, while a physics-informed loss function applies physical
principles to improve model generalization and robustness across previously
unseen conditions. By incorporating real-time prediction results into a model
predictive control (MPC) framework, we achieve improvements in closed-loop
tracking performance. Comprehensive simulations and real-world flight
experiments demonstrate that our approach outperforms baseline methods in terms
of prediction accuracy, tracking precision, and robustness to unknown
environments.",http://arxiv.org/pdf/2507.00816v1,,False
A Probabilistic Approach to Wildfire Spread Prediction Using a Denoising Diffusion Surrogate Model,01/07/2025,"Wenbo Yu, Anirbit Ghosh, Tobias Sebastian Finn, Rossella Arcucci, Marc Bocquet, Sibo Cheng","Thanks to recent advances in generative AI, computers can now simulate
realistic and complex natural processes. We apply this capability to predict
how wildfires spread, a task made difficult by the unpredictable nature of fire
and the variety of environmental conditions it depends on. In this study, We
present the first denoising diffusion model for predicting wildfire spread, a
new kind of AI framework that learns to simulate fires not just as one fixed
outcome, but as a range of possible scenarios. By doing so, it accounts for the
inherent uncertainty of wildfire dynamics, a feature that traditional models
typically fail to represent. Unlike deterministic approaches that generate a
single prediction, our model produces ensembles of forecasts that reflect
physically meaningful distributions of where fire might go next. This
technology could help us develop smarter, faster, and more reliable tools for
anticipating wildfire behavior, aiding decision-makers in fire risk assessment
and response planning.",http://arxiv.org/pdf/2507.00761v1,,False
Guided Unconditional and Conditional Generative Models for Super-Resolution and Inference of Quasi-Geostrophic Turbulence,01/07/2025,"Anantha Narayanan Suresh Babu, Akhil Sadam, Pierre F. J. Lermusiaux","Typically, numerical simulations of the ocean, weather, and climate are
coarse, and observations are sparse and gappy. In this work, we apply four
generative diffusion modeling approaches to super-resolution and inference of
forced two-dimensional quasi-geostrophic turbulence on the beta-plane from
coarse, sparse, and gappy observations. Two guided approaches minimally adapt a
pre-trained unconditional model: SDEdit modifies the initial condition, and
Diffusion Posterior Sampling (DPS) modifies the reverse diffusion process
score. The other two conditional approaches, a vanilla variant and
classifier-free guidance, require training with paired high-resolution and
observation data. We consider eight test cases spanning: two regimes, eddy and
anisotropic-jet turbulence; two Reynolds numbers, 10^3 and 10^4; and two
observation types, 4x coarse-resolution fields and coarse, sparse and gappy
observations. Our comprehensive skill metrics include norms of the
reconstructed vorticity fields, turbulence statistical quantities, and
quantification of the super-resolved probabilistic ensembles and their errors.
We also study the sensitivity to tuning parameters such as guidance strength.
Results show that SDEdit generates unphysical fields, while DPS generates
reasonable reconstructions at low computational cost but with smoothed
fine-scale features. Both conditional approaches require re-training, but they
reconstruct missing fine-scale features, are cycle-consistent with
observations, and possess the correct statistics such as energy spectra.
Further, their mean model errors are highly correlated with and predictable
from their ensemble standard deviations. Results highlight the trade-offs
between ease of implementation, fidelity (sharpness), and cycle-consistency of
the diffusion models, and offer practical guidance for deployment in
geophysical inverse problems.",http://arxiv.org/pdf/2507.00719v1,,False
"Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity",01/07/2025,"Jacopo Nudo, Mario Edoardo Pandolfo, Edoardo Loru, Mattia Samory, Matteo Cinelli, Walter Quattrociocchi","We investigate how Large Language Models (LLMs) behave when simulating
political discourse on social media. Leveraging 21 million interactions on X
during the 2024 U.S. presidential election, we construct LLM agents based on
1,186 real users, prompting them to reply to politically salient tweets under
controlled conditions. Agents are initialized either with minimal ideological
cues (Zero Shot) or recent tweet history (Few Shot), allowing one-to-one
comparisons with human replies. We evaluate three model families (Gemini,
Mistral, and DeepSeek) across linguistic style, ideological consistency, and
toxicity. We find that richer contextualization improves internal consistency
but also amplifies polarization, stylized signals, and harmful language. We
observe an emergent distortion that we call ""generation exaggeration"": a
systematic amplification of salient traits beyond empirical baselines. Our
analysis shows that LLMs do not emulate users, they reconstruct them. Their
outputs, indeed, reflect internal optimization dynamics more than observed
behavior, introducing structural biases that compromise their reliability as
social proxies. This challenges their use in content moderation, deliberative
simulations, and policy modeling.",http://arxiv.org/pdf/2507.00657v1,,False
Forward Reverse Kernel Regression for the Schrödinger bridge problem,01/07/2025,"Denis Belomestny, John. Schoenmakers","In this paper, we study the Schr\""odinger Bridge Problem (SBP), which is
central to entropic optimal transport. For general reference processes and
begin--endpoint distributions, we propose a forward-reverse iterative Monte
Carlo procedure to approximate the Schr\""odinger potentials in a nonparametric
way. In particular, we use kernel based Monte Carlo regression in the context
of Picard iteration of a corresponding fixed point problem. By preserving in
the iteration positivity and contractivity in a Hilbert metric sense, we
develop a provably convergent algorithm. Furthermore, we provide convergence
rates for the potential estimates and prove their optimality. Finally, as an
application, we propose a non-nested Monte Carlo procedure for the final
dimensional distributions of the Schr\""odinger Bridge process, based on the
constructed potentials and the forward-reverse simulation method for
conditional diffusions.",http://arxiv.org/pdf/2507.00640v1,,False
Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping,01/07/2025,"Nuno Capitão, Yi Zhang, Yidong Zhao, Qian Tao","Spin-lattice relaxation time ($T_1$) is an important biomarker in cardiac
parametric mapping for characterizing myocardial tissue and diagnosing
cardiomyopathies. Conventional Modified Look-Locker Inversion Recovery (MOLLI)
acquires 11 breath-hold baseline images with interleaved rest periods to ensure
mapping accuracy. However, prolonged scanning can be challenging for patients
with poor breathholds, often leading to motion artifacts that degrade image
quality. In addition, $T_1$ mapping requires voxel-wise nonlinear fitting to a
signal recovery model involving an iterative estimation process. Recent studies
have proposed deep-learning approaches for rapid $T_1$ mapping using shortened
sequences to reduce acquisition time for patient comfort. Nevertheless,
existing methods overlook important physics constraints, limiting
interpretability and generalization. In this work, we present an accelerated,
end-to-end $T_1$ mapping framework leveraging Physics-Informed Neural Ordinary
Differential Equations (ODEs) to model temporal dynamics and address these
challenges. Our method achieves high-accuracy $T_1$ estimation from a sparse
subset of baseline images and ensures efficient null index estimation at test
time. Specifically, we develop a continuous-time LSTM-ODE model to enable
selective Look-Locker (LL) data acquisition with arbitrary time lags.
Experimental results show superior performance in $T_1$ estimation for both
native and post-contrast sequences and demonstrate the strong benefit of our
physics-based formulation over direct data-driven $T_1$ priors.",http://arxiv.org/pdf/2507.00613v1,,False
Inverse Design in Nanophotonics via Representation Learning,01/07/2025,"Reza Marzban, Ali Adibi, Raphael Pestourie","Inverse design in nanophotonics, the computational discovery of structures
achieving targeted electromagnetic (EM) responses, has become a key tool for
recent optical advances. Traditional intuition-driven or iterative optimization
methods struggle with the inherently high-dimensional, non-convex design spaces
and the substantial computational demands of EM simulations. Recently, machine
learning (ML) has emerged to address these bottlenecks effectively. This review
frames ML-enhanced inverse design methodologies through the lens of
representation learning, classifying them into two categories: output-side and
input-side approaches. Output-side methods use ML to learn a representation in
the solution space to create a differentiable solver that accelerates
optimization. Conversely, input-side techniques employ ML to learn compact,
latent-space representations of feasible device geometries, enabling efficient
global exploration through generative models. Each strategy presents unique
trade-offs in data requirements, generalization capacity, and novel design
discovery potentials. Hybrid frameworks that combine physics-based optimization
with data-driven representations help escape poor local optima, improve
scalability, and facilitate knowledge transfer. We conclude by highlighting
open challenges and opportunities, emphasizing complexity management,
geometry-independent representations, integration of fabrication constraints,
and advancements in multiphysics co-designs.",http://arxiv.org/pdf/2507.00546v1,,False
Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms,01/07/2025,"Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri","Compound AI (cAI) systems chain multiple AI models to solve complex problems.
cAI systems are typically composed of deep neural networks (DNNs),
transformers, and large language models (LLMs), exhibiting a high degree of
computational diversity and dynamic workload variation. Deploying cAI services
on mobile edge platforms poses a significant challenge in scheduling concurrent
DNN-transformer inference tasks, which arrive dynamically in an unknown
sequence. Existing mobile edge AI inference strategies manage multi-DNN or
transformer-only workloads, relying on design-time profiling, and cannot handle
concurrent inference of DNNs and transformers required by cAI systems. In this
work, we address the challenge of scheduling cAI systems on heterogeneous
mobile edge platforms. We present Twill, a run-time framework to handle
concurrent inference requests of cAI workloads through task affinity-aware
cluster mapping and migration, priority-aware task freezing/unfreezing, and
DVFS, while minimizing inference latency within power budgets. We implement and
deploy our Twill framework on the Nvidia Jetson Orin NX platform. We evaluate
Twill against state-of-the-art edge AI inference techniques over contemporary
DNNs and LLMs, reducing inference latency by 54% on average, while honoring
power budgets.",http://arxiv.org/pdf/2507.00491v1,,False
Bisecle: Binding and Separation in Continual Learning for Video Language Understanding,01/07/2025,"Yue Tan, Xiaoqian Hu, Hao Xue, Celso De Melo, Flora D. Salim","Frontier vision-language models (VLMs) have made remarkable improvements in
video understanding tasks. However, real-world videos typically exist as
continuously evolving data streams (e.g., dynamic scenes captured by wearable
glasses), necessitating models to continually adapt to shifting data
distributions and novel scenarios. Considering the prohibitive computational
costs of fine-tuning models on new tasks, usually, a small subset of parameters
is updated while the bulk of the model remains frozen. This poses new
challenges to existing continual learning frameworks in the context of large
multimodal foundation models, i.e., catastrophic forgetting and update
conflict. While the foundation models struggle with parameter-efficient
continual learning, the hippocampus in the human brain has evolved highly
efficient mechanisms for memory formation and consolidation. Inspired by the
rapid Binding and pattern separation mechanisms in the hippocampus, in this
work, we propose Bisecle for video-language continual learning, where a
multi-directional supervision module is used to capture more cross-modal
relationships and a contrastive prompt learning scheme is designed to isolate
task-specific knowledge to facilitate efficient memory storage. Binding and
separation processes further strengthen the ability of VLMs to retain complex
experiences, enabling robust and efficient continual learning in video
understanding tasks. We perform a thorough evaluation of the proposed Bisecle,
demonstrating its ability to mitigate forgetting and enhance cross-task
generalization on several VideoQA benchmarks.",http://arxiv.org/pdf/2507.00469v1,,False
Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design,01/07/2025,"Xingyu Su, Xiner Li, Masatoshi Uehara, Sunwoo Kim, Yulai Zhao, Gabriele Scalia, Ehsan Hajiramezanali, Tommaso Biancalani, Degui Zhi, Shuiwang Ji","We address the problem of fine-tuning diffusion models for reward-guided
generation in biomolecular design. While diffusion models have proven highly
effective in modeling complex, high-dimensional data distributions, real-world
applications often demand more than high-fidelity generation, requiring
optimization with respect to potentially non-differentiable reward functions
such as physics-based simulation or rewards based on scientific knowledge.
Although RL methods have been explored to fine-tune diffusion models for such
objectives, they often suffer from instability, low sample efficiency, and mode
collapse due to their on-policy nature. In this work, we propose an iterative
distillation-based fine-tuning framework that enables diffusion models to
optimize for arbitrary reward functions. Our method casts the problem as policy
distillation: it collects off-policy data during the roll-in phase, simulates
reward-based soft-optimal policies during roll-out, and updates the model by
minimizing the KL divergence between the simulated soft-optimal policy and the
current model policy. Our off-policy formulation, combined with KL divergence
minimization, enhances training stability and sample efficiency compared to
existing RL-based methods. Empirical results demonstrate the effectiveness and
superior reward optimization of our approach across diverse tasks in protein,
small molecule, and regulatory DNA design.",http://arxiv.org/pdf/2507.00445v1,,False
RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation,01/07/2025,"Yi Ru Wang, Carter Ung, Grant Tannert, Jiafei Duan, Josephine Li, Amy Le, Rishabh Oswal, Markus Grotz, Wilbert Pumacay, Yuquan Deng, Ranjay Krishna, Dieter Fox, Siddhartha Srinivasa","We present RoboEval, a simulation benchmark and structured evaluation
framework designed to reveal the limitations of current bimanual manipulation
policies. While prior benchmarks report only binary task success, we show that
such metrics often conceal critical weaknesses in policy behavior -- such as
poor coordination, slipping during grasping, or asymmetric arm usage. RoboEval
introduces a suite of tiered, semantically grounded tasks decomposed into
skill-specific stages, with variations that systematically challenge spatial,
physical, and coordination capabilities. Tasks are paired with fine-grained
diagnostic metrics and 3000+ human demonstrations to support imitation
learning. Our experiments reveal that policies with similar success rates
diverge in how tasks are executed -- some struggle with alignment, others with
temporally consistent bimanual control. We find that behavioral metrics
correlate with success in over half of task-metric pairs, and remain
informative even when binary success saturates. By pinpointing when and how
policies fail, RoboEval enables a deeper, more actionable understanding of
robotic manipulation -- and highlights the need for evaluation tools that go
beyond success alone.",http://arxiv.org/pdf/2507.00435v1,,False
"Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video",01/07/2025,"Alexander Moore, Amar Saini, Kylie Cancilla, Doug Poland, Carmen Carrano","Amodal segmentation and amodal content completion require using object priors
to estimate occluded masks and features of objects in complex scenes. Until
now, no data has provided an additional dimension for object context: the
possibility of multiple cameras sharing a view of a scene. We introduce
MOVi-MC-AC: Multiple Object Video with Multi-Cameras and Amodal Content, the
largest amodal segmentation and first amodal content dataset to date. Cluttered
scenes of generic household objects are simulated in multi-camera video.
MOVi-MC-AC contributes to the growing literature of object detection, tracking,
and segmentation by including two new contributions to the deep learning for
computer vision world. Multiple Camera (MC) settings where objects can be
identified and tracked between various unique camera perspectives are rare in
both synthetic and real-world video. We introduce a new complexity to synthetic
video by providing consistent object ids for detections and segmentations
between both frames and multiple cameras each with unique features and motion
patterns on a single scene. Amodal Content (AC) is a reconstructive task in
which models predict the appearance of target objects through occlusions. In
the amodal segmentation literature, some datasets have been released with
amodal detection, tracking, and segmentation labels. While other methods rely
on slow cut-and-paste schemes to generate amodal content pseudo-labels, they do
not account for natural occlusions present in the modal masks. MOVi-MC-AC
provides labels for ~5.8 million object instances, setting a new maximum in the
amodal dataset literature, along with being the first to provide ground-truth
amodal content. The full dataset is available at
https://huggingface.co/datasets/Amar-S/MOVi-MC-AC ,",http://arxiv.org/pdf/2507.00339v1,,False
