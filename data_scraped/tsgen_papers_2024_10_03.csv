Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking,02/10/2024,"Mattia Segu, Luigi Piccinelli, Siyuan Li, Yung-Hsu Yang, Bernt Schiele, Luc Van Gool","Multiple object tracking in complex scenarios - such as coordinated dance
performances, team sports, or dynamic animal groups - presents unique
challenges. In these settings, objects frequently move in coordinated patterns,
occlude each other, and exhibit long-term dependencies in their trajectories.
However, it remains a key open research question on how to model long-range
dependencies within tracklets, interdependencies among tracklets, and the
associated temporal occlusions. To this end, we introduce Samba, a novel
linear-time set-of-sequences model designed to jointly process multiple
tracklets by synchronizing the multiple selective state-spaces used to model
each tracklet. Samba autoregressively predicts the future track query for each
sequence while maintaining synchronized long-term memory representations across
tracklets. By integrating Samba into a tracking-by-propagation framework, we
propose SambaMOTR, the first tracker effectively addressing the aforementioned
issues, including long-range dependencies, tracklet interdependencies, and
temporal occlusions. Additionally, we introduce an effective technique for
dealing with uncertain observations (MaskObs) and an efficient training recipe
to scale SambaMOTR to longer sequences. By modeling long-range dependencies and
interactions among tracked objects, SambaMOTR implicitly learns to track
objects accurately through occlusions without any hand-crafted heuristics. Our
approach significantly surpasses prior state-of-the-art on the DanceTrack, BFT,
and SportsMOT datasets.",http://arxiv.org/pdf/2410.01806v1,,False
DreamGarden: A Designer Assistant for Growing Games from a Single Prompt,02/10/2024,"Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey","Coding assistants are increasingly leveraged in game design, both generating
code and making high-level plans. To what degree can these tools align with
developer workflows, and what new modes of human-computer interaction can
emerge from their use? We present DreamGarden, an AI system capable of
assisting with the development of diverse game environments in Unreal Engine.
At the core of our method is an LLM-driven planner, capable of breaking down a
single, high-level prompt -- a dream, memory, or imagined scenario provided by
a human user -- into a hierarchical action plan, which is then distributed
across specialized submodules facilitating concrete implementation. This system
is presented to the user as a garden of plans and actions, both growing
independently and responding to user intervention via seed prompts, pruning,
and feedback. Through a user study, we explore design implications of this
system, charting courses for future work in semi-autonomous assistants and
open-ended simulation design.",http://arxiv.org/pdf/2410.01791v1,,False
Trained Transformer Classifiers Generalize and Exhibit Benign Overfitting In-Context,02/10/2024,"Spencer Frei, Gal Vardi","Transformers have the capacity to act as supervised learning algorithms: by
properly encoding a set of labeled training (""in-context"") examples and an
unlabeled test example into an input sequence of vectors of the same dimension,
the forward pass of the transformer can produce predictions for that unlabeled
test example. A line of recent work has shown that when linear transformers are
pre-trained on random instances for linear regression tasks, these trained
transformers make predictions using an algorithm similar to that of ordinary
least squares. In this work, we investigate the behavior of linear transformers
trained on random linear classification tasks. Via an analysis of the implicit
regularization of gradient descent, we characterize how many pre-training tasks
and in-context examples are needed for the trained transformer to generalize
well at test-time. We further show that in some settings, these trained
transformers can exhibit ""benign overfitting in-context"": when in-context
examples are corrupted by label flipping noise, the transformer memorizes all
of its in-context examples (including those with noisy labels) yet still
generalizes near-optimally for clean test examples.",http://arxiv.org/pdf/2410.01774v1,,False
Integrating Protein Sequence and Expression Level to Analysis Molecular Characterization of Breast Cancer Subtypes,02/10/2024,Hossein Sholehrasa,"Breast cancer's complexity and variability pose significant challenges in
understanding its progression and guiding effective treatment. This study aims
to integrate protein sequence data with expression levels to improve the
molecular characterization of breast cancer subtypes and predict clinical
outcomes. Using ProtGPT2, a language model designed for protein sequences, we
generated embeddings that capture the functional and structural properties of
proteins sequence. These embeddings were integrated with protein expression
level to form enriched biological representations, which were analyzed using
machine learning methods like ensemble K-means for clustering and XGBoost for
classification. Our approach enabled successful clustering of patients into
biologically distinct groups and accurately predicted clinical outcomes such as
survival and biomarkers status, achieving high performance metrics, notably an
F1 score of 0.88 for survival and 0.87 for biomarkers status prediction.
Analysis of feature importance highlighted key proteins like KMT2C, GCN1, and
CLASP2, linked to hormone receptor and Human Epidermal Growth Factor Receptor 2
(HER2) expression, which play a role in tumor progression and patient outcomes,
respectively. Furthermore, protein-protein interaction networks and correlation
analyses revealed the interdependence of proteins that may influence breast
cancer subtype behaviors. These findings suggest that integrating protein
sequence and expression data provides valuable insights into tumor biology and
has significant potential to enhance personalized treatment strategies in
breast cancer care.",http://arxiv.org/pdf/2410.01755v1,,False
"Performant, Memory Efficient and Scalable Multi-Agent Reinforcement Learning",02/10/2024,"Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius","As the field of multi-agent reinforcement learning (MARL) progresses towards
larger and more complex environments, achieving strong performance while
maintaining memory efficiency and scalability to many agents becomes
increasingly important. Although recent research has led to several advanced
algorithms, to date, none fully address all of these key properties
simultaneously. In this work, we introduce Sable, a novel and theoretically
sound algorithm that adapts the retention mechanism from Retentive Networks to
MARL. Sable's retention-based sequence modelling architecture allows for
computationally efficient scaling to a large number of agents, as well as
maintaining a long temporal context, making it well-suited for large-scale
partially observable environments. Through extensive evaluations across six
diverse environments, we demonstrate how Sable is able to significantly
outperform existing state-of-the-art methods in the majority of tasks (34 out
of 45, roughly 75\%). Furthermore, Sable demonstrates stable performance as we
scale the number of agents, handling environments with more than a thousand
agents while exhibiting a linear increase in memory usage. Finally, we conduct
ablation studies to isolate the source of Sable's performance gains and confirm
its efficient computational memory usage. Our results highlight Sable's
performance and efficiency, positioning it as a leading approach to MARL at
scale.",http://arxiv.org/pdf/2410.01706v1,,False
Positional Attention: Out-of-Distribution Generalization and Expressivity for Neural Algorithmic Reasoning,02/10/2024,"Artur Back de Luca, George Giapitzakis, Shenghao Yang, Petar Veličković, Kimon Fountoulakis","There has been a growing interest in the ability of neural networks to solve
algorithmic tasks, such as arithmetic, summary statistics, and sorting. While
state-of-the-art models like Transformers have demonstrated good generalization
performance on in-distribution tasks, their out-of-distribution (OOD)
performance is poor when trained end-to-end. In this paper, we focus on value
generalization, a common instance of OOD generalization where the test
distribution has the same input sequence length as the training distribution,
but the value ranges in the training and test distributions do not necessarily
overlap. To address this issue, we propose that using fixed positional
encodings to determine attention weights-referred to as positional
attention-enhances empirical OOD performance while maintaining expressivity. We
support our claim about expressivity by proving that Transformers with
positional attention can effectively simulate parallel algorithms.",http://arxiv.org/pdf/2410.01686v1,,False
Efficient Long-range Language Modeling with Self-supervised Causal Retrieval,02/10/2024,"Xiang Hu, Zhihao Teng, Wei Wu, Kewei Tu","Recently, retrieval-based language models (RLMs) have received much
attention. However, most of them leverage a pre-trained retriever with fixed
parameters, which may not adapt well to causal language models. In this work,
we propose Grouped Cross-Attention, a novel module enabling joint pre-training
of the retriever and causal LM, and apply it to long-context modeling. For a
given input sequence, we split it into chunks and use the current chunk to
retrieve past chunks for subsequent text generation. Our innovation allows the
retriever to learn how to retrieve past chunks that better minimize the
auto-regressive loss of subsequent tokens in an end-to-end manner. By
integrating top-$k$ retrieval, our model can be pre-trained efficiently from
scratch with context lengths up to 64K tokens. Our experiments show our model,
compared with long-range LM baselines, can achieve lower perplexity with
comparable or lower pre-training and inference costs.",http://arxiv.org/pdf/2410.01651v1,,False
Automated Red Teaming with GOAT: the Generative Offensive Agent Tester,02/10/2024,"Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori","Red teaming assesses how large language models (LLMs) can produce content
that violates norms, policies, and rules set during their safety training.
However, most existing automated methods in the literature are not
representative of the way humans tend to interact with AI models. Common users
of AI models may not have advanced knowledge of adversarial machine learning
methods or access to model internals, and they do not spend a lot of time
crafting a single highly effective adversarial prompt. Instead, they are likely
to make use of techniques commonly shared online and exploit the multiturn
conversational nature of LLMs. While manual testing addresses this gap, it is
an inefficient and often expensive process. To address these limitations, we
introduce the Generative Offensive Agent Tester (GOAT), an automated agentic
red teaming system that simulates plain language adversarial conversations
while leveraging multiple adversarial prompting techniques to identify
vulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by
prompting a general-purpose model in a way that encourages reasoning through
the choices of methods available, the current target model's response, and the
next steps. Our approach is designed to be extensible and efficient, allowing
human testers to focus on exploring new areas of risk while automation covers
the scaled adversarial stress-testing of known risk territory. We present the
design and evaluation of GOAT, demonstrating its effectiveness in identifying
vulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama
3.1 and 88% against GPT-4 on the JailbreakBench dataset.",http://arxiv.org/pdf/2410.01606v1,,False
Imaging foundation model for universal enhancement of non-ideal measurement CT,02/10/2024,"Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen","Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.",http://arxiv.org/pdf/2410.01591v1,,False
TiVaT: Joint-Axis Attention for Time Series Forecasting with Lead-Lag Dynamics,02/10/2024,"Junwoo Ha, Hyukjae Kwon, Sungsoo Kim, Kisu Lee, Ha Young Kim","Multivariate time series (MTS) forecasting plays a crucial role in various
real-world applications, yet simultaneously capturing both temporal and
inter-variable dependencies remains a challenge. Conventional Channel-Dependent
(CD) models handle these dependencies separately, limiting their ability to
model complex interactions such as lead-lag dynamics. To address these
limitations, we propose TiVaT (Time-Variable Transformer), a novel architecture
that integrates temporal and variate dependencies through its Joint-Axis (JA)
attention mechanism. TiVaT's ability to capture intricate variate-temporal
dependencies, including asynchronous interactions, is further enhanced by the
incorporation of Distance-aware Time-Variable (DTV) Sampling, which reduces
noise and improves accuracy through a learned 2D map that focuses on key
interactions. TiVaT effectively models both temporal and variate dependencies,
consistently delivering strong performance across diverse datasets. Notably, it
excels in capturing complex patterns within multivariate time series, enabling
it to surpass or remain competitive with state-of-the-art methods. This
positions TiVaT as a new benchmark in MTS forecasting, particularly in handling
datasets characterized by intricate and challenging dependencies.",http://arxiv.org/pdf/2410.01531v1,,False
SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios,02/10/2024,"Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu","The systematic evaluation of speech separation and enhancement models under
moving sound source conditions typically requires extensive data comprising
diverse scenarios. However, real-world datasets often contain insufficient data
to meet the training and evaluation requirements of models. Although synthetic
datasets offer a larger volume of data, their acoustic simulations lack
realism. Consequently, neither real-world nor synthetic datasets effectively
fulfill practical needs. To address these issues, we introduce SonicSim, a
synthetic toolkit de-designed to generate highly customizable data for moving
sound sources. SonicSim is developed based on the embodied AI simulation
platform, Habitat-sim, supporting multi-level adjustments, including
scene-level, microphone-level, and source-level, thereby generating more
diverse synthetic data. Leveraging SonicSim, we constructed a moving sound
source benchmark dataset, SonicSet, using the Librispeech, the Freesound
Dataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the
Matterport3D to evaluate speech separation and enhancement models.
Additionally, to validate the differences between synthetic data and real-world
data, we randomly selected 5 hours of raw data without reverberation from the
SonicSet validation set to record a real-world speech separation dataset, which
was then compared with the corresponding synthetic datasets. Similarly, we
utilized the real-world speech enhancement dataset RealMAN to validate the
acoustic gap between other synthetic datasets and the SonicSet dataset for
speech enhancement. The results indicate that the synthetic data generated by
SonicSim can effectively generalize to real-world scenarios. Demo and code are
publicly available at https://cslikai.cn/SonicSim/.",http://arxiv.org/pdf/2410.01481v1,,False
Flow Matching for Accelerated Simulation of Atomic Transport in Materials,02/10/2024,"Juno Nam, Sulin Liu, Gavin Winter, KyuJung Jun, Soojung Yang, Rafael Gómez-Bombarelli","We introduce LiFlow, a generative framework to accelerate molecular dynamics
(MD) simulations for crystalline materials that formulates the task as
conditional generation of atomic displacements. The model uses flow matching,
with a Propagator submodel to generate atomic displacements and a Corrector to
locally correct unphysical geometries, and incorporates an adaptive prior based
on the Maxwell-Boltzmann distribution to account for chemical and thermal
conditions. We benchmark LiFlow on a dataset comprising 25-ps trajectories of
lithium diffusion across 4,186 solid-state electrolyte (SSE) candidates at four
temperatures. The model obtains a consistent Spearman rank correlation of
0.7-0.8 for lithium mean squared displacement (MSD) predictions on unseen
compositions. Furthermore, LiFlow generalizes from short training trajectories
to larger supercells and longer simulations while maintaining high accuracy.
With speed-ups of up to 600,000$\times$ compared to first-principles methods,
LiFlow enables scalable simulations at significantly larger length and time
scales.",http://arxiv.org/pdf/2410.01464v1,,False
Closed-loop Long-horizon Robotic Planning via Equilibrium Sequence Modeling,02/10/2024,"Jinghan Li, Zhicheng Sun, Fei Li, Cao Sheng, Jiazhong Yu, Yadong Mu","In the endeavor to make autonomous robots take actions, task planning is a
major challenge that requires translating high-level task descriptions into
long-horizon action sequences. Despite recent advances in language model
agents, they remain prone to planning errors and limited in their ability to
plan ahead. To address these limitations in robotic planning, we advocate a
self-refining scheme that iteratively refines a draft plan until an equilibrium
is reached. Remarkably, this process can be optimized end-to-end from an
analytical perspective without the need to curate additional verifiers or
reward models, allowing us to train self-refining planners in a simple
supervised learning fashion. Meanwhile, a nested equilibrium sequence modeling
procedure is devised for efficient closed-loop planning that incorporates
useful feedback from the environment (or an internal world model). Our method
is evaluated on the VirtualHome-Env benchmark, showing advanced performance
with better scaling for inference computation. Code is available at
https://github.com/Singularity0104/equilibrium-planner.",http://arxiv.org/pdf/2410.01440v1,,False
Deep Kernel Posterior Learning under Infinite Variance Prior Weights,02/10/2024,"Jorge Loría, Anindya Bhadra","Neal (1996) proved that infinitely wide shallow Bayesian neural networks
(BNN) converge to Gaussian processes (GP), when the network weights have
bounded prior variance. Cho & Saul (2009) provided a useful recursive formula
for deep kernel processes for relating the covariance kernel of each layer to
the layer immediately below. Moreover, they worked out the form of the
layer-wise covariance kernel in an explicit manner for several common
activation functions. Recent works, including Aitchison et al. (2021), have
highlighted that the covariance kernels obtained in this manner are
deterministic and hence, precludes any possibility of representation learning,
which amounts to learning a non-degenerate posterior of a random kernel given
the data. To address this, they propose adding artificial noise to the kernel
to retain stochasticity, and develop deep kernel inverse Wishart processes.
Nonetheless, this artificial noise injection could be critiqued in that it
would not naturally emerge in a classic BNN architecture under an
infinite-width limit. To address this, we show that a Bayesian deep neural
network, where each layer width approaches infinity, and all network weights
are elliptically distributed with infinite variance, converges to a process
with $\alpha$-stable marginals in each layer that has a conditionally Gaussian
representation. These conditional random covariance kernels could be
recursively linked in the manner of Cho & Saul (2009), even though marginally
the process exhibits stable behavior, and hence covariances are not even
necessarily defined. We also provide useful generalizations of the recent
results of Lor\'ia & Bhadra (2024) on shallow networks to multi-layer networks,
and remedy the computational burden of their approach. The computational and
statistical benefits over competing approaches stand out in simulations and in
demonstrations on benchmark data sets.",http://arxiv.org/pdf/2410.01284v1,,False
Uncertainty-aware Human Mobility Modeling and Anomaly Detection,02/10/2024,"Haomin Wen, Shurui Cao, Leman Akoglu","Given the GPS coordinates of a large collection of human agents over time,
how can we model their mobility behavior toward effective anomaly detection
(e.g. for bad-actor or malicious behavior detection) without any labeled data?
Human mobility and trajectory modeling have been studied extensively with
varying capacity to handle complex input, and performance-efficiency
trade-offs. With the arrival of more expressive models in machine learning, we
attempt to model GPS data as a sequence of stay-point events, each with a set
of characterizing spatiotemporal features, and leverage modern sequence models
such as Transformers for un/self-supervised training and inference. Notably,
driven by the inherent stochasticity of certain individuals' behavior, we equip
our model with aleatoric/data uncertainty estimation. In addition, to handle
data sparsity of a large variety of behaviors, we incorporate epistemic/model
uncertainty into our model. Together, aleatoric and epistemic uncertainty
enable a robust loss and training dynamics, as well as uncertainty-aware
decision making in anomaly scoring. Experiments on large expert-simulated
datasets with tens of thousands of agents demonstrate the effectiveness of our
model against both forecasting and anomaly detection baselines.",http://arxiv.org/pdf/2410.01281v1,,False
Equivariant score-based generative models provably learn distributions with symmetries efficiently,02/10/2024,"Ziyu Chen, Markos A. Katsoulakis, Benjamin J. Zhang","Symmetry is ubiquitous in many real-world phenomena and tasks, such as
physics, images, and molecular simulations. Empirical studies have demonstrated
that incorporating symmetries into generative models can provide better
generalization and sampling efficiency when the underlying data distribution
has group symmetry. In this work, we provide the first theoretical analysis and
guarantees of score-based generative models (SGMs) for learning distributions
that are invariant with respect to some group symmetry and offer the first
quantitative comparison between data augmentation and adding equivariant
inductive bias. First, building on recent works on the Wasserstein-1
($\mathbf{d}_1$) guarantees of SGMs and empirical estimations of probability
divergences under group symmetry, we provide an improved $\mathbf{d}_1$
generalization bound when the data distribution is group-invariant. Second, we
describe the inductive bias of equivariant SGMs using Hamilton-Jacobi-Bellman
theory, and rigorously demonstrate that one can learn the score of a
symmetrized distribution using equivariant vector fields without data
augmentations through the analysis of the optimality and equivalence of
score-matching objectives. This also provides practical guidance that one does
not have to augment the dataset as long as the vector field or the neural
network parametrization is equivariant. Moreover, we quantify the impact of not
incorporating equivariant structure into the score parametrization, by showing
that non-equivariant vector fields can yield worse generalization bounds. This
can be viewed as a type of model-form error that describes the missing
structure of non-equivariant vector fields. Numerical simulations corroborate
our analysis and highlight that data augmentations cannot replace the role of
equivariant vector fields.",http://arxiv.org/pdf/2410.01244v1,,False
From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging,02/10/2024,"Yuling Shi, Songsong Wang, Chengcheng Wan, Xiaodong Gu","While large language models have made significant strides in code generation,
the pass rate of the generated code is bottlenecked on subtle errors, often
requiring human intervention to pass tests, especially for complex problems.
Existing LLM-based debugging systems treat generated programs as monolithic
units, failing to address bugs at multiple levels of granularity, from
low-level syntax errors to high-level algorithmic flaws. In this paper, we
introduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger
by isolating, identifying, and resolving bugs at various levels of granularity.
MGDebugger decomposes problematic code into a hierarchical tree structure of
subfunctions, with each level representing a particular granularity of error.
During debugging, it analyzes each subfunction and iteratively resolves bugs in
a bottom-up manner. To effectively test each subfunction, we propose an
LLM-simulated Python executor, which traces code execution and tracks important
variable states to pinpoint errors accurately. Extensive experiments
demonstrate that MGDebugger outperforms existing debugging systems, achieving
an 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%
repair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes
bugs across different categories and difficulty levels, demonstrating its
robustness and effectiveness.",http://arxiv.org/pdf/2410.01215v1,,False
Polyp-SES: Automatic Polyp Segmentation with Self-Enriched Semantic Model,02/10/2024,"Quang Vinh Nguyen, Thanh Hoang Son Vo, Sae-Ryung Kang, Soo-Hyung Kim","Automatic polyp segmentation is crucial for effective diagnosis and treatment
in colonoscopy images. Traditional methods encounter significant challenges in
accurately delineating polyps due to limitations in feature representation and
the handling of variability in polyp appearance. Deep learning techniques,
including CNN and Transformer-based methods, have been explored to improve
polyp segmentation accuracy. However, existing approaches often neglect
additional semantics, restricting their ability to acquire adequate contexts of
polyps in colonoscopy images. In this paper, we propose an innovative method
named ``Automatic Polyp Segmentation with Self-Enriched Semantic Model'' to
address these limitations. First, we extract a sequence of features from an
input image and decode high-level features to generate an initial segmentation
mask. Using the proposed self-enriched semantic module, we query potential
semantics and augment deep features with additional semantics, thereby aiding
the model in understanding context more effectively. Extensive experiments show
superior segmentation performance of the proposed method against
state-of-the-art polyp segmentation baselines across five polyp benchmarks in
both superior learning and generalization capabilities.",http://arxiv.org/pdf/2410.01210v1,,False
Were RNNs All We Needed?,02/10/2024,"Leo Feng, Frederick Tung, Mohamed Osama Ahmed, Yoshua Bengio, Hossein Hajimirsadegh","The scalability limitations of Transformers regarding sequence length have
renewed interest in recurrent sequence models that are parallelizable during
training. As a result, many novel recurrent architectures, such as S4, Mamba,
and Aaren, have been proposed that achieve comparable performance. In this
work, we revisit traditional recurrent neural networks (RNNs) from over a
decade ago: LSTMs (1997) and GRUs (2014). While these models were slow due to
requiring to backpropagate through time (BPTT), we show that by removing their
hidden state dependencies from their input, forget, and update gates, LSTMs and
GRUs no longer need to BPTT and can be efficiently trained in parallel.
Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1)
use significantly fewer parameters than their traditional counterparts and (2)
are fully parallelizable during training (175x faster for a sequence of length
512). Lastly, we show that these stripped-down versions of decade-old RNNs
match the empirical performance of recent sequence models.",http://arxiv.org/pdf/2410.01201v1,,False
Stochastic Gradient Descent with Adaptive Data,02/10/2024,"Ethan Che, Jing Dong, Xin T. Tong","Stochastic gradient descent (SGD) is a powerful optimization technique that
is particularly useful in online learning scenarios. Its convergence analysis
is relatively well understood under the assumption that the data samples are
independent and identically distributed (iid). However, applying SGD to policy
optimization problems in operations research involves a distinct challenge: the
policy changes the environment and thereby affects the data used to update the
policy. The adaptively generated data stream involves samples that are
non-stationary, no longer independent from each other, and affected by previous
decisions. The influence of previous decisions on the data generated introduces
bias in the gradient estimate, which presents a potential source of instability
for online learning not present in the iid case. In this paper, we introduce
simple criteria for the adaptively generated data stream to guarantee the
convergence of SGD. We show that the convergence speed of SGD with adaptive
data is largely similar to the classical iid setting, as long as the mixing
time of the policy-induced dynamics is factored in. Our Lyapunov-function
analysis allows one to translate existing stability analysis of stochastic
systems studied in operations research into convergence rates for SGD, and we
demonstrate this for queueing and inventory management problems. We also
showcase how our result can be applied to study the sample complexity of an
actor-critic policy gradient algorithm.",http://arxiv.org/pdf/2410.01195v1,,False
Text2PDE: Latent Diffusion Models for Accessible Physics Simulation,02/10/2024,"Anthony Zhou, Zijie Li, Michael Schneier, John R Buchanan Jr, Amir Barati Farimani","Recent advances in deep learning have inspired numerous works on data-driven
solutions to partial differential equation (PDE) problems. These neural PDE
solvers can often be much faster than their numerical counterparts; however,
each presents its unique limitations and generally balances training cost,
numerical accuracy, and ease of applicability to different problem setups. To
address these limitations, we introduce several methods to apply latent
diffusion models to physics simulation. Firstly, we introduce a mesh
autoencoder to compress arbitrarily discretized PDE data, allowing for
efficient diffusion training across various physics. Furthermore, we
investigate full spatio-temporal solution generation to mitigate autoregressive
error accumulation. Lastly, we investigate conditioning on initial physical
quantities, as well as conditioning solely on a text prompt to introduce
text2PDE generation. We show that language can be a compact, interpretable, and
accurate modality for generating physics simulations, paving the way for more
usable and accessible PDE solvers. Through experiments on both uniform and
structured grids, we show that the proposed approach is competitive with
current neural PDE solvers in both accuracy and efficiency, with promising
scaling behavior up to $\sim$3 billion parameters. By introducing a scalable,
accurate, and usable physics simulator, we hope to bring neural PDE solvers
closer to practical use.",http://arxiv.org/pdf/2410.01153v1,,False
Recovering Manifold Structure Using Ollivier-Ricci Curvature,02/10/2024,"Tristan Luca Saidi, Abigail Hickok, Andrew J. Blumberg","We introduce ORC-ManL, a new algorithm to prune spurious edges from nearest
neighbor graphs using a criterion based on Ollivier-Ricci curvature and
estimated metric distortion. Our motivation comes from manifold learning: we
show that when the data generating the nearest-neighbor graph consists of noisy
samples from a low-dimensional manifold, edges that shortcut through the
ambient space have more negative Ollivier-Ricci curvature than edges that lie
along the data manifold. We demonstrate that our method outperforms alternative
pruning methods and that it significantly improves performance on many
downstream geometric data analysis tasks that use nearest neighbor graphs as
input. Specifically, we evaluate on manifold learning, persistent homology,
dimension estimation, and others. We also show that ORC-ManL can be used to
improve clustering and manifold learning of single-cell RNA sequencing data.
Finally, we provide empirical convergence experiments that support our
theoretical findings.",http://arxiv.org/pdf/2410.01149v1,,False
Approximately Aligned Decoding,01/10/2024,"Daniel Melcer, Sujan Gonugondla, Pramuditha Perera, Haifeng Qian, Wen-Hao Chiang, Yanjun Wang, Nihal Jain, Pranav Garg, Xiaofei Ma, Anoop Deoras","It is common to reject undesired outputs of Large Language Models (LLMs);
however, current methods to do so require an excessive amount of computation,
or severely distort the distribution of outputs. We present a method to balance
the distortion of the output distribution with computational efficiency,
allowing for the generation of long sequences of text with difficult-to-satisfy
constraints, with less amplification of low probability outputs compared to
existing methods. We show through a series of experiments that the
task-specific performance of our method is comparable to methods that do not
distort the output distribution, while being much more computationally
efficient.",http://arxiv.org/pdf/2410.01103v1,,False
Generative AI Application for Building Industry,01/10/2024,"Hanlong Wan, Jian Zhang, Yan Chen, Weili Xu, Fan Feng","This paper investigates the transformative potential of generative AI
technologies, particularly large language models (LLMs), within the building
industry. By leveraging these advanced AI tools, the study explores their
application across key areas such as energy code compliance, building design
optimization, and workforce training. The research highlights how LLMs can
automate labor-intensive processes, significantly improving efficiency,
accuracy, and safety in building practices. The paper also addresses the
challenges associated with interpreting complex visual and textual data in
architectural plans and regulatory codes, proposing innovative solutions to
enhance AI-driven compliance checking and design processes. Additionally, the
study considers the broader implications of AI integration, including the
development of AI-powered tools for comprehensive code compliance across
various regulatory domains and the potential for AI to revolutionize workforce
training through realistic simulations. This paper provides a comprehensive
analysis of the current capabilities of generative AI in the building industry
while outlining future directions for research and development, aiming to pave
the way for smarter, more sustainable, and responsive construction practices.",http://arxiv.org/pdf/2410.01098v1,,False
Back to Bayesics: Uncovering Human Mobility Distributions and Anomalies with an Integrated Statistical and Neural Framework,01/10/2024,"Minxuan Duan, Yinlong Qian, Lingyi Zhao, Zihao Zhou, Zeeshan Rasheed, Rose Yu, Khurram Shafique","Existing methods for anomaly detection often fall short due to their
inability to handle the complexity, heterogeneity, and high dimensionality
inherent in real-world mobility data. In this paper, we propose DeepBayesic, a
novel framework that integrates Bayesian principles with deep neural networks
to model the underlying multivariate distributions from sparse and complex
datasets. Unlike traditional models, DeepBayesic is designed to manage
heterogeneous inputs, accommodating both continuous and categorical data to
provide a more comprehensive understanding of mobility patterns. The framework
features customized neural density estimators and hybrid architectures,
allowing for flexibility in modeling diverse feature distributions and enabling
the use of specialized neural networks tailored to different data types. Our
approach also leverages agent embeddings for personalized anomaly detection,
enhancing its ability to distinguish between normal and anomalous behaviors for
individual agents. We evaluate our approach on several mobility datasets,
demonstrating significant improvements over state-of-the-art anomaly detection
methods. Our results indicate that incorporating personalization and advanced
sequence modeling techniques can substantially enhance the ability to detect
subtle and complex anomalies in spatiotemporal event sequences.",http://arxiv.org/pdf/2410.01011v1,,False
Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments,01/10/2024,"Kosuke Imai, Kentaro Nakamura","In this paper, we demonstrate how to enhance the validity of causal inference
with unstructured high-dimensional treatments like texts, by leveraging the
power of generative Artificial Intelligence. Specifically, we propose to use a
deep generative model such as large language models (LLMs) to efficiently
generate treatments and use their internal representation for subsequent causal
effect estimation. We show that the knowledge of this true internal
representation helps separate the treatment features of interest, such as
specific sentiments and certain topics, from other possibly unknown confounding
features. Unlike the existing methods, our proposed approach eliminates the
need to learn causal representation from the data and hence produces more
accurate and efficient estimates. We formally establish the conditions required
for the nonparametric identification of the average treatment effect, propose
an estimation strategy that avoids the violation of the overlap assumption, and
derive the asymptotic properties of the proposed estimator through the
application of double machine learning. Finally, using an instrumental
variables approach, we extend the proposed methodology to the settings, in
which the treatment feature is based on human perception rather than is assumed
to be fixed given the treatment object. We conduct simulation studies using the
generated text data with an open-source LLM, Llama3, to illustrate the
advantages of our estimator over the state-of-the-art causal representation
learning algorithms.",http://arxiv.org/pdf/2410.00903v1,,False
Compressing Recurrent Neural Networks for FPGA-accelerated Implementation in Fluorescence Lifetime Imaging,01/10/2024,"Ismail Erbas, Vikas Pandey, Aporva Amarnath, Naigang Wang, Karthik Swaminathan, Stefan T. Radev, Xavier Intes","Fluorescence lifetime imaging (FLI) is an important technique for studying
cellular environments and molecular interactions, but its real-time application
is limited by slow data acquisition, which requires capturing large
time-resolved images and complex post-processing using iterative fitting
algorithms. Deep learning (DL) models enable real-time inference, but can be
computationally demanding due to complex architectures and large matrix
operations. This makes DL models ill-suited for direct implementation on
field-programmable gate array (FPGA)-based camera hardware. Model compression
is thus crucial for practical deployment for real-time inference generation. In
this work, we focus on compressing recurrent neural networks (RNNs), which are
well-suited for FLI time-series data processing, to enable deployment on
resource-constrained FPGA boards. We perform an empirical evaluation of various
compression techniques, including weight reduction, knowledge distillation
(KD), post-training quantization (PTQ), and quantization-aware training (QAT),
to reduce model size and computational load while preserving inference
accuracy. Our compressed RNN model, Seq2SeqLite, achieves a balance between
computational efficiency and prediction accuracy, particularly at 8-bit
precision. By applying KD, the model parameter size was reduced by 98\% while
retaining performance, making it suitable for concurrent real-time FLI analysis
on FPGA during data capture. This work represents a big step towards
integrating hardware-accelerated real-time FLI analysis for fast biological
processes.",http://arxiv.org/pdf/2410.00948v1,,False
Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction,01/10/2024,"Hyogo Hiruma, Hiroshi Ito, Tetusya Ogata","Uncertainty of environments has long been a difficult characteristic to
handle, when performing real-world robot tasks. This is because the uncertainty
produces unexpected observations that cannot be covered by manual scripting.
Learning based robot controlling methods are a promising approach for
generating flexible motions against unknown situations, but still tend to
suffer under uncertainty due to its deterministic nature. In order to
adaptively perform the target task under such conditions, the robot control
model must be able to accurately understand the possible uncertainty, and to
exploratively derive the optimal action that minimizes such uncertainty. This
paper extended an existing predictive learning based robot control method,
which employ foresight prediction using dynamic internal simulation. The
foresight module refines the model's hidden states by sampling multiple
possible futures and replace with the one that led to the lower future
uncertainty. The adaptiveness of the model was evaluated on a door opening
task. The door can be opened either by pushing, pulling, or sliding, but robot
cannot visually distinguish which way, and is required to adapt on the fly. The
results showed that the proposed model adaptively diverged its motion through
interaction with the door, whereas conventional methods failed to stably
diverge. The models were analyzed on Lyapunov exponents of RNN hidden states
which reflect the possible divergence at each time step during task execution.
The result indicated that the foresight module biased the model to consider
future consequences, which lead to embedding uncertainties at the policy of the
robot controller, rather than the resultant observation. This is beneficial for
implementing adaptive behaviors, which indices derivation of diverse motion
during exploration.",http://arxiv.org/pdf/2410.00774v1,,False
Targeted synthetic data generation for tabular data via hardness characterization,01/10/2024,"Tommaso Ferracci, Leonie Tabea Goldmann, Anton Hinel, Francesco Sanna Passino","Synthetic data generation has been proven successful in improving model
performance and robustness in the context of scarce or low-quality data. Using
the data valuation framework to statistically identify beneficial and
detrimental observations, we introduce a novel augmentation pipeline that
generates only high-value training points based on hardness characterization.
We first demonstrate via benchmarks on real data that Shapley-based data
valuation methods perform comparably with learning-based methods in hardness
characterisation tasks, while offering significant theoretical and
computational advantages. Then, we show that synthetic data generators trained
on the hardest points outperform non-targeted data augmentation on simulated
data and on a large scale credit default prediction task. In particular, our
approach improves the quality of out-of-sample predictions and it is
computationally more efficient compared to non-targeted methods.",http://arxiv.org/pdf/2410.00759v1,,False
AR-Sieve Bootstrap for the Random Forest and a simulation-based comparison with rangerts time series prediction,01/10/2024,"Cabrel Teguemne Fokam, Carsten Jentsch, Michel Lang, Markus Pauly","The Random Forest (RF) algorithm can be applied to a broad spectrum of
problems, including time series prediction. However, neither the classical IID
(Independent and Identically distributed) bootstrap nor block bootstrapping
strategies (as implemented in rangerts) completely account for the nature of
the Data Generating Process (DGP) while resampling the observations. We propose
the combination of RF with a residual bootstrapping technique where we replace
the IID bootstrap with the AR-Sieve Bootstrap (ARSB), which assumes the DGP to
be an autoregressive process. To assess the new model's predictive performance,
we conduct a simulation study using synthetic data generated from different
types of DGPs. It turns out that ARSB provides more variation amongst the trees
in the forest. Moreover, RF with ARSB shows greater accuracy compared to RF
with other bootstrap strategies. However, these improvements are achieved at
some efficiency costs.",http://arxiv.org/pdf/2410.00942v1,,False
TAVRNN: Temporal Attention-enhanced Variational Graph RNN Captures Neural Dynamics and Behavior,01/10/2024,"Moein Khajehnejad, Forough Habibollahi, Ahmad Khajehnejad, Brett J. Kagan, Adeel Razi","We introduce Temporal Attention-enhanced Variational Graph Recurrent Neural
Network (TAVRNN), a novel framework for analyzing the evolving dynamics of
neuronal connectivity networks in response to external stimuli and behavioral
feedback. TAVRNN captures temporal changes in network structure by modeling
sequential snapshots of neuronal activity, enabling the identification of key
connectivity patterns. Leveraging temporal attention mechanisms and variational
graph techniques, TAVRNN uncovers how connectivity shifts align with behavior
over time. We validate TAVRNN on two datasets: in vivo calcium imaging data
from freely behaving rats and novel in vitro electrophysiological data from the
DishBrain system, where biological neurons control a simulated environment
during the game of pong. We show that TAVRNN outperforms previous baseline
models in classification, clustering tasks and computational efficiency while
accurately linking connectivity changes to performance variations. Crucially,
TAVRNN reveals that high game performance in the DishBrain system correlates
with the alignment of sensory and motor subregion channels, a relationship not
evident in earlier models. This framework represents the first application of
dynamic graph representation of electrophysiological (neuronal) data from
DishBrain system, providing insights into the reorganization of neuronal
networks during learning. TAVRNN's ability to differentiate between neuronal
states associated with successful and unsuccessful learning outcomes, offers
significant implications for real-time monitoring and manipulation of
biological neuronal systems.",http://arxiv.org/pdf/2410.00665v1,,False
LASMP: Language Aided Subset Sampling Based Motion Planner,01/10/2024,"Saswati Bhattacharjee, Anirban Sinha, Chinwe Ekenna","This paper presents the Language Aided Subset Sampling Based Motion Planner
(LASMP), a system that helps mobile robots plan their movements by using
natural language instructions. LASMP uses a modified version of the Rapidly
Exploring Random Tree (RRT) method, which is guided by user-provided commands
processed through a language model (RoBERTa). The system improves efficiency by
focusing on specific areas of the robot's workspace based on these
instructions, making it faster and less resource-intensive. Compared to
traditional RRT methods, LASMP reduces the number of nodes needed by 55% and
cuts random sample queries by 80%, while still generating safe, collision-free
paths. Tested in both simulated and real-world environments, LASMP has shown
better performance in handling complex indoor scenarios. The results highlight
the potential of combining language processing with motion planning to make
robot navigation more efficient.",http://arxiv.org/pdf/2410.00649v1,,False
ReXplain: Translating Radiology into Patient-Friendly Video Reports,01/10/2024,"Luyang Luo, Jenanan Vairavamurthy, Xiaoman Zhang, Abhinav Kumar, Ramon R. Ter-Oganesyan, Stuart T. Schroff, Dan Shilo, Rydhwana Hossain, Mike Moritz, Pranav Rajpurkar","Radiology reports often remain incomprehensible to patients, undermining
patient-centered care. We present ReXplain (Radiology eXplanation), an
innovative AI-driven system that generates patient-friendly video reports for
radiology findings. ReXplain uniquely integrates a large language model for
text simplification, an image segmentation model for anatomical region
identification, and an avatar generation tool, producing comprehensive
explanations with plain language, highlighted imagery, and 3D organ renderings.
Our proof-of-concept study with five board-certified radiologists indicates
that ReXplain could accurately deliver radiological information and effectively
simulate one-on-one consultations. This work demonstrates a new paradigm in
AI-assisted medical communication, potentially improving patient engagement and
satisfaction in radiology care, and opens new avenues for research in
multimodal medical communication.",http://arxiv.org/pdf/2410.00441v1,,False
AARK: An Open Toolkit for Autonomous Racing Research,01/10/2024,"James Bockman, Matthew Howe, Adrian Orenstein, Feras Dayoub","Autonomous racing demands safe control of vehicles at their physical limits
for extended periods of time, providing insights into advanced vehicle safety
systems which increasingly rely on intervention provided by vehicle autonomy.
Participation in this field carries with it a high barrier to entry. Physical
platforms and their associated sensor suites require large capital outlays
before any demonstrable progress can be made. Simulators allow researches to
develop soft autonomous systems without purchasing a platform. However,
currently available simulators lack visual and dynamic fidelity, can still be
expensive to buy, lack customisation, and are difficult to use. AARK provides
three packages, ACI, ACDG, and ACMPC. These packages enable research into
autonomous control systems in the demanding environment of racing to bring more
people into the field and improve reproducibility: ACI provides researchers
with a computer vision-friendly interface to Assetto Corsa for convenient
comparison and evaluation of autonomous control solutions; ACDG enables
generation of depth, normal and semantic segmentation data for training
computer vision models to use in perception systems; and ACMPC gives newcomers
to the field a modular full-stack autonomous control solution, capable of
controlling vehicles to build from. AARK aims to unify and democratise research
into a field critical to providing safer roads and trusted autonomous systems.",http://arxiv.org/pdf/2410.00358v1,,False
Contrastive Representation Learning for Predicting Solar Flares from Extremely Imbalanced Multivariate Time Series Data,01/10/2024,"Onur Vural, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi","Major solar flares are abrupt surges in the Sun's magnetic flux, presenting
significant risks to technological infrastructure. In view of this, effectively
predicting major flares from solar active region magnetic field data through
machine learning methods becomes highly important in space weather research.
Magnetic field data can be represented in multivariate time series modality
where the data displays an extreme class imbalance due to the rarity of major
flare events. In time series classification-based flare prediction, the use of
contrastive representation learning methods has been relatively limited. In
this paper, we introduce CONTREX, a novel contrastive representation learning
approach for multivariate time series data, addressing challenges of temporal
dependencies and extreme class imbalance. Our method involves extracting
dynamic features from the multivariate time series instances, deriving two
extremes from positive and negative class feature vectors that provide maximum
separation capability, and training a sequence representation embedding module
with the original multivariate time series data guided by our novel contrastive
reconstruction loss to generate embeddings aligned with the extreme points.
These embeddings capture essential time series characteristics and enhance
discriminative power. Our approach shows promising solar flare prediction
results on the Space Weather Analytics for Solar Flares (SWAN-SF) multivariate
time series benchmark dataset against baseline methods.",http://arxiv.org/pdf/2410.00312v1,,False
