Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
GENESIS: A Generative Model of Episodic-Semantic Interaction,17/10/2025,"Marco D'Alessandro, Leo D'Amato, Mikel Elkano, Mikel Uriz, Giovanni Pezzulo","A central challenge in cognitive neuroscience is to explain how semantic and
episodic memory, two major forms of declarative memory, typically associated
with cortical and hippocampal processing, interact to support learning, recall,
and imagination. Despite significant advances, we still lack a unified
computational framework that jointly accounts for core empirical phenomena
across both semantic and episodic processing domains. Here, we introduce the
Generative Episodic-Semantic Integration System (GENESIS), a computational
model that formalizes memory as the interaction between two limited-capacity
generative systems: a Cortical-VAE, supporting semantic learning and
generalization, and a Hippocampal-VAE, supporting episodic encoding and
retrieval within a retrieval-augmented generation (RAG) architecture. GENESIS
reproduces hallmark behavioral findings, including generalization in semantic
memory, recognition, serial recall effects and gist-based distortions in
episodic memory, and constructive episodic simulation, while capturing their
dynamic interactions. The model elucidates how capacity constraints shape the
fidelity and memorability of experiences, how semantic processing introduces
systematic distortions in episodic recall, and how episodic replay can
recombine previous experiences. Together, these results provide a principled
account of memory as an active, constructive, and resource-bounded process.
GENESIS thus advances a unified theoretical framework that bridges semantic and
episodic memory, offering new insights into the generative foundations of human
cognition.",http://arxiv.org/pdf/2510.15828v1,,False
Chronos-2: From Univariate to Universal Forecasting,17/10/2025,"Abdul Fatir Ansari, Oleksandr Shchur, Jaris Küken, Andreas Auer, Boran Han, Pedro Mercado, Syama Sundar Rangapuram, Huibin Shen, Lorenzo Stella, Xiyuan Zhang, Mononito Goswami, Shubham Kapoor, Danielle C. Maddix, Pablo Guerron, Tony Hu, Junming Yin, Nick Erickson, Prateek Mutalik Desai, Hao Wang, Huzefa Rangwala, George Karypis, Yuyang Wang, Michael Bohlke-Schneider","Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used ""as is"" in real-world forecasting pipelines.",http://arxiv.org/pdf/2510.15821v1,,False
AB-UPT for Automotive and Aerospace Applications,17/10/2025,"Benedikt Alkin, Richard Kurle, Louis Serrano, Dennis Just, Johannes Brandstetter","The recently proposed Anchored-Branched Universal Physics Transformers
(AB-UPT) shows strong capabilities to replicate automotive computational fluid
dynamics simulations requiring orders of magnitudes less compute than
traditional numerical solvers. In this technical report, we add two new
datasets to the body of empirically evaluated use-cases of AB-UPT, combining
high-quality data generation with state-of-the-art neural surrogates. Both
datasets were generated with the Luminary Cloud platform containing automotives
(SHIFT-SUV) and aircrafts (SHIFT-Wing). We start by detailing the data
generation. Next, we show favorable performances of AB-UPT against previous
state-of-the-art transformer-based baselines on both datasets, followed by
extensive qualitative and quantitative evaluations of our best AB-UPT model.
AB-UPT shows strong performances across the board. Notably, it obtains near
perfect prediction of integrated aerodynamic forces within seconds from a
simple isotopically tesselate geometry representation and is trainable within a
day on a single GPU, paving the way for industry-scale applications.",http://arxiv.org/pdf/2510.15808v1,,False
DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation,17/10/2025,"Xinyue Xu, Jieqiang Sun, Jing, Dai, Siyuan Chen, Lanjie Ma, Ke Sun, Bin Zhao, Jianbo Yuan, Yiwen Lu","We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.",http://arxiv.org/pdf/2510.15786v1,,False
Disentanglement of Sources in a Multi-Stream Variational Autoencoder,17/10/2025,"Veranika Boukun, Jörg Lücke","Variational autoencoders (VAEs) are a leading approach to address the problem
of learning disentangled representations. Typically a single VAE is used and
disentangled representations are sought in its continuous latent space. Here we
explore a different approach by using discrete latents to combine
VAE-representations of individual sources. The combination is done based on an
explicit model for source combination, and we here use a linear combination
model which is well suited, e.g., for acoustic data. We formally define such a
multi-stream VAE (MS-VAE) approach, derive its inference and learning
equations, and we numerically investigate its principled functionality. The
MS-VAE is domain-agnostic, and we here explore its ability to separate sources
into different streams using superimposed hand-written digits, and mixed
acoustic sources in a speaker diarization task. We observe a clear separation
of digits, and on speaker diarization we observe an especially low rate of
missed speakers. Numerical experiments further highlight the flexibility of the
approach across varying amounts of supervision and training data.",http://arxiv.org/pdf/2510.15669v1,,False
GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device,17/10/2025,"Jiahao Zhou, Chengliang Lin, Dingji Li, Mingkai Dong, Haibo Chen","Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memory usage by strategically overlapping I/O with computation via
dual-layer sliding window and chunked execution. We evaluate GRATING against
state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple
M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak
memory by up to 94.9% in microbenchmarks, without any loss in precision. Across
three real-world on-device AI applications, GRATING lowers latency by
11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial
improvements in efficiency and deployability.",http://arxiv.org/pdf/2510.15620v1,,False
Kernel-Based Evaluation of Conditional Biological Sequence Models,17/10/2025,"Pierre Glaser, Steffanie Paul, Alissa M. Hummer, Charlotte M. Deane, Debora S. Marks, Alan N. Amin","We propose a set of kernel-based tools to evaluate the designs and tune the
hyperparameters of conditional sequence models, with a focus on problems in
computational biology. The backbone of our tools is a new measure of
discrepancy between the true conditional distribution and the model's estimate,
called the Augmented Conditional Maximum Mean Discrepancy (ACMMD). Provided
that the model can be sampled from, the ACMMD can be estimated unbiasedly from
data to quantify absolute model fit, integrated within hypothesis tests, and
used to evaluate model reliability. We demonstrate the utility of our approach
by analyzing a popular protein design model, ProteinMPNN. We are able to reject
the hypothesis that ProteinMPNN fits its data for various protein families, and
tune the model's temperature hyperparameter to achieve a better fit.",http://arxiv.org/pdf/2510.15601v1,,False
Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism,17/10/2025,"Haoran Sun, Yankai Jiang, Zhenyu Tang, Yaning Pan, Shuang Gu, Zekai Lin, Lilong Wang, Wenjie Lou, Lei Liu, Lei Bai, Xiaosong Wang","The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the ""Sketch-and-Fill"" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.",http://arxiv.org/pdf/2510.15600v1,,False
TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs,17/10/2025,"Sibo Xiao, Jinyuan Fu, Zhongle Xie, Lidan Shou","Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.",http://arxiv.org/pdf/2510.15545v1,,False
OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning,17/10/2025,"Woo-Jin Ahn, Sang-Ryul Baek, Yong-Jun Lee, Hyun-Duck Choi, Myo-Taeg Lim","Reinforcement learning algorithms typically utilize an interactive simulator
(i.e., environment) with a predefined reward function for policy training.
Developing such simulators and manually defining reward functions, however, is
often time-consuming and labor-intensive. To address this, we propose an
Offline Simulator (OffSim), a novel model-based offline inverse reinforcement
learning (IRL) framework, to emulate environmental dynamics and reward
structure directly from expert-generated state-action trajectories. OffSim
jointly optimizes a high-entropy transition model and an IRL-based reward
function to enhance exploration and improve the generalizability of the learned
reward. Leveraging these learned components, OffSim can subsequently train a
policy offline without further interaction with the real environment.
Additionally, we introduce OffSim$^+$, an extension that incorporates a
marginal reward for multi-dataset settings to enhance exploration. Extensive
MuJoCo experiments demonstrate that OffSim achieves substantial performance
gains over existing offline IRL methods, confirming its efficacy and
robustness.",http://arxiv.org/pdf/2510.15495v1,,False
Online Policy Learning via a Self-Normalized Maximal Inequality,17/10/2025,"Samuel Girard, Aurélien Bibaut, Houssam Zenati","Adaptive experiments produce dependent data that break i.i.d. assumptions
that underlie classical concentration bounds and invalidate standard learning
guarantees. In this paper, we develop a self-normalized maximal inequality for
martingale empirical processes. Building on this, we first propose an adaptive
sample-variance penalization procedure which balances empirical loss and sample
variance, valid for general dependent data. Next, this allows us to derive a
new variance-regularized pessimistic off-policy learning objective, for which
we establish excess-risk guarantees. Subsequently, we show that, when combined
with sequential updates and under standard complexity and margin conditions,
the resulting estimator achieves fast convergence rates in both parametric and
nonparametric regimes, improving over the usual $1/\sqrt{n}$
  baseline. We complement our theoretical findings with numerical simulations
that illustrate the practical gains of our approach.",http://arxiv.org/pdf/2510.15483v1,,False
Adversary-Free Counterfactual Prediction via Information-Regularized Representations,17/10/2025,"Shiqin Tang, Rong Feng, Shuxin Zhuang, Hongzong Li, Youzhi Zhang","We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.",http://arxiv.org/pdf/2510.15479v1,,False
Nonlinear Dimensionality Reduction Techniques for Bayesian Optimization,17/10/2025,"Luo Long, Coralia Cartis, Paz Fink Shustin","Bayesian optimisation (BO) is a standard approach for sample-efficient global
optimisation of expensive black-box functions, yet its scalability to high
dimensions remains challenging. Here, we investigate nonlinear dimensionality
reduction techniques that reduce the problem to a sequence of low-dimensional
Latent-Space BO (LSBO). While early LSBO methods used (linear) random
projections (Wang et al., 2013), building on Grosnit et al. (2021), we employ
Variational Autoencoders (VAEs) for LSBO, focusing on deep metric loss for
structured latent manifolds and VAE retraining to adapt the encoder-decoder to
newly sampled regions. We propose some changes in their implementation,
originally designed for tasks such as molecule generation, and reformulate the
algorithm for broader optimisation purposes. We then couple LSBO with
Sequential Domain Reduction (SDR) directly in the latent space (SDR-LSBO),
yielding an algorithm that narrows the latent search domains as evidence
accumulates. Implemented in a GPU-accelerated BoTorch stack with Matern-5/2
Gaussian process surrogates, our numerical results show improved optimisation
quality across benchmark tasks and that structured latent manifolds improve BO
performance. Additionally, we compare random embeddings and VAEs as two
mechanisms for dimensionality reduction, showing that the latter outperforms
the former. To the best of our knowledge, this is the first study to combine
SDR with VAE-based LSBO, and our analysis clarifies design choices for metric
shaping and retraining that are critical for scalable latent space BO. For
reproducibility, our source code is available at
https://github.com/L-Lok/Nonlinear-Dimensionality-Reduction-Techniques-for-Bayesian-Optimization.git.",http://arxiv.org/pdf/2510.15435v1,,False
LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding,17/10/2025,"Peng Ren, Hai Yang","Generating long and stylized human motions in real time is critical for
applications that demand continuous and responsive character control. Despite
its importance, existing streaming approaches often operate directly in the raw
motion space, leading to substantial computational overhead and making it
difficult to maintain temporal stability. In contrast, latent-space
VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality
stylization, but they are generally confined to offline processing. To bridge
this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion
Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a
recent high-performing offline framework for arbitrary motion stylization and
extends it to an online setting through a latent-space streaming architecture
with a sliding-window causal design and the injection of decoded motion
features to ensure smooth motion transitions. This architecture enables
long-sequence real-time arbitrary stylization without relying on future frames
or modifying the diffusion model architecture, achieving a favorable balance
between stylization quality and responsiveness as demonstrated by experiments
on benchmark datasets. Supplementary video and examples are available at the
project page: https://pren1.github.io/lilac/",http://arxiv.org/pdf/2510.15392v1,,False
Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning,17/10/2025,"Mingyang Sun, Pengxiang Ding, Weinan Zhang, Donglin Wang","While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.",http://arxiv.org/pdf/2510.15388v1,,False
Advancing Routing-Awareness in Analog ICs Floorplanning,17/10/2025,"Davide Basso, Luca Bortolussi, Mirjana Videnovic-Misic, Husni Habal","The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.",http://arxiv.org/pdf/2510.15387v1,,False
Sequence Modeling with Spectral Mean Flows,17/10/2025,"Jinwoo Kim, Max Beier, Petar Bevanda, Nayun Kim, Seunghoon Hong","A key question in sequence modeling with neural networks is how to represent
and learn highly nonlinear and probabilistic state dynamics. Operator theory
views such dynamics as linear maps on Hilbert spaces containing mean embedding
vectors of distributions, offering an appealing but currently overlooked
perspective. We propose a new approach to sequence modeling based on an
operator-theoretic view of a hidden Markov model (HMM). Instead of
materializing stochastic recurrence, we embed the full sequence distribution as
a tensor in the product Hilbert space. A generative process is then defined as
maximum mean discrepancy (MMD) gradient flow in the space of sequences. To
overcome challenges with large tensors and slow sampling convergence, we
introduce spectral mean flows, a novel tractable algorithm integrating two core
concepts. First, we propose a new neural architecture by leveraging spectral
decomposition of linear operators to derive a scalable tensor network
decomposition of sequence mean embeddings. Second, we extend MMD gradient flows
to time-dependent Hilbert spaces and connect them to flow matching via the
continuity equation, enabling simulation-free learning and faster sampling. We
demonstrate competitive results on a range of time-series modeling datasets.
Code is available at https://github.com/jw9730/spectral-mean-flow.",http://arxiv.org/pdf/2510.15366v1,,False
TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making,17/10/2025,"Maonan Wang, Yirong Chen, Yuxin Cai, Aoyu Pang, Yuejiao Xie, Zian Ma, Chengcheng Xu, Kemou Jiang, Ding Wang, Laurent Roullet, Chung Shue Chen, Zhiyong Cui, Yuheng Kan, Michael Lepech, Man-On Pun","Air-ground collaborative intelligence is becoming a key approach for
next-generation urban intelligent transportation management, where aerial and
ground systems work together on perception, communication, and decision-making.
However, the lack of a unified multi-modal simulation environment has limited
progress in studying cross-domain perception, coordination under communication
constraints, and joint decision optimization. To address this gap, we present
TranSimHub, a unified simulation platform for air-ground collaborative
intelligence. TranSimHub offers synchronized multi-view rendering across RGB,
depth, and semantic segmentation modalities, ensuring consistent perception
between aerial and ground viewpoints. It also supports information exchange
between the two domains and includes a causal scene editor that enables
controllable scenario creation and counterfactual analysis under diverse
conditions such as different weather, emergency events, and dynamic obstacles.
We release TranSimHub as an open-source platform that supports end-to-end
research on perception, fusion, and control across realistic air and ground
traffic scenes. Our code is available at
https://github.com/Traffic-Alpha/TranSimHub.",http://arxiv.org/pdf/2510.15365v1,,False
GaussGym: An open-source real-to-sim framework for learning locomotion from pixels,17/10/2025,"Alejandro Escontrela, Justin Kerr, Arthur Allshire, Jonas Frey, Rocky Duan, Carmelo Sferrazza, Pieter Abbeel","We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.",http://arxiv.org/pdf/2510.15352v1,,False
Singularity-free dynamical invariants-based quantum control,17/10/2025,"Ritik Sareen, Akram Youssry, Alberto Peruzzo","State preparation is a cornerstone of quantum technologies, underpinning
applications in computation, communication, and sensing. Its importance becomes
even more pronounced in non-Markovian open quantum systems, where environmental
memory and model uncertainties pose significant challenges to achieving
high-fidelity control. Invariant-based inverse engineering provides a
principled framework for synthesizing analytic control fields, yet existing
parameterizations often lead to experimentally infeasible, singular pulses and
are limited to simplified noise models such as those of Lindblad form. Here, we
introduce a generalized invariant-based protocol for single-qubit state
preparation under arbitrary noise conditions. The control proceeds in
two-stages: first, we construct a family of bounded pulses that achieve perfect
state preparation in a closed system; second, we identify the optimal member of
this family that minimizes the effect of noise. The framework accommodates both
(i) characterized noise, enabling noise-aware control synthesis, and (ii)
uncharacterized noise, where a noise-agnostic variant preserves robustness
without requiring a master-equation description. Numerical simulations
demonstrate high-fidelity state preparation across diverse targets while
producing smooth, hardware-feasible control fields. This singularity-free
framework extends invariant-based control to realistic open-system regimes,
providing a versatile route toward robust quantum state engineering on NISQ
hardware and other platforms exhibiting non-Markovian dynamics.",http://arxiv.org/pdf/2510.15340v1,,False
Small Ensemble-based Data Assimilation: A Machine Learning-Enhanced Data Assimilation Method with Limited Ensemble Size,17/10/2025,"Zhilin Li, Yao Zhou, Xianglong Li, Zeng Liu, Zhaokuan Lu, Shanlin Xu, Seungnam Kim, Guangyao Wang","Ensemble-based data assimilation (DA) methods have become increasingly
popular due to their inherent ability to address nonlinear dynamic problems.
However, these methods often face a trade-off between analysis accuracy and
computational efficiency, as larger ensemble sizes required for higher accuracy
also lead to greater computational cost. In this study, we propose a novel
machine learning-based data assimilation approach that combines the traditional
ensemble Kalman filter (EnKF) with a fully connected neural network (FCNN).
Specifically, our method uses a relatively small ensemble size to generate
preliminary yet suboptimal analysis states via EnKF. A FCNN is then employed to
learn and predict correction terms for these states, thereby mitigating the
performance degradation induced by the limited ensemble size. We evaluate the
performance of our proposed EnKF-FCNN method through numerical experiments
involving Lorenz systems and nonlinear ocean wave field simulations. The
results consistently demonstrate that the new method achieves higher accuracy
than traditional EnKF with the same ensemble size, while incurring negligible
additional computational cost. Moreover, the EnKF-FCNN method is adaptable to
diverse applications through coupling with different models and the use of
alternative ensemble-based DA methods.",http://arxiv.org/pdf/2510.15284v1,,False
Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift,17/10/2025,"Emam Hossain, Muhammad Hasan Ferdous, Devon Dunmire, Aneesh Subramanian, Md Osman Gani","Causal modeling offers a principled foundation for uncovering stable,
invariant relationships in time-series data, thereby improving robustness and
generalization under distribution shifts. Yet its potential is underutilized in
spatiotemporal Earth observation, where models often depend on purely
correlational features that fail to transfer across heterogeneous domains. We
propose RIC-TSC, a regionally-informed causal time-series classification
framework that embeds lag-aware causal discovery directly into sequence
modeling, enabling both predictive accuracy and scientific interpretability.
Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave
backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA
meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify
region-specific and invariant predictors of supraglacial lake evolution in
Greenland. Causal graphs are estimated globally and per basin, with validated
predictors and their time lags supplied to lightweight classifiers. On a
balanced benchmark of 1000 manually labeled lakes from two contrasting melt
seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than
correlation-based baselines under out-of-distribution evaluation. These results
show that causal discovery is not only a means of feature selection but also a
pathway to generalizable and mechanistically grounded models of dynamic Earth
surface processes.",http://arxiv.org/pdf/2510.15265v1,,False
Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning,17/10/2025,"Lina Berrayana, Ahmed Heakl, Muhammad Abdullah Sohail, Thomas Hofmann, Salman Khan, Wei Chen","Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.",http://arxiv.org/pdf/2510.15244v1,,False
Extending Audio Context for Long-Form Understanding in Large Audio-Language Models,17/10/2025,"Yuatyong Chaichana, Pittawat Taveekitworachai, Warit Sirichotedumrong, Potsawee Manakul, Kunat Pipatanakul","Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.",http://arxiv.org/pdf/2510.15231v1,,False
Machine Learning for Early Detection of Meningitis: Stacked Ensemble Learning with EHR data,17/10/2025,"Han Ouyang, Jesse Hamilton, Saeed Amal","We utilized a cohort of 214 meningitis patients and 46,303 non-meningitis
patients from the MIMIC-III database. After extensive data preprocessing, which
included ICD-based cohort selection, one-hot encoding of coding, and a
two-stage feature selection process (for both the training set and the testing
sets), clinically relevant features such as gender and high-risk ICD codes
(including subarachnoid hemorrhage, secondary malignant neoplasm of the brain,
and generalized epilepsy) are selected. Overall, these clinically reasonable
and temporally adherent features provided excellent modeling performance. Three
models (Random Forest, LightGBM, and Deep Neural Networks (DNN) are trained as
base models for Ensemble Learning. Base model outputs are aggregated and
stacked into a meta model (Logistic Regression) that uses the base model
outputs as input values in training. Ultimately, soldier outputs (AUC of
Testing Set 1: 0.9637, AUC of Testing Set 2: 0.9472) are obtained through
ensemble learning.
  We created a challenging condition for diagnosing meningitis, simulating a
real-world ER (Emergency Room) scenario to enhance clinical use in real-world
applications. While directly deploying a diagnostic tool that clinicians can
use is challenging, this paper paves the way for a potential future AI-driven
diagnostic approach for meningitis using Ensemble Learning.",http://arxiv.org/pdf/2510.15218v1,,False
