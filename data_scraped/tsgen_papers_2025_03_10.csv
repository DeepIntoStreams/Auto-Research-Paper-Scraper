Title,Publication Date,Author(s),Abstract,Link,DOI,Relevant
Multi-Fidelity Policy Gradient Algorithms,07/03/2025,"Xinjie Liu, Cyrus Neary, Kushagra Gupta, Christian Ellis, Ufuk Topcu, David Fridovich-Keil","Many reinforcement learning (RL) algorithms require large amounts of data,
prohibiting their use in applications where frequent interactions with
operational systems are infeasible, or high-fidelity simulations are expensive
or unavailable. Meanwhile, low-fidelity simulators--such as reduced-order
models, heuristic reward functions, or generative world models--can cheaply
provide useful data for RL training, even if they are too coarse for direct
sim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL
framework that mixes a small amount of data from the target environment with a
large volume of low-fidelity simulation data to form unbiased, reduced-variance
estimators (control variates) for on-policy policy gradients. We instantiate
the framework by developing multi-fidelity variants of two policy gradient
algorithms: REINFORCE and proximal policy optimization. Experimental results
across a suite of simulated robotics benchmark problems demonstrate that when
target-environment samples are limited, MFPG achieves up to 3.9x higher reward
and improves training stability when compared to baselines that only use
high-fidelity data. Moreover, even when the baselines are given more
high-fidelity samples--up to 10x as many interactions with the target
environment--MFPG continues to match or outperform them. Finally, we observe
that MFPG is capable of training effective policies even when the low-fidelity
environment is drastically different from the target environment. MFPG thus not
only offers a novel paradigm for efficient sim-to-real transfer but also
provides a principled approach to managing the trade-off between policy
performance and data collection costs.",http://arxiv.org/pdf/2503.05696v1,,False
Algorithmic Data Minimization for Machine Learning over Internet-of-Things Data Streams,07/03/2025,"Ted Shaowang, Shinan Liu, Jonatas Marques, Nick Feamster, Sanjay Krishnan","Machine learning can analyze vast amounts of data generated by IoT devices to
identify patterns, make predictions, and enable real-time decision-making. By
processing sensor data, machine learning models can optimize processes, improve
efficiency, and enhance personalized user experiences in smart systems.
However, IoT systems are often deployed in sensitive environments such as
households and offices, where they may inadvertently expose identifiable
information, including location, habits, and personal identifiers. This raises
significant privacy concerns, necessitating the application of data
minimization -- a foundational principle in emerging data regulations, which
mandates that service providers only collect data that is directly relevant and
necessary for a specified purpose. Despite its importance, data minimization
lacks a precise technical definition in the context of sensor data, where
collections of weak signals make it challenging to apply a binary ""relevant and
necessary"" rule. This paper provides a technical interpretation of data
minimization in the context of sensor streams, explores practical methods for
implementation, and addresses the challenges involved. Through our approach, we
demonstrate that our framework can reduce user identifiability by up to 16.7%
while maintaining accuracy loss below 1%, offering a viable path toward
privacy-preserving IoT data processing.",http://arxiv.org/pdf/2503.05675v1,,False
VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control,07/03/2025,"Yuxuan Bian, Zhaoyang Zhang, Xuan Ju, Mingdeng Cao, Liangbin Xie, Ying Shan, Qiang Xu","Video inpainting, which aims to restore corrupted video content, has
experienced substantial progress. Despite these advances, existing methods,
whether propagating unmasked region pixels through optical flow and receptive
field priors, or extending image-inpainting models temporally, face challenges
in generating fully masked objects or balancing the competing objectives of
background context preservation and foreground generation in one model,
respectively. To address these limitations, we propose a novel dual-stream
paradigm VideoPainter that incorporates an efficient context encoder
(comprising only 6% of the backbone parameters) to process masked videos and
inject backbone-aware background contextual cues to any pre-trained video DiT,
producing semantically consistent content in a plug-and-play manner. This
architectural separation significantly reduces the model's learning complexity
while enabling nuanced integration of crucial background context. We also
introduce a novel target region ID resampling technique that enables any-length
video inpainting, greatly enhancing our practical applicability. Additionally,
we establish a scalable dataset pipeline leveraging current vision
understanding models, contributing VPData and VPBench to facilitate
segmentation-based inpainting training and assessment, the largest video
inpainting dataset and benchmark to date with over 390K diverse clips. Using
inpainting as a pipeline basis, we also explore downstream applications
including video editing and video editing pair data generation, demonstrating
competitive performance and significant practical potential. Extensive
experiments demonstrate VideoPainter's superior performance in both any-length
video inpainting and editing, across eight key metrics, including video
quality, mask region preservation, and textual coherence.",http://arxiv.org/pdf/2503.05639v1,,False
TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models,07/03/2025,"Mark YU, Wenbo Hu, Jinbo Xing, Ying Shan","We present TrajectoryCrafter, a novel approach to redirect camera
trajectories for monocular videos. By disentangling deterministic view
transformations from stochastic content generation, our method achieves precise
control over user-specified camera trajectories. We propose a novel dual-stream
conditional video diffusion model that concurrently integrates point cloud
renders and source videos as conditions, ensuring accurate view transformations
and coherent 4D content generation. Instead of leveraging scarce multi-view
videos, we curate a hybrid training dataset combining web-scale monocular
videos with static multi-view datasets, by our innovative double-reprojection
strategy, significantly fostering robust generalization across diverse scenes.
Extensive evaluations on multi-view and large-scale monocular videos
demonstrate the superior performance of our method.",http://arxiv.org/pdf/2503.05638v1,,False
A functional approach for curve alignment and shape analysis,07/03/2025,"Issam-Ali Moindjié, Cédric Beaulac, Marie-Hélène Descary","The shape $\tilde{\mathbf{X}}$ of a random planar curve $\mathbf{X}$ is what
remains after removing deformation effects such as scaling, rotation,
translation, and parametrization. Previous studies in statistical shape
analysis have focused on analyzing $\tilde{\bf X}$ through discrete
observations of the curve ${\bf X}$. While this approach has some computational
advantages, it overlooks the continuous nature of both ${\bf X}$ and its shape
$\tilde{\bf X}$. It also ignores potential dependencies among the deformation
variables and their effect on $\tilde{ \bf X}$, which may result in information
loss and reduced interpretability. In this paper, we introduce a novel
framework for analyzing $\bf X$ in the context of Functional Data Analysis
(FDA). Basis expansion techniques are employed to derive analytic solutions for
estimating the deformation variables such as rotation and reparametrization,
thereby achieving shape alignment. The generative model of $\bf X$ is then
investigated using a joint-principal component analysis approach. Numerical
experiments on simulated data and the \textit{MPEG-7} database demonstrate that
our new approach successfully identifies the deformation parameters and
captures the underlying distribution of planar curves in situations where
traditional FDA methods fail to do so.",http://arxiv.org/pdf/2503.05632v1,,False
Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs),07/03/2025,"Prakash Thakolkaran, Yaqi Guo, Shivam Saini, Mathias Peirlinck, Benjamin Alheit, Siddhant Kumar","Traditional constitutive models rely on hand-crafted parametric forms with
limited expressivity and generalizability, while neural network-based models
can capture complex material behavior but often lack interpretability. To
balance these trade-offs, we present Input-Convex Kolmogorov-Arnold Networks
(ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs
leverage the Kolmogorov-Arnold representation, decomposing the model into
compositions of trainable univariate spline-based activation functions for rich
expressivity. We introduce trainable input-convex splines within the KAN
architecture, ensuring physically admissible polyconvex hyperelastic models.
The resulting models are both compact and interpretable, enabling explicit
extraction of analytical constitutive relationships through an input-convex
symbolic regression techinque. Through unsupervised training on full-field
strain data and limited global force measurements, ICKANs accurately capture
nonlinear stress-strain behavior across diverse strain states. Finite element
simulations of unseen geometries with trained ICKAN hyperelastic constitutive
models confirm the framework's robustness and generalization capability.",http://arxiv.org/pdf/2503.05617v1,,False
opXRD: Open Experimental Powder X-ray Diffraction Database,07/03/2025,"Daniel Hollarek, Henrik Schopmans, Jona Östreicher, Jonas Teufel, Bin Cao, Adie Alwen, Simon Schweidler, Mriganka Singh, Tim Kodalle, Hanlin Hu, Gregoire Heymans, Maged Abdelsamie, Arthur Hardiagon, Alexander Wieczorek, Siarhei Zhuk, Ruth Schwaiger, Sebastian Siol, François-Xavier Coudert, Moritz Wolf, Carolin M. Sutter-Fella, Ben Breitung, Andrea M. Hodge, Tong-yi Zhang, Pascal Friederich","Powder X-ray diffraction (pXRD) experiments are a cornerstone for materials
structure characterization. Despite their widespread application, analyzing
pXRD diffractograms still presents a significant challenge to automation and a
bottleneck in high-throughput discovery in self-driving labs. Machine learning
promises to resolve this bottleneck by enabling automated powder diffraction
analysis. A notable difficulty in applying machine learning to this domain is
the lack of sufficiently sized experimental datasets, which has constrained
researchers to train primarily on simulated data. However, models trained on
simulated pXRD patterns showed limited generalization to experimental patterns,
particularly for low-quality experimental patterns with high noise levels and
elevated backgrounds. With the Open Experimental Powder X-Ray Diffraction
Database (opXRD), we provide an openly available and easily accessible dataset
of labeled and unlabeled experimental powder diffractograms. Labeled opXRD data
can be used to evaluate the performance of models on experimental data and
unlabeled opXRD data can help improve the performance of models on experimental
data, e.g. through transfer learning methods. We collected \numpatterns
diffractograms, 2179 of them labeled, from a wide spectrum of materials
classes. We hope this ongoing effort can guide machine learning research toward
fully automated analysis of pXRD data and thus enable future self-driving
materials labs.",http://arxiv.org/pdf/2503.05577v1,,False
Removing Geometric Bias in One-Class Anomaly Detection with Adaptive Feature Perturbation,07/03/2025,"Romain Hermary, Vincent Gaudillière, Abd El Rahman Shabayek, Djamila Aouada","One-class anomaly detection aims to detect objects that do not belong to a
predefined normal class. In practice training data lack those anomalous
samples; hence state-of-the-art methods are trained to discriminate between
normal and synthetically-generated pseudo-anomalous data. Most methods use data
augmentation techniques on normal images to simulate anomalies. However the
best-performing ones implicitly leverage a geometric bias present in the
benchmarking datasets. This limits their usability in more general conditions.
Others are relying on basic noising schemes that may be suboptimal in capturing
the underlying structure of normal data. In addition most still favour the
image domain to generate pseudo-anomalies training models end-to-end from only
the normal class and overlooking richer representations of the information. To
overcome these limitations we consider frozen yet rich feature spaces given by
pretrained models and create pseudo-anomalous features with a novel adaptive
linear feature perturbation technique. It adapts the noise distribution to each
sample applies decaying linear perturbations to feature vectors and further
guides the classification process using a contrastive learning objective.
Experimental evaluation conducted on both standard and geometric bias-free
datasets demonstrates the superiority of our approach with respect to
comparable baselines. The codebase is accessible via our public repository.",http://arxiv.org/pdf/2503.05520v1,,False
EuroBERT: Scaling Multilingual Encoders for European Languages,07/03/2025,"Nicolas Boizard, Hippolyte Gisserot-Boukhlef, Duarte M. Alves, André Martins, Ayoub Hammal, Caio Corro, Céline Hudelot, Emmanuel Malherbe, Etienne Malaboeuf, Fanny Jourdan, Gabriel Hautreux, João Alves, Kevin El-Haddad, Manuel Faysse, Maxime Peyrard, Nuno M. Guerreiro, Patrick Fernandes, Ricardo Rei, Pierre Colombo","General-purpose multilingual vector representations, used in retrieval,
regression and classification, are traditionally obtained from bidirectional
encoder models. Despite their wide applicability, encoders have been recently
overshadowed by advances in generative decoder-only models. However, many
innovations driving this progress are not inherently tied to decoders. In this
paper, we revisit the development of multilingual encoders through the lens of
these advances, and introduce EuroBERT, a family of multilingual encoders
covering European and widely spoken global languages. Our models outperform
existing alternatives across a diverse range of tasks, spanning multilingual
capabilities, mathematics, and coding, and natively supporting sequences of up
to 8,192 tokens. We also examine the design decisions behind EuroBERT, offering
insights into our dataset composition and training pipeline. We publicly
release the EuroBERT models, including intermediate training checkpoints,
together with our training framework.",http://arxiv.org/pdf/2503.05500v1,,False
Soft Policy Optimization: Online Off-Policy RL for Sequence Models,07/03/2025,"Taco Cohen, David W. Zhang, Kunhao Zheng, Yunhao Tang, Remi Munos, Gabriel Synnaeve","RL-based post-training of language models is almost exclusively done using
on-policy methods such as PPO. These methods cannot learn from arbitrary
sequences such as those produced earlier in training, in earlier runs, by human
experts or other policies, or by decoding and exploration methods. This results
in severe sample inefficiency and exploration difficulties, as well as a
potential loss of diversity in the policy responses. Moreover, asynchronous PPO
implementations require frequent and costly model transfers, and typically use
value models which require a large amount of memory. In this paper we introduce
Soft Policy Optimization (SPO), a simple, scalable and principled Soft RL
method for sequence model policies that can learn from arbitrary online and
offline trajectories and does not require a separate value model. In
experiments on code contests, we shows that SPO outperforms PPO on pass@10, is
significantly faster and more memory efficient, is able to benefit from
off-policy data, enjoys improved stability, and learns more diverse (i.e. soft)
policies.",http://arxiv.org/pdf/2503.05453v1,,False
Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts,07/03/2025,"Weigao Sun, Disen Lan, Tong Zhu, Xiaoye Qu, Yu Cheng","Linear Sequence Modeling (LSM) like linear attention, state space models and
linear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant
architectural improvements. In this paper, we introduce Linear-MoE, a
production-level system for modeling and training large-scale models that
integrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules
for linear-complexity sequence modeling and MoE layers for sparsely activation,
aiming to offer high performance with efficient training. The Linear-MoE system
comprises: 1) Modeling subsystem, which provides a unified framework supporting
all instances of LSM. and 2) Training subsystem, which facilitates efficient
training by incorporating various advanced parallelism technologies,
particularly Sequence Parallelism designed for Linear-MoE models. Additionally,
we explore hybrid models that combine Linear-MoE layers with standard
Transformer-MoE layers with its Sequence Parallelism to further enhance model
flexibility and performance. Evaluations on two model series, A0.3B-2B and
A1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining
competitive performance on various benchmarks, showcasing its potential as a
next-generation foundational model architecture. Code:
https://github.com/OpenSparseLLMs/Linear-MoE.",http://arxiv.org/pdf/2503.05447v1,,False
Physics-based machine learning for fatigue lifetime prediction under non-uniform loading scenarios,07/03/2025,"Abedulgader Baktheer, Fadi Aldakheel","Accurate lifetime prediction of structures subjected to cyclic loading is
vital, especially in scenarios involving non-uniform loading histories where
load sequencing critically influences structural durability. Addressing this
complexity requires advanced modeling approaches capable of capturing the
intricate relationship between loading sequences and fatigue lifetime.
Traditional fatigue simulations are computationally prohibitive, necessitating
more efficient methods. This study highlights the potential of physics-based
machine learning ($\phi$ML) to predict the fatigue lifetime of materials.
Specifically, a FFNN is designed to embed physical constraints from
experimental evidence directly into its architecture to enhance prediction
accuracy. It is trained using numerical simulations generated by a physically
based anisotropic continuum damage fatigue model. The model is calibrated and
validated against experimental fatigue data of concrete cylinder specimens
tested in uniaxial compression. The proposed approach demonstrates superior
accuracy compared to purely data-driven neural networks, particularly in
situations with limited training data, achieving realistic predictions of
damage accumulation. Thus, a general algorithm is developed and successfully
applied to predict fatigue lifetimes under complex loading scenarios with
multiple loading ranges. Hereby, the $\phi$ML model serves as a surrogate to
capture damage evolution across load transitions. The $\phi$ML based algorithm
is subsequently employed to investigate the influence of multiple loading
transitions on accumulated fatigue life, and its predictions align with trends
observed in recent experimental studies. This work demonstrates $\phi$ML as a
promising technique for efficient and reliable fatigue life prediction in
engineering structures, with possible integration into digital twin models for
real-time assessment.",http://arxiv.org/pdf/2503.05419v1,,False
VLMs Play StarCraft II: A Benchmark and Multimodal Decision Method,07/03/2025,"Weiyu Ma, Yuqian Fu, Zecheng Zhang, Guohao Li","We introduce VLM-Attention, a multimodal StarCraft II environment that aligns
artificial agent perception with the human gameplay experience. Traditional
frameworks such as SMAC rely on abstract state representations that diverge
significantly from human perception, limiting the ecological validity of agent
behavior. Our environment addresses this limitation by incorporating RGB visual
inputs and natural language observations that more closely simulate human
cognitive processes during gameplay. The VLM-Attention framework consists of
three integrated components: (1) a vision-language model enhanced with
specialized self-attention mechanisms for strategic unit targeting and
battlefield assessment, (2) a retrieval-augmented generation system that
leverages domain-specific StarCraft II knowledge to inform tactical decisions,
and (3) a dynamic role-based task distribution system that enables coordinated
multi-agent behavior. Our experimental evaluation across 21 custom scenarios
demonstrates that VLM-based agents powered by foundation models (specifically
Qwen-VL and GPT-4o) can execute complex tactical maneuvers without explicit
training, achieving comparable performance to traditional MARL methods that
require substantial training iterations. This work establishes a foundation for
developing human-aligned StarCraft II agents and advances the broader research
agenda of multimodal game AI. Our implementation is available at
https://github.com/camel-ai/VLM-Play-StarCraft2.",http://arxiv.org/pdf/2503.05383v1,,False
Semi-Supervised Learning for Dose Prediction in Targeted Radionuclide: A Synthetic Data Study,07/03/2025,"Jing Zhang, Alexandre Bousse, Laetitia Imbert, Song Xue, Kuangyu Shi, Julien Bert","Targeted Radionuclide Therapy (TRT) is a modern strategy in radiation
oncology that aims to administer a potent radiation dose specifically to cancer
cells using cancer-targeting radiopharmaceuticals. Accurate radiation dose
estimation tailored to individual patients is crucial. Deep learning,
particularly with pre-therapy imaging, holds promise for personalizing TRT
doses. However, current methods require large time series of SPECT imaging,
which is hardly achievable in routine clinical practice, and thus raises issues
of data availability. Our objective is to develop a semi-supervised learning
(SSL) solution to personalize dosimetry using pre-therapy images. The aim is to
develop an approach that achieves accurate results when PET/CT images are
available, but are associated with only a few post-therapy dosimetry data
provided by SPECT images. In this work, we introduce an SSL method using a
pseudo-label generation approach for regression tasks inspired by the FixMatch
framework. The feasibility of the proposed solution was preliminarily evaluated
through an in-silico study using synthetic data and Monte Carlo simulation.
Experimental results for organ dose prediction yielded promising outcomes,
showing that the use of pseudo-labeled data provides better accuracy compared
to using only labeled data.",http://arxiv.org/pdf/2503.05367v1,,False
Speculative Decoding for Multi-Sample Inference,07/03/2025,"Yiwei Li, Jiayi Shi, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Yueqi Zhang, Ji Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li","We propose a novel speculative decoding method tailored for multi-sample
reasoning scenarios, such as self-consistency and Best-of-N sampling. Our
method exploits the intrinsic consensus of parallel generation paths to
synthesize high-quality draft tokens without requiring auxiliary models or
external databases. By dynamically analyzing structural patterns across
parallel reasoning paths through a probabilistic aggregation mechanism, it
identifies consensus token sequences that align with the decoding distribution.
Evaluations on mathematical reasoning benchmarks demonstrate a substantial
improvement in draft acceptance rates over baselines, while reducing the
latency in draft token construction. This work establishes a paradigm shift for
efficient multi-sample inference, enabling seamless integration of speculative
decoding with sampling-based reasoning techniques.",http://arxiv.org/pdf/2503.05330v1,,False
A Map-free Deep Learning-based Framework for Gate-to-Gate Monocular Visual Navigation aboard Miniaturized Aerial Vehicles,07/03/2025,"Lorenzo Scarciglia, Antonio Paolillo, Daniele Palossi","Palm-sized autonomous nano-drones, i.e., sub-50g in weight, recently entered
the drone racing scenario, where they are tasked to avoid obstacles and
navigate as fast as possible through gates. However, in contrast with their
bigger counterparts, i.e., kg-scale drones, nano-drones expose three orders of
magnitude less onboard memory and compute power, demanding more efficient and
lightweight vision-based pipelines to win the race. This work presents a
map-free vision-based (using only a monocular camera) autonomous nano-drone
that combines a real-time deep learning gate detection front-end with a classic
yet elegant and effective visual servoing control back-end, only relying on
onboard resources. Starting from two state-of-the-art tiny deep learning
models, we adapt them for our specific task, and after a mixed
simulator-real-world training, we integrate and deploy them aboard our
nano-drone. Our best-performing pipeline costs of only 24M multiply-accumulate
operations per frame, resulting in a closed-loop control performance of 30 Hz,
while achieving a gate detection root mean square error of 1.4 pixels, on our
~20k real-world image dataset. In-field experiments highlight the capability of
our nano-drone to successfully navigate through 15 gates in 4 min, never
crashing and covering a total travel distance of ~100m, with a peak flight
speed of 1.9 m/s. Finally, to stress the generalization capability of our
system, we also test it in a never-seen-before environment, where it navigates
through gates for more than 4 min.",http://arxiv.org/pdf/2503.05251v1,,False
Discrete Contrastive Learning for Diffusion Policies in Autonomous Driving,07/03/2025,"Kalle Kujanpää, Daulet Baimukashev, Farzeen Munir, Shoaib Azam, Tomasz Piotr Kucner, Joni Pajarinen, Ville Kyrki","Learning to perform accurate and rich simulations of human driving behaviors
from data for autonomous vehicle testing remains challenging due to human
driving styles' high diversity and variance. We address this challenge by
proposing a novel approach that leverages contrastive learning to extract a
dictionary of driving styles from pre-existing human driving data. We
discretize these styles with quantization, and the styles are used to learn a
conditional diffusion policy for simulating human drivers. Our empirical
evaluation confirms that the behaviors generated by our approach are both safer
and more human-like than those of the machine-learning-based baseline methods.
We believe this has the potential to enable higher realism and more effective
techniques for evaluating and improving the performance of autonomous vehicles.",http://arxiv.org/pdf/2503.05229v1,,False
Deep Sequence Models for Predicting Average Shear Wave Velocity from Strong Motion Records,07/03/2025,"Baris Yilmaz, Erdem Akagündüz, Salih Tileylioglu","This study explores the use of deep learning for predicting the time averaged
shear wave velocity in the top 30 m of the subsurface ($V_{s30}$) at strong
motion recording stations in T\""urkiye. $V_{s30}$ is a key parameter in site
characterization and, as a result for seismic hazard assessment. However, it is
often unavailable due to the lack of direct measurements and is therefore
estimated using empirical correlations. Such correlations however are commonly
inadequate in capturing complex, site-specific variability and this motivates
the need for data-driven approaches. In this study, we employ a hybrid deep
learning model combining convolutional neural networks (CNNs) and long
short-term memory (LSTM) networks to capture both spatial and temporal
dependencies in strong motion records. Furthermore, we explore how using
different parts of the signal influence our deep learning model. Our results
suggest that the hybrid approach effectively learns complex, nonlinear
relationships within seismic signals. We observed that an improved P-wave
arrival time model increased the prediction accuracy of $V_{s30}$. We believe
the study provides valuable insights into improving $V_{s30}$ predictions using
a CNN-LSTM framework, demonstrating its potential for improving site
characterization for seismic studies. Our codes are available via this repo:
https://github.com/brsylmz23/CNNLSTM_DeepEQ",http://arxiv.org/pdf/2503.05224v1,,False
FinTMMBench: Benchmarking Temporal-Aware Multi-Modal RAG in Finance,07/03/2025,"Fengbin Zhu, Junfeng Li, Liangming Pan, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, Tat-Seng Chua","Finance decision-making often relies on in-depth data analysis across various
data sources, including financial tables, news articles, stock prices, etc. In
this work, we introduce FinTMMBench, the first comprehensive benchmark for
evaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG)
systems in finance. Built from heterologous data of NASDAQ 100 companies,
FinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It
encompasses a hybrid of financial tables, news articles, daily stock prices,
and visual technical charts as the corpus. 2) Temporal-aware Questions: Each
question requires the retrieval and interpretation of its relevant data over a
specific time period, including daily, weekly, monthly, quarterly, and annual
periods. 3) Diverse Financial Analysis Tasks: The questions involve 10
different tasks, including information extraction, trend analysis, sentiment
analysis and event detection, etc. We further propose a novel TMMHybridRAG
method, which first leverages LLMs to convert data from other modalities (e.g.,
tabular, visual and time-series data) into textual format and then incorporates
temporal information in each node when constructing graphs and dense indexes.
Its effectiveness has been validated in extensive experiments, but notable gaps
remain, highlighting the challenges presented by our FinTMMBench.",http://arxiv.org/pdf/2503.05185v1,,False
Look Before You Leap: Using Serialized State Machine for Language Conditioned Robotic Manipulation,07/03/2025,"Tong Mu, Yihao Liu, Mehran Armand","Imitation learning frameworks for robotic manipulation have drawn attention
in the recent development of language model grounded robotics. However, the
success of the frameworks largely depends on the coverage of the demonstration
cases: When the demonstration set does not include examples of how to act in
all possible situations, the action may fail and can result in cascading
errors. To solve this problem, we propose a framework that uses serialized
Finite State Machine (FSM) to generate demonstrations and improve the success
rate in manipulation tasks requiring a long sequence of precise interactions.
To validate its effectiveness, we use environmentally evolving and long-horizon
puzzles that require long sequential actions. Experimental results show that
our approach achieves a success rate of up to 98 in these tasks, compared to
the controlled condition using existing approaches, which only had a success
rate of up to 60, and, in some tasks, almost failed completely.",http://arxiv.org/pdf/2503.05114v1,,False
TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting,07/03/2025,"Shibo Feng, Wanjin Feng, Xingyu Gao, Peilin Zhao, Zhiqi Shen","Spiking Neural Networks (SNNs) offer a promising, biologically inspired
approach for processing spatiotemporal data, particularly for time series
forecasting. However, conventional neuron models like the Leaky
Integrate-and-Fire (LIF) struggle to capture long-term dependencies and
effectively process multi-scale temporal dynamics. To overcome these
limitations, we introduce the Temporal Segment Leaky Integrate-and-Fire
(TS-LIF) model, featuring a novel dual-compartment architecture. The dendritic
and somatic compartments specialize in capturing distinct frequency components,
providing functional heterogeneity that enhances the neuron's ability to
process both low- and high-frequency information. Furthermore, the newly
introduced direct somatic current injection reduces information loss during
intra-neuronal transmission, while dendritic spike generation improves
multi-scale information extraction. We provide a theoretical stability analysis
of the TS-LIF model and explain how each compartment contributes to distinct
frequency response characteristics. Experimental results show that TS-LIF
outperforms traditional SNNs in time series forecasting, demonstrating better
accuracy and robustness, even with missing data. TS-LIF advances the
application of SNNs in time-series forecasting, providing a biologically
inspired approach that captures complex temporal dynamics and offers potential
for practical implementation in diverse forecasting scenarios. The source code
is available at https://github.com/kkking-kk/TS-LIF.",http://arxiv.org/pdf/2503.05108v1,,False
"Perceiving, Reasoning, Adapting: A Dual-Layer Framework for VLM-Guided Precision Robotic Manipulation",07/03/2025,"Qingxuan Jia, Guoqin Tang, Zeyuan Huang, Zixuan Hao, Ning Ji, Shihang, Yin, Gang Chen","Vision-Language Models (VLMs) demonstrate remarkable potential in robotic
manipulation, yet challenges persist in executing complex fine manipulation
tasks with high speed and precision. While excelling at high-level planning,
existing VLM methods struggle to guide robots through precise sequences of fine
motor actions. To address this limitation, we introduce a progressive VLM
planning algorithm that empowers robots to perform fast, precise, and
error-correctable fine manipulation. Our method decomposes complex tasks into
sub-actions and maintains three key data structures: task memory structure, 2D
topology graphs, and 3D spatial networks, achieving high-precision
spatial-semantic fusion. These three components collectively accumulate and
store critical information throughout task execution, providing rich context
for our task-oriented VLM interaction mechanism. This enables VLMs to
dynamically adjust guidance based on real-time feedback, generating precise
action plans and facilitating step-wise error correction. Experimental
validation on complex assembly tasks demonstrates that our algorithm
effectively guides robots to rapidly and precisely accomplish fine manipulation
in challenging scenarios, significantly advancing robot intelligence for
precision tasks.",http://arxiv.org/pdf/2503.05064v1,,False
